Exploiting Social Tagging Profiles to Personalize Web 

Search 

David Vallet, Iván Cantador, Joemon M. Jose 

 

University of Glasgow, Glasgow, UK 
{dvallet, cantador, jj}@dcs.gla.ac.uk 

Abstract. In this paper, we investigate the exploitation of user profiles defined 
in social tagging services to personalize Web search. One of the key challenges 
of  a  personalization  framework  is  the  elicitation  of  user  profiles  able  to 
represent user interests. We propose a personalization approach that exploits the 
tagging  information  of  users  within  a  social  tagging  service  as  a  way  of 
obtaining their interests. We evaluate this approach in Delicious, a social Web 
bookmarking service, and apply our personalization approach to a Web search 
system.  Our  evaluation  results  indicate  a  clear  improvement  of  our  approach 
over related state of the art personalization approaches. 

1 

Introduction 

Nowadays, the size and pace of growth of information available to users constitute 
a  difficult  challenge  for  content  retrieval  technologies.  The  rapid  propagation  of  the 
World  Wide  Web  (WWW)  has  allowed  users  worldwide  to  have  access  to  an 
unprecedented amount of information. Furthermore, in the WWW environment, there 
is a lack of strong global organization, with decentralized content provision, dynamic 
networks, etc., where query-based and browsing technologies often find their limits. 
Traditionally, users of Web search systems have described their information needs by 
providing  a  small  set  of  keywords,  with  which  the  systems  attempt  to  select  the 
documents  that  best  match  these  keywords.  The  majority  of  these  queries  are  short 
(containing no more than 3 keywords on 85% of the times) and ambiguous [7], and 
often  fail  to  represent  the  user’s  information  need.  Although  the  information 
contained in these keywords rarely suffices for the exact determination of user wishes, 
this is a simple way of interaction users are accustomed to; therefore, there is a need 
to  investigate  ways  to  enhance  information  retrieval,  without  altering  the  way  they 
specify their requests. Consequently, information about user needs has to be found in 
other sources. It is in this scenario where personalized information retrieval can help 
the user to satisfy their information needs, using a range of personalization techniques 
that attempt to consider both the user’s long and short term interests [4]. 

With  the  advent  of  the  Web  2.0,  social  services  have  been  exponentially 
increasing, in both terms of users and content. Some of these services allow users to 

2 

David Vallet, Iván Cantador, Joemon M. Jose 

provide  annotations  of  resources.  For  instance,  in  Last.fm1,  users  annotate  their 
favourite  songs;  in  Flickr2,  users  store  and  tag  their  own  photo  streams;  and  in 
Delicious3, users bookmark and tag interesting Web pages. Apart from facilitating the 
organization  and  sharing  of  content,  these  ‘social  tagging’  actions  can  be  a  fairly 
accurate source user interests. Several studies have proven that a user profile can be 
effectively  harvested  from  these  tagging  services  [1,10],  and  later  exploited  on 
different  personalization  services,  such  as 
item 
recommendation [9], and personalized search [6,9,12], to name a few. 

recommendation 

[3], 

tag 

In this work, we present a new personalized retrieval approach that makes use of a 
user  profile  defined  within  a  social  tagging  service.  The  main  research  question 
investigated  herein  is  whether  Web  search  systems,  such  as  Google  or  Yahoo!,  can 
benefit  from  social  tagging  services.  In  particular,  we  investigate  if  a  user  profile 
defined  in  Delicious  can  be  exploited  to  personalize  a  Web  search  system. 
Additionally,  in  order  to  evaluate  our  personalization  approach,  we  propose  an 
automatic technique to generate evaluation sets from social tagging corpora.  

The  rest  of  this  paper  is  structured  as  follows.  In  Section  2,  we  define  the  Web 
search  personalization  model  based  on  a  social  tagging  profile,  providing  a  brief 
comparison  with  the  state  of  the  art.  In  Section  3,  we  introduce  our  personalization 
approach.  Section  4  describes  our  evaluation  framework,  and  the  followed 
experimental methodology. The results of our evaluation are presented in Section 5. 
Finally, Section 6 presents conclusions, together with possible future work. 

2 

Problem Definition 

We  first  define  a  user  and  document  profile  model  based  on  the  underlying 

. 

T
 

U
, 

D
, 

A
(cid:5)
, 

 and D

= (cid:2)(cid:6)(cid:7), … , (cid:6)(cid:9)(cid:5)

= (cid:2)(cid:12)(cid:7), … , (cid:12)(cid:13)(cid:5)

= (cid:2)(cid:10)(cid:7), … , (cid:10)(cid:11)(cid:5)

folksonomy  of  a  social  tagging  service.  A  folksonomy  F  is  defined  as  a  tuple  F
=
 is the set of tags that comprise the vocabulary expressed 
T
(cid:2)
by the folksonomy. U
 are respectively the set of 
users  and  the  set  of  documents  that  annotate  and  are  annotated  with  the  tags  of  T. 
Finally, A
 to a 
document 

(cid:6)(cid:16)
(cid:10)(cid:15)(cid:21)(cid:21)(cid:21)(cid:21)(cid:21)(cid:22) =
  is  the  number  of  times  the 
(cid:23)(cid:10)(cid:15),(cid:7), … , (cid:10)(cid:15),(cid:9)(cid:24)
  is  defined  as  a  vector 
user  has  annotated  resources  with  tag 
  is  the  number  of  times 
(cid:12)(cid:17)(cid:21)(cid:21)(cid:21)(cid:21)(cid:22) = (cid:23)(cid:12)(cid:17),(cid:7), … , (cid:12)(cid:17),(cid:9)(cid:24)
. In our Web search scenario, the set of 
the document has been annotated with tag 
documents  D  represents  the  resources  present  in  the  Web,  and  are  identified  by  an 
URL. Users are identified by a user id. 

D is the set of assignments of each tag 
  is  defined  as  a  vector 

(cid:12)(cid:17)
(cid:12)(cid:17),(cid:16) = |(cid:2)(cid:14)(cid:10), (cid:6)(cid:16), (cid:12)(cid:17) (cid:18) ∈ A|(cid:10) ∈ U(cid:5)|

U
.  The  profile  of 

= (cid:2)(cid:14)(cid:10)(cid:15), (cid:6)(cid:16), (cid:12)(cid:17)(cid:18)(cid:5) ∈
(cid:12)(cid:17)

(cid:10)(cid:15),(cid:16) = (cid:25)(cid:26)(cid:23)(cid:10)(cid:15),, (cid:6)(cid:16), (cid:12) (cid:24) ∈ A|(cid:12) ∈ D(cid:30)(cid:25)

.  The  profile  of 

  by  a  user 

  where 

  where 

(cid:10)(cid:15)

(cid:10)(cid:15)

×

×

(cid:6)(cid:16)

(cid:6)(cid:16)

T

We  exploit  the  user  and  document  profiles  in  order  to  personalize  a  Web  search 
system. Let D be the set of documents present on the Web, a non-personalized Web 
search system S provides a rank list of documents S
 that satisfy a given query 

(cid:14) (cid:18) ⊆ D

                                                           
1 http://www.last.fm 
2 http://www.flickr.com 
3 http://www.delicious.com 

Exploiting Social Tagging Profiles to Personalize Web Search  

3 

τ = [(cid:12)(cid:7) ≥ (cid:12)% ≥ ⋯ ≥ (cid:12)']

, 
. The rank list will follow an ordering 
topic 
 
and 
 is the ordering relation used by the search system. Similarly, we can define a 
≥
personalization approach as a search system which provides a rank list of documents 
S
.  The  personalization  approach 
(cid:10)
. The ordering relation is defined 
provides a final ordering
 τ′ = [(cid:12)(cid:7) ≥ (cid:12)% ≥ ⋯ ≥ (cid:12)']
by 
  is  a  similarity  function 
.  Typical  personalization  techniques  implement  this 
between  user 
user-document similarity function.  

  that  satisfy  the  preferences  of  user 

(cid:12)) ≥ (cid:12)+ ⟺ sim(cid:14)(cid:10), (cid:12))(cid:18) ≥ sim(cid:23)(cid:10), (cid:12)+(cid:24)

  and  document 

sim(cid:14)(cid:10), (cid:12)(cid:18)

(cid:14)(cid:10)(cid:18) ⊆ D

,  where 

 where 

(cid:12)) ∈ D

(cid:12)

(cid:10)

2.1  Related Work 

In  this  paper,  we  investigate  whether  a  user  profile  defined  in  a  social  tagging 
service, such as Delicious, can be successfully exploited for personalized Web search. 
There  have  been  previous  studies  which  have  investigated  the  use  of  the  Delicious 
corpus in order to improve the retrieval process. For instance, Hotho et al. developed 
the  FolkRank  algorithm  [4],  an  adaptation  of  the  PageRank  algorithm  to  the 
folksonomy  structure.  Among  other  applications,  FolkRank  proved  to  be  a  better 
popularity  measure  of  a  document  than  PageRank,  as  it  exploits  the  user  generated 
folksonomy,  rather  than  the  Web  links.  Bao  et  al.  also  investigated  the  use  of  a 
popularity measure derived from the folksonomy structure, but focused its application 
in  a  Web  search  system  [2].  They  introduced  two  importance  score  values, 
SocialSimRank and SocialPageRank, which calculate the relevance of a document to 
a  query,  and  the  popularity  of  a  document,  respectively.  They  concluded  that  these 
measures  provide  a  better  performance  than  traditional  measures,  such  as  term 
matching  and  PageRank.  Similar  to  the  studies  of  Hotho  et  al.  and  Bao  et  al.,  we 
exploit  the  folksonomy  structure  available  on  Delicious,  but  focus  on  offering  a 
personalized search to the user, rather than improving the overall rank of documents. 
As Bao et al., we apply our approach to the Web search domain. 

A personalized retrieval model that exploits user profiles defined in a folksonomy 
has  been  investigated  in  previous  approaches  [9,6,12].  Shepitsen  et  al.  applied  a 
hierarchical  clustering  algorithm  to  the  tags  associated  to  a  user  profile,  defined  in 
Delicious  [9].  They  used  the  generated  tag  clusters  to  provide  personalized  item 
recommendations.  Rather than item recommendation, the  approach presented in this 
paper follows a personalized retrieval model applicable to Web search, where a list of 
result are re-ranked according to the user preferences. This model is also followed by 
Xu et al. by presenting a user-document  similarity function that relates the user and 
document  tags  [12].  Additionally,  they  presented  a  tag  expansion  approach,  applied 
over  a  restricted  corpus,  which  enriches  the  user  profile  representation.  Noll  and 
Meinel [6] also presented a personalized Web search model that exploits the user and 
document  related  tags,  which  improved  a  Web  search  system  during  their  user 
evaluation. Our personalization approach follows the same  personalization  model as 
Xu et al.’s, and Null and Meinel’s, but utilizes a different personalization technique to 
calculate  the  user-document  similarity.  Therefore,  we  compare  and  evaluate  our 
proposed approach against the approaches presented by these authors.  

David Vallet, Iván Cantador, Joemon M. Jose 

4 

3 

Personalization Approaches Based on the Vector Spatial 
Model 

This  section  presents  the  personalization  approaches  evaluated  in  our  study.  For 
convenience, Table 1 presents a number of definitions, which are standard weighting 
schemes used in the IR area and will be used by the presented personalization scores.   

Table 1. Standard IR weighting schemes adapted to the folksonomy model 

Description 

Definition 

User tag frequency 

Document tag frequency 

User-based tag inverse 
document frequency 

(cid:6)012(cid:14)(cid:6)(cid:16)(cid:18) = (cid:10)(cid:15),(cid:16)

(cid:6)034(cid:14)(cid:6)(cid:16)(cid:18) = (cid:12)(cid:17),(cid:16)

 

 

5(cid:12)01(cid:14)(cid:6)(cid:16)(cid:18) = log

, :1(cid:14)(cid:6)(cid:16)(cid:18) = (cid:25)(cid:26)(cid:10)(cid:15) ∈ U|(cid:10)(cid:15),(cid:16) > 0(cid:30)(cid:25)

 

Document-based tag inverse 
document frequency 

5(cid:12)03(cid:14)(cid:6)(cid:16)(cid:18) = log

 
, :3(cid:14)(cid:6)(cid:16)(cid:18) = (cid:25)(cid:26)(cid:12)(cid:17) ∈ D|(cid:12)(cid:17),(cid:16) > 0(cid:30)(cid:25)

:1(cid:14)(cid:6)(cid:16)(cid:18)

M

D

:3(cid:14)(cid:6)(cid:16)(cid:18)

We adopt the well known information retrieval Vector Space Model (VMS). The 
VSM  represents  user  queries  and  documents  as  vectors  in  a  finite  space  in  order  to 
calculate a similarity value between them. In Table 1, we define the tag frequency and 
inverse document frequency. These are an adaptation of the classic 
 weighting 
scheme,  where  the  frequency  of  a  term  in  the  document  (
),  and  the  inverse 
document frequency (
) value of the term in the collection are considered. The term 
frequency follows the hypothesis that the more frequent a term is in a document, the 
more  important  this  term  is  in  describing  the  document.  The  inverse  document 
frequency  is  a  measure  of  the  general  importance  of  a  term,  meaning  how  common 
the  term  is  in  the  collection  of  documents.  In  our  model,  we  use  the  tag  frequency 
instead of the term frequency.  

(cid:6)0-5(cid:12)0

5(cid:12)0

(cid:6)0

(cid:6)0

5(cid:12)0

Whereas the user and document 

 define how important is the tag to the user and 
the  document,  respectively,  we  can  disregard  the  document  and  user  collections  in 
order to calculate the global importance measure (such as 
). On the one hand, the 
user 
 measure considers the importance of a tag by how common is the tag across 
users. On the other hand, the document 
 measure considers the importance of a tag 
by  how  common  is  the  tag  across  documents.  Note  that  in  the  classic  VSM,  the 
document collection is the only source of the term’s frequency and inverse document 
frequency.  Analyzing  our  results,  we  will  be  able  to  conclude  which  of  these 
measures  is  better  to  use  on  a  personalization  approach  based  on  folksonomy  user 
profiles. The approaches presented previously by Xu et al. [12] and Noll and Meinel 
[6] also follow the VSM. We present and evaluate their similarity functions, together 
with our own personalization technique. 

5(cid:12)0

5(cid:12)0

Exploiting Social Tagging Profiles to Personalize Web Search  

5 

3.1  Cosine Similarity Approach 

The  approach  presented  by  Xu  et  al.  use  the  classic  cosine  similarity  measure  to 
compute  the  similarity  between  user  and  document  profiles.  As  weighting  scheme, 
 (cid:6)0-5(cid:12)04  value.  Following  our  model,  their  approach  can  be  defined  as 
they  use  the
follows: 

cos@A-)3A(cid:14)(cid:10)(cid:15), (cid:12)(cid:17)(cid:18) =

∑ C(cid:6)0(cid:10)D(cid:14)(cid:6)E(cid:18) ∙ 5(cid:12)0(cid:10)D(cid:14)(cid:6)E(cid:18) ∙ (cid:6)0(cid:12):(cid:14)(cid:6)E(cid:18) ∙ 5(cid:12)0(cid:12):(cid:14)(cid:6)E(cid:18)G

H

 

 ,

I∑ (cid:14)(cid:6)0(cid:10)D(cid:14)(cid:6)E(cid:18) ∙ 5(cid:12)0(cid:10)D(cid:14)(cid:6)E(cid:18)(cid:18)%

H

∙ I∑ (cid:14)(cid:6)0(cid:12):(cid:14)(cid:6)E(cid:18) ∙ 5(cid:12)0(cid:12):(cid:14)(cid:6)E(cid:18)(cid:18)%

H

  vectors  associated  to  the  user 
where  the  numerator  is  the  dot  product  of  the 
and the document, and the denominator is the user and document length normalization 
factors, calculated as the magnitude value of those vectors. Xu et al. compute a cosine 
similarity measure with a different weighting scheme, inspired by the BM25 retrieval 
model. We henceforth denote this measure as 
. More information on 
this measure can be found in the authors’ paper [12]. 

cosJK%L(cid:14)(cid:12)(cid:17), (cid:10)(cid:15)(cid:18)

(cid:6)0-5(cid:12)0

3.2 

Scalar Tag Frequency Approach 

The  approach  presented  by  Noll  and  Meinel  differs  from  the  previous  in  that  it 
performs  a  scalar  product  eliminating  the  user  and  document  length  normalization 
factors  [6].  Also,  they  do  not  make  use  of  global  tag  importance  measures,  such  as 
.  They  normalize  all  document  tag  frequencies  to  1,  since  they  state  that  the 
5(cid:12)0
intention  of  this  normalization  is  to  give  more  importance  to  the  user  profile  when 
computing the similarity measures, by only taking into consideration the matched tags 
between  the  user  profile  and  the  document  associated  tags.  Following  the  notation 
given in Table 1, their similarity approach can be defined as follows: 

(cid:6)0(cid:14)(cid:10)(cid:15), (cid:12)(cid:17)(cid:18) = ∑

H:34,NOP

(cid:6)012(cid:14)(cid:6)(cid:16)(cid:18)

 . 

3.3 

Scalar 

 Approach 

QR----STR

(cid:6)0-5(cid:12)0

Next,  we  present  our  proposed  personalization  approach.  Similarly  to  Xu  et  al.’s 
approach, we  use  the 
  weighting  scheme, but  we eliminate the document and 
user length normalization factors. In the VSM, the finality of the length normalization 
factor is to penalize the score of documents that contain a high amount of information 
(i.e. a large quantity of terms). One of the drawbacks of this normalization  factor is 
that short documents are usually ranked higher that larger ones, even if they have less 
terms  in  common  with  the  user’s  query.  In  terms  of  tags,  a  document  with  a  high 
number of related tags may mean that it is more popular for users, as more users have 
bookmarked  it.  Hence,  if  we  used  a  length  normalization  factor,  we  would  penalize 
the  score  of  popular  documents.  In  summary,  whereas  the  document  length  in  the 

                                                           
4 Xu et al. do not specify if they use the user or document 

use both, as it gave the best performance values.  

 weights, or both. We chose to 

5(cid:12)0

6 

David Vallet, Iván Cantador, Joemon M. Jose 

classic  VSM  denotes  the  amount  of  content  presented,  the  document  length  in  our 
model can be understood as a measure of the popularity of the document on the social 
tagging  site.  As  several  works  point  out,  this  popularity  value  is  a  good  source  of 
relevancy [2,4]. Thus, it would not be advisable to penalize popular documents. Note 
that eliminating the user length normalization factor does not have any effect, as it is 
constant in all user-document similarity calculations.  

5(cid:12)0

The  main  difference  between  our  approach  and  Noll  and  Meinel’s  is  that  we 
 global tag importance factor, following the VSM idea that a more 
incorporate the 
rare  tag  is  more  important  when  describing  either  the  user’s  interests  or  the 
document’s content. We neither normalize the content of the document, as we believe 
that the distribution of tags on a document may give insights on how important a tag 
is to describe the document’s content. As mentioned previously, we can exploit two 
different  sources  in  order  to  calculate  the 
  value  associated  to  a  tag:  the  user 
collection and the document collection. To investigate which is the best source for the 

5(cid:12)0

 measure, we present three variations of our approach: 

5(cid:12)0

-
5(cid:12)0(cid:14)(cid:10)(cid:15), (cid:12)(cid:17)(cid:18) = ∑ U(cid:6)012(cid:14)(cid:6)(cid:16)(cid:18) ∙ 5(cid:12)012(cid:14)(cid:6)(cid:16)(cid:18) ∙ (cid:6)034(cid:14)(cid:6)(cid:16)(cid:18) ∙ 5(cid:12)034(cid:14)(cid:6)(cid:16)(cid:18)V 

H

. 

(cid:6)0

-
5(cid:12)012(cid:14)(cid:10)(cid:15), (cid:12)(cid:17)(cid:18) = ∑ U(cid:6)012(cid:14)(cid:6)(cid:16)(cid:18) ∙ 5(cid:12)012(cid:14)(cid:6)(cid:16)(cid:18) ∙ (cid:6)034(cid:14)(cid:6)(cid:16)(cid:18) ∙ 5(cid:12)012(cid:14)(cid:6)(cid:16)(cid:18)V

H

(cid:6)0

 .  

-
5(cid:12)034(cid:14)(cid:10)(cid:15), (cid:12)(cid:17)(cid:18) = ∑ U(cid:6)012(cid:14)(cid:6)(cid:16)(cid:18) ∙ 5(cid:12)034(cid:14)(cid:6)(cid:16)(cid:18) ∙ (cid:6)034(cid:14)(cid:6)(cid:16)(cid:18) ∙ 5(cid:12)034(cid:14)(cid:6)(cid:16)(cid:18)V

H

 . 

(cid:6)0

where Equation 1 makes use of the user 
document 
measure on both components, and Equation 3 uses the document 

 measure on the user component and the 
 

  measure  on  the  document  component,  Equation  2  uses  the  user 

 measure.  

5(cid:12)0

5(cid:12)0

5(cid:12)0

5(cid:12)0

(1) 

(2) 

(3) 

4 

An Evaluation Framework for Personalized Web Search 

Noll  and  Meinel  [6]  evaluated  their  personalization  approach  combined  with  a 
Web search engine. They adopted a user centred evaluation approach by creating a set 
of predefined queries, and by asking users to evaluate the results. More specifically, 
users  were  asked  to  evaluate  which  result  list  they  preferred:  either  the  Web  search 
ranking  or  the  personalized  ranking.  Xu  et  al.  [12]  used  the  social  bookmarking 
information  to  create  an  automatic  evaluation  framework.  The  main  advantage  of 
their framework is that the experiments could be reproduced. However, they did not 
explore  the  performance  of  their  personalization  approaches  when  combined  with  a 
Web  search  engine.  They  combined  their  approach  with  a  search  system  that  was 
limited  to  the  bookmarks  pertinent  to  their  test  beds,  ranging  from  1K  to  15K  Web 
documents.  The  goal  of  our  evaluation  frameworks  falls  in  the  middle  of  these  two 
approaches:  1)  as  Noll  and  Meinel,  we  are  more  interested  in  testing  our 
personalization approach in a real Web search environment; and 2) as Xu et al.,  we 
adopt  an  automatic  evaluation  framework  with  a  test  bed  of  topics  and  relevance 
judgments  extracted  from  the  social  bookmarking  information.  In  this  section,  we 
describe our evaluation framework, highlighting the main differences between it and 
the previously presented evaluation frameworks.  

Exploiting Social Tagging Profiles to Personalize Web Search  

7 

4.1  Topic and Relevance Judgement generation 

We split the tagging information of a given user into two parts. The first part forms 
the  user  profiling  information,  whereas  the  second  is  used  for  the  automatic  topic 
generation process. Hence, the subset of tag assignments used in the topic generation 
process is not included in the user profile, and thus are not part of our training data. 
This splitting process is applied to all users belonging to the initial test bed collection. 
Figure 1 outlines how the partition is made.  

d1

dn

dt

User

u

a1,1 a2,1

…

al,1

…

a1,n a2,n

…

al,n

…

a1,t a2,t

…

al,t

al,n={u, tl, dn}

A

∊

User profile

Topic generation

 

Fig. 1. Partitioning of user tag assignments into user profile and information intended for topic 

generation. 

As  shown  in  Figure  1,  the  topic  creation  process  attempts  to  create  a  new  topic 
. The topic is defined by extracting 
from each annotated document 
. We use the most popular tags as they 
the top most popular tags related to document 
are more objective to describe the document contents than those assigned by a single 
user. These tags are used to launch a Web search, and collect the result list obtained.  

(cid:12) ∈ [(cid:12)(cid:17)W(cid:7), … , (cid:12)@]

(cid:12)

(cid:12)

We  then  study  how  the  different  personalization  approaches  re-rank  the  returned 
result list. As document 
 was contained in the original user profile, we can assume 
that the document is relevant to the user. Thus, a good personalization approach will 
always  rank  the  document  in  the  top  positions  of  the  result  list.  We  use  the  Mean 
Reciprocal  Rank  (MRR)  [11]  metric 
the  performance  of  our 
personalization approach. This measure assigns a value of performance for a topic of 
 in the final personalized result list. We 
1/Z
also provide the P@N (Precision at position N) metric, which has a value of 1 iff 
 
Z ≤
N.  These  values  will  be  then  averaged  over  all  the  generated  topics.  The  topic 
generation and evaluation can be summarised in the following steps.  

 is the position of the relevant 

to  measure 

, where 

(cid:12)

Z

For each document 

(cid:12) ∈ [(cid:12)(cid:17)W(cid:7), … , (cid:12)@]

: 

i.  Generate a topic description using the top k most popular tags associated to 

the document. 

ii.  Execute the topic on a Web search system and return the top 

 documents as 

the topic’s result list.  
If document 

iii. 
iv.  Apply the different personalization approaches to the result set. 
v.  Calculate MRR and P@N. 

 is not found in the result list, discard the topic for evaluation 

(cid:12)

R

8 

David Vallet, Iván Cantador, Joemon M. Jose 

(cid:12)

^ = 3

In  our  experiments,  we  used  a  query  size  of 

  tags,  and  a  size  result  list  of 
  documents.  Several  studies  point  out  an  average  user  query  size  of  2-3 
R = 300
keywords  in  Web  search  [7].  We  thus  opted  for  a  query  size  of  three  in  order  to 
emulate  user  using  a  Web  search  system,  and  to  evaluate  if  user  profiles  obtained 
from the social tagging actions of the users could be successfully exploited to improve 
a  Web  search  system.  We  also  investigated  the  generation  of  topics  with  two 
keywords obtaining performance results similar to those obtained with topic sizes of 
three keywords. There is of course a chance that document 
 does not appear in the 
result  list.  In  this  case,  the  document  is  discarded  for  topic  generation.  With  these 
settings, 23.8% of the topics were successfully generated, and the average position of 
document 

 on the result list was 65.4. 

(cid:12)

Xu et al. also built a test bed from the users’ social tagging information. First, they 
applied  the  personalization  techniques  to  a  custom  search  engine  that  only  retrieves 
documents that belong to the same test bed. On the other hand, we use a Web search 
system to return our documents, in this way we intend to have a more realistic set up. 
Second,  they  created  the  topic  descriptions  by  using  the  tags  associated  to  the  user 
profile.  They  used  a  topic  query  size  of  one  keyword  (i.e.  one  tag  belonging  to  the 
user profile), and made the assumption that if a document is tagged by the user with 
the  same  tag,  it  is  relevant  to  the  user.  As  we  were  using  a  Web  search  system  to 
generate  the  topic  results,  using  a  single  keyword  very  often  failed  to  return  any 
document that belonged to the user profile. This would have restricted our evaluation 
to documents that are highly popular (and thus are prone to be rank high on a single 
keyword  query).  We  consider  Xu  et  al.’s  approach  to  be  less  restrictive  than  our 
approach; the topic definition are more broader, by only using one keyword to define 
them,  and  the  relevance  judgments  are  more  loose  by  considering  all  documents 
tagged by the same tag. Our approach utilizes a more specific query, and restricts the 
relevance  judgment  to  the  document  described  by  this  query.  Although  we  consider 
that  our  approach  is  more  suited  to  evaluate  a  personalized  Web  search,  both 
approaches  could  complement  each  other  in  order  to  give  more  insights  on  the 
performance of a personalization approach. 

4.2  Experimental Setup 

We  create  a  test  bed  formed  by  600  Delicious  users.  Delicious  is  a  social 
bookmarking site for Web pages. As of the 26th of November of 2008, delicious had 
5.3  million  users5,  up  from  1  million  users  registered  on  September  of  20066.  With 
over 180 million unique URLs, delicious can be considered a fairly accurate “people’s 
view”  of  the  Web.  This  vast  amount  of  user  information  has  been  previously 
successfully  exploited  in  order  to  e.g.  improve  Web  search  [2],  to  provide  personal 
recommendations [4,9], or to personalize search [6,12].  

Due to limitations of Delicious API, we only extract the latest 100 bookmarks of 
each user, from  which  we use 90% of the bookmarks to create the user profile, and 

                                                           
5 http://blog.delicious.com/blog/2008/11/delicious-is-5.html 
6 http://blog.delicious.com/blog/2006/09/million.html 

Exploiting Social Tagging Profiles to Personalize Web Search  

9 

the  remaining  10%  to  generate  the  evaluation  topics.  The  test  bed  contains  44,742 
documents and 31,280 distinct tags. We did not apply any preprocessing steps to the 
user  tags.  Users  used  an  average  of  5.6  tags  to  describe  each  bookmark.  As 
experimental  Web  search  system,  we  use  Yahoo!’s  open  Web  search  platform, 
Yahoo! Boss7. After the topic generation process, we ended up with 1,717 evaluation 
topics.  

For  each  document  in  the  topic  result  set,  we  downloaded  the  100  most  recent 
bookmarks. Those bookmarked documents had an average of 24.3 distinct associated 
tags. On average, 20.3% of the documents of the result list had been bookmarked at 
least once by a user. Figure 2 shows the distribution of this probability relative to the 
document position on the result list. Interestingly, this probability seems to stabilize at 
around 0.15 from the 200th position, which indicates that the proposed personalization 
approaches can be applied beyond the top results.  

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

50

100

150

200

250

Fig. 2. Probability of a document being bookmarked relative to its position in the result list. 

5 

Experiment Results 

In this section, we study the performance of the proposed personalization approaches 
within  our  evaluation  framework.  First,  we  make  a  comparison  between  all 
personalization approaches when applied to the evaluation topics. Second, we analyze 
the performance of these approaches when combined with the Web search results.  

Table 2. Personalization approaches performance. Values with an asterix indicate a statistically 

significant higher value than the 

 approach (Wilcoxon test, p < 0.05). 

Metric 

MRR 
P@5 
P@10 
P@20 

 

cos@A-)3A
0.0786 
0.0897 
0.1805 
0.3512 

 

cos`(cid:15)%L
0.0991 
0.1235 
0.2155 
0.3780 

(cid:6)0

 

(cid:6)0

0.2708 
0.4281 
0.6086 
0.7734 

 

-
(cid:6)0
5(cid:12)034
0.2878* 
0.4502* 
0.6290* 
0.7816 

-
 
(cid:6)0
5(cid:12)0
0.2989* 
0.4671* 
0.6325* 
0.7880 

 

-
(cid:6)0
5(cid:12)012
0.2990* 
0.4677* 
0.6302* 
0.7833 

                                                           
7 http://developer.yahoo.com/search/boss/ 

10 

David Vallet, Iván Cantador, Joemon M. Jose 

(cid:14)(cid:10)(cid:18)

 and 

Table  2  shows  the  MRR  values  and  Precision  at  5,  10  and  20  of  the  presented 
personalization  approaches.  Following  the  definitions  of  Section  2,  this  table  shows 
the  performance  of  the  ranked  result  list  according  to  the  user’s  interests,  namely 
. The approaches are ordered in terms of the MRR  metric. The performance of 
S
the approaches presented by Xu et al. [12], 
, have much lower 
performance values than the rest of approaches, even though Xu et al. report a better 
performance  of  the 
  approach,  presented  by  Noll  and  Meinel  [6].  The  possible 
reason  of  this  contradiction  is  that  Xu  et  al.’s  made  use  of  controlled  document 
collections,  no  larger  than  15K  documents,  whereas  in  this  evaluation  and  in  the 
evaluation  performed  by  Noll  and  Meinel’s,  a  free  Web  search  system  was  used  to 
search for documents. As hypothesised in Section 3.3, the cosine similarity function 
penalizes  those  documents  with  a  high  amount  of  assigned  tags  (i.e.  popular 
documents), in favour of documents in the result set that have fewer related tags. This 
penalization factor does not seem to work as good as the other approaches, which do 
not use the document length normalization factor. 

cos@A-)3A

cosJK%L

(cid:6)0

(cid:6)0

5(cid:12)0

All the  variations of our personalization approach outperform the performance of 
Noll  and  Meinel’s  approach, 
.  The  improvement  is  statistically  significant 
(Wilcoxon test, p < 0.05). We believe that this improvement is achieved thanks to the 
use  of  the 
  value,  which  calculates  the  global  importance  of  a  tag. The  obtained 
results  are  encouraging:  we  achieve  a  10%  improvement  on  the  MRR  metric  with 
, and a 9.2% improvement in terms of P@5. 
respect to the state of the art approach, 
As  explained  in  Section  3.3,  the 
values  can  be  computed  from  two  sources,  the 
user set or the document collection. By analyzing the results, we can conclude that the 
 
user  set  is  a  better  source  for  the 
-
5(cid:12)012
personalization  approaches  use  the  user 
  in  the  user  component  and  both 
components,  respectively.  The  difference  on  performance  of  these  two  approaches 
and the approach that use the document 

 is also statistically significant.  

  computation.  The 

-
5(cid:12)0

  and 

5(cid:12)0

5(cid:12)0

5(cid:12)0

(cid:6)0

(cid:6)0

(cid:6)0

(cid:14) (cid:18)

, with the result list produced by the personalization approaches, i.e. S

We  now  investigate  the  performance  of  the  personalization  approaches  when 
combined  with  the  Web  search  results.  In  order  to  do  this,  we  have  to  combine  the 
result  list  returned  by  the  Web  search  system  with  no  personalization,  denoted  as 
S
. As a 
baseline,  we  use  the  Web  search  system  results,  but,  in  order  to  make  a  more  fair 
comparison,  we  eliminated  from  the  result  list  those  documents  that  were  not 
bookmarked  by  any  user.  The  final  ranked  list  is  a  combination  of  both  the  non-
personalized  and  the  personalized  rank  lists.  We  can  define  this  combination  as 
S
  is  a  function  that  merges  both  ranked  lists.  We 
opted for a parameter free combination  function,  CombSUM,  which is a rank based 
aggregation method [8]. 

(cid:14) , (cid:10)(cid:18) = Ψ(cid:23)b(cid:14) (cid:18), b(cid:14)(cid:10)(cid:18)(cid:24)

  where 

(cid:14)(cid:10)(cid:18)

Ψ

5(cid:12)0

 Table  3  shows  the  performance  values  of  the  personalization  approaches 
combined with the Web search. Values are correlated with those presented in Table 2. 
The cosine similarity personalization approaches degrade the performance of the Web 
search,  while  the  rest  of  approaches  perform  better  than  the  baseline.  All  the 
variations of the personalization approach introduced in this work outperform both the 
i.e. 
baseline 
 
. It is interesting to point that once our approach variations are combined with the 

performing 

approach, 

state 

best 

and 

the 

the 

art 

of 

(cid:6)0

Exploiting Social Tagging Profiles to Personalize Web Search  

11 

(cid:6)0

5(cid:12)0

-
5(cid:12)012 

,  and  those  exploit  of  the  document 

approach,  which  uses  only  of  the  user 

Web search results, there are no statistical differences between the performance of the 
approaches  that  use  the  user 
.  However, 
,  is  the  best  performing,  in 
the 
terms  of  MRR.  This  approach  achieves  a  21.3%  and  a  4.5%  improvement  with 
respect  to  the  baseline  and 
  approaches,  respectively,  with  statistically  significant 
differences. Again, the elimination of the document length normalization factor, and 
exploitation of the 
 measure seems to be the key elements for these performance 
improvements. 

5(cid:12)0

5(cid:12)0

5(cid:12)0

(cid:6)0

Table 3. Personalization approaches performance when combined with the Web search engine 

result. Values with an asterix indicate a statistically significant higher value than the Web 
search ranking (Wilcoxon test, p < 0.05). Values marked with a † also indicate a statistically 

significant higher value than the 

 approach.  

(cid:6)0

Metric 

baseline

  cos@A-)3A

 

MRR  0.3346 
P@5 
0.4607 
P@10  0.5812 
P@20  0.6948 

0.1573 
0.2225 
0.3809 
0.5795 

 

cosJK%L
0.1813 
0.2638 
0.4042 
0.5649 

 

(cid:6)0

0.3885* 
0.5614* 
0.6832* 
0.7833* 

 

(cid:6)0

-
5(cid:12)034

-
 
(cid:6)0
5(cid:12)0
0.4023†  0.4026† 
0.5649*  0.5702* 
0.6820*  0.6907* 
0.7851*  0.7886* 

 

-
(cid:6)0
5(cid:12)012
0.4060† 
0.5696* 
0.6913* 
0.7874* 

6 

Conclusions and Future Work 

In  this  paper,  we  introduce  an  approach  that  exploits  the  user  profile  defined  in  a 
social tagging service to personalize a retrieval system. This personalization approach 
can  be  applied  to  any  Web  search  system  to  provide  personalization  capabilities  to 
any user who has a profile in a social tagging service, such as Delicious. This adds a 
new benefit of these  services:  with  no extra effort, the  user can take advantage of a 
personalized  Web  search  system.  In  order  to  evaluate  our  approach,  we  propose  an 
automatic  test  bed  generation  mechanism,  which  makes  use  of  the  tagging 
information  available  on  the  user  profiles.  The  results  of  our  evaluation  our 
encouraging,  and  show  that  the  adoption  of  global  tag  importance  values,  and  the 
elimination of document length normalization factors significantly improves the state 
of the art personalization approaches, enhancing traditional Web search engines.  

The  popularity  measure  of  a  document  is  an  important  factor  to  measure  its 
relevance  to  a  query  and  a  user.  Although  a  Web  search  algorithm  takes  this 
importance  factor  into  account  (e.g.  the  PageRank  measure),  we  should  investigate 
how  the  folksonomy-based  personalization  approaches  combine  with  folksonomy-
based popularity measures, e.g. [4,2].  

The  folksonomy  structure  has  been  proven  to  be  a  good  ground  to  expand  the 
folksonomy-based user profiles [12], but these techniques are not scalable. A scalable 
expansion  technique  would  allow  its  application  to  personalization  approaches 
focused on Web search.  

12 

David Vallet, Iván Cantador, Joemon M. Jose 

Acknowledgments. This research was supported by the European Commission under 
contract FP6-027122-SALERO. The expressed content is the view of the authors but 
not necessarily the view of the SALERO project as a whole. 

References 

1.  Au-Yeung,  C. M.,  Gibbins,  N.,  Shadbolt,  N.:  A  study  of  user  profile  generation  from 
folksonomies.  In:  Proceedings  of  the  WWW  2008  Social  Web  and  Knowledge 
Management, Social Web Workshop (2008) 

2.  Bao,  S.,  Xue,  G.,  Wu,  X.,  Yu,  Y.,  Fei,  B.,  Su,  Z.:  Optimizing  web  search  using  social 
annotations.  In:  Proceedings  of  the  16th  international  conference  on  World  Wide  Web 
(WWW 2007), pp. 501--510. ACM Press, New York (2007) 

3.  Chirita,  P. A.,  Costache,  S.,  Nejdl,  W.,  Handschuh,  S.:  P-tag:  large  scale  automatic 
generation  of  personalized  annotation  tags  for  the  web.  In:  Proceedings  of  the  16th 
international  conference  on  World  Wide  Web  (WWW  2007),  pp.  845--854.  ACM,  New 
York (2007) 

4.  Hotho, A., Jäschke, R., Schmitz, C., Stumme, G.: Information Retrieval in Folksonomies: 
Search  and  Ranking.  The  Semantic  Web:  Research  and  Applications.  LNCS,  vol.  4011, 
pp. 411--426. Springer, Heidelberg (2006) 

5.  Micarelli, A., Gasparetti, F., Sciarrone, F., Gauch, S.: Personalized search on the world wide 

web. The Adaptive Web. LNCS, vol. 4321, pp. 195--230. Springer, Heidelberg (2007) 

6.  Noll, M. G., Meinel, C.: Web search personalization via social bookmarking and tagging. 
In:  Proceedings  of  the  6th  International  Semantic  Web  Conference  and  2nd  Asian 
Semantic  Web  Conference  (ISWC  2007/ASWC  2007).  LNCS,  vol.  4825,  pp.  367--380. 
Springer, Heidelberg (2007) 
Jansen, B. J., Spink, A., Bateman, J., Saracevic, T.: Real life information retrieval: a study 
of user queries on the web. SIGIR Forum 32 (1), 5--17 (1998) 

7. 

8.  Renda,  E. M.,  Straccia,  U.:  Web  metasearch:  rank  vs.  score  based  rank  aggregation 
methods.  In:  Proceedings  of  the  2003  ACM  symposium  on  Applied  computing  (SAC 
2003), pp. 841--846, ACM Press, New York (2003) 

9.  Shepitsen, A., Gemmell, J., Mobasher, B., and Burke, R.: Personalized recommendation in 
social  tagging  systems  using  hierarchical  clustering.  In:  Proceedings  of  the  2nd  ACM 
Conference  on  Recommender  Systems  (RecSys  2008),  pp.  259--266.  ACM  Press,  New 
York (2008) 

10.  Szomszor,  M.,  Alani,  H.,  Cantador,  I.,  O'hara,  K.,  Shadbolt,  N.:  Semantic  modelling  of 
user interests based on cross-folksonomy analysis. In: Proceedings of the 8th International 
Semantic  Web  Conference.  LNCS,  vol.  5318,  pp.  pp.  632--648.  Springer,  Heidelberg 
(2008) 

11.  Voorhees,  E.:  The  TREC-8  Question  Answering  Track  Report.  In:  The  Eighth  Text 

REtrieval Conference (TREC 8), pp. 77--82 (1999) 

12.  Xu, S., Bao, S., Fei, B., Su, Z., Yu, Y.: Exploring folksonomy for personalized search. In: 
Proceedings  of  the  31st  annual  international  ACM  SIGIR  conference  on  Research  and 
development in information retrieval (SIGIR 2008), pp. 155--162, ACM Press, New York 
(2008) 

