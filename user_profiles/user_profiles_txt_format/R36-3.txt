Reverted Indexing for Feedback and Expansion

Jeremy Pickens, Matthew Cooper, Gene Golovchinsky

jeremy@fxpal.com, cooper@fxpal.com, gene@fxpal.com

FX Palo Alto Laboratory
Palo Alto, CA 94304 USA

ABSTRACT
Traditional interactive information retrieval systems func-
tion by creating inverted lists, or term indexes. For every
term in the vocabulary, a list is created that contains the
documents in which that term occurs and its relative fre-
quency within each document. Retrieval algorithms then
use these term frequencies alongside other collection statis-
tics to identify the matching documents for a query. In this
paper, we turn the process around: instead of indexing doc-
uments, we index query result sets. First, queries are run
through a chosen retrieval system. For each query, the re-
sulting document IDs are treated as terms and the score or
rank of the document is used as the frequency statistic. An
index of documents retrieved by basis queries is created. We
call this index a reverted index. With reverted indexes, stan-
dard retrieval algorithms can retrieve the matching queries
(as results) for a set of documents (used as queries). These
recovered queries can then be used to identify additional
documents, or to aid the user in query formulation, selec-
tion, and feedback.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

General Terms
Algorithms, Experimentation

1.

INTRODUCTION

In ad hoc information retrieval, users describe their in-
formation needs by queries to search a document collec-
tion. Query terms are often used with an inverted index
to rank documents by estimated relevance. In query expan-
sion based on relevance feedback, users explicitly identify
relevant documents to help reﬁne a search iteratively.
In
this paper, we present and evaluate a general approach to
indexing a collection for exploration using document-based

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CIKM’10, October 26–30, 2010, Toronto, Ontario, Canada.
Copyright 2010 ACM 978-1-4503-0099-5/10/10 ...$10.00.

queries, which we call Reverted Indexing. Reverted indexing
is a variant of inverted indexing founded on the retrievabil-
ity of documents by queries [5]. While traditional inverted
indexing associates terms with documents in which they oc-
cur, reverted indexing relates documents with the queries
that retrieve them.

To build the reverted index, we ﬁrst assemble a large set
of queries, and refer to its elements as basis queries to distin-
guish them from the user queries that represent users’ infor-
mation needs. Basis queries can be compiled from keywords
extracted from query logs or from the documents comprising
the collection, or by using other conjunctive mechanisms to
form more complex queries (e.g. using metadata or facets).
Once a set of basis queries is determined, we use a standard
ranking function to order documents by their relevance to
each basis query. For each document we construct the vector
with elements corresponding to the basis queries and values
determined by that document’s estimated relevance to that
basis query. This reverted index thus associates each doc-
ument with the basis queries that retrieve it, as in Figure
1(b). This processing is performed oﬀ-line and does not re-
quire substantial computation for simple ranking functions.
The process is analogous to standard term-based inverted
indexing. A conventional inverted indexes is a set of lists,
one for each term. A given term’s list contains elements for
each document in which that term occurs, as in Figure 1(a).
Each element is weighted according to the term’s importance
within the corresponding document.

In sum, the basic conceptual foundation for conventional
inverted indexes is term occurrence, while reverted indexes
are founded on document retrievability.
In the next sec-
tion, we review related representations for document collec-
tions. We then describe our indexing scheme in detail and
present query expansion experiments that demonstrate im-
proved performance over well-regarded methods. We also
show that our method reduces online computational costs,
and conclude the paper with a discussion of our results and
potential future extensions.

2. BACKGROUND

In this section, we summarize related work and discuss
diﬀerences with our proposed framework. A primary source
of inspiration was the work of Azzopardi et al. [5]. Adopting
a document-centric view of information retrieval, they ask
what portion of a document collection is retrieved by a large
set of queries at a rank less than or equal to k. Building on
the notion of retrievability, we index the set of documents re-
trieved by basis queries. We then apply established informa-

1049(a) A depiction of traditional inverted indexing. ti and
dn denote terms and document IDs, respectively.

(b) A depiction of reverted indexing. qb and dn denote
basis queries and document IDs, respectively.

Figure 1: Traditional Inverted Indexing versus Reverted Indexing

tion retrieval algorithms to the reverted index to determine
the basis queries most characteristic of a given document.
The reverted index also identiﬁes documents that are likely
to not be retrievable in the sense used by Azzopardi et al. [5].
Robertson [18] explored symmetries in information re-
trieval within the classic vector space framework, examining
the concept of duality in representing documents by terms,
and vice versa. From this perspective, both queries and doc-
uments are treated as “bags of terms.” In reverted indexing,
on the other hand, basis queries are never processed accord-
ing to their constituent terms, but rather treated as a atomic
units distinct from other basis queries with which they may
share common terms.

Craswell et al. [9] use a web-scale search engine to col-
lect a large set of queries and clicked results. They com-
bine these sets into a bi-partite graph and use random walks
on the graph to infer likely end points from a single start-
ing point. Knowing what documents many internet users
clicked after issuing a query makes it possible to go back-
wards to ﬁnd the most common queries related to a given
document. Our work diﬀers in key ways. First, by relating
queries and clicks in a bipartite graph, Craswell et al. [9] is
constrained to a single document starting point, i.e. you can
initiate a random walk from only one document at a time.
In contrast, reverted indexing can process a group of docu-
ments as a set. Furthermore, documents can be combined
using boolean operators or other query constructs within
reverted indexing. Craswell et al. [9] associate documents
only with queries that users have issued. Our framework
can use any automatically-extracted basis queries (n-grams,
conjunctions, and such) that can be handled by the base
ranking algorithm. Reverted indexing is broadly applicable
to both large web collections with abundant user data, and
to smaller enterprise or personal collections without avail-
able clickthrough statistics.

Query expansion is an established approach to improving
users’ search experience. Traditionally, query expansion is
performed at search time using explicit relevance feedback
(e.g. [19]) though other variants propose implicit relevance
feedback (e.g. [17, 11]). Billerbeck et al. [6] present methods
for query expansion based on processing user logs to deter-
mine which previously issued queries returned a given docu-
ment. They deﬁne “document surrogates” comprised of the
terms in issued queries for which a given document appeared
among the top 19 results. The number of queries associated
with any given document is limited to 39 to retain queries
with maximum statistical similarity. Three variations on
their general approach permute the representations used in

the ﬁrst and second rounds of retrieval. Either the full doc-
ument collection or the collection of surrogates is used to
perform retrieval or select expansion terms.

In federated information retrieval (FIR), query-based sam-
pling [7] has been proposed to aid in database selection and
query expansion. For this, a set of queries is assembled
and executed and the set of returned documents are used
to estimate collection word frequency statistics, typically to
then produce a traditional inverted index. In this manner,
multiple document collections are indexed more eﬃciently
using partial information. Ogilvie and Callan [13] applied
the approach to query expansion using blind (pseudo) rele-
vance feedback [11] in the FIR setting to examine sampling
density and performance tradeoﬀs with poor results. More
recently, Shokouhi, et al., [20] extended this approach by
experimenting with database selection and local and global
expansion to show improvements in FIR.

Puppin et al. [15, 16] use query logs to partition a web-
scale document collection using a query-document matrix.
They ﬁnd the top 100 documents for each query from a
training set (derived from a query log), and then discover
query-document clusters. The text terms of the query set
from each document cluster comprises a “document surro-
gate”. A secondary inverted index is constructed from these
proxy documents. In use, a query is ﬁrst evaluated against
the secondary index, and well-matching proxy documents
are then used to select which primary subcollection index
to search. Thus Puppin et al.’s two-tier term→document
inverted indexes are close in spirit to Billerbeck et al.
[6],
who create proxy documents by augmenting documents with
terms derived from queries that retrieved them. In Biller-
beck et al., surrogates are query-text proxies for individual
documents, while Puppin et al.’s surrogates are query-text
proxies for document clusters. In both cases, the entity be-
ing indexed is a text document.

We share with both Billerbeck et al. and Puppin et al.
the notion of retrievability, but draw a strong distinction
in our work relative to what is being indexed.
Instead of
indexing document proxies composed of query text, we index
results sets directly. Our document proxies are constructed
out of document identiﬁers (docids) from query results sets,
a process that we call “reverted indexing”. This allows us
to query the reverted index using document ids to identify
queries that were eﬀective at retrieving the given documents.
These retrieved queries can be used in a variety of ways:
to expand the original query, to browse the collection, etc.
Furthermore, reverted indexing should not be confused with
direct ﬁles: whereas a direct ﬁle contains only the terms

1050KL

Bo1

Term

df

Term

df

Reverted PL2
Term

df

KL

Bo1

Term

df

Term

df

Reverted PL2
Term

df

Topic 172 : “eﬀectiveness of medical products and related

programs utilized in the cessation of smoking” : 4 rels

smoking
cessation
smokers
nicotine
health

intervention

study
quit

researchers

patch
drug

quitting

state
forms
disease
avg df = 17435

2459
627
722
235
33887
5485
48065
4641
6725
1960
22258
575
108787
14873
10224

2891
22
331
1163
1014
356
743
748
4298
117
3479
10636
20390
42
483

smoking
cessation
smokers
nicotine

intervention

health

quit

researchers

patch

quitting

study
drug
forms
disease

birthweight

poaching
wildlife
kenya
ivory

elephants
elephant

deer

poachers
conserva..

species
tusks
african
namibia
animals

2459
627
722
235
5485
33887
4641
6725
1960
575
48065
22258
14873
10224
41

22
331
2891
1163
1014
356
743
748
117
4298
3479
42
10636
483
3928

cessation

birthweight

smokers
nicotine
smoking

bloodstream

quitting

scip
quit

questiona..
pretesting
clonidine
podiatry

gum

worksites

tsavo
leakey
tusks

elephants

wildlife

kws
kez
ivory

jealousies
elephant

conserv..ists

kenya
ﬁefdom

627
41
722
235
2459
196
575
11
4641
22
16
20
22
494
47

331
117
12
22
42
356
2891
9
173
1014
56
743
293
1163
129

Topic 407 : “poaching wildlife preserves” : 10 rels
poaching
poachers

leakey

wildlife
leakey

poaching

kenya
ivory

elephants
elephant

deer

conserva..
poachers
species
african
africa
tusks

namibia

airport
security

faa

baggage
heathrow
passengers

airports
aviation
detectors
screening

police
persons
metal

air

boarding

tires
tire

waste

landﬁlls
recycling
million
energy
disposal

dump

nuisance

new

recycle
county

old

detectors
security
airport
hijacker

faa

airport
security

Topic 341 : “airport security” : 11 rels
11769
61748
1213
817
993
4758
2923
5289
379
1762
31862
10777
8948
34988
787

11769
61748
1213
817
993
4758
379
2923
5289
1762
787
66
8948
10777
4661

baggage
heathrow
passengers
detectors
airports
aviation
screening
boarding

kean
metal
persons
terrorist

luggage
outﬁtted
baggage
bicolor
unchall..
wuerenli..
boarding

kean
knbc

screeners

lapse

Topic 419 : “recycle, automobile tires” : 2 rels
shredding
bulkiness
pyrolysis

tires
tire

landﬁlls

1050
910
10022
542
2038
51272
24068
7150
1608
553
200289
652
52281
61378
639

1050
910
542
10022
2038
24068
553
7150
1608
51272
652
639
10518
61378
52281

waste

recycling

energy
nuisance
disposal

dump
million
recycle
dumps
illegal

old

decompos..

spagnoli
retreaded

tires

lackawanna

westley
folkways
landﬁlls
nuisance
diapers
gaddi

379
61748
11769
108
66
182
749
239
817
5
384
3
787
741
8

113
4
22
194
3
9
1050
32
12
14
542
553
218
146
303

avg df = 3114

avg df = 2016

avg df = 490

dumps
avg df = 27630

county
avg df = 14979

incineration

avg df = 214

avg df = 10185

avg df = 675

avg df = 11934

avg df = 7793

avg df = 5199

Table 1: Example query expansion terms and associated term frequencies of terms identiﬁed using KL, Bo1 and
reverted indexing (PL2) at a judgment depth of 20. Terms are sorted in score order, though scores are not shown due
to space. Note the number of found relevant documents used to construct these sets. The document frequency (df )
associated with each expansion term is discussed in Section 4.4

of the corresponding document, a reverted index contains
queries that retrieved the document. These queries may
be simple terms, conjunctions, or more complex expressions
available in the underlying search engine.

We are also not required to mine query logs for our set of
system (basis) queries, Q. Billerbeck et al. and Puppin et
al., note that 25% of the documents in their collection have
no associated queries, and thus no surrogates. This result is
consistent with the experiments in [5]. Automatically gen-
erating a large set of basis queries is likely to associate more
documents in the collection with at least one basis query.
Additionally, the surrogates don’t preserve each query as a
distinct unit, in contrast to our approach (but similar to
[18]). Because logged queries sharing terms are collapsed
into terms within a surrogate, the richness (and size) of the
representation of documents by surrogates is reduced. Nor-
malizations for the distinctiveness of a system query (akin to
inverse document frequency) will in turn be skewed. Also,
the estimated relevance and ranking information associated
with the logged queries is not retained in the document sur-
rogates. We preserve this information and use it for normal-
izations that have proven beneﬁcial in standard information
retrieval settings. We expect them in turn to improve per-
formance within our framework.

3. REVERTED INDEXING

We now describe the reverted index in detail. Whereas
an inverted index associates terms with the documents in

which they occur, a reverted index associates documents
with the basis queries that retrieve them. The structure of
the reverted index is identical to the structure of an inverted
index, and retrieval algorithms created for inverted indexes
are directly applicable to reverted indexes. In the following
subsections, we detail the construction of a reverted index,
and describe its use for retrieval. We ﬁnally present our
experimental system and its results in Section 4.

3.1 Index Construction

We start with a collection of documents D = {d1, · · · , dN }.
The ﬁrst step is to determine a set of basis queries. While
this can be done in any number of ways, the most obvious
technique is to employ the same tokenizer that was used
to build the standard inverted index of the document col-
lection. The terms of an inverted index can constitute the
basis queries qb ∈ Q used to construct the reverted index.
Retrieval algorithms that operate on the inverted index are
used to evaluate each query.

In addition, Q may include bi-grams or larger n-grams,
(contiguous and non-contiguous, ordered and unordered),
window phrase queries, metadata (e.g. document geographic
location, creation time and date, categorical classiﬁcation,
etc.), and arbitrary conjunctions and disjunctions of terms
and metadata (e.g. a singleton term combined with a ge-
ographic location). One obvious source for basis queries is
existing user query logs [6, 15, 9, 16], though it is an open
question whether user logs oﬀer the necessary coverage of a

1051collection. Ideally, Q should be suﬃciently large to represent
both the content of the corpus (depth) as well as the breadth
of potential user queries. The choice of Q also depends on
the target application or user model for which the retrieval
system is being designed.
In general, the only constraint
on basis queries is that they can be evaluated by the base
retrieval algorithm. For the query expansion experiments
in this paper, Q contains all singleton (unigram) terms that
appear in at least two documents (df ≥ 2) in the collection.
We next use a base retrieval algorithm to rank the doc-
uments with respect to each basis query. Examples include
Best Match, Vector Space, Language Modeling [14], Diver-
gence From Randomness, and so on. In this paper, we use
PL2 [2, 10] as the base retrieval algorithm. Each basis query
qb ∈ Q generates a result list rb ⊆ D containing documents
and their corresponding relevance scores. This information
is processed as a synthetic reverted document. Each element
in the list corresponds to a document identiﬁer n such that
dn ∈ rb with a value computed from the retrieval score or
rank within rb. This list may be normalized by either the
number of relevant documents |rb| or by the sum of scores.
The set of lists for all basis queries can be viewed as a re-
trievability index (cf.
[5]). This index is inverted (using
traditional IR techniques) to generate the “reverted” index,
in which each document is represented by the basis queries
that retrieve it. This is illustrated in Figure 1(b).

Results lists rb are truncated at 1000; consistent with the
retrievability [5] inspiration for this work, only these top
ranked docids dn are included. Taking a cue from [4], the
results list for each basis query is then further normalized:
We shift, (minmax) scale, and quantize the retrieval scores
to the integer range {1, · · · , 10}. The di with the highest
score (at the top rank) gets a value of 10, and the lowest, 1.

3.2 Index Usage: Reverted Querying

A user (or system) can combine this reverted index with a
standard retrieval algorithm to retrieve the best basis queries
in response to document identiﬁer queries, a process that we
call reverted querying. Reverted queries may be best match,
boolean, or may use standard query operators such as syn-
onyms, distance windows (e.g. you can ﬁnd two docids that
were retrieved within a given window size of each other by
a particular basis query. The retrieval algorithm to do re-
verted querying is not required to be the same algorithm
used to construct the reverted index (i.e.
to issue basis
queries). For the sake of consistency, and to demonstrate
how easily deployable reverted indexes are, we use the same
algorithm, PL2. (See Table 2 for more details.)

The queries against a traditional inverted index consist
of terms and are issued to retrieve lists of documents. In a
reverted index, queries consist of document ids (di) that re-
trieve basis queries qb. Once the best basis queries have been
retrieved, the terms or other aspects of those basis queries
may be used as query suggestions, as query expansions, and
so forth. Queries enhanced or reﬁned in this manner may
then be issued back against the original inverted index to
retrieve new documents.

We adapt global and local statistical machinery from con-
ventional inverted indexing. Intuitively, suppose that a par-
ticular docid (di) is retrieved (or “retrievable” [5]) by only
a few basis queries. The presence of di in a reverted query
should be weighted more heavily than other more commonly
retrieved documents. Similarly, the estimated relevance of

di to a particular basis query qb is a natural local statistic.
Similarly, the sum of all relevance scores in a speciﬁc results
list provides a per-basis query normalizing factor. These
intuitions are rooted in established methods (and easily im-
plemented using existing software packages).
Inverse doc-
ument frequency measures in a standard index correspond
to the inverse retrievability statistic described above. The
relevance score associating a document and a basis query is
the local statistic analogous to traditional term frequency.
This above normalization corresponds to common usage of
document length (sum of term frequencies). Models other
than tf·idf use concepts such as eliteness [2, 10] and risk [14];
those statistics are also applicable in the reverted setting. In
this manner, decades of information retrieval research and
algorithm development can be applied directly to reverted
indexes.

Table 1 contains examples of generated query expansion
terms. For each TREC topic, an initial query was run and
documents were identiﬁed according to NIST relevance judg-
ments at a ranked depth of 20. To establish the baseline for
comparison, we applied the KL and Bo1 [2, 3] query expan-
sion techniques to identify candidate terms. The columns
labeled Reverted PL2 represent the results of using these
same identiﬁed relevant documents as reverted queries, the
basis query qb results of which are ranked using the PL2 re-
trieval algorithm. Again, while other basis queries are possi-
ble, the direct correspondence between terms in the inverted
index and basis queries in the reverted index is employed to
insure fair comparison in the experimental section.

While the KL and Bo1 method reasonably capture the gist
of the topic, they does so using relatively generic terms. For
example, Topic 172’s description and narrative require not
only information about quitting smoking, but speciﬁc prod-
ucts and their eﬀectiveness. From the four identiﬁed relevant
documents, KL and Bo1 extract terms such as “study” and
“patch”, while Reverted PL2 mentions a speciﬁc product by
name (“Clonidine”). Similarly, even though only two rele-
vant documents were identiﬁed in Topic 419’s (ﬁnding new
uses for old tires) initial retrieval list, reverted querying pro-
duces very reasonable results. The KL and Bo1 terms for
Topic 419 generically mention recycling, waste, and disposal.
But the reverted methods select more speciﬁc methods for
recycling, such as shredding and pyrolysis, as well as speciﬁc
uses such as retread[ing] and [turning into] diaper[s].

3.3 Index Application: Query Expansion

After a reverted query (constructed from the appropriate
relevant document identiﬁers) is issued, query expansion is
done thusly:

(a) The top m basis query qb results are selected

(b) The raw reverted query retrieval scores of these m re-

sults are shifted and scaled to [0, 1]

(c) The results are then treated as regular terms and the |m|
vector is added back to the original (title-only TREC
query)

Table 3 shows an example of Step (c) using information
from Table 1, the top few basis queries that were retrieved
by the Reverted PL2 algorithm for Topic 407, “poaching
wildlife preserves”. The residual average precision (not count-
ing documents already examined) for Topic 407 using all 15

1052Step

Description

Baseline

Our Method

0
1
2
3
4

Reverted Index Construction
Initial Title-Only Retrieval

Performance of Relevance Judgments

Term Selection and Weighting (m = 500)

Final Expanded Query

Algorithm Calculation

Index
<not applicable>

Algorithm

Inverted

PL2

Index

Inverted
Inverted

“User”

Inverted Bo1 or KL Reverted
Inverted
Inverted

PL2

PL2
PL2

PL2
PL2

Oﬄine
Online
Online
Online
Online

Table 2: Experimental Setup. Conditions are held constant across every step, except Step (3). In Step (3), the Bo1
(or KL) technique for selecting and weighting expansion terms is compared against the PL2 algorithm on a reverted
index (Reverted PL2).

expansion terms (and their associated weights, not shown
due to space constraints) from Table 1 is [0.188, 0.231, 0.248]
for KL, Bo1, and Reverted PL2 respectively. For Topic 172
it is:
[0.138, 0.141, 0.202] For Topic 419 the improvement
was even greater: [0.0065, 0.0065, 0.088].

Table 3: Application of reverted results (retrieved
basis queries) to query expansion.

poaching
poachers
tsavo
leakey
tusks
elephants
wildlife
kws
· · ·
preserves

Original Reverted Expanded
2.0
0.565
0.563
0.413
0.394
0.340
1.243
0.197
· · ·
1.0

1.0
0.565
0.563
0.413
0.394
0.340
0.243
0.197
· · ·
0

1.0
0
0
0
0
0
1.0
0
· · ·
1.0

4. EXPERIMENTS

4.1 Experimental setup

We evaluate our approach using a common scenario: query
expansion. Such work has a long history, from Rocchio in
the early 1970s [19] to today. Query expansion typically
proceeds in the following manner (see also Table 2):

(1) User issues query, system returns ranked documents

(2) User judges the top n documents, and marks

1 ≤ k ≤ n of them as relevant

(3) System selects m terms from these k relevant documents

and assigns a weight to each term

(4) System runs the expanded, weighted query against the
collection and returns as-yet unseen results to the user

Variations on these steps interchange system and user in-
volvement. For example, in Step (2) if the user were to make
document relevance judgments to a depth in the ranked list
of n, marking k ≤ n documents as relevant, this is called rel-
evance feedback (RF). If the system instead automatically
assumes that all n documents are relevant, this is called
pseudo-relevance feedback (PRF). In Step (4) if the user
rather than the system were to choose which of the top m
terms to add back to the query, this is called manual query
expansion. In this paper we focus on automatic query ex-
pansion, which means that the system is wholly responsible

for constructing and issuing the expanded query based on
the (relevant or pseudo-relevant) documents supplied to it.
To compare several approaches to automatic query ex-
pansion algorithms, we ﬁx steps (1), (2), and (4) across all
conditions and only vary Step (3).
In Step (1) the topic
title-only query is issued using the PL2 retrieval model and
the system returns a ranked list of documents. For RF, in
Step (2), NIST relevance judgments are used to simulate
user judgment on the top n documents returned by Step
(1). (Note that we are applying n judgments of relevance
rather than trying to identify n relevant documents.) For
PRF, all n documents are simply assumed relevant. Docu-
ments identiﬁed in Step (2) are fed to the various automated
query expansion algorithms of Step (3). In Step (4), PL2 is
again used to retrieve documents using the expanded and
weighted queries from Step (3).

After an initial comparison of several well-regarded al-
gorithms, we chose a Divergence from Randomness model,
PL2, for Steps (1) and (4) as it exhibits high precision at
low recall, a necessary condition for obtaining many high-
ranked relevant documents for RF or PRF. In both con-
ditions, we use the PL2 algorithm with the same model-
speciﬁc parameters on the same standard index. The only
diﬀerence comes at Step (3), how the expansion terms are
selected and weighted. For the control condition, we use
two established expansion algorithms, Kullback-Leibler Di-
vergence (KL) and Bose-Einstein (Bo1), for expansion term
selection and weighting, as implemented in the Terrier open
source retrieval platform [1]. For comparison, we use PL2
ranking on our reverted indexes to select and weight expan-
sion terms as in Section3.2. The number of expansion terms
is m = 500 for all conditions, but this choice was based
solely on a parameter sweep over the baseline KL and Bo1
expansion algorithms. While ﬁfty expansion terms is a more
typical setting, we found that baseline eﬀectiveness contin-
ued to improve as more terms were added. We chose to
compare against the strongest possible baseline. For our ex-
periments we use two primary TREC collections: (a) Topics
51-200 from TREC 1-3 on Disks 1 and 2, and (b) Topics
301-450 from TREC 6-8 on Disks 4 and 5. We label each of
these collections TREC123 and TREC678, respectively.

4.2 Relevance Feedback

If a certain topic has not yielded any relevant documents
at judgment depth n, there is no relevance information for
expansion. We drop such topics from the evaluation as
they do not diﬀerentiate the algorithms’ performance. Nat-
urally, as the judgment depth deepens, more topics retrieve
at least one relevant document. Nevertheless, even at a
rather shallow depth of 5 judgments, 119 of the 150 available
queries for TREC123, and 115 of the 150 available queries for

1053Residual MAP results for 123 (left) and 678 (right).

Percentage diﬀerence of Reverted PL2 over both KL and Bo1 baselines for 123 (left) and 678 (right).

Figure 2: Relevance Feedback: Residual MAP

TREC678, contain at least one relevant document. Impor-
tantly, for TREC123 improvements for Reverted PL2 are
statistically signiﬁcant at a 0.01 value using t-test at all
depths n ≥ 1; for TREC678 the same signiﬁcance holds
at all depths n ≥ 3.

The primary metric of query expansion performance is
residual mean average precision (MAP) [12]. When an ex-
panded query is run, it is of little use to the user to repeat-
edly see documents that she has already judged. We operate
under the assumption that any document that the user has
already judged, whether relevant or not, is removed from
the results list of the subsequent, expanded query. Only
documents that the user has not yet seen matter for evalua-
tion. Residual MAP captures that idea; for a given judgment
depth of n, all n documents that were judged are removed,
and average precision is calculated across only the remaining
documents.

Figure 2 shows residual MAP results for both collections
as a function of judgment depth. Results are presented
for three algorithms. KL and Bo1 are our baselines; Re-
verted PL2 is our experimental system. As the judgment
depth increases, fewer relevant documents remain in the ex-
panded results list and residual MAP values decrease. This
accounts for the downward-sloping MAP curves. Note that
residual MAP results are not comparable at diﬀerent judg-
ment depths.

The key comparison is between Reverted PL2 and KL or
Bo1 at each judgment depth. Figure 2 also shows graphs of

the percentage diﬀerence between Reverted PL2 and KL or
Bo1. For each ﬁxed judgment depth (i.e. for the same set
of found relevant documents), Reverted PL2 outperforms
both of these baselines. Performance varies slightly by col-
lection, but even with fewer than ﬁve relevance judgments,
Reverted PL2 does 10-20% better than either KL or Bo1.
For TREC123 that diﬀerence narrows as the judgment depth
increases, while for TREC678 it holds steady in the mid
teens. These results demonstrate the clear superiority of
Reverted PL2 over both the KL and Bo1 strong baselines.
While full MAP as an evaluation metric suﬀers from ﬂaws
described above, it does permit performance comparisons
between judgment depths. Figure 3 shows these same ex-
perimental runs without the removal of judged documents.
We see that the percentage improvement of Reverted PL2
over both KL and Bo1 continues to rise. While the residual
MAP results show that the reverted method improves pre-
cision for unseen documents, these full MAP results show
that the reverted method also does an overall better job of
“memorizing” seen relevant documents. While residual MAP
results provide the more valuable comparison, the full MAP
results demonstrate the robustness of the method.

4.3 Pseudo Relevance Feedback

We designed reverted indexing to improve interactive in-
formation retrieval, but it is also applicable for other types
of feedback. For non-interactive applications, a system may
run an initial pseudo-relevance feedback step in which the

1054Full MAP results for 123 (left) and 678 (right).

Percentage diﬀerence of Reverted PL2 over both KL and Bo1 baselines for 123 (left) and 678 (right).

Figure 3: Relevance Feedback: Full MAP

top n documents are assumed relevant and the query au-
tomatically expanded. Figure 4 contain MAP and percent-
age diﬀerence results for Reverted PL2 over both baselines.
Again, results are given at increasing judgment depths n.
Because the user does not actually examine any documents,
we report full MAP rather than residual MAP. Results shown
are for all 150 queries for each collection, whether or not
there are true relevant documents within the top n, as the
discrimination made in the previous section is not possible
in a pseudo-relevance context.

All three techniques (Reverted PL2, KL and Bo1) either
equal (at pseudo judgment depth n = 1) or outperform
(n > 1) doing no query expansion, on average. As n in-
creases, the improvement stabilizes (on TREC123) or wors-
ens (on TREC678), but this reﬂects the number of available
relevant documents in each collection. TREC123 tends to be
much more plentiful than 678, so the pseudo-relevance judg-
ments contain many more true relevant documents. This
keeps the expansion from drifting too much. However, the
primary comparison is between Reverted PL2 and each of
the baselines. At low n, reverted indexing outperforms both
KL and Bo1 on both collections, but generally the diﬀer-
ences are not statistically signiﬁcant. Bo1 slowly narrows
the gap as n increases. At the optimal value of n for each
collection (around 20 on TREC123, around 14 on TREC678)
there is only about a 2% diﬀerence, that is not statistically
signiﬁcant.

In terms of PRF eﬀectiveness, Reverted PL2 is at least as

good as state-of-the-art query expansion methods. However,
we will demonstrate in the following section that PRF under
reverted indexing is an order of magnitude more eﬃcient.
Though not developed with PRF in mind, reverted indexing
is widely applicable.

4.4 Efﬁciency

Reverted indexing is more eﬀective than the baselines, but
it is also signiﬁcantly more eﬃcient.
Inspecting Table 2,
there are two stages at which complexity diﬀerences may
occur: In Step (3) the selection and weighting of the most
informative expansion terms, and in Step (4) the execution
of the expanded query. We examine these separately.

All of the following experiments were run under the same
operating environment on a dual core, 2.83 GHz Intel ma-
chine with 3 GB of RAM. The codebase (Terrier[1]) and
standard indexes were also shared, so implementation issues
do not account for diﬀerences in eﬃciency. In the interest
of space, we show results for the TREC678 collection only,
although the same patterns of improvement were observed
for both collections. We also note that building the reverted
index for TREC678 takes approximately eight hours on this
single machine. This includes both basis query execution
time as well as reverted (results set) indexing time for all
295k basis queries, or approximately 97 ms per basis query.
This is an oﬄine process that is trivially parallelizable, so
the rest of our analysis will focus on the online computation
costs.

1055+

Pseudo-relevance MAP results for 123 (left) and 678 (right).

Percentage diﬀerence of Reverted PL2 over both KL and Bo1 baselines for 123 (left) and 678 (right).

Figure 4: Pseudo-Relevance Feedback: Full MAP

4.4.1 Selection and Weighting Time

4.4.2 Execution Time

The ﬁrst potential diﬀerence in eﬃciency (overall running
time) is the selection and weighting of expansion terms. The
top half of Figure 5 shows the term selection and weighting
time data for Reverted PL2, KL, and Bo1 for both RF and
PRF. Reverted indexing is an order of magnitude faster than
both KL and Bo1. Average time for RF (reverted) ranges
from 3.4 milliseconds at a single document, to 4.8 ms at 40
documents. Under PRF the range is 8.3 to 10.7 ms. For
both the KL and Bo1 methods, RF ranges from 12.0 to 47.2
ms, and PRF from 10.7 to 106.7 ms.

The explanation for this diﬀerence is simple. For KL and
Bo1, a score or weight needs to be calculated online for every
unique term in the set of feedback documents (whether RF
or PRF). With reverted indexing, selection and weighting is
as eﬃcient as running a reverted query using the relevant
docids. The weights are partially precomputed, and selec-
tion is simply a matter of choosing the top m results from
the reverted query ranked list. This accelerates selection
time immensely without sacriﬁcing eﬀectiveness. But be-
cause of this oﬄine processing, selection time is perhaps not
the fairest comparison as it may be possible to precompute
Bo1 or KL weights for each document and achieve similar
speedups. We turn our attention to the second factor: exe-
cution time.

In the bottom half of Figure 5, the average execution time
for the expanded query is slightly more than an order of
magnitude faster for Reverted PL2. For RF, reverted in-
dexing execution times range from 107 ms (at 1 document)
to 323 ms (at 40), while Bo1 and KL execution times range
from 3394 to 4857 milliseconds. The diﬀerence is greater
for PRF wherein the highest Reverted PL2 execution time
across any judgments depth was 556 ms, compared to 5387
ms and 5915 ms for KL and Bo1, respectively.

Recall from Step (4) in Table 2 that the same underly-
ing algorithm (PL2) is used in all conditions for the ﬁnal,
expanded query. The retrieval algorithm is parameterized
by the actual terms that were selected in Step (3), so diﬀer-
ences in execution time are due to the diﬀerent document
frequencies df of the expansion terms. Higher df means a
longer inverted list, which means a longer execution time
when that term is part of the expanded query. Even with
optimizations (e.g. optimal skips [8]), an optimized shorter
list runs faster than an optimized longer list. A detailed
analysis of document frequencies is beyond the scope of this
paper, but the examples in Table 1 demonstrate the diﬀer-
ences: with as few as m = 15 expansion terms, the average
df of the highest weighted (best) expansion terms is in the
thousands for KL and Bo1, as opposed to the hundreds for
Reverted PL2.

In Section 4.4.1, we suggested that it might be possible

1056Selection Time (in milliseconds) for TREC678; Relevance Feedback (left) and Pseudo Relevance Feedback (right)

Execution Time (in milliseconds) for TREC678; Relevance Feedback (left) and Pseudo Relevance Feedback (right)

Figure 5: Selection (top) and execution (bottom) timing plots for RF and PRF experiments on TREC678.

to precompute some Bo1 and KL weights or at least partial
weights to achieve parity with reverted indexing’s enhanced
selection time. However, (from Figure 5) since execution
time dominates selection time by two orders of magnitude
(10s to 1000s of milliseconds), the overall eﬃciency of the
reverted approach would still dominate.
In summary, the
reverted indexing approach achieves equal (PRF) or greater
(RF) eﬀectiveness with an order of magnitude improvement
in eﬃciency.

5. FUTURE WORK

This paper introduces a framework for ad hoc retrieval of
basis queries (as results) using document-ids (as queries).
A basis query set and a base retrieval function combine to
construct the reverted index. By choosing speciﬁc reverted
retrieval functions and a reverted query language, we use
the reverted index for retrieval focusing on the problem of
automated query expansion. There are two major directions
for future work. One is to invent better methods for con-
structing and querying the reverted index; the other is to
create applications and interactions for the ad hoc retrieved
basis queries.

For reverted index construction, extensions include auto-
matically extracting bi-grams and longer n-grams, adding
facets and other metadata to the basis queries, and incorpo-
rating eﬀective queries mined from large scale search logs.
When creating the reverted index using base retrieval func-
tions, one is not limited to traditional IR models; any func-

tion that can produce a ranking can be used. For example,
to bring this approach more in line with Craswell et al. [9],
one could use relative click rates as a ranking function. A
reverted index would then allow users to construct ad hoc
multi-docid queries to retrieve the most likely basis queries
to have been responsible for producing clicks on those mul-
tiple documents.

Another interesting idea is to construct the index by run-
ning the same set of basis queries across multiple retrieval
algorithms or (web) search engines, and storing that algo-
rithmic choice as part of the basis query. When doing a
reverted query, one would then be able to retrieve or dis-
cover not only the best basis queries, but also the algorithm
or engine to use to produce those results.
Integration of
multiple media types (images and image queries, music and
music queries) is also possible; a reverted song ID query
could retrieve textual, audio, and image basis queries.

For reverted index querying, one interesting approach re-
lates to synonyms. If a user’s information need can be de-
composed into multiple aspects, then relevant documents
identiﬁed as belonging to each aspect could be treated as
synonyms. For example, if dw and dx are relevant to one
aspect, and dy and dz are relevant to another, the reverted
query could be [syn(dw dx) syn(dy dz)]. This conﬂation has
an eﬀect on global and local statistics and could produce bet-
ter results. Boolean constructs for integrating non-relevant
documents may be useful as well, e.g. if dw and dy are rel-

1057evant, and dx and dz are non-relevant, a possible ad hoc
reverted query might be: [(dw ∧ ¬ dx) ∨ (dy ∧ ¬ dz)].

6. CONCLUSION

In this paper, we described reverted indexes as a repre-
sentation for document collections. Using the retrievability
of documents, reverted indexes complement term-based in-
verted indexes. Index construction involves issuing a broad
set of basis queries to establish retrievability within the col-
lection. Document identiﬁers are then used as generalized
ad hoc queries against the reverted index to retrieve “rele-
vant” basis queries. Because the reverted index is wholly
analogous to standard inverted indexing, most Information
Retrieval techniques for ranking and retrieval (models, query
languages and operators, et cetera) are directly applicable.
Our experiments demonstrate high performance query ex-
pansion using reverted indexing in combination with proven
ranking techniques. Results show that this approach out-
performs two strong, established baselines for query expan-
sion for on test collections with consistent and signiﬁcant
improvements over a range of judgment depths and types.
Also, the computational costs of using reverted indexing are
substantially lower at retrieval time relative to the baselines.

7. REFERENCES
[1] Terrier information retrieval platform,

http://ir.dcs.gla.ac.uk/terrier/.

[2] G. Amati. Probability Models for Information

Retrieval based on Divergence from Randomness. PhD
thesis, Department of Computing Science, University
of Glasgow, June 2003.

[3] G. Amati and C. J. Van Rijsbergen. Probabilistic

models of information retrieval based on measuring
the divergence from randomness. ACM Trans. Inf.
Syst., 20(4):357–389, 2002.

[4] V. N. Anh and A. Moﬀat. Simpliﬁed similarity scoring

using term ranks. In SIGIR ’05: Proceedings of the
28th annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 226–233, New York, NY, USA, 2005. ACM.

[5] L. Azzopardi and V. Vinay. Retrievability: an

evaluation measure for higher order information access
tasks. In CIKM ’08: Proceeding of the 17th ACM
conference on Information and knowledge
management, pages 561–570, New York, NY, USA,
2008. ACM.

[6] B. Billerbeck, F. Scholer, H. E. Williams, and J. Zobel.

Query expansion using associated queries. In CIKM
’03: Proceedings of the twelfth international conference
on Information and knowledge management, pages
2–9, New York, NY, USA, 2003. ACM.

[7] J. Callan and M. Connell. Query-based sampling of

text databases. ACM Trans. Inf. Syst., 19(2):97–130,
2001.

[8] F. Chierichetti, S. Lattanzi, F. Mari, and

A. Panconesi. On placing skips optimally in
expectation. In WSDM ’08: Proceedings of the
international conference on Web search and web data
mining, pages 15–24, New York, NY, USA, 2008.
ACM.

[9] N. Craswell and M. Szummer. Random walks on the

click graph. In SIGIR ’07: Proceedings of the 30th
annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 239–246, New York, NY, USA, 2007. ACM.
[10] B. He and I. Ounis. Term frequency normalisation

tuning for bm25 and dfr model. In Proceedings of the
27th European Conference on Information Retrieval
(ECIR’05), pages 200–14. Springer, 2005.

[11] V. Lavrenko and W. B. Croft. Relevance based

language models. In SIGIR ’01: Proceedings of the
24th annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 120–127, New York, NY, USA, 2001. ACM.

[12] C. D. Manning, P. Raghavan, and H. Sch¨utze.

Introduction to Information Retrieval. Cambridge
University Press, New York, 2008.

[13] P. Ogilvie and J. Callan. The eﬀectiveness of query

expansion for distributed information retrieval. In
CIKM ’01: Proceedings of the tenth international
conference on Information and knowledge
management, pages 183–190, New York, NY, USA,
2001. ACM.

[14] J. M. Ponte and W. B. Croft. A language modeling

approach to information retrieval. In SIGIR ’98:
Proceedings of the 21st annual international ACM
SIGIR conference on Research and development in
information retrieval, pages 275–281, New York, NY,
USA, 1998. ACM.

[15] D. Puppin, F. Silvestri, and D. Laforenza.

Query-driven document partitioning and collection
selection. In InfoScale ’06: Proceedings of the 1st
international conference on Scalable information
systems, page 34, New York, NY, USA, 2006. ACM.

[16] D. Puppin, F. Silvestri, R. Perego, and

R. Baeza-Yates. Tuning the capacity of search engines:
Load-driven routing and incremental caching to
reduce and balance the load. ACM Trans. Inf. Syst.,
28(2):1–36, 2010.

[17] Y. Qiu and H.-P. Frei. Concept based query

expansion. In SIGIR ’93: Proceedings of the 16th
annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 160–169, New York, NY, USA, 1993. ACM.

[18] S. E. Robertson. Query-document symmetry and dual

models. Journal of Documentation, 50(3):233–238,
September 1994.

[19] J. J. Rocchio. Relevance feedback in information

retrieval. SMART Retrieval System Experimens in
Automatic Document Processing, 1971.

[20] M. Shokouhi, L. Azzopardi, and P. Thomas. Eﬀective

query expansion for federated search. In SIGIR ’09:
Proceedings of the 32nd international ACM SIGIR
conference on Research and development in
information retrieval, pages 427–434, New York, NY,
USA, 2009. ACM.

1058