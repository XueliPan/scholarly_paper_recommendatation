An Empirical Study of Privacy-Violating Information Flows

in JavaScript Web Applications

Dongseok Jang Ranjit Jhala Sorin Lerner Hovav Shacham

Dept. of Computer Science and Engineering

University of California, San Diego, USA
{d1jang,jhala,lerner,hovav}@cs.ucsd.edu

ABSTRACT
The dynamic nature of JavaScript web applications has
given rise to the possibility of privacy violating information
ﬂows. We present an empirical study of the prevalence of
such ﬂows on a large number of popular websites. We have
(1) designed an expressive, ﬁne-grained information ﬂow pol-
icy language that allows us to specify and detect diﬀerent
kinds of privacy-violating ﬂows in JavaScript code, (2) im-
plemented a new rewriting-based JavaScript information
ﬂow engine within the Chrome browser, and (3) used the
enhanced browser to conduct a large-scale empirical study
over the Alexa global top 50,000 websites of four privacy-
violating ﬂows: cookie stealing, location hijacking, history
sniﬃng, and behavior tracking. Our survey shows that sev-
eral popular sites, including Alexa global top-100 sites, use
privacy-violating ﬂows to exﬁltrate information about users’
browsing behavior. Our ﬁndings show that steps must be
taken to mitigate the privacy threat from covert ﬂows in
browsers.

Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and Protection – Unauthorized access;
D.2.4 [Software Engineering]: Software/Program Veriﬁ-
cation – Validation

General Terms
Security, Experimentation, Languages

Keywords
privacy, web security, information ﬂow, JavaScript, web ap-
plication, dynamic analysis, rewriting, history sniﬃng

1.

INTRODUCTION

JavaScript has enabled the deployment of rich browser-
based applications that are fashioned from code sourced

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
Copyright 2010 ACM 978-1-4503-0244-9/10/10 ...$10.00.

from diﬀerent mutually distrusting and potentially mali-
cious websites. However, JavaScript lacks language-based
protection and isolation mechanisms and sports several ex-
tremely dynamic language features. Browser-level isolation
policies like the same-origin policy for domain object model
(DOM) objects are coarse-grained and do not uniformly ap-
ply to application resources. Consequently, the proliferation
of JavaScript has also opened up the possibility of a variety
of security vulnerabilities.

In this paper, we present an empirical study of the preva-
lence of an important class of vulnerabilities that we call
privacy-violating information ﬂows. This general class in-
cludes several diﬀerent kinds of attacks that have been in-
dependently proposed and studied in the literature.

1. Cookie Stealing: Code included from a particular site,
say for displaying an advertisement, has access to all the
information on the hosting web page, including the cookie,
the location bar, and any other sensitive information stored
on the page. Thus, if the ad code is malicious it can cause the
cookie and other sensitive pieces of information to be leaked
to the third-party ad agencies, and can lead to a variety of
routinely observed attacks like request forgery.

2. Location Hijacking:
In a manner similar to the above
case, the dynamically loaded untrusted code can inﬂuence
the document’s location, by inﬂuencing the values stored in
URL string variables that are read to dynamically generate
HTTP requests. Consequently, the dynamically loaded code
can navigate the page to a malicious site that exploit a bug in
the browser to fully compromise the machine [24] or mounts
a phishing attack.

3. History Sniﬃng: In most browsers, all application do-
mains share access to a single visited-page history, ﬁle
cache, and DNS cache [12]. This leads to the possibility
of history sniﬃng attacks [14], where a malicious site (say,
attacker.com) can learn whether a user has visited a speciﬁc
URL (say, bankofamerica.com), merely by inducing the user
to visit attacker.com. To this end, the attack uses the fact
that browsers display links diﬀerently depending on whether
or not their target has been visited [6]. In JavaScript, the
attacker creates a link to the target URL in a hidden part
of the page, and then uses the browser’s DOM interface to
inspect how the link is displayed. If the link is displayed as a
visited link, the target URL is in the user’s history. Tealium
and Beencounter sell services that allow a website to collect
the browsing history of their visitors using history sniﬃng.

4. Behavior Tracking: The dynamic nature of JavaScript
allows a website to construct a high-ﬁdelity timeline of how

270a particular user interacted with a web page including, for
example, precise information about the user’s mouse clicks
and movements, scrolling behavior, and what parts of the
text were highlighted, simply by including JavaScript event
handlers that track mouse and keyboard activity. This in-
formation can then be sent back to the server to compute
statistics about how users interact with a given web page.
Several web-analytics companies sell products that exploit
these ﬂows to track information about users. For exam-
ple, ClickTale allows websites to precisely track their users’
mouse movements and compute aggregate heat maps based
on where users move their mouse, and tynt allows websites
to track what text is being copied from them. services al-
low websites to gather ﬁned-grained information about the
behaviors of their users without any indication to users that
additional information gathering is taking place. We be-
lieve that users understand that page navigation (as a re-
sult of clicking on a link) causes information to be sent to
the server, but do not believe they understand that other
actions,
like mousing over an image, can silently do the
same. Verifying this belief will require a user study. We
hope that the data we have collected will help inform the
broader discussion about the privacy implications of such
ﬂows.

Privacy-violating information ﬂows are not merely theo-
retical possibilities of academic interest. Indeed, the possi-
bility of history sniﬃng has prompted a discussion spanning
8 years and over 261 comments in Bugzilla about preventing
history sniﬃng in Firefox [3], which has ﬁnally culminated
in a recent ﬁx [2]. This lengthy process illustrates the im-
portance of privacy-violating ﬂows for Web 2.0 users and the
diﬃculty of designing defenses against them without break-
ing legitimate websites.

Despite the knowledge that privacy-violating ﬂows are
possible and even likely, little is actually known about their
occurrence in the wild. For example, how many websites
extract this kind of information from their users? Are there
any popular sites that do this? Do websites use pre-packaged
solutions like Tealium, Beencounter and ClickTale? Or do
they construct their own implementations? Are these imple-
mentations obfuscated to evade detection, and, if so, how?
The lack of empirical data about the prevalence of privacy-
violating ﬂows has hampered the development and deploy-
ment of eﬀective defenses against this increasingly important
class of attacks. The main contribution of this paper is to
provide concrete data to answer such questions through an
exhaustive empirical evaluation of several privacy-violating
ﬂows in a large number of popular websites. We have carried
out this study in three steps.

First, we have designed an expressive, ﬁne-grained infor-
mation ﬂow policy language that allows us to specify and de-
tect diﬀerent kinds of privacy-violating ﬂows in JavaScript
code (Section 2.1).
In essence, our language allows us to
describe diﬀerent privacy-violating ﬂows by specifying sites
within the code where taints are injected and sites from
which certain taints must be blocked. For example, to spec-
ify a cookie stealing ﬂow, we inject a “secret” taint into the
cookie, and block that taint from ﬂowing into variables con-
trolled by third-party code. To specify a location hijacking
ﬂow, we inject an “untrusted” taint onto any values origi-
nating third-party code, and block that taint from ﬂowing
into the document’s location ﬁeld. To specify a history sniﬀ-
ing ﬂow, we inject a “history” taint on the ﬁelds containing

the style attributes of links, and block that taint from ﬂow-
ing into the parameters of methods that send messages over
the network. To specify a behavior tracking ﬂow, we inject
“behavior” taint to the inputs of the handlers registered for
events triggered by user behavior.

Second, we have implemented a new JavaScript informa-
tion ﬂow engine in the Chrome browser. Unlike previous
JavaScript information ﬂow infrastructures [10, 30, 8], our
engine uses a dynamic source-to-source rewriting approach
where taints are injected, propagated and blocked within
the rewritten code (Section 2.2). Although the rewriting is
performed inside the browser, implementing our approach
requires understanding only the browser’s AST data struc-
ture, and none of the complexity of the JavaScript run-
time. Thus, in addition to supporting an extremely ﬂexi-
ble ﬂow policy speciﬁcation language, our approach is sim-
ple to implement and can readily be incorporated inside
other browsers. Even though the taints are propagated in
JavaScript, as opposed to natively, the overhead of our ap-
proach is not prohibitively high. Our approach adds on av-
erage 60 to 70% to the total page loading time over a fast
network (which is the worst condition to test our JavaScript
overhead). This is eﬃcient enough for our exploratory study,
and with additional simple optimizations could even be fea-
sible for interactive use (Section 3).

Third, we have used our modiﬁed version of the Chrome
browser to conduct a large-scale empirical study over the
Alexa global top 50,000 websites of four privacy-violating
ﬂows: cookie stealing, location hijacking, history sniﬃng
and behavior tracking. Our results reveal interesting facts
about the prevalence of these ﬂows in the wild. We did not
ﬁnd any instances of location hijacking on popular sites, but
we did ﬁnd that there are several third party ad agencies
to whom cookies are leaked. We found that several pop-
ular sites — including an Alexa global top-100 site — make
use of history sniﬃng to exﬁltrate information about users’
browsing history, and, in some cases, do so in an obfus-
cated manner to avoid easy detection. We also found that
popular sites, such as Microsoft’s, track users’ clicks and
mouse movements, and that huffingtonpost.com has the
infrastructure to track such movements, even though we did
not observe the actual ﬂow in our experiments. Finally, we
found that many sites exhibiting privacy-violating ﬂows have
built their own infrastructure, and do not use pre-packaged
solutions like ClickTale, tynt, Tealium, or Beencounter.
Thus, our study shows that popular Web 2.0 applications
like mashups, aggregators, and sophisticated ad targeting
are rife with diﬀerent kinds of privacy-violating ﬂows, and,
hence, there is a pressing need to devise ﬂexible, precise and
eﬃcient defenses against them.

2.

INFORMATION FLOW POLICIES

We present our approach for dynamically enforcing in-
formation ﬂow policies through an example that illustrates
the mechanisms used to generate, propagate and check taint
information for enforcing ﬂow policies. The focus of our in-
formation ﬂow policies and enforcement mechanism is to de-
tect many privacy-violating ﬂows in the wild, not to provide
a bullet-proof protection mechanism (although our current
system could eventually lead to a protection mechanism, as
discussed further in Section 7). For space reasons, we defer
a formal treatment of our rewriting algorithm to a technical
report [15].

271eval(load("http://adserver.com/display.js"));

r .f (x . . .)

var initSettings = function(s){

searchUrl = s;

initSettings("a.com");

var doSearch = function() {

var searchBox = getSearchBoxValue();
var searchQry = searchUrl + searchBox;
document.location = searchQry;

}

}

Figure 1: JavaScript code from a website a.com.

Web page Consider the JavaScript in Figure 1. Suppose
that this code is a distillation of the JavaScript on a web
page belonging to the domain a.com. The web page has a
text box whose contents can be retrieved using a call to
the function getSearchBoxValue (not shown). The func-
tion initSettings is intended to be called once to initialize
settings used by the page. The doSearch function is called
when the user clicks a particular button on the page.
Dynamically Loaded Code The very last line of the code
in Figure 1 is a call to load() which is used to dynam-
ically obtain a string from adserver.com. This string is
then passed to eval() which has the eﬀect of “executing”
the string in order to update the web page with an adver-
tisement tailored to the particular user.
Malicious Code Suppose that the string returned by the
call to adserver.com was:

initSettings("evil.com");

When this string is passed to eval() and executed, it over-
writes the page’s settings. In particular, it sets the variable
searchUrl which is used as the preﬁx of the query string,
to refer to an attacker site evil.com. Now, if the user clicks
the search button, the document.location gets set to the
attacker’s site, and thus the user is redirected to a website
which can then compromise her machine. Similarly, dynam-
ically loaded code can cause the user to leak their password
or other sensitive information.

2.1 Policy Language

The ﬂexibility and dynamic nature of JavaScript makes
it diﬃcult to use existing language-based isolation mecha-
nisms. First, JavaScript does not have any information hid-
ing mechanisms like private ﬁelds that could be used to iso-
late document.location from dynamically loaded code. In-
deed, a primary reason for the popularity of the language is
that the absence of such mechanisms makes it easy to rapidly
glue together diﬀerent libraries distributed across the web.
Second, the asynchronous nature of web applications makes
it diﬃcult to enforce isolation via dynamic stack-based ac-
cess control.
Indeed, in the example above, the malicious
code has done its mischief and departed well before the user
clicks the button and causes the page to relocate.

Thus, to reconcile safety and ﬂexible, dynamic code com-
position, we need ﬁne-grained isolation mechanisms that
prevent untrusted code from viewing or aﬀecting sensitive
data. Our approach to isolation is information ﬂow con-
trol [11, 21], where the isolation is ensured via two steps.

First, the website’s developer provides a ﬁne-grained policy
that describes which values can aﬀect and be aﬀected by
others. Second, the language’s compiler or run-time enforce
the policy, thereby providing ﬁne-grained isolation.

Policies In our framework a ﬁne-grained information ﬂow
policy is speciﬁed by deﬁning taints,
injection sites and
checking sites. A taint is any JavaScript object, e.g., a URL
string denoting the provenance of a given piece of informa-
tion. A site

corresponds to the invocation of the method f with the ar-
guments x . . ., on the receiver object r . Such site expressions
can contain concrete JavaScript (e.g., document.location),
or pattern variables (e.g., $1) that can match against dif-
ferent concrete JavaScript values, and which can later be
referenced.

In order to allow sites to match ﬁeld reads and writes, we
model these using getter and setter methods. In particular,
we model a ﬁeld read using a call to method getf, which
takes the name of the ﬁeld as an argument, and we model
a ﬁeld write using a call to a method setf, which takes
the name of a ﬁeld and the new value as arguments. To
make writing policies easier, we allow some simple syntactic
sugar in expressing sites: r .x used as an r-value translates
to r .getf(x) and r .x = e translates to r .setf(x, e).

An injection site

at S if P inject T

stipulates that the taint T be added to the taints of the
object output by the method call described by the site S as
long as the condition P holds at the callsite. For example,
the following injection site unconditionally injects a “secret”
taint at any point where document.cookie is read:

at document.cookie if true inject “secret”

To make the policies more readable, we use the following
syntactic sugar: when “if P ” is omitted, we assume “if true”.
As a result, the above injection site can be expressed as:

at document.cookie inject “secret”

(1)

A checking site

at S if P block T on V

stipulates that at site S , if condition P holds, the expression
V must not contain the taint T . We allow the guard (P ),
the taint (T ) and the checked expression (V ) to refer to the
any pattern variables that get bound within the site S . As
before, when “if P ” is omitted, we assume “if true”.
For example, consider the following checking site:

at $1.x=$2 if $1.url (cid:54)= “a.com” block “secret” on $2 (2)

The url ﬁeld referenced above is a special ﬁeld added by our
framework to every object, indicating the URL of the script
that created the object. The above checking site therefore
ensures that no value tainted with “secret” is ever assigned
into an object created by a script that does not originate
from a.com.
Conﬁdentiality policies can be speciﬁed by injecting a spe-
cial “secret” taint to the getter-methods for conﬁdential vari-
ables, and checking that such taints do not ﬂow into the
inputs of the setter-methods for objects controlled by code

272originating at domains other than a.com. Such a policy could
be formally speciﬁed using (1) and (2) above.

Integrity policies can be speciﬁed by injecting special “un-
trusted” taints to getter-methods for untrusted variables,
and checking that such taints do not ﬂow into the inputs
of setter-methods for trusted variables. Such a policy could
be formally specifed as:

at $1.x if $1.url (cid:54)= “a.com” inject “untrusted”
at document.location = $1 block “untrusted” on $1

We can specify even ﬁner grained policies by reﬁning the
taints with information about individual URLs. The ex-
pressiveness of our policy language allows us to quickly ex-
periment with diﬀerent kinds of ﬂows within the same basic
framework, and could also lay the foundation for a browser-
based protection mechanism.

2.2 Policy Enforcement

The nature of JavaScript and dynamic code loading makes
precise static policy enforcement problematic, as it is im-
possible to predict what code will be loaded at run-time.
Thus, our approach is to carry out the enforcement in a fully
dynamic manner, by rewriting the code in order to inject,
propagate and checks taints appropriately.

Although there are known dangers to using rewriting-
based approaches for protection [20], our current goal is
actually not protection, bur rather to ﬁnd as many privacy-
violating ﬂows as possible. As such, one of our primary con-
cerns is ease of prototyping and ﬂexibility; in this setting,
rewrite-based approaches are very useful. In particular, im-
plementing our approach only required understanding the
browser’s AST data structure, and none of the complexities
of the JavaScript runtime, which allowed us to quickly build
and modify our prototype as needed. Furthermore, keeping
our framework clearly separate from the rest of the browser
gives us the ﬂexibility of quickly porting our approach to
new versions of Chrome, or even diﬀerent browsers.

Policy Enforcement Our
framework automatically
rewrites the code using the speciﬁed injection and checking
sites to ensure that taints are properly inserted, propagated
and checked in order to enforce the ﬂow policy. First, we
use the checking (resp.
injection) sites to synthesize wrap-
pers around the corresponding methods that ensure that
the inputs only contain (resp. outputs are tainted with)
the taints speciﬁed by the corresponding taint expressions
whenever the corresponding guard condition is met. Sec-
ond, we rewrite the code so that it (dynamically) propagates
the taints with the objects as they ﬂow through the pro-
gram via assignments, procedure calls etc.. We take special
care to ensure correct propagation in the presence of tricky
JavaScript features like eval, prototypes, and asynchronous
calls.

Rewriting Strategy Our strategy for enforcing ﬂow poli-
cies, is to extend the browser with a function that takes a
code string and the URL from which the string was loaded,
and returns a rewritten string which contains operations
that perform the injection, propagation and checking of
taints. Thus, to enforce the policy, we ensure that the code
on the web page is appropriately rewritten before it is eval-
uated. We ensure that “nested” eval-sites are properly han-
dled as follows. We implement our rewriting function as a
procedure in the browser source language (e.g., C++) that

//var initSettings = function(){...}
tmp0 = box(function(s){searchUrl = s;}, "a.com"),
var initSettings = tmp0;

//initSettings("a.com");
tmp1 = box("a.com", "a.com"),
initSettings(tmp1);

//var doSearch = function(){...}
var doSearch = box(function(){

var searchBox = getSearchBoxValue();

//var searchQry = searchBox + searchUrl;
var searchQry = TSET.direct.add(searchUrl),

tmp2 = unbox(searchUrl),

TSET.direct.add(searchBox),
tmp3 = unbox(searchBox),

tmp4 = tmp2 + tmp3,
TSET.boxAndTaint(tmp4, "a.com");

//document.location = searchQry;
check(searchQry, "untrusted"),
document.location = searchQry;
}, "a.com");

//eval(load("http://adserver.com/display.js"));
tmp5 = box("http://adserver.com/display.js", "a.com"),
tmp6 = box(load(tmp5), "www.a.com"),
tmp6.url = tmp5,
eval(RW(tmp6, tmp6.url));

Figure 2: Rewritten code from a.com. The comments
above each block denote the original version of the
rewritten block.

can be called from within JavaScript using the name RW and
the rewriter wraps the arguments of eval within a call to
RW to ensure they are (recursively) rewritten before evalua-
tion [32].

When the rewriting procedure is invoked on the code from
Figure 1 and the URL a.com, it emits the code shown in
Figure 2. The rewriting procedure rewrites each statement
and expression.
(In Figure 2, we write the original code
as a comment above the rewritten version.) Next, we step
through the rewritten code to illustrate how taints are in-
jected, checked and propagated, for the integrity property
that speciﬁes that document.location should only be inﬂu-
enced by a.com.

Injection To inject taints, we extend every object with two
special ﬁelds url and taint. To achieve this, we wrap all
object creations inside a call to a special function box which
takes a value and a url and creates a boxed version of the
value where the url ﬁeld is set to url indicating that the ob-
ject originated at url , and the taint ﬁeld is set to the empty
set of taints. We do this uniformly for all objects, including
functions (e.g., the one assigned to initSettings), liter-
als (e.g., the one passed as a parameter to initSettings),
etc.. Next, we use the speciﬁed injection sites to rewrite the
code in order to (conditionally) populate the taint ﬁelds at
method calls that match the sites. However, the integrity
injection site does not match anywhere in the code so far,
and so no taints are injected yet – they will be injected when
code gets loaded from the ad server.

273Checking Before each call site that matches a speciﬁed
check site, we insert a call to a special check function. The
call to check is predicated on the check site’s condition.
The function check is passed the checked expression V and
taint T corresponding to the matching check site. The func-
tion determines whether the taints on the checked expression
contain the prohibited taint, and if so, halts execution.

For example, consider the rewritten version of the assign-
ment to document.location in the body of doSearch which
matches the checking site from the integrity policy. The
rewrite inserts a call to check. At run-time, when this
call is executed it halts the program with a ﬂow-violation
message if searchQry.taint has a (taint) value of the form
“untrusted”.
Propagation Next, we consider how the rewriting instru-
ments the code to add instructions that propagate the taints.

• For assignments and function calls, as all objects are
boxed, the taints are carried over directly, once we have
created temporaries that hold boxed versions of values.
For example, the call to initSettings uses tmp0, the
boxed version of the argument, and hence passes the
taints into the function’s formals. The assignment to
searchBox is unchanged from before, as the right-hand
side is function call (whose result has already been
appropriately boxed).

• For binary operations, we must do a little more work,
as many binary operations (e.g., string concatena-
tion) require their arguments be unboxed. To handle
such operations, we extend the code with a new ob-
ject called the taint-set, named TSET. We use this
object to accumulate the taints of sub-expressions
of compound expressions. The object supports two
operations.
First, TSET.direct.add(x, url), which
adds the taints in x.taint to the taint-set. Second,
TSET.boxAndTaint(x, url), which creates a boxed ver-
sion of x (if it is not boxed), and the taints accumulated
on the taint-set, clears the taint-set, and returns the
boxed-and-tainted version of x. We use the direct
ﬁeld as there are several other uses for the TSET object
that are explained later. For example, consider the
rewritten version of searchBox + searchUrl. We add
the taints from searchBox (resp. searchUrl) to the
taint-set, and assign an unboxed version to the fresh
temporary tmp2 (resp. tmp3). Next, we concatenate
the unboxed strings, and assign the result to tmp4. Fi-
nally, we call TSET.boxAndTaint(tmp4, “a.com”), which
boxes tmp4, adds the taints for the sub-expressions
stored in the taint-set and returns the boxed-and-
tainted result.

• For code loading operations (modeled as load(·)), the
rewriting boxes the strings, and then adds a url ﬁeld
to the result that indicates the domain from which
the string was loaded. For example, consider the code
loaded from adserver.com. The name of the URL is
stored in the temporary tmp5, and the boxed result is
stored in a fresh temporary tmp6, to which we add a
url ﬁeld that holds the value of tmp5.

it is evaluated. For example, consider the operation
at the last line of the code from Figure 1 which eval’s
the string loaded from adserver.com. In the rewritten
version, we have a boxed version of the string stored
in tmp6; the rewriting ensures that the string that gets
executed is actually tmp6 rewritten assuming it origi-
nated at tmp6.url, which will have the eﬀect of ensur-
ing that taints are properly injected, propagated and
checked within the dynamically loaded code.

The above code assumes, for ease of exposition, that the
ﬁelds taint and url are not read, written or removed by
any code other than was placed for tracking.
Attack Prevention Suppose that the load(·) operation re-
turns the string initSettings("evil.com"). The rewritten
code invokes the rewriting function RW on the string, and the
URL adserver.com yielding the string

tmp10 = box("evil.com", "adserver.com"),
if (tmp10.url != "a.com"){

tmp10.taint += ["untrusted"]

},
initSettings(tmp10);

The if-expression injects the taints to the value re-
turned by the implicit getter-call (i.e., the read of tmp10)
that yields the value passed to initSettings. Thus,
the argument passed to initSettings carries the taint
“untrusted”, which ﬂows into searchUrl when the as-
signment inside initSettings is executed. Finally, when
the button click triggers a call to doSearch, the taint
ﬂows through the taint-set into the value returned by the
call TSET.boxAndTaint(tmp4, “a.com”), and from there into
searchQry. Finally, the check (just before the assignment to
document.location) halts execution as the ﬂow violates the
integrity policy, thereby preventing the redirection attack.
Rewriting for Conﬁdentiality Policies The above exam-
ple illustrates how rewriting enforces integrity policies. The
case for conﬁdentiality policies diﬀers only in how taints are
injected and checked; the taints are propagated in an identi-
cal fashion. To inject taints, the rewriting adds a “secret”
taint to the results of each read from a conﬁdential object
(e.g., document.cookie.) To check taints, the rewriting in-
serts calls to check before any writes to variables (i.e., invo-
cations of setter methods) in code originating in untrusted
URLs. The check halts execution before any value with the
“secret” taint can ﬂow into an untrusted location.
Robustness Even though the primary purpose of our tool
so far has been to evaluate existing ﬂows (a scenario under
which we don’t need to worry about malicious code trying
to subvert our system), our framework does in fact protect
its internal data structures from being maliciously modiﬁed.
In particular, our tool disallows a user JavaScript program
from referencing any of the variables and ﬁelds used for taint
tracking such as TSET. More speciﬁcally, since our frame-
work tracks reads and writes to all variable and ﬁeld, it can
simply stop a program that tries to read or write to any of
the internal variables that we use to track information ﬂow.

2.3 Indirect Flows

• For eval operations, our rewriting interposes code that
passes the string argument to eval and the URL from
which the string originated to the the rewriting func-
tion RW, thereby ensuring the code is rewritten before

Next, we look at how the rewriting handles indirect ﬂows
due to control dependencies. We start with the data struc-
ture that dynamically tracks indirect ﬂows, and then de-
scribe the key expressions that are aﬀected by indirect ﬂows.

274Indirect Taint Stack (TSET.indirect) To track indirect
ﬂows, we augment the taint set object with an indirect-taint
stack (named TSET.indirect). Our rewriting ensures that
indirect taints are added and removed from the indirect taint
stack as the code enters and leaves blocks with new control
dependences. The TSET.boxAndTaint(·, ·) function, which
is used to gather the taints for the RHS of assignments,
embellishes the (RHS) object with the direct taints at the
top of the direct taint stack, and the indirect taints stored
throughout the indirect taint stack. The latter ensures that
at each assignment also propagates the indirect taints that
held at the point of the assignment.
Branches For branch expressions of the form if e1 e2 e2,
we ﬁrst assign the rewritten guard to a new temporary tmp1,
and push the taints on the guard onto the indirect taint
stack. These taints will reside on the indirect taint stack
when (either) branch is evaluated, thereby tainting the as-
signments that happen inside the branches. After the entire
branch expression has been evaluated, the rewritten code
pops the taints, thereby reverting the stack to the set of
indirect taints before the branch was evaluated.
Example
expression:
if (z) { x = 0 } To ensure that taints from z ﬂow
into x when the assignment occurs inside the then-branch,
the expression is rewritten to:

Consider

branch

the

tmp = z,
TSET.indirect.push(tmp),
if (unbox(tmp)){

},
TSET.indirect.pop()

x = TSET.boxAndTaint(box(0,...),...)

The ellipses denote the URL string passed to RW and we
omit the calls to check and TSET.direct.add(·, ·) for brevity.
The rewrite ensures that the taints from the guard z are on
the indirect taint stack inside the branch, and these taints
are added to the (boxed version of) 0 that is used for the
assignment, thereby ﬂowing them into x. The pop after the
branch ﬁnishes reverts the indirect stack to the state prior
to the branch.
Indirect vs. Implicit Flows. The above example illus-
trates a limitation of our fully dynamic approach; we can
track indirect ﬂows induced by a taken branch (such as the
one above) but not implicit ﬂows that occur due to a not-
taken branch. For example, if the above branch was pre-
ceded by an assignment that initialized x with 1, then an
observer that saw that x had the value 1 after the branch
would be able to glean a bit of information about the value
of z. Our rewriting, and indeed, any fully dynamic analysis
[7] will fail to detect and prohibit such implicit ﬂows.
Function Calls Our rewriting adds an indirect taint pa-
rameter to each function deﬁnition. This parameter holds
the indirect taints that hold at the start of the function
body; the taints on it are pushed onto the indirect taint
stack when the function begins execution. Furthermore, the
rewriting ensures that at each function callsite, the indirect
taints (in the indirect taint stack) at the caller are passed
into the indirect taint parameter of the callee.
Event Handlers cause subtle information ﬂows. For ex-
ample, if foo is the handler for the MouseOver event, the
fact that foo is executed contains the information that the
mouse hovered over some part of the page. We capture these

ﬂows as indirect ﬂows triggered by the tests within the DOM
event dispatch loop

while(1){

e = getEvent();
if (e.isClick()) onClick(e);
if (e.isMouseOver()) onMouseOver(e);
if (e.isScroll()) onScroll(e);
...

}

to capture ﬂows

Thus,
triggered by a MouseOver
event, we simply inject a taint at the output of the
$1.isMouseOver(...). The if ensures that the taint ﬂows
into the indirect taint parameter of the registered handler
(bound to onMouseOver).
Full JavaScript The examples described in this section
have given a high-level overview of our rewriting-based ap-
proach to enforcing information ﬂow policies. Our imple-
mentation handles all of JavaScript including challenging
language features like prototypes, with-scoping, and higher-
order functions. Our implementation also incorporates sev-
eral subtle details pertaining to how taints can be stored
and propagated for unboxed objects, to which a taint ﬁeld
cannot be added. The naive strategy of boxing all objects
breaks several websites as several DOM API functions re-
quire unboxed objects as arguments. We refer the reader to
an accompanying technical report [15] for the details.

3.

IMPLEMENTATION AND PERFOR-
MANCE EVALUATION

This section presents our implementation of rewrite-based
information ﬂow framework for JavaScript in the Chrome
browser, and describes several experiments that quantify the
performance overhead of our approach.

Implementation We implement the rewriting function as
a C++ method (within Chrome) that is invoked on any
JavaScript code just before it gets sent into the V8 execu-
tion engine. Thus, our implementation rewrites every piece
of JavaScript including that which is loaded by <script>
tags, executed by eval or executed by changing the web
page via document.write. The TSET library is implemented
in pure JavaScript, and we modiﬁed the resource loader of
Chrome to insert the TSET library code into every JavaScript
program it accesses. The TSET library is inserted into each
web page as ordinary JavaScript using a <script> tag before
any other code is loaded. The ﬂow-enhanced Chrome can
run in normal mode or in taint tracking mode. When the
taint tracking is on, the modiﬁed Chrome tracks the taint
ﬂow as a user surfs on websites.

Optimizations We describe the three most important op-
timizations we performed for the “optimized” bar. The ﬁrst
and most important optimization is that we implemented
the two most frequently executed TSET methods using 65
lines of C++, namely the methods for taint lookup and un-
boxing. Second, in the TSET.direct stack, when there is a
pop followed by a push, and just before the pop there are
no taints stored at the top of the stack, we cache the object
at the top of the stack before poping, and then reuse that
same object at the next push, thus avoiding having to create
a new object. Because the push is called on every assign-
ment, removing the object creation provides a signiﬁcant

275Site and rank

1. google
2. yahoo
3. facebook
4. youtube
5. myspace
6. wikipedia
7. bing
8. blogger
9. ebay

10. craigslist
11. amazon
12. msn
13. twitter
14. aol
15. go
−. Average

Total
KLOC
1.8
7.4
9.1
7.5
12.2
<0.1
0.7
1.8
13.6
0
5.3
7.3
5.6
12.7
1.1
8.2

Other KLOC
s
w

# Taint Val(k)
s
w

d

d
-
-
-
0
9.1
9.1
7.3
5.7
-
8.6
-
-
-
-
-
0
-
12.9
-
-
-
-
6.1
5.6
-
1.3
- <0.1
-
3.0

0.2
4.5

0
7.0
9.1
7.3
11.9
0
0
1.1
13.4
0
4.8
6.7
5.5
9.6
0.9
6.1

0
29.5
12.4
21.0
35.3
0
0
0.8
244.9
0
40.1
462.4
48.2
129.8
76.3
63.1

-
-
9.3
20.7
-
-
-
-
-
-
-
462.3
-
-
2.0
52.7

s

Cookie

d w s

Location
d w
- × × × × × ×
0 × × × × × ×
8.4 × × × × × ×
20.7 (cid:88) (cid:88) (cid:88) × × ×
28.4 (cid:88) (cid:88) (cid:88) × × ×
- × × × × × ×
- × × × × × ×
0.2 (cid:88) (cid:88) × × × ×
244.9 (cid:88) (cid:88) (cid:88) × × ×
- × × × × × ×
- × × × × × ×
462.3 (cid:88) × × × × ×
38.3 × × × × × ×
60.9 (cid:88) (cid:88) × × × ×
- (cid:88) × × × × ×
0

35.9

38

48

17

0

0

Figure 3: Flow results for a subset of the Alexa global 100 (last row summarizes results for all 100 sites).

savings. Third, we also cache ﬁeld reads in our optimized
TSET library. For example, whenever a property a.b is refer-
enced several times in the library, we store the value of the
property in a temporary variable and reuse the value again.
This produces signiﬁcant savings, despite the fact that all
our measurements used the JIT compiler of the V8 engine.
Benchmarks We employ a set of stress experiments us-
ing the standard cookie conﬁdentiality and location integrity
policies to evaluate the eﬃciency of our approach and the
eﬀect of optimizations. These policies require a signiﬁcant
amount of taint propagation, as the cookie and location
properties are heavily accessed. As our benchmarks, we use
the front pages on the websites from the latest Alexa global
top 100 list. Alexa is a company which ranks websites based
on traﬃc. The websites on the Alexa global top 100 vary
widely in size and how heavily they use JavaScript, from 0.1
KLOC to 31.6 KLOC of JavaScript code. We successfully
ran our dynamic analysis on all of the pages of Alexa global
top 100 list, and we visited many of them manually to make
sure that they function properly.

3.1 Policies

To measure eﬃciency, we checked two important policies
on each site. First, document.cookie should remain conﬁ-
dential to the site. Second, document.location should not
be inﬂuenced by another site. Both policies depend on a
deﬁnition of what “another site” is. Unfortunately, using ex-
actly the same URL or domain name often leads to many
false alarms as what looks like a single website is in fact the
agglomeration of several diﬀerent domain names. For ex-
ample, facebook.com refers to fbcdn.net for many of their
major resources, including JavaScript code. Moreover, there
are relatively well known and safe websites for traﬃc statis-
tics and advertisements, which are referenced on many other
websites, and one may want to consider those as safe. Thus,
we considered three URL policies (i.e., three deﬁnitions for
“another site”) (1) the same-origin policy stating that any
website whose hostname is diﬀerent from the hostname of
the current one is considered a diﬀerent site. (2) the same-
domain policy, which is the same as the same-origin policy,
except that websites from the same domain are considered
to be the same (e.g., ads.cnn.com is considered the same as
www.cnn.com). (3) the white-list policy, which is the same
as the same-domain policy, except that there is a global

list of common websites that are considered the same as
the source website. For our experiments, we treat websites
referenced by three or more diﬀerent Alexa benchmarks as
safe. The white-list mainly consists of statistics and adver-
tisement websites. We use a whitelist only to evaluate the
performance of our system under such conditions; we leave
the exact criteria for trusting a given third-party site to fu-
ture work. Our rewriting framework makes it trivial to con-
sider diﬀerent URL policies; we need only alter the notion of
URL equality in the checks done inside TSET.boxAndTaint
and TSET.check.

Detected Flows Figure 3 shows the results of running our
dynamic information framework on the Alexa global top 100
list using the above policies. Because of space constraints,
we only show a subset of the benchmarks, but the average
row is for all 100 benchmarks.

The columns in the table are as follows: “Site and rank” is
the name of the website and its rank in the Alexa global 100
list; “Total KLOC” is the number of lines of JavaScript code
on each website, including code from other sites, as format-
ted by our pretty printer; “Other KLOC” is the number of
lines of code from other sites; “# Taint Val” is the number
of dynamically created taint values; “Cookie” describes the
document.cookie conﬁdentiality policy, and “Location” de-
scribes the document.location integrity policy: (cid:88)indicates
policy violation, and ×indicates no ﬂow i.e., policy satisfac-
tion.

The above columns are sub-categorized into three sub-
columns depending on the applied URL policy: “s” is for the
same-origin policy; “d” is for the same-domain policy; “w”
is for the white-list policy. A dash in a table entry means
that the value for that table entry is the same as the entry
immediately to its left.

The code for each website changes on each visit. Thus, we
ran our enhanced Chrome 10 times on each website. To gain
conﬁdence in our tool, we manually inspected every program
on which a ﬂow is detected, and conﬁrmed that every ﬂow
was indeed real.

Variation based on URL policies The number of lines of
code from other sites decreases as we move from the same-
origin policy to the same-domain policy to the white-list
policy. Note that in some cases, for example facebook, code
from other sites is almost the same as the total lines of code.

276Figure 4: Slowdown for JavaScript (left) and Page Loading (right)

This is because most of the JavaScript code for facebook
comes from a website fbcdn.net. This website is not in
the same domain as facebook, and it is only referenced by
one website and hence, not included in our whitelist.
In
such situations, a site-speciﬁc white-list would help, but we
have not added such white-lists because it would be diﬃcult
for us to systematically decide for all 100 benchmarks what
these white-lists should be. Thus, as we do not use site-
speciﬁc white-lists, our policy violations may not correspond
to undesirable ﬂows.

As the amount of other-site code decreases as we move
from “s” to “d” to “w”, the number of dynamically created
taint values also decreases, at about the same rate. That
is, a large drop in other-site code leads to a correspondingly
large drop in the number of taint values created. Moreover,
as expected, the number of policy violations also decreases,
as shown on the last line of the table: the violations of the
document.cookie policies goes from 48 to 38 to 17. We did
not see a violation of the document.location policy in any
of our benchmarks.

3.2 Timing Measurements

Our rewrite-based information ﬂow technique performs
taint-tracking dynamically, and so it is important to eval-
uate the performance overhead of our approach. We mea-
sure performance using two metrics: total page load time,
and JavaScript run time. We modiﬁed the Chrome browser
to allow us to measure for each website (1) the time
spent executing JavaScript on the site, and (2) the to-
tal time spent to download and display the site. Fig-
ures 4 describes our timing measurements for JavaScript
time, and total download time on the 10 benchmarks with
the largest JavaScript code bases. The measurements were
performed while tracking both the document.cookie conﬁ-
dentiality and document.location integrity policies. The
“average” benchmark represents the average time over all
10 benchmarks. For each benchmark there are ﬁve bars
which represent running time, so smaller bars mean faster
execution. For each benchmark, the 5 bars are normal-
ized to the time for the unmodiﬁed Chrome browser for
that benchmark. Above each benchmark we display the
time in milliseconds for the unmodiﬁed Chrome browser
(which indicates what “1” means for that benchmark). The
left most bar “not-optimized” represents our technique us-

ing the original version of our TSET library, and using the
same-origin URL policy. For the remaining bars, each
bar represents a single change from the bar immediately
to its left: “optimized” uses a hand-optimized version of
our TSET library, rather than the original version; “dmn”
changes the URL policy to same-domain; “whlist” changes
the URL policy to white-list; and “trust-all” changes the
URL policy to the trivial policy where all websites are
trusted.

JavaScript execution time The left chart of Figure 4
shows just the JavaScript execution time. As expected,
the bars get shorter from left-to-right; from “not-optimized”
to “optimized”, we are adding optimizations; and then the
remaining bars consider progressively more inclusive URL
policies meaning there are fewer taints to generate, propa-
gate and check.

The data from Figure 4 shows that our original TSET li-
brary slows down JavaScript execution signiﬁcantly – any-
where from about 2.1X to 7.9X, and on average about 4.3X.
The optimized TSET library provides signiﬁcant performance
gains over the original library and provides 3.0X slowdown.
The various white-lists provide some additional gain, but
the gain is relatively small. To understand the limits of
how much white-lists can help, we use the “trust-all” bar,
which essentially corresponds to having a white-lists with
every website on it. Overall, it seems that even in the best
case scenario, white-lists do not help much in the overhead
of our approach. This is because our approach needs to
track the ﬂow of cookie regardless of the number of exter-
nal sites.

Total execution time The right chart of Figure 4 shows
the total execution time of the enhanced Chrome while load-
ing the web page and running the scripts on it. These
measurements were collected on a fast network at a large
university. The faster the network, the larger the over-
heads in Figure 4 will be, as the time to download the web
page can essentially hide the overhead of running JavaScript.
Thus, by using a fast network, Figure 4 essentially shows
some of the worst case slowdowns of our approach. Here
again, we see that the “optimized” bar is signiﬁcantly faster
than the “not-optimized” bar. We can also see that the
“whlst” bar provides a loading experience that is about 73%
slower.

not optimizedoptimizeddmnwhlsttrust‐allnot optimizedoptimizeddmnwhlsttrust‐all15511653144957477811451155411801220675673842163298713671729312201804953113651367250821278947760342508117812110huff‐postwsjmapquestfoxnewscnnnytimestwitpicweatherwalmartlatimesaverage0huff‐postwsjmapquestfoxnewscnnnytimestwitpicweatherwalmartlatimesaverage2774. EMPIRICAL STUDY OF HISTORY HI-

JACKING

Next, we present an empirical study of the prevalence of
history hijacking on popular websites. Recall that links cor-
responding to URLs visited by the user are typically ren-
dered diﬀerently than links corresponding to URLs not vis-
ited by the user. In essence, the attack works by inserting
invisible links into the web page and having JavaScript in-
spect certain style properties of links, for example the color
ﬁeld, thereby determining whether the user has visited a
particular URL. While researchers have known about the
possibility of such attacks, hitherto it was not known how
prevalent they are in real, popular websites. We have used
our JavaScript information ﬂow framework to detect and
study the prevalence of such attacks on a large set of web-
sites, and show that history hijacking is used, even by quite
popular websites.

Policies We formalize history hijacking in our framework
using the following information ﬂow policies:

at $1.getCompStyle($2, . . .) if $2.isLink() inject “secret”
at document.send($1, $2) block “secret” on $2

In particular, whenever the computed style of a link is
read using getCompStyle, the return value is marked as
secret. Whenever a value is sent on the network using
document.send, the second parameter (which is the actual
data being sent) should not be tainted.

Benchmarks and Summary of Results To evaluate the
prevalence of history hijacking, we ran our information ﬂow
framework using the above two policies on the front pages of
the Alexa global top 50,000 websites.1 To visit these sites au-
tomatically, we implemented a simple JavaScript web page
that directs the browser to each of these websites. We suc-
cessfully ran our framework on these sites in a total of about
50 hours. The slowdown for history sniﬃng was as follows:
the JavaScript code slowed down by a factor 2.4X and to-
tal page loading time on a fast network increased by 67%.
Overall, we found that of these 50,000 sites, 485 of them in-
spect style properties that can be used to infer the browser’s
history. Out of 485 sites, 63 are reported as transferring the
browser’s history to the network, and we conﬁrmed that 46
of them are actually doing history hijacking, one of these
sites being in the Alexa global top 100.

Real cases of history sniﬃng Out of 63 websites reported
as transferring the browser’s history by our framework, we
conﬁrmed that the 46 cases were real history sniﬃng occur-
rences. Table 1 lists these 46 websites. For each history-
sniﬃng site, we give its Alexa rank, its URL, a description
of the site, where the history-sniﬃng code comes from, and
a list of some of the URLs inspected in the browser history.
Each one of the websites in Table 1 extracts the visitor’s
browsing history and transfers it to the network. Many of
these websites seem to try to obfuscate what they are do-
ing. For example, the inspected URLs on youporn.com are
listed in the JavaScript source in encoded form and decoded
right before they are used. On other websites, the history-
sniﬃng JavaScript is not statically inserted in a web page,
but dynamically generated in a way that makes it hard to
understand that history sniﬃng is occurring by just looking

1Here and elsewhere in the paper we use the Alexa list as of
February 1st, 2010.

Rank Site
61
867
2333
2415
2811
3508
3603
4266
4581
5233
5357
6500
7198
7323
8064
8644
9616
10152
10415
11330
12084
12164
16752
17379
17655
17882
18361
20240
20822
22010
23577
23626
24109
24414
24597
24815
25750
27366
31638
34661
35773
37333
41490
45264
48284
49549

youporn
charter.net
feedjit
gamestorrents
newsmax
namepros
fulltono
youporngay
osdir
gamesfreak
morningstar
espnf1
netdoctor
narutocentral
subirimagenes
fucktube
straightdope
guardafilm
estrenosdtl
bgames
10best
twincities
kaushik.net
todocvcd
filmannex
planet-f1
trailersplay
minyanville
pixmac
fotoflexer
xepisodes
s-p*
mimp3.net
allaccess
petitchef
bleachcentral
hoopsworld
net-games.biz
6speedonline
msgdiscovery
moneynews
a-g*
divxatope
subtorrents
sesionvip
youporncocks

Src
H
I
F
M
I
F
M
H
I
I
I
I
I
I

Desc
adult
news
traﬃc
fun
news
forum
music
adult
tech
fun
ﬁnance
sports
health
fun
hosting M
H
adult
I
news
M
movie
movie
M
I
fun
I
travel
I
news
blog
H
content M
I
movie
I
sports
M
movie
ﬁnance
I
hosting H
I
widget
fun
M
F
movie
M
music
I
news
M
food
fun
I
I
sports
I
fun
I
car
M
tech
ﬁnance
I
religion H
content M
content M
M
movie
adult
H

Inspected URLs
pornhub,tube8,+21
cars,edmunds,+46
twitter,facebook,+6
amazon,ebay,+220
cars,edmunds,+46
twitter,facebook,+6
amazon,ebay,+220
pornhub,tube8,+21
cars,edmunds,+46
cars,edmunds,+46
cars,edmunds,+46
cars,edmunds,+46
cars,edmunds,+46
cars,edmunds,+46
amazon,ebay,+220
tube8,xvideos,+9
cars,edmunds,+46
amazon,ebay,+220
amazon,ebay,+220
cars,edmunds,+46
cars,edmunds,+46
cars,edmunds,+46
facebook,+100
amazon,ebay,+220
cars,edmunds,+46
cars,edmunds,+46
amazon,ebay,+220
cars,edmunds,+46
istockphoto,+27
amazon,ebay,+220
amazon,ebay,+220
facebook,youtube,+8
amazon,ebay,+220
amazon,ebay,+220
amazon,ebay,+220
amazon,ebay,+220
amazon,ebay,+220
cars,edmunds,+46
cars,edmunds,+46
amazon,ebay,+220
cars,edmunds,+46
facebook,+62
amazon,ebay,+220
amazon,ebay,+220
amazon,ebay,+220
pornhub,tube8,+21

Table 1: Websites that perform real sniﬃng. Top-
level domains are .com if not otherwise speciﬁed.
s-p and a-g abbreviate sincortespublicitarios.com
and answersingenesis.org. “Src” is the source of
the history sniﬃng JavaScript code: “I”, “M” and
“F”, indicate the code came from interclick.com,
meaningtool.com, and feedjit.com respectively, and
“H” indicates the code came from the site itself.

at the static code. We also found that many of these web-
sites make use of a handful of third-party history-sniﬃng
libraries. In particular, of the 46 cases of conﬁrmed sniﬃng,
22 sites use history-sniﬃng code from interclick.com and
14 use history-sniﬃng code from meaningtool.com.

Figure 5 shows the JavaScript attack code exactly as found
on youporn.com. The code creates an obfuscated list of in-
spected websites (line 1). We only show part of the list —
the actual list had 23 entries. For each site, the code decodes
the website name (line 6), creates a link to the target site on
the page (lines 11–12), reads the color of the link that was

2781:var k = { 0: "qpsoivc/dpn",

1: "sfeuvcf/dpn", ... };

2:var g = [];
3:for(var m in k) {
4: var d = k[m];
5: var a = "";
6: for(var f = 0; f < d.length; f++) {

a += String.fromCharCode(d.charCodeAt(f)-1)

}

7: var h = false;
8: for(var j in {"http://":"","http://www.":""}){
9:
10:
11:

var l = document.createElement("a");
l.href = j + a;
document.getElementById("ol").

12:
13:

14:
15:
16:

17:
18:

appendChild(l);

var e = "";
if(navigator.appName.

e = l.currentStyle.color

} else {

e = document.defaultView.

indexOf("Microsoft") != -1 ){

getComputedStyle(l, null).

getPropertyValue("color")

}
if(e == "rgb(12, 34, 56)" ||

e == "rgb(12,34,56)") { h = true }

19: }
20: if(h) { g.push(m) }
21:}
22:var b = (g instanceof Array)? g.join(",") : "";
23:var c = document.createElement("img");
24:c.src= "http://ol.youporn.com/blank.gif?id="+b;
25:document.getElementById("ol").appendChild(c)

Figure 5: Attack code as found on youporn.com

just created (lines 12–17), and ﬁnally tests the color (line
18). If the color indicates a visited link, the h variable is set
to true, which in turn causes the link to be inserted in the
list g of visited sites (line 20). This list is then ﬂattened into
a string (line 22), and an image is added to the current web
page, encoding the ﬂattened string into the src name of the
image (lines 23–25).

The ﬂow in Figure 5 from the color property e to the ar-
ray of visited sites g is actually an indirect ﬂow that passes
through two conditionals (on lines 18 and 20). Our frame-
work’s ability to track such indirect ﬂows allowed us to ﬁnd
this history-sniﬃng attack. Note however that our frame-
work found the ﬂow because the sites being tested had ac-
tually been previously visited (because we had already run
the experiments once, and so all the top 50,000 Alexa global
sites were in the history). If none of the tested sites had been
visited, the g array would have remained empty, and no vio-
lation of the policy would have been observed, even though
in fact the user’s empty history would have been leaked.
This example is precisely the implicit ﬂow limitation that
was mentioned in Section 2.3.

False-positive cases of history sniﬃng Of the 63 sites
ﬂagged by our framework, 17 are false positives in that a
manual examination of the source code and run-time behav-
ior did not allow us to conclude that they were real cases of
history sniﬃng. Out of these 17 sites, 12 contain JavaScript
code that is too complicated to understand. The remaining 5
sites contain a history sniﬃng widget from interclick.com,
but no suspicious runtime behavior was detected by monitor-
ing their network access. Our framework reported these sites

Provider Description
addtoany
infolinks
kontera
other

social
advertisement
advertisement
-

Sites
83
124
87
32

Inspected URLs
120.2
14
11.5
44.4

Table 2: Characteristics of suspicious websites de-
pending on JavaScript widget provider

either because they inspected style properties for purposes
other than history sniﬃng, or because too many irrelevant
values were tainted by our handling of indirect ﬂows.

A more stringent policy To investigate the possibility of
history hijacking further, we also looked at all the sites that
simply read the computed style of a link. This uncovered an
additional 422 websites that read style properties of links,
but did not send the properties out on the network. Un-
fortunately, because our framework does not cover all the
corner cases of information ﬂow in JavaScript (as discussed
later), we cannot immediately conclude that these sites did
not transfer the browser history. Even if we were certain
that the style information was not sent to the network, it is
still possible that the absence of sending data was used to re-
veal information about the browsing history. For example,
if a site sent the browsing history only if a link was vis-
ited, then the server could have learned about certain links’
not being visited without any information’s being transfered
from the client. Thus, to better understand the behavior of
these additional websites, we inspected them in detail, and
categorized them into two bins: suspicious websites, and
non-suspicious websites.

Suspicious sites Of the 422 sites, 326 sites exhibit what
we would categorize as suspicious behavior. In particular,
these suspicious websites inspect a large number of external
links, and some of these links are dynamically generated, or
they are located in an invisible iframe. We found that many
of them embed a JavaScript widget developed by another
website that inspects the browser history systematically.

Table 2 shows how such widgets are used on the 326 sites.
For each JavaScript widget, we give the name of its provider,
a description of its provider, the number of sites embedding
it, and the number of URLs it inspects on average over the
sites on which it is embedded. The most notable is a menu
widget developed by addtoany.com which inspects around
120 URLs on average to activate or deactivate each menu
item depending on the browser history.

Non-suspicious sites The remaining 96 sites seemed non-
suspicious. Of these, 77 simply inspect their own website
history. The remaining 19 samples have JavaScript code
that is too complicated for us to fully understand, but where
the sites seem non-suspicious.

Incompleteness Our current implementation would miss
information ﬂow induced by certain browser built-in meth-
ods. For example, consider the code:

arr.push(z); var result = arr.join(’,’)

The value z is inserted into an array and then all the el-
ements of the array are joined into a string using the the
built-in method join. Even though we have implemented
a wrapper object for arrays to track array assignments and

279reads, we have not yet implemented a complete set of wrap-
pers for all built-in methods. Thus, in the above case, even
though result should be tainted, our current engine would
not discover this.
It would be straightforward, although
time-consuming, to create precise wrappers for all built-in
methods that accurately reﬂect the propagation of taints.
Moreover, our current implementation does not track infor-
mation ﬂow through the DOM, although recent techniques
on tracking information ﬂow through dynamic tree struc-
tures [25] could be adapted to address this limitation.

Even if our implementation perfectly tracked the taints of
all values through program execution, our approach would
still miss certain history hijacking attacks. For example, the
attacking website can use a style sheet to set the font of vis-
ited links to be much larger than the size of unvisited links.
By placing an image below a link, and using JavaScript to
observe where the image is rendered, the attacker can de-
termine whether the link is visited or not. These kinds of
attacks that use layout information would currently be very
hard to capture using a taint-based information ﬂow engine.
Some attacks in fact don’t even use JavaScript. For ex-
ample, some browsers allow the style of visited links to be
customized with a background image that is speciﬁc to that
link, and this background image can be located on the at-
tacker’s server. By observing which images are requested,
the attacker can infer which links have been visited, without
using any JavaScript.

Despite all these sources of incompleteness, our JavaScript
information ﬂow framework can still be used as a diagnostic
tool to ﬁnd real cases of history sniﬃng in the wild. By
running experiments on the Alexa global top 50,000 we have
found that 46 sites really do perform history sniﬃng, and
one of these sites is in the Alexa global top 100. We have
also found several sites that have suspicious behavior, even
though our current tool does not allow us to conclude with
full certainty that these sites transfer the browser’s history.

5. EMPIRICAL STUDY OF ATTENTION

TRACKING

We have also conducted an empirical study on the preva-
lence of keyboard/mouse tracking on popular websites.
JavaScript code can install handlers for events related to the
mouse and keyboard to collect detailed information about
what a user is doing on a given website. This information
can then be transfered over the network. It is not enough
to take a naive approach of simply prohibiting information
from being transfered into the network while the event han-
dler is being executed since the gathered information can
be accumulated in a global variable, and then sent over the
network in bulk (which is what most attacks actually do).
Policies To use our information ﬂow framework for detect-
ing keyboard/mouse tracking, we use the following policies
in our framework:

at $1.isMouseOver() inject “secret”
at $1.isClick() inject “secret”
at $1.isScroll() inject “secret”
. . .
at document.send($1, $2) block “secret” on $2

front pages of the Alexa global top 1,300 websites. One of
the challenges in performing this empirical study automati-
cally is that, to observe keyboard/mouse tracking, one has
to somehow simulate keyboard and mouse activity. Instead
of actually simulating a keyboard and mouse, we instead
chose to automatically call event handlers that have been
registered for any events related to the keyboard or mouse
(click,mousemove,mouseover,mouseout,scroll,copy,select).
To this end,
in each web page we included a common
piece of JavaScript code that automatically traverses the
DOM tree of the current page and systematically triggers
each handler with an event object that is appropriately
synthesized for the handler. Another challenge is that many
of the sites that track keyboard/mouse activity accumulate
information locally, and then send the information in bulk
back to the server at regular intervals, using timer events.
These timer events are sometimes set to intervals spanning
several minutes, and waiting several minutes per site to
observe any ﬂow would drastically increase the amount of
time needed to run our test suite. Furthermore, it’s also
hard to know, a priori, how long to wait. To sidestep these
issues,
in addition to calling keyboard and mouse event
handlers, we also automatically call timer event handlers.
We successfully ran our framework on the Alexa top 1,300
websites in a total of about two hours.

Overall, we found 328 websites on which network transfers
were ﬂagged as transferring keyboard/mouse information to
the network. Of these transfers, however, many are visu-
ally obvious to the user. In particular, many websites use
mouse-over events to change the appearance of the item be-
ing moused-over. As an example, it is common for a website
to display a diﬀerent image when the mouse moves over a
thumbnail (possibly displaying a larger version of the thumb-
nail). Although these kinds of ﬂows can be used to track
mouse activity, they are less worrisome because the user
sees a change to the web page when the mouse movement
occurs, and so there is a hint that something is being sent
to the server.

Ideally, we would like to focus on covert keyboard/mouse
tracking, in which the user’s activities are being tracked
without any visual cues that this is happening (as opposed
to visible tracking where there is some visual cue).2 How-
ever, automatically detecting covert tracking is challenging
because it would require knowing if the keyboard/mouse
activity is causing visual changes to the web page.
In-
stead, we used a simple heuristic that we developed af-
ter observing a handful of sites that perform visible key-
board/mouse tracking. In particular, we observed that when
the mouse/keyboard information is sent to the server be-
cause of a visual change, the server responds with a relatively
large amount of information (for example a new image). On
the other hand, we hypothesized that in covert tracking,
the server would not respond with any substantial amount
of data (if any at all). As a result, of all the network trans-
fers found by our information ﬂow tool, we ﬁltered out those
where the response was larger than 100 bytes (with the as-
sumption that such ﬂows are likely to be visible tracking).
After this ﬁltering, we were left with only 115 websites. We
sampled the top 10 ranked websites among these 115 sites.

Real cases of covert tracking Of the 10 sites we sampled,

Benchmarks and Summary of Results We ran our
information ﬂow framework using the above policies on the

2One could view this heuristic as charging sites, in band-
width, for the privilege of exﬁltrating user attention data.

280Rank
3
11
15
19
34
53
65

Site
youtube
yahoo.co.jp
sina.com.cn
microsoft
mail.ru
soso
about

Description
contents
portal
portal
software
email
search engine
search engine

Events
click
click
click
mouseover,click
click
click
click

Table 3: Top 7 websites that perform real behavior
sniﬃng

Rank
503
548
560
622
713
910
1236

Site
thesun.co.uk
metrolyrics
perezhilton
wired
suite101
technorati
answerbag

Description
news
music
entertainment
news
blog
blog
search engine

Events
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover

Table 4: Websites that perform real behavior sniﬀ-
ing using tynt.com

we found that 7 actually perform covert keyboard and mouse
tracking that we were able to reliably replicate. These 7
websites are listed in Table 3. For each site, we give its
Alexa rank, its URL, a short description, and events being
tracked covertly. One may be surprised to see “clicking” as
being tracked covertly. After all, when a user clicks on a
link, there is a clear visual cue that information is being
sent over the network – the target of the link will know that
the user has clicked. However, when we list clicking as being
tracked covertly, we mean that there is an additional event-
handler that tracks the click, and sends information about
the click to another server. google is known for doing this:
when a user clicks on a link on the search page, the click is
recorded by google through an event handler, without any
visual cue that this is happening (we do not list google in
Table 3 because we only visit the front pages of websites,
and google’s tracking occurs on the search results page)

The most notable example in Table 3 is the microsoft.
com site, which covertly tracks clicking and mouse behavior
over many links on the front page and sends the information
to the web statistics site webtrends.com.

Cases of visible tracking Of the 10 sites that were sam-
pled, 3 were actually cases of visible tracking, despite our ﬁl-
tering heuristic. In one of these cases, the server responded
with very small images (less than 100 bytes) that were be-
ing redrawn in response to mouse-over events. In an other
case, the server responded with small JSON commands that
caused some of the web page to be redrawn. In all of these
cases, there was a clear visual cue that the information was
being sent to the server.

Cases of using tracking libraries Of the 115 sites on
which the ﬁltered ﬂows were reported, we found that 7 used
a behavior tracking software product developed by tynt.com
to track what is copied oﬀ the sites. These 7 websites are
listed in Table 4. The library monitors the copy event.
When a visitor copies the content of a web page to her

clipboard, the library inserts the URL of the page into the
copied content. Thus, the URL is contained within subse-
quent pastes from the clipboard, e.g., in emails containing
the pasted text, thereby driving more traﬃc to the URL. Us-
ing our framework, we discovered that on each client website,
the copied content is also transferred to tynt.com.

sites
Suspicious website While investigating several
that installed event handlers, we also found that the
huffingtonpost.com site exhibits suspicious behavior.
In
particular, every article on the site’s front page has an on-
mouse-over event handler. These handlers collect in a global
data structure information about what articles the mouse
passes over. Despite the fact the information is never sent
on the network, we still consider this case to be suspicious
because not only is the infrastructure present, but it in fact
collects the information locally.

6. RELATED WORK

Information ﬂow [7] and non-interference [11] have been
used to formalize ﬁne-grained isolation for nearly three
decades. Several static techniques guarantee that certain
kinds of inputs do no ﬂow into certain outputs. These in-
clude type systems [31, 23], model checking [28], Hoare-
logics [1], and dataﬂow analyses [18, 26]. Of these, the most
expressive policies are captured by the dependent type sys-
tem of [21], which allows the speciﬁcation and (mostly) static
enforcement of rich ﬂow and access control policies includ-
ing the dynamic creation of principals and declassiﬁcation of
high-security information. Unfortunately, fully static tech-
niques are not applicable in our setting, as parts of the code
only become available (for analysis) at run time, and as they
often rely on the presence of underlying program structure
(e.g., a static type system).

Several authors have investigated the use of dynamic taint
propagation and checking, using specialized hardware [27,
29], virtual machines [4], binary rewriting [22], and source-
level rewriting [5, 19]. In the late nineties, the JavaScript
engine in Netscape 3.0 implemented a Data Tainting mod-
ule [10], that tracked a single taint bit on diﬀerent pieces of
data. The module was abandoned in favor of signed scripts
(which today are rarely used in Web 2.0 applications), in
part because it led to too many alerts. Our results show that,
due to the prevalence of privacy-violating ﬂows in popular
Web 2.0 applications, the question of designing eﬃcient, ﬂex-
ible and usable ﬂow control mechanisms should be revisited.
Recently, Vogt et al. [30] modiﬁed the browser’s JavaScript
engine to track a taint bit that determines whether a piece of
data is sensitive and report an XSS attack if this data is sent
to a domain other than the page’s domain, and Dhawan and
Ganapathy [8] used similar techniques to analyze conﬁden-
tiality properties of JavaScript browser extensions for Fire-
fox. Our approach provides a diﬀerent point in the design
space. In particular, our policies are more expressive, in that
our framework can handle both integrity and conﬁdential-
ity policies, and more ﬁne-grained, in that our framework
can carry multiple taints from diﬀerent sources at the same
time, rather than just a single bit of taint. On the down-
side, our approach is implemented using a JavaScript rewrit-
ing strategy rather than modifying the JavaScript run-time,
which results in a larger performance overhead. Dynamic
rewriting approaches for client-side JavaScript information
ﬂow have also been investigated in a theoretical setting [5,

28119]. Our work distinguishes itself from these more theoret-
ical advances in terms of experimental evaluation: we have
focused on implementing a rewriting-based approach that
works on a large number of popular sites, and on evaluating
the prevalence of privacy-violating ﬂows on these websites.
One way to ensure safety on the client is to disallow un-
known scripts from executing [16]. However, this will likely
make it hard to use dynamic third-party content. Finally,
Yu et al. [32] present a formal semantics of the interac-
tion between JavaScript and browsers and builds on it a
proxy-based rewriting framework for dynamically enforcing
automata-based security policies [17]. These policies are
quite diﬀerent from information ﬂow in that they require
sparser instrumentation, and cannot enforce ﬁne-grained iso-
lation.

The possibility of history sniﬃng was ﬁrst raised in the
academic community a decade ago [9]. The original form of
history sniﬃng used timing diﬀerence between retrieving a
resource that is cached (because it has previously been re-
trieved) and one that is not. In general, many other forms
of history sniﬃng are possible based on CSS link decoration,
some of which (for example, setting the background property
of a visited link to url(...)) work even when JavaScript is
disabled. This, together with the genuine user-interface util-
ity that visited link decoration provides, is the reason that
history sniﬃng is so diﬃcult to address comprehensively in
browsers (cf. [13] for a proposed server-side solution, [12] for
a proposed client-side solution and [2] for the ﬁx recently
deployed by the Firefox browser.) The potential of history
sniﬃng has been recently proven to be enormous [14]. How-
ever, since to date there has been no public disclosure re-
garding the use of history sniﬃng, and no publicly available
tools for detecting it, we expect that, today, many malicious
sites will prefer the simple, robust approach of querying and
exﬁltrating link computed style. Accordingly, it is this data
ﬂow that we focus on; if there are sites that use other ap-
proaches, we will not have detected them. Our goal in this
paper is to draw attention to the use of clandestine history
sniﬃng at popular, high-traﬃc sites, which means that false
negatives are acceptable. In future work, we hope to extend
our tool to detect other forms of history sniﬃng as well.

7. CONCLUSIONS AND FUTURE WORK

In this paper, we proposed a rewriting-based informa-
tion ﬂow framework for JavaScript and evaluated the per-
formance of an instantiation of the framework. Our evalu-
ation showed that the performance of our rewriting-based
information ﬂow control is acceptable given our engineering
and optimization eﬀorts, but it still imposes a perceptible
running-time overhead. We also presented an extensive em-
pirical study of the prevalence of privacy-violation informa-
tion ﬂows: cookie stealing, location hijacking, history sniﬀ-
ing, and behavior tracking. Our JavaScript information ﬂow
framework found many interesting privacy-violating infor-
mation ﬂows including 46 cases of real history sniﬃng over
the Alexa global top 50,000 websites, despite some incom-
pleteness.

One direction for future work is a larger scale study on
privacy-violating information ﬂows. Such a study could per-
form a deeper crawl of the web, going beyond the front-
pages of web sites, and could look at more kinds of privacy-
violating information ﬂows. Moreover, we would also like to

investigate the prevalence of security attacks led by privacy-
violating information ﬂows like phishing and request forgery.
Another direction for future work is to extend our cur-
rent framework to become a bullet-proof client-side protec-
tion mechanism. The primary purpose of our tool so far
has been to observe existing ﬂows in the wild, a scenario for
which we don’t need to worry about malicious code trying
to circumvent our system. However, with additional work,
our framework could possibly lead to a protection mecha-
nism as well. For this purpose, we would have to soundly
cover all possibly forms of information ﬂow, including im-
plicit ﬂow, ﬂows induced by the DOM and browser built-in
APIs. In addition, we would also need better performance to
deliver a practical browsing experience. However, we believe
that with careful and extensive engineering eﬀorts, there is
a possibility that our framework could lead to a practical
protection mechanism.

8. ACKNOWLEDGMENTS

This material

is based upon work supported by the
National Science Foundation under Grant Nos. CCF-
0644306, CCF-0644361, CNS-0720802, CNS-0831532, and
CNS-0964702. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this material are those of the
authors and do not necessarily reﬂect the views of the Na-
tional Science Foundation.

9. REFERENCES
[1] T. Amtoft and A. Banerjee. Information ﬂow analysis

in logical form. In R. Giacobazzi, editor, Proceedings
of SAS 2004, volume 3148 of LNCS, pages 100–15.
Springer-Verlag, Aug. 2004.

[2] L. D. Baron. Preventing attacks on a user’s history

through CSS :visited selectors, Apr. 2010. Online:
http://dbaron.org/mozilla/visited-privacy.
[3] Bugzilla@Mozilla. Bug 147777 – :visited support

allows queries into global history, May 2002. Online:
https:
//bugzilla.mozilla.org/show_bug.cgi?id=147777.
[4] J. Chow, B. Pfaﬀ, T. Garﬁnkel, K. Christopher, and

M. Rosenblum. Understanding data lifetime via whole
system simulation. In M. Blaze, editor, Proceedings of
USENIX Security 2004, pages 321–36. USENIX, Aug.
2004.

[5] A. Chudnov and D. A. Naumann. Information ﬂow

monitor inlining. In M. Backes and A. Myers, editors,
Proceedings of CSF 2010. IEEE Computer Society,
July 2010.

[6] A. Clover. Timing attacks on Web privacy. Online:

http://www.securiteam.com/securityreviews/
5GP020A6LG.html, Feb. 2002.

[7] D. E. Denning. A lattice model of secure information

ﬂow. Commun. ACM, 19(5):236–243, 1976.

[8] M. Dhawan and V. Ganapathy. Analyzing information

ﬂow in JavaScript-based browser extensions. In
C. Payne and M. Franz, editors, Proceedings of
ACSAC 2009, pages 382–91. IEEE Computer Society,
Dec. 2009.

[9] E. W. Felten and M. A. Schneider. Timing attacks on
Web privacy. In S. Jajodia, editor, Proceedings of CCS
2000, pages 25–32. ACM Press, Nov. 2000.

282[10] D. Flannagan. JavaScript: The Deﬁnitive Guide.

[22] J. Newsome and D. X. Song. Dynamic taint analysis

O’Reilly, ﬁfth edition, Aug. 2006.

[11] J. A. Goguen and J. Meseguer. Security policies and
security models. In Proceedings of IEEE Security and
Privacy (“Oakland”) 1982, pages 11–20. IEEE
Computer Society, Apr. 1982.

[12] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell.

Protecting browser state from Web privacy attacks. In
C. Goble and M. Dahlin, editors, Proceedings of
WWW 2006, pages 737–44. ACM Press, May 2006.

[13] M. Jakobsson and S. Stamm. Invasive browser sniﬃng

and countermeasures. In C. Goble and M. Dahlin,
editors, Proceedings of WWW 2006, pages 523–32.
ACM Press, May 2006.

[14] A. Janc and L. Olejnik. Feasibility and real-world
implications of Web browser history detection. In
C. Jackson, editor, Proceedings of W2SP 2010. IEEE
Computer Society, May 2010.

[15] D. Jang, R. Jhala, S. Lerner, and H. Shacham.
Rewriting-based dynamic information ﬂow for
JavaScript. Technical report, University of California,
San Diego, Jan. 2010. Online:
http://pho.ucsd.edu/rjhala/dif.pdf.

[16] T. Jim, N. Swamy, and M. Hicks. Defeating script
injection attacks with browser-enforced embedded
policies. In P. Patel-Schneider and P. Shenoy, editors,
Proceedings of WWW 2007, pages 601–10. ACM
Press, May 2007.

[17] H. Kikuchi, D. Yu, A. Chander, H. Inamura, and

I. Serikov. JavaScript instrumentation in practice. In
G. Ramalingam, editor, Proceedings of APLAS 2008,
volume 5356 of LNCS, pages 326–41. Springer-Verlag,
Dec. 2008.

[18] M. S. Lam, M. Martin, V. B. Livshits, and J. Whaley.

Securing Web applications with static and dynamic
information ﬂow tracking. In R. Gl¨uck and
O. de Moor, editors, Proceedings of PEPM 2008,
pages 3–12. ACM Press, Jan. 2008.

[19] J. Magazinius, A. Russo, and A. Sabelfeld. On-the-ﬂy

inlining of dynamic security monitors. In
K. Rannenberg and V. Varadharajan, editors,
Proceedings of SEC 2010, Sept. 2010.

[20] L. A. Meyerovich and V. B. Livshits. Conscript:

Specifying and enforcing ﬁne-grained security policies
for javascript in the browser. In Proceedings of IEEE
Security and Privacy (“Oakland”) 2010, pages
481–496. IEEE Computer Society, 2010.

[21] A. C. Myers. Programming with explicit security
policies. In M. Sagiv, editor, Proceedings of ESOP
2005, volume 3444 of LNCS, pages 1–4.
Springer-Verlag, Apr. 2005.

for automatic detection, analysis, and signature
generation of exploits on commodity software. In
D. Boneh and D. Simon, editors, Proceedings of NDSS
2005. ISOC, Feb. 2005.

[23] F. Pottier and V. Simonet. Information ﬂow inference
for ML. In J. C. Mitchell, editor, Proceedings of POPL
2002, pages 319–330. ACM Press, Jan. 2002.

[24] N. Provos, D. McNamee, P. Mavrommatis, K. Wang,

and N. Modadugu. The ghost in the browser: Analysis
of Web-based malware. In N. Provos, editor,
Proceedings of HotBots 2007. USENIX, Apr. 2007.
[25] A. Russo, A. Sabelfeld, and A. Chudnov. Tracking

information ﬂow in dynamic tree structures. In
M. Backes and P. Ning, editors, Proceedings of
ESORICS 2009, volume 5789 of LNCS, pages 86–103.
Springer-Verlag, Sept. 2009.

[26] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner.

Detecting format string vulnerabilities with type
qualiﬁers. In D. Wallach, editor, Proceedings of
USENIX Security 2001, pages 201–17. USENIX, Aug.
2001.

[27] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas.

Secure program execution via dynamic information
ﬂow tracking. In K. McKinley, editor, Proceedings of
ASPLOS 2004, pages 85–96. ACM Press, Oct. 2004.

[28] T. Terauchi and A. Aiken. Secure information ﬂow as
a safety problem. In C. Hankin, editor, Proceedings of
SAS 2005, volume 3672 of LNCS, pages 352–67.
Springer-Verlag, Sept. 2005.

[29] N. Vachharajani, M. J. Bridges, J. Chang, R. Rangan,
G. Ottoni, J. A. Blome, G. A. Reis, M. Vachharajani,
and D. I. August. RIFLE: An architectural framework
for user-centric information-ﬂow security. In
A. Gonz´alez and J. P. Shen, editors, Proceedings of
MICRO 2004, pages 243–54. IEEE Computer Society,
Dec. 2004.

[30] P. Vogt, F. Nentwich, N. Jovanovic, E. Kirda,
C. Kr¨ugel, and G. Vigna. Cross site scripting
prevention with dynamic data tainting and static
analysis. In W. Arbaugh and C. Cowan, editors,
Proceedings of NDSS 2007. ISOC, Feb. 2007.

[31] D. Volpano and G. Smith. Verifying secrets and

relative secrecy. In T. Reps, editor, Proceedings of
POPL 2000, pages 268–76. ACM Press, Jan. 2000.

[32] D. Yu, A. Chander, N. Islam, and I. Serikov.

JavaScript instrumentation for browser security. In
M. Felleisen, editor, Proceedings of POPL 2007, pages
237–49. ACM Press, Jan. 2007.

283