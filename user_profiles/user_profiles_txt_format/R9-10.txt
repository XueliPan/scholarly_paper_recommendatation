SECURITY AND COMMUNICATION NETWORKS
Security Comm. Networks. 2008; 1:287–299
Published online 6 June 2008 in Wiley InterScience
(www.interscience.wiley.com) DOI: 10.1002/sec.22

Using selective, short-term memory to improve resilience
against DDoS exhaustion attacks

Qi Liao, David A. Cieslak, Aaron D. Striegel∗,† and Nitesh V. Chawla
Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556, U.S.A.

Summary

Distributed denial of service (DDoS) attacks originating from botnets can quickly bring normally effective web
services to a screeching halt. This paper presents SESRAA (selective short-term randomized acceptance algorithms),
an adaptive scheme for maintaining web service despite the presence of multifaceted attacks in a noisy environment.
In contrast to existing solutions that rely upon ‘clean’ training data, we presume that a live web service environment
makes ﬁnding such training data difﬁcult if not impossible. SESRAA functions much like a battleﬁeld surgeon’s
triage: focusing on quickly and efﬁciently salvaging good connections with the realization that the chaotic nature
of the live environment implicitly limits the accuracy of such detections. SESRAA employs an adaptive k-means
clustering approach using short-term extraction and limited centroid evolution to defend the legitimate connections
in a mixed attack environment. We present the SESRAA approach and evaluate its performance through experimental
studies in a diverse attack environment. The results show signiﬁcant improvements against a wide variety of DDoS
conﬁgurations and input trafﬁc patterns. Copyright © 2008 John Wiley & Sons, Ltd.

KEY WORDS: DDoS attack; data mining; clustering; network security; botnet

1.

Introduction

With the advent of tools and scripts that trivialize the
creation and management of large numbers of com-
promised hosts (aka botnets), low proﬁle armies exist
that are ready to launch devastating distributed denial
of service (DDoS) attacks at any moment. The sheer
prevalence and highly distributed nature of the hosts
further complicates matters. Hence, considerable re-
search attention has been brought to bear on how to ef-
fectively prevent, detect, defend, and/or neutralize the
botnet threat [1]. Moreover, the diversity of botnets in
the ‘wild’ necessitate multi-tiered strategies in order to
effectively weather attacks.

In this paper, we speciﬁcally examine the issue of
end host defense against such a distributed resource ex-
haustion attacks with non-spoofed legitimate requests.
Based on the vast amount of data that the servers ob-
serve daily, can one use lightweight data mining tech-
niques to enable mitigation mechanisms that reduce
or nullify the offending botnet(s)? We assume that the
end service operates from the perspective of isolation
with no external information services beyond those
directly initiated by itself are available. As the issue
of end host defense has roots in load balancing and
anomaly detection, we note the key novelties of our
work versus that of the large body of existing work
[2–11]:

*Correspondence to: Aaron D. Striegel, Department of Computer Science and Engineering, University of Notre Dame,
Notre Dame, IN 46556, U.S.A.
†E-mail: striegel@nd.edu
Copyright © 2008 John Wiley & Sons, Ltd.

288

Q. LIAO ET AL.

Fig. 1. View of SESRAA co-located with a load balancer.

• Effectiveness of short-term data views: we note that
short-term pattern extraction (extracting patterns in
the order of minutes versus hours or days) can be
effective against botnets. Rather than attempting to
extract the long-term ‘clean’ signal, short-term ex-
traction meshes well with open sites whose input
trafﬁc is highly variant (for example, eBay, CNN,
etc.).

• Pattern evolution as an input: while short-term pat-
tern extraction provides an excellent baseline, the
evolution of the extracted patterns (for example, clus-
ters) is interesting. We introduce the notion of adap-
tively skipping between past patterns under sustained
attacks to prevent attacker proﬁling and comment on
using evolution as a secondary ﬁltering input.

• Quality metric—session completion time: while in-
tuitively understood, we note the distinctive perfor-
mance effects of considering the satisfaction of mul-
tiple TCP ﬂows (for example, web trafﬁc) as requisite
for a successful session (group of ﬂows). We intro-
duce the notion of session completion time (SCT)
for evaluating botnet performance mitigation. To the
best of our knowledge, ours is the ﬁrst study to con-
sider session-wise rather than connection-wise qual-
ity of service (QoS).

We describe SESRAA (selective short-term random-
ized acceptance algorithms), a host-based scheme that
employs a nimble and adaptive response mechanism
to mitigate malicious attacks in a noisy, live environ-
ment. Our solution is co-located with the traditional
load balancer (see Figure 1). Rather than attempting to
remove the noise inherently present in the trafﬁc, our
scheme embraces the noise and adapt rapidly to net-
work dynamics. The design of our solution is centered
around a difﬁcult problem faced by research commu-
nity: How should a system react when attacks are mas-

Copyright © 2008 John Wiley & Sons, Ltd.

sive, distributed, rapid, dynamic, and there exists little
to no pattern of what constitutes good behavior? To that
end, SESRAA attempts to offer an effective ﬁrst line
of defense to handle short-term mitigation while more
sophisticated but slower schemes (pushback, tracing,
etc.) run their course. Through the adaptive applica-
tion of k-means clustering and recording of the cluster
evolution, SESRAA consistently changes its defense
proﬁle to both better isolate ongoing attacks and to re-
duce its vulnerability to proﬁling attacks.

The remainder of the paper is organized as follows.
Section 2 differentiates our research approach with ex-
isting work and acknowledge the previous studies in
the ﬁeld. In Section 3 we discusses the environment
in which our solution operates and theory behind our
approach. Detail explanation is given to how the clus-
tering should work and how the suggested probability
should be generated. Section 4 shows some trafﬁc anal-
ysis and the evaluation of proposed solution to DDoS
attacks via simulation. Further experiments is studied
and discussed in Section 5. Finally, Section 6 offers
several concluding remarks and comments on the on-
going future work for SESRAA.

2. Related Work

Traditionally, DDoS attacks have been characterized
as either TCP SYN or UDP data ﬂooding. In the case of
TCP SYN ﬂooding, the three-way handshake is never
completed (SYN ﬂood) or the handshake completed
but data never sent. In contrast, UDP data ﬂooding
simply overwhelms the link in question through sheer
bandwidth with the source address often spoofed to
hide the location of the source(s). Critically, a ﬁrst
step in defense is the identiﬁcation that an attack is oc-
curring versus the server simply being overloaded due

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

SELECTIVE, SHORT-TERM MINING AGAINST DDoS

289

to popular content. In Reference [19], the concept of a
one-way connection density (OWCD) function is used
to describe the asymmetric property of incoming and
outgoing trafﬁc for detection of DDoS attacks. Simi-
larly, the basic assumption in Reference [20] is that the
ratio of incoming trafﬁc over outgoing trafﬁc is high
during the DDoS period because the server could not
respond quickly under heavy load. Kang, Zhang, and Ju
proposed the use of hierarchical clustering in Reference
[21] to classify the type of DDoS attacks. Conversely,
our work focuses on the initial mitigation mechanisms
rather than detection but does not preclude the use of
existing work with regards to DDoS attack detection
as a trigger mechanism rather than solely using
system load.

As ﬂooding typically involves spooﬁng the source of
the packet, numerous works have attempted to reduce
or eliminate spoofed packets. Xu and Lee propose in
Reference [22] is to ﬁlter spoofed packets through URL
redirection via MAC veriﬁcation but require router
support to provide such a mechanism. In Reference
[23], Kim et al. propose a packet scoring mechanism
whereby packets are discarded based on a per-packet
score threshold. Yaar, Lessig, and Song propose SIFF in
Reference [24] which controls Internet ﬂows based on
the notion of privileged or unprivileged channels. In a
similar vein, path identiﬁcation [6] is a packet marking
technique that embeds a path ﬁngerprint within each
packet by altering the IP Identiﬁcation ﬁeld. This al-
lows a victim to identify packets traversing the same
paths through the Internet on a per packet basis, despite
spooﬁng. Path identiﬁcation can remain effective in a
partial deployment, up to 50%, but still suffers from
the cost of deployment on a large scale.

In the case where attacks are not spoofed, an ap-
proach to curtailing the DDoS attack problem is
through IP traceback [2–4]. The goal of traceback is to
identify systems responsible for generating attack traf-
ﬁc and to determine the network path through which
the malicious communication ﬂows. However, in the
botnet setting, attacks may involve involves hundreds
if not thousands of machines intermixed with legiti-
mate trafﬁc making tracing back to individual hosts
impractical. Park and Lee [2] present a discussion on
the effectiveness of source identiﬁcation through prob-
abilistic packet marking. This technique may poten-
tially reduce the DoS problem to a manageable level,
however, this scheme suffers as spooﬁng of the packet
marking ﬁeld eliminates the ability of the method to
perform an accurate traceback.

In addition to genuineness of source, DDoS can also
be categorized into bandwidth depletion and resource

Copyright © 2008 John Wiley & Sons, Ltd.

depletion attacks. Bandwidth depletion attack can be
mitigated by ﬁltering unwanted trafﬁc earlier which
would have been discarded anyway later at the end
server (for example, UDP data ﬂood). In Reference
[17], Mahajan et al. propose a pushback mechanism to
control aggregates at the upstream router. The rate lim-
iting scheme from the upstream gateway can be com-
bined with our approach to provide a comprehensive
end host defense against DDoS attacks. In a similar
vein, level k max–min proposed in Reference [18] of-
fers an alternative over the earlier recursive pushback
mechanism when attacking hosts are spread across
the network. However, the rate limiting requires the
identiﬁcation of the offending nodes in order to effec-
tively contain the malicious trafﬁc. We note that SES-
RAA could be applied as the input for rate limiting to
blend the two techniques which could be a subject for
future research.

A signiﬁcant hindrance to many of these techniques
discussed above is the requirement of extensive deploy-
ment throughout the router infrastructure of the Inter-
net versus more deployable but typically less effective
host-based solutions. The approach by Xu and Lee in
Reference [22] uses game theory to model the attack-
ers and defenders and apply a quota to each client to
conﬁne the clients to their fair bandwidth share. In con-
trast, our work focuses on probabilistically ﬁltering the
likely botnet patterns rather than diluting the share of
each client which we believe provides a more respon-
sive solution. Speciﬁcally, our work incurs only a ﬁxed
state when in the overloaded state and only imposes
increased state/load when the system is lightly loaded
as opposed to potentially per-client state in Reference
[22]. Another promising victim-based DDoS attack de-
tection scheme was proposed by Jin and Yeung in Ref-
erence [25] using covariance models to combat SYN
ﬂooding attacks but unfortunately the work provided
minimal mapping for how to apply the results with re-
gards to mitigation. Jin, Wang, and Shin proposed an
alternative ﬁltering scheme based on hop-count ﬁlter-
ing in Reference [26]. This technique is able to allow
a server to infer authenticity based on an analysis of
expected and actual TTL values of packets from a sin-
gle host. However, a study of the effectiveness of this
technique against a DDoS featuring unspoofed trafﬁc
has yet to be performed.

The ﬁrst large-scale study of the application of
the subspace method to trafﬁc ﬂows was performed
in Reference [27]. Incorporating anomaly detection
with this technique has yielded strong results, allow-
ing analysts to note distinct trafﬁc behavior such as
ﬂash crowds, worms, and even changes of routing pol-

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

290

Q. LIAO ET AL.

icy. While this technique is not an automated solu-
tion, it demonstrates the power the subspace method
in terms of network trafﬁc identiﬁcation. In static
clustering (SC) and network-aware clusters (NAC)
[28,29] clients are clustered by some common prop-
erties like the longest matched preﬁx/netmask BGP
routing table snapshots. Finally, we also acknowl-
edge another attack model called reduction of qual-
ity (RoQ) [30], which targets adaptation mechanisms
and keeps an adaptive mechanism oscillating between
overload and underload conditions. Unlike DDoS,
RoQ optimizes the attack trafﬁc to produce the max-
imum damage while keeping a low proﬁle to avoid
detection.

3. Architecture Design of SESRAA

In the literature, DoS attacks typically employ IP and
port spooﬁng to quickly overwhelm the server. Rather
than addressing the removal of spoofed IP addresses,
we assume that the handshake portion of the TCP con-
nection can be largely ofﬂoaded to the load balancer,
thus only creating load in the bandwidth rather than
computational sense. In contrast, we focus on a more
difﬁcult problem in which a series of hosts attempt
to overwhelm the server through legitimate connec-
tion requests (i.e., handshake is completed and all data
are downloaded). This resource exhaustion attack is
made possible with the recent emergence of large scale
botnets in which vast amount zombies do not even
bother to hide their real addresses. The threat model
we are considering is that an attacker, such as a bot-
net master, controls tens of thousands of compromised
machines and makes legitimate connection requests to
victim machines, such as a web server, thus making its

resources unavailable to valid users. Hence, SESRAA
targets the mitigation of botnet-style DDoS exhaustion
attacks wherein the attack consists of a burst of activity
to the target victim.

Our conjecture is that despite the noise of the
Internet, there is good behavior to be extracted over
short periods of time. To that end, we consider k-means
clustering [12] to discover clusters of normal activ-
ity or behavior based on connection requests. This
premise further bolstered by observations in Refer-
ences [13,14], which noted that connection requests
tend to cluster over time. Intuitively, if the normal trafﬁc
tends to self-organize in cohesive clusters, the overload
state will introduce anomalous or malicious behavior
that falls outside of clusters or overloads existing clus-
ters. Conversely, trafﬁc that falls within a cluster has
a higher probability of being good, until the cluster
density increases beyond an acceptable load. By prob-
abilistically ﬁltering attackers based on the weighting
of the clusters and a distance function, SESRAA infers
the potential for a connection to be bad in a lightweight
and efﬁcient manner. Moreover, clusters are continu-
ally recomputed with multiple characteristics, which
presents an attacker with a non-static defense scheme.

3.1. Operation of SESRAA

When the server (S) reaches a warning state (Swarn), the
most recent set of centroids M derived from k-means
clustering over IP and TCP characteristics freezes. The
proportion of distributions around some members of M
will rise as other fall while connection requests ﬂood
the system, which is seen in Figure 2. New connec-
tion requests are placed into clusters, which will cause
a disruption to the population balance, allowing SES-
RAA to probabilistically adapt to the attack in order

Fig. 2. Side-by-side analysis of connections characteristics. The left is a partial view of collection of connections immediately

prior to the DDoS and the right is partway through the attack.

Copyright © 2008 John Wiley & Sons, Ltd.

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

SELECTIVE, SHORT-TERM MINING AGAINST DDoS

291

Table I. SESRAA and server actions within each state.

Server load

Server action

SESRAA action

Overload (Sover)
Warning (Swarn)
Normal (Snormal)

Maximum probabilistic connection rejection
Probabilistic rejection of new connections
All connections accepted

Trigger adaptation clustering
Clusters ﬁxed
Recompute clusters at intervals

to better serve members from the good clients (CG).
Based on the load to the server (S), the differential be-
tween the actual and expected cluster size, and the rel-
ative distance (based on deviation and cluster density)
from the cluster’s centroid, an acceptance probability
is assigned. This method allows the isolation of collec-
tions of ﬂows that are different from those found when
the trafﬁc was in a normal state. Ideally, such ﬂows
are those of the bad clients (CB). As the botnet attacks
recedes, the server reverts to a normal state (Snormal),
allowing it to prepare for the next attack. This offers a
unique, adaptable, and resilient method to managing
a botnet attack while still delivering service to legit-
imate users. Table I summarizes the actions taken at
SESRAA during different sever loads.

While the normal state (Snormal) does not imply that
all accesses are good, we believe that one can infer
that a higher probability of goodness for connections
received during this state. However, SESRAA can be
tuned to not use this metric as the sole test for good-
ness as this assumption possesses two key weaknesses.
First, an attacker may be conducting a low level botnet
attack that does not overwhelm the server. Second, a
cluster of hosts that was previously considered good
may become compromised. In both cases, the simple
metric of training the goodness of connections based
the underload state may be deceptive. However, it is
important to note that the increase in trafﬁc that oc-
curs with a botnet attack will likely cause previously
noted good cluster(s) to become overweighted and thus
subject to increased rejection probabilities. Even a slow
ramp-up for the botnet attack is not immune to rejection
by overweighting as the cluster weight for the botnet
cluster will still manifest itself by the magnitude of the
number of connections in the cluster.

To further defend against those bots that attempt to
poison the clustering, Wcluster and Wcentroids are used
for the evolution of cluster and centroids in SESRAA.
For each window size of Wcluster, the cluster’s centroids
are recomputed and all trafﬁc data points are discarded.
These centroids will be used as the fresh starting points
in each cluster for the new round of Wcluster. Wcentroids
is used to keep a history of recent past sets of computed
centroids. In the event that the current clustering tech-

Copyright © 2008 John Wiley & Sons, Ltd.

niques do not mitigate the overload state (Sover) at the
server due to the insufﬁcient learned pattern, a random
hop between these centroid sets at ﬁxed intervals is
adopted until all trafﬁc move to Snormal. Overall, these
adaptation mechanisms provide a non-deterministic re-
jection method to botnet. Our future work will explore
a method of differential of clustering for botnet attacks.

3.2. Rejection Probability Generation

When the data are manageable, these requests are
merely noted as examples with which clusters are es-
tablished. However, when the server is in danger of
failing, SESRAA needs the ability to distinguish traf-
ﬁc falling within the accepted pattern. Thus, SESRAA’s
task becomes that of outlier detection. To perform
outlier detection, we were initially inclined to apply
a method that incorporates local outlier factor [15],
which is a useful measure of both a point’s distance
from a cluster and the relative measure of the cluster’s
density. However, such an operation is computationally
infeasible given the requirement to calculate nearest
neighbor (NN) for each connection and the small quan-
tum of time budgeted to accept or decline the connec-
tion. Thus, our system must rely on a faster heuristic
for assigning a probability that the connection belongs
to a given cluster.

As the exact distribution of connections is unknown,
we rely upon Chebyshev’s theorem stating that no more
than k−2 of the examples exists at a distance k standard
deviations or greater from the mean [16]. This is invalu-
able in determining acceptance probabilities based on
the cluster information we have gathered, as this model
makes no assumptions about the distribution of con-
nections within each cluster. For each new connection
received when the server is under attack, Chebyshev’s
theorem suggests:

Pcluster(X) =

σ2

(µ − X)2

where µ represents the cluster mean, X represents the
connection data point, and σ represents the cluster stan-
dard deviation. As new trafﬁc enters the connection

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

292

Q. LIAO ET AL.

subspace, those points distanced furthest from cluster
centers will receive the lowest acceptance probability
(such as the sparse points distant from centroids), while
those closer to cluster centroids will be increasingly ac-
cepted.

As the load on the server increases, the policy also
needs to become much harsher to prevent server over-
loading. The primary danger of the botnet attack stems
from overloading the capacity of the server. Given two
scenarios where the server was presented an identical
connection request and the distributions and partitions
were identical between scenarios, the server cannot is-
sue the same acceptance probability if one scenario fea-
tures a differing trafﬁc load than the other. As the server
reaches its resource capacity, the rate of rejection must
rise signiﬁcantly. This implies that any rejection proba-
bility component derived from load over threshold will
follow an exponential growth pattern. Therefore, the
acceptance probability function based on load is

(cid:1)

(cid:2)

λ· l(t)−lthres

lthres

−
Pload = e

where λ is a constant weight, l(t) is the load on the
server at time t and lthres represents the server’s thresh-
old load.

The ﬁnal considerations of the acceptance proba-
bility generation is where a connection maintains the
existing distribution of connections around each clus-
ter. If a connection causes a cluster to deviate over its
natural distribution against the entire population, then
the probability of its rejection should be increased. For
distribution consideration, it is sufﬁcient to calculate a
probability based on the separation from the actual and
expected distribution of the cluster.

Pdist(X) = dexp
d(X)

where d(X) represents the percentage of all packets
within the cluster of connection packet X and dexp rep-
resents the percentage of connections within the given
cluster at the point when the clusters are ﬁxed. This
component of probability generation will therefore as-
sign connections falling within heavy regions to very
low acceptance probabilities as these localized changes
to the overall trafﬁc aggregate likely reﬂect a botnet at-
tack.

While it is straightforward to merge the above func-
tions to calculate an acceptance probability during Sover
using a linear combination of weights and probabilities,
this metric has some shortcomings. First, after an ex-

Copyright © 2008 John Wiley & Sons, Ltd.

tended period of attack, ideally the weighting can adapt
to focus on Pcluster, Pdist, or Pload. However, the dynam-
ically adjusting the weights entails extra computation
cost. Second, the magnitude of rejection does not in-
crease signiﬁcantly using the linear relation, which is
particularly important within the context of a botnet at-
tack. Therefore, for simplicity and effectiveness, prod-
uct of the above probabilities is adopted to calculate the
ﬁnal probability, which the load balancer then uses to
decide connection acceptance or rejection. Although a
discrete accept/reject model is nearly infeasible, such
a probabilistic heuristic should prove to be an effective
method to mitigating a botnet attack.

3.3. Discussions

Beyond the core operations of SESRAA, we discuss
the following items in more detail: ﬂash crowds, false
positives, and the computation cost of SESRAA.
Flash crowds: while one can debate whether ﬂash
crowds can be deﬁned as ‘good’ or ‘bad’ behaviors,
the reality is that ﬂash crowd are generally not inten-
tionally malicious, rather the requests are driven by ex-
ceptionally popular content. Although SESRAA’s dis-
cerning offers limited beneﬁt in discerning the partic-
ipants of the ﬂash crowd versus the normal trafﬁc be-
havior, SESRAA will still control admissions to ensure
that those connections admitted can indeed be served
in a timely manner. SESRAA does have the capac-
ity to limit highly localized ﬂash crowds (for example,
university message board posting) which can be a de-
sirable outcome to encourage caching on the part of
the remote network. In particular, we note that SES-
RAA will not do any harm beyond what a normal load
balancer would employ if all requests are considered
‘good’ in the larger network context.
False decision: for a system without perfect knowl-
edge of request intention, false positives and false neg-
atives are a practical reality of the system. Critically,
SESRAA is targeted at systems where the noise of the
Internet precludes the creation of extremely accurate
models, that is, the users of a site change over time
rather than exhibiting an easily extractable behavior
such as with eBay, CNN, Amazon, and university web
sites rather than an authorization-driven web site such
as scientiﬁc portals and others. We accept that SES-
RAA will clearly make incorrect decisions but that
tradeoff is taken in exchange for nimbleness of the sys-
tem (preventing simply proﬁling attacks via adaptation)
and elimination of long-term training periods (simply
unfeasible). As noted in our upcoming experimental
studies, SESRAA offers signiﬁcantly improved results

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

SELECTIVE, SHORT-TERM MINING AGAINST DDoS

293

over the merely randomized load balancing demon-
strating a clear improvement in false positives/false
negatives. Hence, we believe the beneﬁt gain in our
approach outweighs the incorrect decisions made by
the server in accepting/rejecting clients requests dur-
ing the DDoS period in order to maintain a reasonable
load with the realization of good QoS for the majority
of legitimate users.
Computation cost: it is important to note that the core
of SESRAA are relatively lightweight data mining op-
erations that are conducted at the load balancer, not the
web server itself. Moreover, the transition to a highly
loaded state freezes the set of centroids (recent and
past) used for evaluation and does not incur a data min-
ing load when the system itself is under attack. These
computations could also be directed to a separate server
besides the load balancer if the load balancer does not
have sufﬁcient resources when under a light load. While
we do acknowledge that the k-means clustering pro-
cess is not deterministic, the lack of determinism is
mitigated by its invocation during only periods of low
load. The computation during the rejection phase is also
relatively lightweight as the Euclidean distance versus
existing clusters is a constant factor that does not re-
quire signiﬁcant overhead and creates a ﬁxed impact
per connection.
Bandwidth exhaustion attack: ﬁnally, we note that SES-
RAA does not mitigate pure bandwidth exhaustion at-
tacks (for example, UDP ﬂood). SESRAA solely fo-
cuses on the issue of botnet-style resource exhaustion
via legitimate requests for which traditional SYN-ﬂood
pushback-style mechanisms [17,18] would offer little
beneﬁt. SESRAA does not preclude the use of these
techniques to ﬁlter out unwanted trafﬁc and is largely
complementary to those techniques.

usage of actual data rather than synthetically data in-
creases the difﬁculty of defense, we ﬁrmly believe that
our results more accurately reﬂect what would occur
under an actual botnet exhaustion attack. The univer-
sity tap data were used both for the simulation and
experimental analyses.

To enable testing across a wide variety of scenarios, a
discrete-event simulator for SESRAA was developed in
Java.‡ The clustering criteria uses characteristics from
the packet headers of both the network and transport
layer, which includes but not limited to IP address, port
numbers, TTL values, and sequence numbers. While
Euclidean distance of multi-dimension is easy to com-
pute and is actually adopted by our approach, for vi-
sualization easiness, we present results using only the
src ip and src port to form a 2D space for k-means
clustering.

With regards to clustering, a sliding window of 55
simulation seconds is used. If there has not been a re-
cent attack, the data points of the current clusters will
be dropped and only the centroids themselves will be
saved. In the simulation, the cluster centroids are up-
dated each simulation second provided that the server
is under the appropriate load level. Client-side charac-
teristics are modeled with a 100 Mb/s link and varying
WAN-side RTTs. The load and SESRAA threshold are
set 0.8 and 0.6, respectively, denoting the load at which
the respective algorithms are invoked. The timeout at
the server is set 3 Seconds while the client SYN time-
out set to be 2 Seconds with a maximum of three re-
tries before declare failure. The policies of load only
(probabilistic rejection beyond a threshold), SESRAA
(outlined earlier), and perfect (always reject attackers)
are compared.

The primary performance metric, quality preserva-
tion in terms of SCT, is deﬁned in the following manner:

4. Simulation Analysis

SCT = Max(FCTf0 , FCTf1 , · · · , FCTfn)

To understand the trafﬁc pattern and to evaluate SES-
RAA, we performed simulation and experimental anal-
yses that are discussed in the next two sections. To start,
we conducted a simulation analysis based on months
of live captured data from the primary web server on
the university campus. The usage of actual data allows
for the avoidance of artifacts of random addresses, ran-
dom ports, and other trafﬁc characteristics that would
be trivial to extract via data mining. Moreover, the us-
age of actual data allows for the accurate simulation of
members of a ‘live’ botnet with real addresses, ports,
TTLs, and request characteristics that represent sub-
verted hosts from the observed trafﬁc ﬂows. While the

Copyright © 2008 John Wiley & Sons, Ltd.

where FCTfn is the ﬂow completion time of ﬂow n. In
order for a session to be successful, each ﬂow within
the session must complete its gathering of data before
the timeliness requirement of the client. For instance,
a real web session might require three connections to
render a webpage, and each of which must complete in
their entirety. A session is then determined to be suc-
cessful if the SCT ≤ TQoS, where TQoS is the QoS con-
straint of the user. Session-wise QoS is more important
than connection-wise QoS because good connection-

‡ Available at http://netscale.cse.nd.edu.

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

294

Q. LIAO ET AL.

wise QoS does not necessarily guarantee that session-
wise QoS will be satisﬁed. In the case of load balanc-
ing, this is especially critical as a rejected connection
will prevent the completion of a successful session.
From the session completion metric, the percentage of
good hosts serviced successfully serves as an effec-
tive metric to evaluate the effectiveness of botnet mit-
igation. If not enough ‘bad’ users are prevented from
accessing the server, the QoS for all sessions will suf-
fer. Consequently, if a load balancing scheme is indis-
criminate, individual connections of good users may be
rejected which prevents the completion of the overall
session.

To that end, we studied the hourly, daily, and weekly
trafﬁc pattern of all incoming web requests to the main
web sever on campus. Figure 3 shows a 7-day trafﬁc
pattern of all incoming web requests to the main web
sever on campus. While the majority of total number of
connections for a speciﬁc subnet (/24 is the default unit
used) within an hour is below 10, there are some ex-
tremes observed in certain /24 IP addresses. A diurnal
pattern can also be observed for some IP ranges which
is an interesting observation that is not currently ac-
counted for in SESRAA but is an open topic for future
research.

A scatter plot of the 2D space used for clustering
formed by the source IP addresses and port numbers
is shown in Figure 4. It provides a snapshot of about
one hour of web trafﬁc coming to the web servers on
campus. Short-term clustering on IP and port shows
that port numbers are heavily distributed at low and
high ends for certain IP range. A simulation visualizer
(Figure 5) was developed to visualize the clusters and
centroids evolution. One can zoom in each individual
cluster and see the centroid movement within that
cluster by stepping through each time unit, or we
can get an overview of the distance between different
centroids of clusters. The visualization helps one to
understand the potential pattern and provide better
adaptation to botnet attack behavior.

A comparison of QoS performance of various poli-
cies are summarized in Figure 6. The perfect policy
is the oracle that knows exactly which SYN packets
are good or bad, that is, the equivalent of an ‘evil’
bit in the packet header. The load policy represents
a nominal load balancer that exempliﬁes a traditional
load balancer. We note that in the ﬁgure, the load pol-
icy performs relatively well at the initial phase of the
botnet attack as the existing connections are still le-
gitimate hosts. Once the legitimate hosts ﬁnish their

Fig. 3. A 3D view of the number of connections of all incoming web trafﬁc for a 7-day monitoring period. X-axis is time in unit
of hours; Y-axis is the IP with the ﬁrst three signiﬁcant bytes; and Z-axis is the total number of connection requests during that

hour.

Copyright © 2008 John Wiley & Sons, Ltd.

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

SELECTIVE, SHORT-TERM MINING AGAINST DDoS

295

Fig. 4. A 2D view of incoming web request for a monitoring period of approximately 1 h. X-axis is the source IPv4 addresses

normalized to 232 and Y-axis is the source ports normalized to 216.

Fig. 5. Screenshot of clusters evolution visualizer (zoomed-in for the centroids movement within one chosen cluster).

Copyright © 2008 John Wiley & Sons, Ltd.

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

296

Q. LIAO ET AL.

Fig. 6. Comparison of QoS performance of perfect, SESRAA, and load policy only in a random botnet attack (time 300 to time

600).

existing connections, the overwhelming nature of the
botnet drastically reduces the rate of good connections
having their session-wise QoS satisﬁed despite having
the same relative request rate as before the initial at-
tack. In contrast, SESRAA offers a rate of successful
sessions for good clients roughly halfway between the
perfect and load policies with a k setting of k = 10.
Clearly, SESRAA is incorrectly rejecting a portion of
good connection requests but serves its purported role,
that is, to act as a triage, salvaging part but not all of
the connections to in essence buy time for other mech-
anisms to function. By the end of the DDoS period,
SESRAA has provided a roughly 25% cumulative im-
provement over the normal load balancing scheme in
terms of good users with their sessions successfully
satisﬁed.

While setting k = 10 offers reasonable performance,
an interesting question is posed with the ideal set-
ting of k. In Figure 7, possible choices of k values
are studied with the same data input as with Figure
6. Normally, k should be increased with higher con-
nection rate depending on the server’s trafﬁc volume.
One possible choice of k is to minimize the cost func-
tion C(distortion + MDL). The distortion function is
i=1 (xi − cj)2, where Cj is the jth
deﬁned as
cluster, xi a data point in each cluster, and cj is the
centroid in the cluster. Minimum description language

(cid:3)
k
j=1

(cid:3)|Cj|

Copyright © 2008 John Wiley & Sons, Ltd.

(MDL) is deﬁned as λ(m · k · logn), where λ is a prede-
ﬁned constant, m the number of features (IP, Port, TTL,
etc.), k the number of clusters, and n is number of in-
stances in training data set. The choice of λ depends on
each web application. To avoid overﬁtting, we need to
reduce the number features and the number of clusters.
As we can see from Figure 7, one cluster (k = 1) has
the worst performance as the single cluster is clearly in-
sufﬁcient to ﬁt the data. Conversely, a larger k improves
performance but only up to a certain level as shown by
how how a k value of 30 is only slightly better than the
initial k value of 10.

5. Experimental Studies

In addition to our trafﬁc analysis and simulation stud-
ies, a preliminary version of SESRAA was developed to
validate our initial results. In our experiments, the envi-
ronment is divided into four components: clients, emu-
lated network, load balancer, and the server. The clients
are responsible for generating connection requests via
wget to the server. In the emulated network, connec-
tion requests are mapped to a characteristics space
derived from live university trafﬁc from network tap.
The list of potential clients was separated into groups
of good and bad clients with the bad clients elected

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

SELECTIVE, SHORT-TERM MINING AGAINST DDoS

297

Fig. 7. Performance of choices for various K values during the attacking period (time 300 to 600).

to conduct a botnet attack during the experimental
period.

The experimental

testbed was connected by a
100 Mb/s switched network with layer 2 overlay con-
nectivity provided by libpcap. The web content served
reﬂected a CNN style page: a 66 kB hypertext page
featuring several small pictures. All content retrievals
were conducted using wget which employed HTTP 1.0
(separate connections for each object). The DDoS at-
tack lasted 150 s for all experiments. We selected HTTP
1.0 as it is signiﬁcantly more difﬁcult than HTTP 1.1
due to the fact that the denial of any single connec-
tion for a good client (i.e., image one in the web-
page) will cause the good client session to be counted
as failed.

We deﬁne different scenarios of attack for each ex-
periment separately. In the simplest generation method
(random DDoS), attackers are selected randomly from
the client space; in essence, a random set of clients
from C form Cb. A more sophisticated attack (clus-
tered DDoS) represents a localization within the con-
nection space. Here, a single centroid is picked within
the connection space. Members from C are more likely
to join Cb the closer they are to the selected centroid,
generating a singular attack cluster. The most sophis-
ticated form of attack (homologous clustered DDoS)
mimics the pattern of legitimate trafﬁc, making differ-
entiation between good and bad clients nearly impos-

Copyright © 2008 John Wiley & Sons, Ltd.

Fig. 8. Summary of QoS preservation (100% represents all

legitimate hosts serviced).

sible. While such an attack is extremely unlikely as the
attacker would need to have inside information (i.e.,
access to the tap), we present this scenario to demon-
strate that SESRAA can still offer a beneﬁt even in this
worst case.

Figure 8 indicates that as expected, the overall Qual-
ity of Service based on our metric falls between the load
policy and perfect policy. The ﬁgure itself shows the
end result of performance after the test has completed.
In the ﬁrst case of randomized attackers, SESRAA per-
forms best, noting the discrepancies as the clients in the
botnet themselves tend to fall into the outlier range and

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

298

Q. LIAO ET AL.

Fig. 9. Cumulative total of good sessions successfully completed.

have a higher rate of rejection. The introduction of clus-
tering to the clients reduces the performance of SES-
RAA slightly as the request is less likely to fall into
the outlier category and must overload a cluster ﬁrst
before being rejected. The cluster type of attack does
require some intelligence in the attack and a reason-
able approximation or biasing of the clusters to group
the attackers into a single cluster. In the third case,
SESRAA still outperforms normal load balancing but
only slightly due to the fact that the botnet trafﬁc is
nearly perfectly balanced among the normal clusters
that would be derived. In practice, such an attack is ex-
tremely unlikely as it would require that the attacker
have precise information about all connections (i.e., a
tap to all network data to the server) in order to appro-
priately guide their botnet with regards to attacking.

The graph in Figure 9 represents several scenarios
that a server may face. This case generates indepen-
dent clusters of attack trafﬁc. This represents the case
in which a number of similar machines are compro-
mised to form the zombie army. Suppose a Trojan horse
compromised a university’s residential computing net-
work. As most machines are likely Windows machines,
leading to similar TTL values, for personal use and the
range of addresses is relatively tight, a botnet attack
generated from such a collection would likely gener-
ate a separate cluster than that of the normal trafﬁc.
Figure 9 demonstrates the domination of the perfect

Copyright © 2008 John Wiley & Sons, Ltd.

policy curve over both the load and SESRAA poli-
cies. While SESRAA outperforms the load policy, the
degree of domination is less than in the case of the
purely randomized DDoS. Although SESRAA assigns
high probabilities to connections falling within attack
clusters with sufﬁcient separation from legitimate traf-
ﬁc clusters, overlapping attack and legitimate trafﬁc
clusters lead to a reduced rate of attack connection
rejections. In an applied setting, if there is a grouping
of legitimate machines, such as a university cluster, for
a SESRAA server’s content and then a compromising
within this group occurs, SESRAA will have difﬁculty
in distinguishing between attack and legitimate hosts
within this cluster. On the basis of its bias, SESRAA’s
performance will suffer, particularly in instances of
overlap. In such a case, we believe the use of cluster
evolution in a combined heuristic with the basic SES-
RAA approach could provide interesting insight. The
inclusion of evolution directly into the heuristic is an
on-going work.

6. Conclusion and Future Work

In this paper, we present SESRAA, an effective
probabilistic connection rejection method that provides
management against botnet-based DDoS attacks. Our
technique employs k-means clustering while there is a

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

SELECTIVE, SHORT-TERM MINING AGAINST DDoS

299

manageable load on the server. As the load becomes un-
bearable, the server then applies several metrics based
on distance from cluster center and cluster population
and uses these to assign rejection probabilities accord-
ingly. Using this method will assist in isolating connec-
tions likely to be attacks and will enhance the Quality of
Service delivered to legitimate clients. Once the attack
has passed, the server reverts to its learning state.

The results of our experiments indicate that this is
an effective technique, which leads to several other
avenues of study. We intend to perform a full-scale
study of temporal network trafﬁc and determine meth-
ods of segmentation, using both clustering and hyper
rectangles, and visualization, which will be useful in
better understanding network trafﬁc, particularly dur-
ing a botnet attack. Further works includes expanding
the usage of cluster evolution as well as long-term stud-
ies of network trafﬁc.

Acknowledgment

The authors would like to thank the anonymous review-
ers for their insight and comments on this paper.

References

1. Holz T. A short visit to the bot zoo. IEEE Security & Privacy

2005; 3(3): 76–79.

2. Park K, Lee H. On the effectiveness of probabilistic packet mark-
ing for IP traceback under denial of service attack. In Proceed-
ings of INFOCOM 2001, 2001; pp. 338–347.

3. Snoeren A, Partridge C, Sanchez L, et al. In Proceedings of

SIGCOMM, 2001; pp. 3–14.

4. Savage S, Wetherall D, Karlin AP, Anderson T. Practical network
support for (IP) traceback. In Proceedings of SIGCOMM, 2000;
pp. 295–306.

5. Ioannidis J, Bellovin SM. Implementing pushback: router-based
defense against DDoS attacks. In Proceedings of Network
and Distributed System Security Symposium, Catamaran Resort
Hotel San Diego, California, 6–8 February 2002. The Internet
Society, February 2002.

6. Yaar A, Perrig A, Song D. Pi: a path identiﬁcation mechanism to
defend against DDoS attacks. In IEEE Symposium on Security
and Privacy, May 2003; pp. 93–107.

7. Keromytis A, Misra V, Rubenstein D. Sos: an architecture for
mitigating DDoS attacks. IEEE Journal on Selected Areas of
Communications (JSAC) 2004; 22(1): 176–188.

8. Peng T, Leckie C, Ramamohanarao K. Protection from dis-
tributed denial of service attack using history-based ip ﬁltering.
In IEEE International Conference on Communication (ICC),
Vol. 1, May 2003; pp. 482–486.

9. Wang H, Zhang D, Shin K. Detecting SYN ﬂooding attacks. In

Proceedings of IEEE INFOCOM, 2002.

10. Hussain A, Heidemann J, Papadopoulos C. A Framework for
Classifying Denial of Service Attacks. In Proceedings of ACM
SIGCOMM, 2003; pp. 99–110.

11. Shu Z, Dasgupta P. Denying denial-of-service attacks: a router
based solution. In International Conference on Internet Com-
puting 2003, 2003; pp. 301–307.

Copyright © 2008 John Wiley & Sons, Ltd.

12. MacQueen J. Some methods for classiﬁcation and analysis of
multivariate observations. In Proceedings of the 5th Berkeley
Symposium on Mathematical Statistics and Probability, 1965;
pp. 281–297.

13. Chhabra P, John A, Saran H. PISA: automatic extraction of trafﬁc
signatures. In Proceedings of IFIP NETWORKING, 2005; pp.
730–742.

14. Lazarevic A, Ertoz L, Kumar V, Ozgur A, Srivastava J. A com-
parative study of anomaly detection schemes in network intru-
sion detection. In Proceedings of 3rd SIAM Conference on Data
Mining, San Francisco, CA, January 2003.

15. Breunig MM, Kriegel H-P, Ng RT, Sander J. LOF: identify-
ing density-based local outliers. In ACM SIGMOD International
Conference on Management of Data, 2000; pp. 93–104.

16. Mood A, Graybill F, Boes D. Introduction to the Theory of Statis-
tics (3rd edn). John Wiley & Sons, Ltd: Chichester, West Sussex,
1974; 564.

17. Mahajan R, Bellovin S, Floyd S, Ioannidis J, Paxon V, Shenker
S. Controlling high bandwidth aggregates in the network. ACM
SIGCOMM Computer Communication Review 2002; 32(3): 62–
73.

18. Yau DKY, Lui JCS, Liang F, Yam Y. Defending against dis-
tributed denial-of-service attacks with max-min fair server-
centric router throttles. IEEE/ACM Transactions on Networking
2005; 13(1): 29–42.

19. Xu T, He DK, Zheng Y. Detecting DDOS attack based on one-
way connection density. In 10th IEEE Singapore International
Conference on Communication Systems (ICCS), October 2006;
pp. 1–5.

20. Lu W, Traore I. An unsupervised approach for detecting DDoS
attacks based on trafﬁc-based metrics. In IEEE Paciﬁc Rim Con-
ference on Communications, Computers and Signal Processing
(PACRIM), August 2005; pp. 462–465.

21. Kang J, Zhang Y, Ju J-B. Classifying DDoS attacks by hierarchi-
cal clustering based on similarity. In 2006 Internaltional Confer-
ence on Machine Learning and Cybernetics, August 2006; pp.
2712–2717.

22. Xu J, Lee W. Sustaining availability of web services under dis-
tributed denial of service attacks. Transactions on Computers
2003; 52(2): 195–208.

23. Kim Y, Lau WC, Chuah MC, Chao HJ. Packetscore: statistics-
based overload control against distributed denial-of-service at-
tacks. In Proceedings of INFOCOM, 2004; pp. 2594–2604.

24. Yaar A, Perrig A, Song D. SIFF: a stateless internet ﬂow ﬁlter to
mitigate DDoS ﬂooding attacks. In IEEE Symposium on Security
and Privacy, May 2004; pp. 130–143.

25. Jin S, Yeung D. A covariance analysis model for DDoS
attack detection. In Proceedings of the IEEE International
Conference on Communications (ICC), Vol. 4, June 2004;
pp. 1882–1886.

26. Jin C, Wang H, Shin K. Hop-count ﬁltering: an effective defense
against spoofed DoS trafﬁc. In Proceedings of the 10th ACM
Conference on Computer and Communications Security, 2003;
pp. 30–41.

27. Lakhina A, Crovella M, Diot C. Characterization of network-
wide anomalies in trafﬁc ﬂows. In Proceedings of the 4th ACM
SIGCOMM Conference on Internet Measurement, Italy, 2004;
pp. 201–206.

28. Krishnamurthy B, Wang J. On network-aware clustering of web
clients. In Proceedings of the ACM SIGCOMM, Stockholm,
Sweden, August 2000; pp. 97–110.

29. Collins M, Reiter MK. An empirical analysis of target-resident
dos ﬁlters. In IEEE Symposium on Security and Privacy, May
2004; pp. 103–114.

30. Guirguis M, Bestavros A, Matta I, Zhang Y. Reduction of qual-
ity (RoQ) attacks on dynamic load balancers: vulnerability as-
sessment and design tradeoffs. In Infocom’07: The IEEE Inter-
national Conference on Computer Communication, Anchorage,
Alaska, May 2007; pp. 857–865.

Security Comm. Networks. 2008; 1:287–299
DOI: 10.1002/sec

