Discriminative Category Matching: Efﬁcient Text Classiﬁcation for Huge

Document Collections

Gabriel Pui Cheong Fung

Jeffrey Xu Yu

Dept. of Sys. Eng. & Eng. Management
The Chinese University of Hong Kong

Dept. of Sys. Eng. & Eng. Management
The Chinese University of Hong Kong

Hong Kong, China

pcfung@se.cuhk.edu.hk

Hong Kong, China
yu@se.cuhk.edu.hk

Hongjun Lu

Dept. of Computer Science

The Hong Kong Uni. of Science & Technology

Hong Kong, China

luhj@cs.ust.hk

Abstract

With the rapid growth of textual information available
on the Internet, having a good model for classifying and
managing documents automatically is undoubtly important.
When more documents are archived, new terms, new con-
cepts and concept-drift will frequently appear. Without a
doubt, updating the classiﬁcation model frequently rather
than using the old model for a very long period is abso-
lutely essential. Here, the challenges are: a) obtain a high
accuracy classiﬁcation model; b) consume low computa-
tional time for both model training and operation; and c)
occupy low storage space. However, none of the existing
classiﬁcation approaches could achieve all of these require-
ments. In this paper, we propose a novel text classiﬁcation
approach, called Discriminative Category Matching, which
could achieve all of the stated characteristics. Extensive ex-
periments using two benchmarks and a large real-life col-
lection are conducted. The encouraging results indicated
that our approach is hignhly feasible.

1 Introduction

With the tremendous growth in the volume of infor-
mation represented in textual format on the Internet, such
as news articles, government reports, company announce-
ments, product promotions, etc., new terms and new con-
cepts are more likely to appear than ever. Concept of a
collection may easily drift from one aspect to another also.
Boardly speaking, the general requirements for a model to

classify a huge document collection under the assumption
of possible concept drift are as follows:

x

x

1. High classiﬁcation accuracy.
2. Low computational cost and storage requirements for:
a) constructing the initial model; b) updating the model
after the model is built; and c) operation.

3. No parameter tuning and highly adaptable in any do-

x

mains.

While the existing approaches have shown their effec-
tiveness in text classiﬁcation [9, 10, 14, 21, 22, 23], none
of them are able to achieve all of the stated requirements.
In particular,
3 is
difﬁcult to achieve.

1 is, somehow, conﬂict with

2, while

x

x

x

For the existing techniques, SVM is properly the best in
term of accuracy. However, its training cost is quadratic
with the number of training instances [14]. In term of com-
putational cost, Naive Bayes should be the best. How-
ever,
its accuracy is not high [23]. Besides, most of
the approaches require performance tuning, such as fea-
ture selection, threshold decision, parameter setting, etc
[7, 15, 22, 23], which leads to the difﬁculty for handling a
huge document collection with frequently model updating.
In this paper, we propose a novel text classiﬁcation ap-
proach, called Discriminative Category Matching (DCM),
which could satisfy all of the stated requirements by using a
new weighting scheme. Here, we argue that none of the ex-
isting weighting schemes are suitable for text classiﬁcation.
In fact, all of them are designed for information retrieval but
not for classiﬁcation. Their motivation is: features which

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

appear frequently in many documents will have limited dis-
crimination power, and therefore have to be de-emphasized
[4, 17]. However, this is not the case for text classiﬁcation.
In addition, most of them have the difﬁculty in updating the
feature domain once the model is built [4, 8].

Our new weighting scheme aims at discriminating a cat-
egory from others by assigning the features with higher
weights if they appear in fewer categories. Extensive ex-
periments are conducted using two benchmarks (Reuters-
21578 and TREC9-MeSH) and a very large collection of ar-
ticles (namely, Reuters News Collection). Our experimen-
tal results show that DCM achieves high accuracy and low
computational cost and storage requirement, which make it
feasible for online classiﬁcation.

The rest of the paper is organized as follows. Section
2 discusses the related work. Section 3 describes DCM in
details. Evaluations and experimental results are reported
in Section 4. Finally, a summary and conclusion is given in
Section 5.

2 Related Work

In this section, we brieﬂy discuss the merits and limi-
tations of two popular approaches: Naive Bayes (NB) and
Support Vector Machines (SVM).

2.1 Naive Bayes

NB is a probabilistic-base algorithm in which its basic
idea is to compute the posterior probability of the incoming
document given a particular category [11, 12]. Mathemati-
cally, it is calculated by the Bayes rule:

P

c

P

d

c

(

)

(

)

j

i

j

P

d

c

(

) =

i

j

(cid:1)

j

j

P

d

(

)

i

(1)

i

j

d

where
.
tor and
assumption.

P

P

c

(

(

)

j

j

is the incoming document and
is the category
is computed by the maximum likelihood estima-
is computed under the word independent

c

j

d

c

)

i

j

There are two versions of NB: Multivariate Bernoulli and
Multinomial Mixture. The former one only takes the term
occurrence into account, while the later one further takes
the term frequency into consideration. In general, Multino-
mial Mixture model performs better [13, 23]. An efﬁcient
implementation of NB is the Rainbow package by McCal-
lum.1

The merit of NB lies on its robustness and consumes
little computational resources.
Its major criticism is the
word independence assumption. Several research tries to
address this problem by generating some association-like

1http://www.cs.cmu.edu/ mccallum/bow

Symbol Meaning

d

k

f

i

f

i;x

l

d

N

k

N

nf

i;d

df

i;k

(cid:12)

i;k

C

i

w

i;d

W

i;k

(i.e. the total number of features)

2

[

]

i

i

d

k

x

x

d; k

in

A document
Category
Feature
Feature
, where
Length of document
Total number of documents in category
Total number of categories in the collection
Number of time feature
Number of documents contain feature
The risk estimator of feature
The set of categories contain feature
The weight of feature
The weight of feature

in document
in category

in category

k

d

f

f

f

f

f

i

i

i

i

i

f

k

i

appear in document

d

in category

k

k

Table 1. Symbols and their meanings

rules [3, 14, 15]. Although an improvement on classiﬁca-
tion accuracy is obtained, the computational cost is far more
expensive then before.

2.2 Support Vector Machines

SVM is developed based on statistical learning theory for
solving two-class pattern recognition problem [18]. Con-
ceptually, it tries to generate a decision hyperplane that
maximizes the margin between the positive and the nega-
tive examples in a training set. Mathematically, it requires
minimizing the following quadratic programming [1]:

1

W

(cid:11)

(

) =

(cid:11)

Q

(cid:11)

(cid:11)

b

y

(cid:11)

+

i

ij

i

i

i

i

(2)

2

(cid:0)

i;j

i

i

X

X

X

ij

Q

where
is the Lagrange multiplier and
ing example and 0 otherwise.

is the symmetric positive deﬁnite kernel matrix,

b

equals 1 for positive train-

y

i

The algorithm used for solving linearly separable case
can be extended to solve linearly non-separable case by ei-
ther introducing some soft margin hyperplans or mapping
the original vectors to a higher dimensional space. Some ef-
ﬁcient implementation of it include SVMlight by Joachims2
and Sequential Minimal Optimization by Platt3 [16].

Recent research shows that SVM achieves very high ac-
curacy for text classiﬁcation [9]. The major draw back of it
is the very expensive training cost which is quadratic to the
number of training instances. This leads to the problem for
very large-scale learning or updating.

3 Discriminative Category Matching (DCM)

In this section, we introduce our novel text classiﬁcation
approach, the Discriminative Category Matching (DCM).
Table 1 shows a list of symbols and their corresponding

2SVMlight is available at: http://svmlight.joachims.org/
3SMO is available at: http://research.microsoft.com/ jplatt/smo.html

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

meanings that will be used in the following discussions.
Like the existing works, we use a vector space model to
represent a document and a category:

d

f

w

; f

w

; : : : ; f

=

:

:

:

w

;d

;d

;d

;d

n;d

n;d

1

1

2

2

h

i

k

f

W

; f

W

; : : : ; f

=

:

:

:

W

;k

;k

;k

;k

m;k

m;k

1

1

2

2

h

i

Classiﬁcation is achieved by ﬁnding the maximum sim-
among all of the categories. The

ilarity between
similarity is measured by the Jaccard coefﬁcient:

and

d

k

(3)

(4)

2500

2000

1500

1000

500

s
t
n
e
m
u
c
o
D

 
f

o
 
r
e
b
m
u
N

0

1

S

d; k

(

) =

(cid:1)

2

2

2

i

d

(

w

W

)

i;d

i;k

2

2

2

i

d

i;d

i

d

i;k

i

d

w

+

W

(

w

W

)

i;d

i;k

P

P

P

P

(cid:0)

(cid:1)

(5)

Figure 1. The distribution of
egory EARN in Reuters-21578

. Here

is the cat-

d

k

i;k

10

100

1000

10000

Number of Features (log scale)

Jaccard coefﬁcient expresses the degree of overlapping
between the document and the category as the proportion of
overlapping from the whole. It provides both intuitive and
practical ﬁtness to our model – matching a document with
a category. Other measurements, such as cosine coefﬁcient,
may not be suitable as they will take the size of document
and category into account.

Note that, in Equation (5), not all of the features in both
the document and the category are compared. Only the fea-
tures appearing in the document will be considered. In the
following subsections, we present all other components in
Equation (5) in details.

3.1 Weighting a Feature within a Document

The weight for the relative importance of

in

is:

f

d

i

log

(

+ 1)

2

nf

i;d

w

=

i;d

log

(

+ 1)

2

l

d

(6)

times cannot imply that it is

Here, the feature is assigned a higher weight if it appears
frequently within a document. As pointed out in [2], a fea-
times more
ture appearing
important. Thus, a logarithmic relationship rather than a
linear relationship is taken. This actually follows the results
in other studies [2, 4, 17], especially the one from Harman
[5].

n

n

3.2 Weighting a Feature within a Category

The weight of

in

is:

f

k

i

W

AI

=

i;k

i;k

(cid:1)

p

2

2

2

W C

C C

i;k

i

(7)

(cid:1)

(cid:18)

(cid:1)

(cid:19)

2

2

W C

C C

+

i;k

i

q

2

is used for normalization such that

Here, p
The main components are: 1) the relative importance of
(
(
gories (
These components are further computed as follows:

); and 3) the average importance of

); 2) the relative importance of

among all cate-
).

.

W C

C C

AI

i;k

i;k

i;k

i;k

i;k

W

(cid:20)

(cid:20)

1

0

f

f

f

i

i

W C

=

i;k

log2 (

+ 1)

df

i;k

log2 (

+ 1)

N

k

C C

i

= log

(cid:1)

f

g

N

max

W C

1

k

C

i;k

2

i

N

k

=1

i;k

W C

(cid:1)

log

N

P

2

d

k

w

i;d

(cid:12)

i;k

AI

=

i;k

(cid:18)

df

(cid:19)

i;k

P

(cid:12)

i;k

= 2

W C

i;k

(cid:0)

(8)

(9)

(10)

(11)

The motivations of these equations are explained be-
low. In order to demonstrate the effectiveness of DCM, the
benchmark Reuters-21578 is used for illustration and expla-
nation. Extensive experiments have also been conducted,
and are presented in Section 4.

3.2.1 The Relative Importance of a Feature in a Cate-

gory (

)

W C

i;k

Documents belonging to the same category should inherit
some common themes in nature, otherwise they would have
no reasons to be grouped together. In other words, features
that appear frequently within a category should be critical
in term of classiﬁcation. As a result, Equation (8) is formu-
lated.

In Equation (8), both numerator and denominator are
logarithmic. This is based on our observation that the fre-
quency of a feature appearing over many documents is rare.
Figure 1 illustrates this using the category EARN in Reuters-
21578. In Figure 1, the probability of a feature that appears
in many documents is very low. Similar ﬁnding is also re-
, where
ported in [6]. Figure 2 shows
a linear shape is obtained.
It shows that the number of
features which appears in many documents and their cor-
responding importance form a logarithmic relationship.

versus

W C

i;k

i;k

d

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

10

100

1000

10000

Number of Documents (log scale)

Figure 2. The relationship between
Here

is the category EARN in Reuters-21578

and

i;k

d

k

.

W C

i;k

0

0

10

30

20
40
Number of Categorys

50

60

(a)

vs

CC

C

i

i

j

j

Feature

1

0.8

0.6

0.4

0.2

t

i

n
e
c
i
f
f

e
o
C
 
y
r
o
g
e
a
C
-
n
h

t

i

t
i

W

0

1

Feature: BARREL

Feature: REGULATION

Category
ACQ
CPU
CRUDE
EARN
FUEL
GAS
GNP
HEAT
NAT-GAS
RETAIL
WPI

Occ.
5
1
140
7
4
2
2
2
2
1
1

Category
Doc.
ACQ
1595
CPI
54
CRUDE
253
EARN
2840
GAS
4
GOLD
10
GRAIN
59
INTEREST
6
24 MONEY-FX
19
14

SUGAR
TRADE

Occ.
12
1
1
3
1
1
3
2
6
4
7

Doc.
1595
54
253
2840
10
70
41
191
222
97
251

Table 2. The distribution of two features, BARREL
and REGULATION, in Reuters-21578.

3.2.2 The Relative Importance of a Feature Across

Categories (

)

C C

i

i;k

W C

above is designed to capture the information within
category, but it cannot gain any global information about
the feature distribution in the whole collection. However,
having a global view across categories is very important.
appears
and
For instance, given two features,
in more than half of the categories and
appears only in
provides far more precious
a few categories. Obviously,
information for text classiﬁcation than
has
much higher discriminative power.

, because

, where

f

f

f

f

f

f

f

j

j

j

j

i

i

i

To be more speciﬁc, consider the feature REUTERS
which appears over 5930 out of 6560 documents in 53 cat-
egories. Obviously, it does not have any value for classi-
ﬁcation. In other words, a feature is more valuable if its
occurrence is skewed.

However,

in computing the importance of a feature
across categories, we argue that it is not realistic to weight
the importance it by simply counting the number of cate-
gories that the feature appeared as suggested in [20]. As
an example, the distribution of two features, BARREL and

Feature

Feature

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

t

i

n
e
c
i
f
f

e
o
C
 
y
r
o
g
e
a
C
-
s
s
o
r
C

t

t

i

n
e
c
i
f
f

e
o
C
 
y
r
o
g
e
a
C
-
s
s
o
r
C

t

0

1

10

100

1000

10000

Number of Documents (log scale)

(b)

vs

CC

d

i

i;k

Figure 3. The properties of

C C

i

REGULATION, is shown in Table 2. Both of them ap-
peared in 11 categories. If we weight their importance by
simply counting the number of categories they appeared,
then both of them will be assigned to the same weight.

However, note that

the occurrence of BARREL is
skewed in the category CRUDE, whereas REGULATION
is more or less evenly distributed. In other words, BAR-
REL has a much higher discriminative power than REG-
ULATION. Thus, BARREL should receive much higher
weight. Unfortunately, there are no reported studies on how
to weight the discriminative power of a feature for classi-
ﬁcation purposes. In this paper, we ﬁrst propose a formula
which weights features based on their discriminative power.
In Equation (9), the summation is used for gathering the
total importance of a feature across all categories, while the
maximum is used for averaging the summation value. If a
feature is regarded as important in many categories, then
this feature is obviously not important for classiﬁcation.
In other words, the higher the value of the numerator, the
,
smaller the discriminative power is. The term,
is used for normalization such that

.
Figure 3 (a) shows the relationship between

and

log(

C C

N

(cid:20)

(cid:20)

1

0

1

=

)

i

C C

i

and Figure 3 (b) shows the relationship between

C

i

C C

i

j

j

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

Feature

Feature

t

r
o
a
m

i
t
s
E
 
k
s
R

i

2

1.8

1.6

1.4

1.2

1

1

10

100

1000

10000

Number of Documents (log scale)

Figure 4. Risk estimator (
quency (

)

d

i;k

) versus document fre-

(cid:12)

and

. The category EARN is used for illustration.

d

i;k

i

i

C C

C C

. First,

tends to decrease while

Figure 3 (a) shows a number of important properties of
increases, as
even
expected from Equation (9). Second,
if
,
appearing in the same number of categories do not neces-
sarily have the same discriminative power. For references,
are 0.61 and 0.29, re-

. It is because the two features,

and

and

C C

C C

i;k

=

=

C

C

d

f

f

j

j

j

j

j

j

j

i

i

i

C C

C C

BARREL

REGU LAT I ON

spectively.

i

C C

is computed by

Finally, although

, which, in
turn, depends on
.
No trends could be seen in Figure 3 (b). It is very important
, the system may bias for
because if
those large size categories.

is in fact independent on

depends on

,

W C

C C

C C

i;k

i;k

i;k

i;k

d

d

d

i

i

3.2.3 The Average Importance of a Feature in a Cate-

gory (

)

AI

i;k

i

i;k

C C

W C

and

above are computed at the category level.
However, the importance of a feature within an individ-
ual document has not yet been addressed. Thus, average-
importance of a feature, is introduced. In Equation (10),
the term within the bracket is to average the weights of
among all documents in
, is used to
determine the suitability of this average. The motivation of
this estimator is based on the observation that: if there are
, then this averaged value can
more documents containing
be a better estimator for its true importance.

. The risk estimator,

(cid:12)

k

f

f

i

i

f

and

For instance, given two features:

appears in
appears in only a few documents. It
is more
. Thus,
is, the higher the risk will be, and fewer

most documents but
is more conﬁdent to declare that the average for
likely to reﬂect the true status of it than that of
the higher the
documents will contain the corresponding feature.

,

(cid:12)

f

f

f

f

f

j

j

j

i

i

i

Figure 4 shows the

values versus the number of doc-
, which is decreasing linearly. If we
from the equation, a deteriorate result will be ob-

uments containing
remove
tained. More details are given in Section 4.

(cid:12)

(cid:12)

f

i

)

 

C
C
+
C
W

 

(
 
t

i

 

h
g
e
W
d
e
b
n
m
o
C

i

)

 

 

C
C
+
C
W
+

 

 
I

A

(
 
t

i

h
g
e
W

 
l

a
n
F

i

0

1

1

0.8

0.6

0.4

0.2

0.3

0.2

0.1

0

1

10
1000
Number of Documents (log scale)

100

10000

(a) without

AI

i;k

Feature

10

100

1000

10000

Number of Documents (log scale)

(b) with

AI

i;k

Figure 5. The Effectiveness of

AI

i;k

Standard Dev.

0.008199

0.041573

AI

AI

i;k

i;k

with

without

Table 3. The standard deviation of
without

.

AI

i;k

with and

W

i;k

i;k

AI

Figure 5 shows the effectiveness of

. The overall
shape of both ﬁgures is very similar, but the points (fea-
tures) in Figure 5 (b) are much denser. This is very impor-
tant as the standard deviation of the weights among different
can reduce
features will be lowered. In other words,
the discrepancy among weights. This can increase the recall
and precision of the model. Table 3 shows the effectiveness,
with and without using of

.

AI

i;k

AI

i;k

4 Experimental Studies

All of the experiments are conducted on a Sun Blade-
1000 workstation with 512MB physical memory and a
750MHz Ultra-SPARC-III CPU running Solaris 2.8. All
features are stemmed and converted to lower case, in which
punctuation marks are removed, numbers and web page ad-
dresses are ignored.

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

6
Dataset
Reuters-21578
TREC9-MeSH
Reuters News Collection

Training
6,560
5,182
133,380

Testing
2,568
26,327
33,345

Cat.
52
154
38

Features
13,270
25,245
206,897

Table 4. A summary of the corpora used.

We compare DCM with NB and SVM. The standard
measurement of recall and precision [2] are used. In order
1-measure is taken
to have a harmonic average of them,
[21]:

F

2

precision

recall

F

=

1

(cid:2)

(cid:2)

precision

recall

+

(12)

We restrict the evaluation to single category classiﬁca-
tion: assigning a document to only one category. The full
advantage of DCM is that it can continuous to learn when-
ever there is any new document arrives. We implement
two versions of DCMs. The ﬁrst version, denoted DCM,
does not update once it is built. The second version, de-
noted DCM+, continues to learn whenever a new document
is classiﬁed.

4.1 Datasets

The corpora used for evaluations are: Reuters-215784,
TREC9-MeSH5 and Reuters News Collection. They are
summarized in Table 4 and their details are as follows:

(cid:15)

(cid:15)

(cid:15)

Reuters-21578: We take the ModApte-split and select
documents that are assigned to one category such that
each category has at least one document for training
and one document for testing. Note that this collection
is highly skewed: the largest category contains 2,840
training documents, while the smallest category con-
tains only 1. About 85% of the categories contain less
than 100 documents.
TREC9-MeSH: It is a selected subset of MeSH cate-
gories in Ohsumed233445. The selection criteria are:
1) at least four relevant documents in the 1987 training
data set; and 2) at least one relevant document in each
year of the testing set. We further select documents
that are assigned to one disease category.
Reuters News Collection: It is a set of news articles
that we have archived from Reuters directly from Oc-
tober 2000 to March 2002. Our task is to assign the
news articles to one of the 38 Morgan Stanley Capi-
tal International (MSCI) category. Note that Reuters
has already classiﬁed the articles to the correct cate-
gories. The news articles are ordered by broadcasting
time. The ﬁrst 80% is used for training while the re-
maining 20% is used for testing.

4http://kdd.ics.uci.edu
5http://trec.nist.gov

Method M-Precision M-Recall M-F
0.544
NB
0.712
SVM
0.720
DCM
0.749
DCM+

0.603
0.791
0.775
0.837

0.565
0.681
0.750
0.762

1 m-F
0.863
0.914
0.910
0.933

1

Table 5. A summary of the evaluation results for
Reuters-21578.

Method M-Precision M-Recall M-F
0.386
NB
0.525
SVM
0.529
DCM
0.542
DCM+

0.492
0.662
0.579
0.595

0.374
0.495
0.579
0.592

1 m-F
0.577
0.692
0.598
0.600

1

Table 6. A summary of the evaluation results for
TREC9-MeSH.

4.2 Evaluation using benchmarks

Table 5 and Table 6 summarized the accuracy for
Reuters-21578 and TREC9-MeSH, respectively. Four stan-
dard measurements are: macro-precision (M-Precision),
macro-recall (M-Recall), macro-

1 and micro-

1 [21].

F

F

As shown in the tables, SVM outperforms NB signiﬁ-
cantly in both benchmarks. This replicates previous ﬁnd-
ings [9, 14, 23]. Comparing with SVM, DCM outperforms
it in Reuters-21578. For TREC9-MeSH, DCM performs
better at macro level, whereas SVM is better at micro level.
This can be explained by the performance consistence of
DCM over all categories with different sizes, as macro-
measure looks at the global picture of the performance of
all categories, while micro-measure favors the performance
on large sized categories. However, a direct comparison
between them is inappropriate as they focus on different
aspects. Since neither SVM nor DCM dominate in both
measures, we cannot conclude which approach is better in
TREC9-MeSH. It all depends on which measurement one
may concern with.

4.3 Scalability

In order to evaluate the scalability, CPU time in both
training and operation phrase are measured by scaling up
the Reuters-21578 corpus with a factor of 10. Figure 6
shows the model training and testing CPU time (second).

In Figure 6 (a), the training time of SVM increases sig-
niﬁcantly with the number of training examples. This deﬁ-
nitely leads to the problem of model updating for huge doc-
ument collections. For NB, its advantages are the very low
training and operational costs. However, the accuracy of it
is the worst among all classiﬁers. For DCM, although its

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

DCM
NB
SVM

1200

1000

800

600

400

200

i

 

)
c
e
s
(
 
e
m
T
U
P
C
g
n
n
a
r
T

 

i

i

0

0

i

)
c
e
s
(
 
e
m
T
U
P
C
g
n

 

 

i
t
s
e
T

70

65

60

55

50

45

40

35

30

25

20

15

10000 20000 30000 40000 50000 60000 70000

Number of Training Documents

(a) Training Time

DCM
NB
SVM

0

10000 20000 30000 40000 50000 60000 70000

Number of Training Documents

(b) Testing Time

Figure 6. The training and testing CPU time.

operational cost is highest, it still performs well.

4.4 Evaluation using real-life large collection

The scalability study in Section 4.3 shows the effective-
ness and efﬁciency of DCM using Reuters-21578. How-
ever, as listed in Table 4, this dataset is rather small in size.
The number of features are only 13,270. We further con-
ducted another experiment using our Reuters News Collec-
tion which contains over 206,897 features. The numbers of
training and testing documents are 133,380 and 33,345, re-
spectively. Table 7 shows a summary of the classiﬁcation
accuracy.

F

NB does not perform well, as both

1 values are less
than 0.5. Among all, SVM performs the best in term of
1 measure, whereas DCM+ per-
M-Precision and micro-
1 measure.
forms the best in term of M-Recall and macro-
In fact, in all of the corpora used, DCM always performs
excellent with macro-measure. This gives a suggestion that
those small-size categories may be more beneﬁcial using
DCM.

F

F

Method M-Precision M-Recall M-F
0.336
NB
0.667
SVM
0.603
DCM
0.687
DCM+

0.617
0.758
0.677
0.721

0.329
0.667
0.589
0.678

1 m-F
0.465
0.779
0.706
0.730

1

Table 7. A summary of the evaluation results for
Reuters News Collection.

Exp. No.

use

use

use

W C

C C

AI

i;k

i;k

i

1
2
3
4
5
6
7
8

(cid:2)

p

p

p

p

p

p

p

(cid:2)

(cid:2)

(cid:2)

p

(cid:2)

p

(cid:2)

(cid:2)

(cid:2)

(cid:2)

p

p

+

p

p

p

Table 8.

Analysis.

W

i;k

4.5 The Combined Effectiveness of the Three

Components Used in

W

i;k

i

i;k

i;k

AI

C C

W C

,

and

In this section, we examine the importance of each of the
, in Equation (5). Eight
components,
experiments are conducted using Reuters-21578 shown in
Table 8. Here, a tick denotes that the corresponding com-
ponent is included, whereas a cross denotes for ignorance.
Experiment 7 is set up such that the three components are
, is ignored. Experiment 8
included but the risk estimator,
uses all of the coefﬁcients including the risk estimator.

(cid:12)

The results of these experiments are shown in Table 9.
Obviously, none of the settings can outperform Experiment
8 – using all of the components. Experiment 4 and 5 use
, and obtain extremely poor results.
either
However, the accuracy of using both
(Ex-
periment 1) improves dramatically. For Experiment 7, ig-
noring the the risk estimator obtains inferior result, which
explains the importance of it.

and

or

W C

W C

C C

C C

i;k

i;k

i

i

5 Conclusion

In this paper, we proposed a novel text classiﬁcation
approach, called discriminative category matching (DCM).
DCM does not need to generate any sophisticated models
but only requires simple statistical data. Furthermore, DCM
can be updated immediately whenever a new document ar-
rives.

For the computational time, DCM depends on the num-
ber of categories and the number of features in the collec-
tion. Online classiﬁcation is highly feasible as the respond
time is very short. For the data storage, DCM does not need

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

.

1

Method M-Precision M-Recall M-F
1
0.650
2
0.637
3
0.709
4
0.158
5
0.075
6
0.603
7
0.452
8
0.749

0.797
0.772
0.808
0.213
0.143
0.736
0.626
0.837

0.589
0.589
0.657
0.183
0.068
0.548
0.390
0.762

1 m-F
0.892
0.903
0.911
0.136
0.142
0.898
0.820
0.933

Table 9. A comparison of using different combina-
tion of the coefﬁcients.

to store the whole documents and only requires simple sta-
tistical data.

Two main advantages of DCM are: 1) it can train the
model very efﬁciently regardless the size of the collection;
and 2) it is able to deal with concept-drift by updating the
newly received features with higher weights. Further inves-
tigations on these areas will be done.

In fact, most text classiﬁcation approaches focus on the
model generation and performance tuning. None of them
try to discover the feature distribution within a collection.
The detailed analysis on the characteristics of features pre-
sented here will certainly provide valuable guildlines for
developing weighting schemes in text classiﬁcation appli-
cations.

Acknowledgments

The work described in this paper was partially sup-
ported by grants from the Research Grants Council of
the Hong Kong Special Administrative Region, China
(CUHK4229/01E, DAG01/02.EG14).

References

[1] G. Cauwenberghs and T. Poggio.

Incremental and decre-
mental support vector machine learning. In Proceedings of
Advances in Neural Information Processing Systems, pages
409–105, 2000.

[2] W. B. Frakes and R. Baeza-Yates.

Information Retrieval:

Data Structures and Algorithms. Prentice Hall PTR, 1992.

[3] N. Friedman, D. Giger, and M. Goldszmidt. Bayesian net-
work classiﬁers. Machine Learning, 29(203):131–163, 1997.
[4] W. R. Greiff. A theory of term weighting based on ex-
In Proceedings of SIGIR-98 21th
ploratory data analysis.
ACM International Conference on Research and Develop-
ment in Information Retrieval, pages 11–19, 1998.

[5] D. Harman. An experimental study of factors important in
document ranking. In Proceedings of SIGIR-86 9th Interna-
tional Conference on Research and Development in Informa-
tion Retrieval, pages 186–193, 1986.

[6] J. D. Holt and S. M. Chung. Efﬁcient mining of associa-
tion rules in text databases. In Proceedings of 8th Interna-
tional Conference on Information and Knowledge Manage-
ment, pages 234–242, 1999.

[7] D. J. Ittner, D. D. Lewis, and D. D. Ahn. Text categorization
of low quality images. In Symposium on Document Analysis
and Information Retrieval, pages 301–315, 1995.

[8] T. Joachims. Text categorization with support vector ma-
chines: Learning with many relevant features. Technical Re-
port LS-8-23, University of Dortmund, 1997.

[9] T. Joachims. Text categorization with support vector ma-
chines: Learning with many relevant features. In Proceed-
ings of 13th European Conference on Machine Learning,
pages 137–142, 1998.

[10] W. Lam and C. Y. Ho. Using a generalized instance set for
In Proceedings of SIGIR-98
automatic text categorization.
21th ACM International Conference on Research and Devel-
opment in Information Retrieval, pages 81–89, 1998.

[11] D. D. Lewis. An evaluation of phrasal and clustered repre-
In Proceedings of
sentations on a text categorization task.
SIGIR-92 15th ACM International Conference on Research
and Development in Information Retrieval, pages 37–50,
1992.

[12] D. D. Lewis. Naive (bayes) at forty: The independence as-
sumption in information retrieval. In Proceedings of 13th Eu-
ropean Conference on Machine Learning, pages 4–15, 1998.
[13] A. McCallum and K. Nigam. A comparison of event models
for naive bayes text classiﬁcation. In AAAI 1998 Workshop
on Learning for Text Categorization, 1998.

[14] D. Meretakis, D. Fragoudis, H. Lu, and S. Likothanassis.
In Proceed-
Scalable association-based text classiﬁcation.
ings of 10th International Conference on Information and
Knowledge Management, pages 5–11, 2001.

[15] D. Meretakis, H. Lu, and B. Wuthrich. A study on the per-
In Proceedings of 15th
formance of large bayes classiﬁer.
European Conference on Machine Learning, pages 271–279,
2000.

[16] J. Platt. Sequential minimal optimization: A fast algorithm
for training support vector machines. Technical Report MST-
TR-98-14, Microsoft Research, 1998.

[17] G. Salton and C. Buckley. Term-weighting approaches in
automatic text retrieval. Information Processing and Man-
agement, 24(5):513–523, 1988.

[18] V. Vapnik.

The Nature of Statistical Learning Theory.

Springer, 1995.

[19] I. H. Witten and E. Frank. Data Mining: Practical Machine
Learning Tools and Techniques with Java Implementations.
Morgan Kaufmann Publishers, 2000.

[20] K. Yamamoto, S. Masuyama, and S. Naito. Automatic text
classiﬁcation method with simple class-weighting approach.
In Natural Language Processing Paciﬁc Rim Symposium,
1995.

[21] Y. Yang. An evaluation of statistical approaches to text cate-

gorization. Information Retrieval, 1-2(1):69–90, 1999.

[22] Y. Yang. A study on thresholding strategies for text cate-
gorization. In Proceedings of SIGIR-01 24th ACM Interna-
tional Conference on Research and Development in Informa-
tion Retrieval, pages 137–145, 2001.

[23] Y. Yang and X. Liu. A re-examination of text categorization
In Proceedings of SIGIR-99 22th ACM Interna-
methods.
tional Conference on Research and Development in Infor-
mation Retrieval, pages 42–49, 1999.

Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM’02) 
0-7695-1754-4/02 $17.00 © 2002 IEEE 

