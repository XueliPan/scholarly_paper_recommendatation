Anthill: A Scalable Run-Time Environment for Data Mining Applications

Renato Ferreira Wagner Meira Jr. Dorgival Guedes

Speed-DCC-UFMG

Lucia Drumond

IC-UFF

Abstract

Data mining techniques are becoming increasingly more
popular as reasonable means to collect summaries from the
rapidly growing datasets in many areas. However, as the
size of the raw data increases, parallel data mining algo-
rithms are becoming a necessity. In this paper we present a
run-time support system that was designed to allow the efﬁ-
cient implementation of data-mining algorithms on hetero-
geneous distributed environments. We believe that the run-
time framework is suitable for a broader class of applica-
tions, beyond data mining. We also present, through an ex-
ample, a parallelization strategy that is supported by the
run-time system. We show scalability results of two different
data-mining algorithms that were parallelized using our ap-
proach and our runt-time support. Both applications scale
very close to linearly with large number of nodes.

1. Introduction

Very large datasets are becoming common place in many
areas. This fact is a consequence of both a continuous drop
on the cost of data storage and a continuous increase in
the sophistication of equipments and algorithms that col-
lect and store such data. Analyzing these huge datasets
is rapidly becoming impractical in its raw form, and data
mining techniques have increased in popularity lately as
means of collecting meaningful summarized information
from these huge datasets. However, even the fastest sequen-
tial algorithms may not be enough to sumarize such volume
of data and therefore, the development of efﬁcient parallel
algorithms for such tasks is crucial.

At the same time, Grid Computing [5] is emerging as an
alternative to very expensive supercomputers. The Grid is a
large distributed system created by connecting together sev-
eral clusters of machines on different sites through WAN
connections. The clusters are sets of homogeneous ma-
chines connected by LAN. While the potential computing

power made available by the Grid is very large, exploiting
this power is not trivial.

Much work has been done in developing parallel data
mining algorithms over the years [11, 7]. The main limita-
tion in all those algorithms, to the best of our knowledge,
is that they have not been shown to scale well to very large
number of processors. We have recently published a paral-
lel implementation for the Frequent Itemset Mining prob-
lem for large heterogeneous distributed environments and
our experimetns have shown it to scale really well [9].

In the process of creating this implementation, we gener-
ated both a parallelization strategy for a larger class of data-
mining algorithms, as well as a run-time framework to sup-
port such strategy. In this paper, we focus on these two is-
sues. The framework is refeered to as Anthill, and we show
two new data mining algorithms that were implemented us-
ing the same strategy as the one for the earlier Frequent
Itemset Mining problem. The two new algorithms are: k-
means for clustering and ID3 for classiﬁcation. Our exper-
iments with these new applications have shown high scala-
bility, similar to the earlier algorithm. In particular, the ap-
plications are shown to scale very close to linearly up to
dozens of distributed nodes.

We believe that our framework exposes a convenient pro-
gramming abstraction which is suitable for designing ef-
ﬁcient parallel versions of algorithms in several areas be-
sides data mining. The run-time assumes that the applica-
tions eventually run on large heterogenous distributed envi-
ronments (grids). The starting point of Anthill is Datacut-
ter [3], which is a data-ﬂow based run-time environment for
distributed architectures, but Anthill supports a richer pro-
gramming model that allows a wide range of paralleliza-
tions to be efﬁciently implemented.

The remaining of the paper is organized as follows. In
Section 2 we present Anthill run-time environment and its
programming model. Section 3 describes the ID3 algorithm
and its parallelization and Section 4 present some experi-
mental results. We conclude and present some future direc-
tions in Section 6.

2. Run-time framework

In this section we describe Anthill, our run-time support
framework for scalable applications on grid environments.
Building applications that may efﬁciently exploit such en-
vironment, while maintaining good performance is a chal-
lenge. In this scenario, the datasets are usually distributed
across several machines in the Grid. Moving the data to
where the processing is about to take place is often inef-
ﬁcient. Usually, for such applications, the resulting data is
many times smaller than the input. The alternative is to
bring the computation to where the data resides. Success
in this approach depends on the application being divided
into portions that may be instantiated on different nodes on
the Grid for execution. Each of these portions will perform
part of the transformation on the data starting from the in-
put dataset and until the resulting dataset.

The discussion above indicates that a good paralleliza-
tion of any application in such environment should consider
both data parallelism and task parallelism at the same time.
Our strategy uses these two approaches together with a third
approach that works over the time dimension allowing some
degree of asynchronous execution of independent sub-tasks.
The beneﬁts of these three dimensions combined produces
the high speedups observed in our experiments.

We based Anthill on an earlier run-time support frame-
work for distributed environments call Datacutter, which is
in turn based upon the ﬁlter-stream programming model.
We now describe Datacutter and the extensions that are sup-
ported in Anthill.

2.1. Datacutter

The ﬁlter-stream programming model was origi-
nally proposed for Active Disks [1]. The idea was to
create the concept of disklets or little pieces of the appli-
cation computation that could be off-loaded to the pro-
cessors within the disks. In that context, the disklets, or
ﬁlters, are entities that perceive streams of data ﬂow-
ing in, and after some computation it would generate
streams of data ﬂowing out. Later, this concept was ex-
tended as a programming model suitable for a Grid environ-
ment, and a runtime system was developed that supported
such model [4]. This runtime system is called Datacut-
ter and there has been a considerable amount of effort put
into various aspects of this system [8, 2].

In Datacutter, streams are abstractions for communica-
tion which allow ﬁxed sized untyped data buffers to be
transferred from one ﬁlter to another. In a sense, it is very
similar to the concept of UNIX pipes. The difference is that
while pipes only have one stream of data coming in and one
going out, in the proposed model, arbitrary graphs with any
number of input and output streams are possible.

Creating an application that runs in DataCutter is a pro-
cess referred to as decomposition into ﬁlters. In this process,
the application is modeled into a dataﬂow computation and
broken into a network of ﬁlters. At execution time, the ﬁl-
ters that compose the application are instantiated on several
machines comprising a Grid and the streams are connected
from source to destination.

To execute an application, a description of the ﬁlters and
the streams that connect them need to be provided to the
run-time environment. With that information, a number of
copies of each of the ﬁlters are instantiated on different
nodes of the distributed environment. These are referred to
as transparent copies of a ﬁlter.

2.2. Anthill

In this paper we presented our parallel programming
model and discuss how it supports highly scalable dis-
tributed computing. Our approach is based on the simple
observation that the applications can be decomposed in a
pipeline of operations, which represents task parallelism.

Further, for many applications, the execution consists of
multiple interations of this pipeline. The application starts
with an initial set of possible solutions, and as these pos-
sibilities are passed down the pipeline, new possible solu-
tions are created. In our experience, we noticed that many
applications ﬁt this model. Also, this strategy allows asyn-
chronous execution, in the sense that several possible solu-
tions are being tested simultaneously at run-time.

Our proposed model, therefore, consist of exploiting
maximum parallelism of the applications by using all three
possibilities discussed above: task parallelism, data paral-
lelism and asynchrony. Because the actual compute units
are copies of pipeline stages, we can have a very ﬁne
grain parallelism and since all these are happenening asyn-
chronously, the execution will be mostly bottleneck free. In
order to reduce latency, the grain of the parallelism should
be deﬁned by the application designer at run-time.

Three important issues arise from this proposed model:

1. The transparent copies mechanism allows every stage
of the pipeline to be distributed across many nodes of
a parallel machine and the data that goes through that
stage can be partitioned across the transparent copies,
which represents data parallelism.Some times it is nec-
essary for a certain data block to reach one speciﬁc
copy of a stage of the pipeline;

2. These distributed stages often have some state, which

need to be maintained globally;

3. Because of the nature of the application decomposi-
tion, it can be very tricky for them to detect that the
computation is ﬁnished.

These issues are discussed on the folowing subsections.

2.3. Labeled stream

The labeled stream abstraction is designed to provide a
convenient way for the application to allow a customized
routing of the message buffers to speciﬁc transparent copies
of the receiving ﬁlter. As mentioned earlier, each stage of
the application pipeline is actually executed on several dif-
ferent nodes on the distributed environment. Each copy of
a pipeline stage is different than the other in the sense
that they do data parallelism, meaning that each transpar-
ent copy will handle a distinct and independent portion of
the space comprised by the stage’s input data.

Which copy should handle any particular data buffer de-
pends upon the data itself. With labeled stream we add a
label to every message that traverses the stream thus cre-
ating a tuple < l; m > where l is the label and m is the
original message. Instead of just sending the message m
down the stream, the application will now send the entire
tuple < l; m >. Associated to each labeled stream, there is
also a hash function. For every message tuple traversing the
stream, the hash function is called with the tuple as parame-
ter. The output of this hash function indicates to the system
the particular copy to which that message should be deliev-
ered.

This mechanism gives the application total control of
the messages. Because the hash function is called at run-
time, the actual routing decision is taken individually for
each message and can change dynamically as the execution
progresses. This feature is convenient for it allows dynamic
reconﬁguration, which is particularly useful to balance the
load on dynamic and irregular applications. The hash func-
tion is also a little bit relaxed in the sense that the output
does not have to be necessarily return one single ﬁlter. In-
stead, it can output a set of ﬁlters, and in that case, a mes-
sage can be replicated and sent to multiple instances. This is
particularly useful for applications in which one single in-
put data element inﬂuences several output data elements.
Broadcast is one instance of this situation.

2.4. Global persistent storage

As mentioned earlier, each stage of the pipeline is dis-
tributed across many nodes on a Grid environment. Often
times these stages are stateful. This means that the stage
has an internal state which changes as more and more of
the computation chunks is passed down the pipeline. Anthill
needs a mechanism that allows the set of transparent copies
of any ﬁlter to share a global state. For some applications,
once the stage is partitioned across the nodes, the state vari-
ables on each transparent copy will reside locally on them.
But in many cases, this state may need to be updated on
different locations. This is particularly true for situations
where the applications are dynamically reconﬁguring itself

to balance the workload, or in failure situations in which the
system is automatically recovering.

If we consider the fault tolerance scenario, we add inter-
esting features to this state. It now requires to be stable, in
the sense that it has transactional property. Once a change
is committed on the state, it has to be maintained. So, hav-
ing multiple copies of the state on separate hosts is very im-
portant for the sake of safety.

As described above, two features are very important for
any data structure maintaining the global state. First, the
several data points within this state need to migrate conve-
niently from one ﬁlter to the other as the computation pro-
gresses. Second, it has to be stable in the sense that the data
stored there need to be preserved even in the case of fail-
ures on individual hosts running ﬁlter copies. We are imple-
menting a tuple space which is similar to Linda tuple space
to maintain the state. Such structure seems very convenient
for our purposes. Whenever a ﬁlter copy updates a data ele-
ment, it is updated on the tuple space. A copy of it is main-
tained on the same ﬁlter for performance reasons, while a
copy of it will be forward to another host for safekeeping.
The system then allows some degree of fault tolerance in the
sense that once a copy of a tuple is safely stored on a differ-
ent host, the update is assumed to be committed.

2.5. Termination problem

In Anthill, applications are modelled as generic directed
graphs. As long as such graphs remain acyclic, termination
detection for any application is straight forward: whenever
data in a stream ends the ﬁlter reading from it is notiﬁed.
When it ﬁnishes processing any outstanding tasks it may
propagate the information that the ﬂow ended to its outgo-
ing streams and terminate. When application graphs have
cycles, however, the problem is not that simple.

It may be the case that ﬁlters operating in a cycle can-
not decide by themselves whether a stream has ended or
not. Remember that each ﬁlter may have any number of
copies, all completely independent. Therefore, although a
ﬁlter copy may have local information indicating its job is
done, processing taking place in another copy may produce
new data that might travel through the loop and reach the
ﬁrst ﬁlter again.

When such situation happens in an application in Anthill,
leaving the task of detecting the termination condition to the
programmer is not reasonable solution. One of the goals of
the system is exactly to simplify the development of the ap-
plication, what would be compromised in that case. In order
to avoid that, Anthill implements a complete distributed ter-
mination detection protocol which may be relied upon by
applications that require it. The protocol is implemented in
the run time system, so applications need not be concerned
with it. Whenever the programmer designs a ﬁlter graph

with cycles all that is required is an indication of which
stream should be chosen by the run time system to insert
an end-of-stream notiﬁcation. The insertion of that message
breaks the cycle and causes the ﬁlters to propagate the in-
formation accordingly.

We now describe in more details our termination algo-

rithm.

2.5.1. Termination Detection Protocol For the sake of
the termination protocol, the ﬁlter graph is replaced by the
graph with all ﬁlter copies, where each copy is seen as con-
nected to all copies of the ﬁlters that are connected to its ﬁl-
ter in both directions (a copy is not connected to the other
copies of the same ﬁlter, since that is a premise of the orig-
inal ﬁlter-stream model). The algorithm works in rounds,
when some ﬁlter copy suspects computation has completed
and begins to contact its neighbors. If some ﬁlter is still
computing and produces new data, that round fails and the
algorithm proceeds to another round sometime in the fu-
ture. If all copies of all ﬁlters agree on termination during
a single round, termination is reached. The ﬁnal decision is
left for a process leader, responsible for collecting informa-
tion from all ﬁlters.

Three types of message are then exchanged in the pro-
tocol: copies that suspect
termination was reach send
SUSPECT(R) to their neighbors stating they suspect ter-
mination in round R; when a copy reaches an agreement
with all its neighbors, it notiﬁes the process leader us-
ing a TERMINATE(R) message, also identifying the
round number; if the leader collects TERMINATE mes-
sages from all ﬁlter copies for a same round it brodcasts
a END message back to them. Although streams are uni-
directional at the application level, the run-time system
uses them bidirectionally and guarantee the communica-
tion channels are reliable and messages between two ﬁl-
ter copies are always delivered in the order they were
sent.

Besides the round counter, R, each ﬁlter copy keeps a list
of the neighbors which suspect the same termination round
R has been reached. The core of the protocol is illustrated
by the extended Finite State Machine (FSM) in Figure 1.
Each ﬁlter copy may be in one of two states: as long as the
copy is running and/or there is data still to be read from its
input streams, it remains in the running state. If the ﬁlter
code blocks waiting for data from streams that are empty,
that is an indication that it is done computing (in fact, it
waits for a short interval before taking that decision, in case
data is about to arrive).

While a ﬁlter is computing and/or has data in its input
streams still to be read it does not propagate messages for
the termination protocol. If it receives data from another ﬁl-
ter (an application message), it removes the sender from its
list of neighbors suspected of having terminated, since it is
obviously computing. If it receives a SUSPECT(R’) mes-

App. msg. from i
Remove i from list

list has all neighbors

snd(leader,TERMINATE(R))

Running

Suspected
Termination

App.Msg.

update R <− R+1

Idle

tell all neighbors
SUSPECT(R)

SUSPECT(R’) from i

update R <− R’

Add i to suspects list

SUSPECT(R’) from i

if R’ > R

update R <− R’
tell all neighbors
Add i to suspects list

Figure 1. Extended FSM for the termination
algorithm

sage from another node, it ﬁrst checks whether the indicated
round R’ is the same it is in; if that is not the case and the
R’ round is newer (R’ > R), it updates R to the new value
and resets its list of suspects. After that, it adds the sender
of the SUSPECT message to its list.

If the run-time system in a ﬁlter copy detects it has been
idle for some time (no computation taking place, and the
copy is blocked waiting for data in an empty input stream),
it moves to a suspecting termination state and notiﬁes all its
neighbors sending them a SUSPECT message with its cur-
rent round number. It keeps the list of suspected neighbors
it collected while in running state, since they were consid-
ered to be in the same termination round as itself.

When in suspecting state, a copy keeps track of which
of its neighbors are in the same round as itself and have
also reached a possible termination state. As it receives
SUSPECT messages from its neighbors it adds them to the
list of suspects. No reply message is needed since, as that
copy is alread in round R, it must have send SUSPECT mes-
sages to all neighbors when it entered that state.

If the copy receives a SUSPECT message with a larger
round number R’, it indicates other copies may have gone
farther in their processing while that copy remained waiting
for a consensus from its neighbors. It must therefore update
its round counter to the new value and clear its list of sus-
pects (since all there belonged to a previous round, now).
Only the sender of the message will be added to the list at
that point.

Whenever a copy has collected SUSPECT from all its
neighbors for a given round, there is a widespread suspi-
cion that termination has been reached, although that may
be true for just the vicinities of that copy. At that point the
process leader must be informed with a TERMINATE(R)
message.

While in the suspecting state, application messages may
still arrive; it may be the case that one of its neighbors had
just been computing for a longer time before it had any data
to send. When that happens, the arrival of data in a stream is
bound to cause new computation to start in that ﬁlter copy,
so it must give up its suspicions about termination and get
back to work. At that point, it must clear its list of suspected
neighbors, prepare itself for a new (future) round by incre-
menting its round counter, and switch back to the running
state.

The process leader, on its turn, must keeep track of the
newest termination round it has heard of (R). Whenever it
receives a TERMINATE(R’) message from a ﬁlter copy, it
must compare R and R’: if R’ is lower, the message may be
simply discarded, since it relates to a round that is already
known to have passed; if R’ is larger than R, a new round
was started, and R is not relevant anymore, so the list of ter-
minated copies must be cleared and just the sender of that
message must be added to it; ﬁnally, if they are equal, an-
other ﬁlter copy has joined the group of processes that sus-
pect termination was reached, so it must be added to the list
of processes in termination. When that list is complete with
all processes the leader can declare the aplication over. At
that point it broadcast the END message and all processes
take their ﬁnal steps toward the end. In the ﬁlter stream
model, that leads to the reinitialization of the terminatio pro-
tocol, and the stream selected by the user is closed, deliver-
ing an end-of-stream notiﬁcation to the ﬁlter reading from
it.

Since the ﬁlter graph describing an application is re-
quired to be strongly connected (although directed), the
graph created by the relation of each ﬁlter copy to its neigh-
bors will also be, specially since the neighbor relationship
is always bidirectional. That way, when all ﬁlter copies do
reach global termination, they will all be in the suspecting
state. Since the value of the round counter grows monotoni-
cally and only gets added when a copy switches back to the
running state, all copies are bound to converge to a same
value of R, when termination will be agreed upon.

3. Parallelization of ID3

In this section we describe our parallel implementation
of the ID3 decision tree algorithm. In a decision tree, the
leaf nodes are the individual data elements. The internal
nodes contain an attribute and each descending pointer en-
codes a possible value for the attributed mapped on the node
which will distinguish the descendants. The depth of such
tree is the maximum number of questions about attribute
values that need to be asked about the data element in or-
der to ﬁnd one single element on the data. The basic idea of
the ID3 algorithm is to use a top-down and greedy search
on the data to ﬁnd the most discriminating attribute on each

P artitions(cid:0) = p
q = ft 2 p:dataset ^ p:atr = p:instanceg
8a 2 Attributes

probc = jft2q^t:a=t:v^t:c=cgj
inf oa;v = Pc2Classes (cid:0)probc (cid:3) log(probc)

jft2q^t:a=t:vgj

probv = jft2q^t:a=t:vgj
gaina = Pv2V alues(a) inf oa;v (cid:3) probv

jqj

8v 2 V alues(a)

p.atr = None
p.instance = None
p.dataset = T

1
2
3
4 while (9p 2 P artitions)
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

8a 2 Attributes

disc = ajgainaisM aximum
8v 2 V alues(disc)
p:atr = disc
p:instance = v
p:dataset = q
P artitions+ = p

Figure 2. ID3 Algorithm

level of the tree. For the sake of the ﬁlter deﬁnition, we dis-
tinguish three main tasks to insert a node in the decision
tree:

1. For each value of each attribute, count the number of

instances that have that value;

2. Compute the information gain of each attribute;

3. Find the attribute with the highest information gain.

The starting point of the ID3 algorithm is a set of m tu-
ples, containing instances of n attributes and one out of c
possible classes. Each attribute a may assume va values.
The tree generation process is based on discriminants. Each
discriminant is a test on an speciﬁc attribute that is used to
divide a set of tuples in two or more subsets (depending on
the number of different values that occur for the discrimi-
nant). Initially, there is no discriminant and the partition is
the whole set of tuples. Then, as we ﬁnd new discriminants
we recursively partition the set of tuples into subsets, un-
til all tuples in one partition belong to the same class.

The pseudo-code of the algorithm is presented in Fig-
ure 2. Lines 1–3 are the initialization of the P artitions,
the ﬁrst one being the entire database. The loop in line 4 will
execute until there are no new partitions. For each of them
(line 5), we select the tuples that will compose the partition
q in line 6. Then we compute the information (using an en-
tropy metric) for each attribute and instance value in lines
7–10. Lines 11-13 compute the information gain for each
attribute and, in the ﬁnal step, ﬁnd the attribute that yields
maximum information gain and inserts the corresponding

partitions into P artitions. In terms of parallelization, there
are two multi-target reductions in lines 10 and 13, which
identify boundaries among ﬁlters. We divide the process-
ing into three ﬁlters. The ﬁrst ﬁlter, named Counter, per-
forms the operations associated with lines 4 to 9, and is re-
sponsible for counting the number of instances that each
value of each attribute has. The second ﬁlter, Attribute, per-
forms the operations associated with lines 10 to 12, which
corresponds to computing the information gain on each of
the attributes tested on the previous ﬁlter. The third, Deci-
sion, performs the remaining operations, which corresponds
to communicating the decision of the appropriate attribute
to back to the ﬁrst ﬁlter where the process will continue,
selecting new discriminating attributes for each of the pro-
duced classes.

In our algorithm we exploited two dimensions of par-
allelism: base partition and decision tree node pipelining.
Base partition is achieved by running several instances of
the counter ﬁlter, so each instance process a subset of the
database and pipelining is when one ﬁlter is processing one
node of the tree the others are processing others nodes so
all nodes stay busy practically all the time. Granularity of
base partition parallelism is very ﬁne. We can assign a sin-
gle instance to a ﬁlter with no changes to the code. An-
other source of parallelism is asynchrony. The ﬁlters may
be working on multiple partitions simultaneously, in an at-
tempt to achieve maximum efﬁciency.

4. Experimental Results

In this section we evaluate the implementation of two
data mining algorithms in Anthill, focusing on their efﬁ-
ciency and scalability. The experiments were run on a 16
node cluster of PCs, connect using switched Fast Ethernet.
Each node is a 3GHz Pentium IV with 1GB main memory,
running Linux 2.6.

4.1. ID3

We start with an evaluation of our ID3 implementation,
as described earlier. In these experiments, we run the De-
cision ﬁlter alone on a separate node. The other nodes run
both Counter and Attribute ﬁlters.

To evaluate our algorithm, we used synthetic datasets
that are described in [10]. In particular we used two clas-
siﬁcation functions with different complexity: functions 2
and 7. Function 2 is simpler and produces smaller decision
trees when compared with function 7. In table 1 we show
the characteristics of the datasets generated for these two
functions. The notation F x-Ay-DzK is used to denote a
dataset with function x, containing y attributes and z (cid:3) 1000
instances.

Dataset

DB Size (MB)

No. Levels

Max Leaves/Level

F2-A32-D1000K
F7-A32-D750K

172
129

8
8

5612
8195

Table 1. Dataset characteristics

F2A32D1000K

f(x)

p
u
d
e
e
p
S

 18

 16

 14

 12

 10

 8

 6

 4

 4

p
u
d
e
e
p
S

 16

 14

 12

 10

 8

 6

 4

 4

 6

 8

 10

 12

 14

 16

Number of Processors

Figure 3. Speedup F2-A32-D1000K

We start by analyzing the speedups. Figures 3 and 4 show
the speedups for datasets F2 and F7, respectively. We can
observe that the executions of the F2 dataset scale better
than those using F7, and both show superlinear behavior. F2
scales better because it is simpler and demands less mem-
ory, which seems to affect the speedup signiﬁcantly. In or-
der to understand the superlinear speedups, we performed a
detailed analysis of the processor cache usage as we change
the number of processors. We used PAPI (Performance Ap-
plication Programming Interface [6]) to measure the num-
ber of cache misses for each conﬁguration. Figures 5 and 6
shows that there is a substantial drop on the number of cache
misses as processors are added for the execution, which
is expected, and explains the superlinear behavior. For in-
stance, in ﬁgure 5 we notice that increasing the number of
processors from 4 to 14 (a factor of 3.5), resulted in a re-
duction of the total number of cache misses by a factor of
11.

We now focus our analysis on three criteria, to demon-
strate how the various aspects of Anthill collaborate to the
observed speedups.

4.1.1. Task Analysis Each task in our algorithm is asso-
ciated with analyzing and determining the discriminant for

F2A32D1000K

f(x)

 6

 8

 10

 12

 14

 16

Number of Processors

Figure 4. Speedup F7-A32-D750K

 6

 8

 10

 12

 14

Machines

Figure 5. Total Cache Misses X Number of
Processors - F2-A32-D1000K

 0

−50

 0

 50

 100

 150

 200

 250

 300

 350

 400

 450

 500

Time (sec)

Figure 7. Active Tasks X Execution Time

Cache Miss

Cache Miss

i

2
L
 
s
s
M
 
e
h
c
a
C

 
l
a
t
o
T

i

2
L
 
s
s
M
 
e
h
c
a
C

 
l
a
t
o
T

 2.2e+08

 2e+08

 1.8e+08

 1.6e+08

 1.4e+08

 1.2e+08

 1e+08

 8e+07

 6e+07

 4e+07

 2e+07

 0

 4

 1.6e+08

 1.4e+08

 1.2e+08

 1e+08

 8e+07

 6e+07

 4e+07

 2e+07

 0

 4

 6

 8

 10

 12

 14

Machines

Figure 6. Total Cache Misses X Number of
Processors - Speedup F7-A32-D750K

a decision tree node. Asynchrony arises by overlapping the
processing of several tree nodes, which may belong to the
same tree level or not. Notice that all tasks from the same
tree level are independent and the parallelism in this case is
trivial, and has been exploited in other contexts. We are in-
terested in verify whether we may observe tasks from more
than one level being executed simultaneously, thus exploit-
ing all the potential parallelism present on the algorithm.
We evaluate the level of asynchrony by plotting the num-
ber of active tasks from each tree level across time. Figure 7
shows the tasks behavior during the execution unning on
16 processors using F7 as input. We clearly see tasks from
more than one tree level overlaping during the whole exper-
iment (e.g., execution time 325), explaining the algorithm
efﬁciency.

4.1.2. Filter Analysis Table 2 shows the break-down of
the task execution time per ﬁlter. We consider executions
from 9 to 12 nodes and F7 as the input. We observe that the
majority of the processing time (over 95%) of the task oc-
curs in the Counter ﬁlter.

We conﬁrm the higher demand imposed by the Counter
ﬁlter checking the message counters for the same conﬁgu-
rations, as presented in Table 3, where we observe how the
amount of data to be processed decreases as we go from
the Counter to the Decision ﬁlter. Finally, it is interesting

Level 1
Level 2
Level 3
Level 4
Level 5
Level 6
Level 7
Level 8
Total

 700

 600

 500

 400

 300

 200

 100

s
k
s
a
T
 
e
v
i
t
c
A

Number of Processors

Attribute

Decision

9
10
11
12

Counter
96.17
95.27
96.13
96.10

3.36
4.20
3.30
3.36

0.46
0.52
0.56
0.52

Table 2. Percent of the Time in Each Filter.
Test F7A32D750K.

to notice that there is a signiﬁcant amount of parallelism
to explore, since the elapsed time for executing the tasks is
usually larger than the elapsed time in each processor (Fig-
ure ??), which demonstrates that a larger number of proces-
sors would allow even better results.

It is interesting to note, that, despite the high vari-
ability on the demand imposed by the different ﬁlters,
the application scaled very well. Other task paralleliza-
tion schemes, such as pipelining, may suffer signiﬁcant per-
formance degradation as a result of such imbalance, but our
application was not affected at all.

4.1.3. Filter Instance Analysis Finally, we evaluated the
performance of the ﬁlter instances, in order to evaluate the
imbalance that is generated by the data skewness, by the la-
beled stream, or even both. One basic metric for such eval-
uation is the variability of the execution time of each ﬁl-
ter instance, since the execution time of the tasks may vary
signiﬁcantly among tasks, and comparing their times does
not quantify the load imbalance among ﬁlter instances. We
then calculated, for each task and for each ﬁlter, the rel-
ative standard deviation among the execution times of the
ﬁlter instances. The resulting values are presented in Ta-
ble 4 where we observe a slight increase on the variability

Number of Processors

9
10
11
12

Counter
36785592
40872880
44960168
49047456

Attribute
408649
408649
408649
408649

Decision

15185
15185
15185
15185

Table 3. Number of Sent Messages. Test
F7A32D750K.

Counter
Attribute
Decision
Total

)
s
(
 
n
o
i
t
a
r
u
D

 14

 12

 10

 8

 6

 4

 2

 0

 1

 10

 100

 1000

 10000

 100000

Task

Figure 8. Elapsed time per ﬁlter and overall

Procs
9
10
11
12

Counter
40.82%
45.10%
46.59%
50.39%

Attribute
28.45%
28.59%
29.65%
29.79%

Table 4. Variability of execution times among
ﬁlter instances

with the number of instances, as expected, since the load as-
signed to each instance is reduced, and skewness may have
a stronger impact. We also observe that the relative stan-
dard deviations are quite high, although there is a compen-
sating effect taking place, that is, the instance that works
more for a given task, works less later, showing that the la-
beled stream presents good performance as both load distri-
bution and balancing mechanisms.

4.2. Association Analysis

Association analysis determines association rules, which
show attribute instances (usually called items) that occur
frequently together and present a causality relation between
them. We divide the problem of determining association
rules into two phases: determining the frequent itemsets and
building the rules from them. Since the ﬁrst phase is much
more computationally intensive, we parallelize just the ﬁrst
phase. In this case, the input is a set of transactions, where
each transaction contains the objects that occur simultane-
ously, and the output is the set of items that occurs more
than a frequency threshold known as support.

Most of the association rule algorithms are based on a
simple and powerful principle: for an itemset of k items to
be frequent, all of its k subsets of size k (cid:0) 1 must also be
frequent. Based on this principle we may easily build the
itemset dependency graph, which explicits the dependen-
cies among tasks.

Each task is divided into three partitioned reductions:
counter, veriﬁer, and candidate generator. The counter re-
duction just counts the number of occurrencies of a given
itemset, which are forwarded to the veriﬁer ﬁlter. The ver-
iﬁer ﬁlter receives the partial counts and adds them, veri-

fying whether the itemset is frequent or not considering the
whole database. Whenever the veriﬁer ﬁnds a frequent item-
set, it informs the candidate generator. The candidate gener-
ator keeps track about the itemsets found frequent so that it
is able to check whether an itemset may be counted and ver-
iﬁed, according to the task graph.

In these experiments we used different synthetic
databases with size ranging from 560MB to 2.240GB, gen-
erated using the procedure described in [9]. These
databases mimic the transactions in a retailing environ-
ment. All the experiments were performed with a min-
imum support value of 0.1%. Sensitivity analysis was
conducted on data distribution, data size, and degree of par-
allelism.

To better understand the effects of data distribution, we
distributed the transactions among the partitions in two dif-
ferent ways:

Random Transaction Distribution: Transactions are ran-
domly distributed among equal-sized partitions. This
strategy tends to reduce data skewness, since all parti-
tions have an equal probability to take a given transac-
tion.

Original Transaction Distribution: The database is sim-
ply splited into partitions, preserving its original data
skewness.

We evaluate the parallel performance of the data min-
ing application by means of two metrics: speedup and
scaleup. As can be seem in Figure 9, better speedup num-
bers are achieved with the original transaction distribution.
The reason is that the baseline time (i.e. with 8 counter
ﬁlters) is much larger when the database has its original
(skewed) transaction distribution. However, as we increase
the number of counter ﬁlters, the execution times for dif-
ferent data distributions tend to approach (since the parti-
tions get smaller, and parallel opportunities are reduced).
For the scaleup experiment we increase (in the same pro-
portion) the database size and the number of counter ﬁlters.
As we can see, our parallel data mining application shows
to scale very well, even for skewed databases.

In order to better understand the dynamics of the appli-
cations, we deﬁned some metrics that may be used to un-
derstand. We will focus on the data mining algorithm, but
the same applies to the vision application.

We may divide the determination of the support of an

itemset into four phases:

Activation: The various notiﬁcations necessary for an
itemset become a candidate may not arrive at the
same time, and the veriﬁcation ﬁlter has to wait un-
til the conditions for an itemset be considered candi-
date are satisﬁed.

Execution Time - T20D3.2MI1K - minsupp=0.1%

Execution Time - T20D6.4MI1K - minsupp=0.1%

Original Distribution
Random Distribution

Original Distribution
Random Distribution

Proc Activation
2.741046
1.264842
1.229330

8
16
32

Contention
5.564751
2.058052
0.273229

Counting
9.412093
4.893773
1.129718

Checking
8.469050
4.691232
1.986129

Processing
0.001645
0.000759
0.000369

 5

 10

 15

 20

 25

 30

 35

 5

 10

 15

 20

 25

 30

 35

#Filters

#Filters

Speedup - minsupp=0.1%

Scaleup - T20D3.2M-D12.8MI1K - minsupp=0.1%

Table 5. Speedup Experiments: Proﬁling of
Itemset Processing

)
s
c
e
s
(
 

l

e
u
a
V

 70

 60

 50

 40

 30

 20

 10

l

e
u
a
V

 35

 30

 25

 20

 15

 10

 5

 5

)
s
c
e
s
(
 

l

e
u
a
V

 90

 80

 70

 60

 50

 40

 30

 20

 10

 1.1

 1.05

l

e
u
a
V

 1

 0.95

 0.9

 5

Ideal
Original Distribution
Random Distribution

Ideal
Original Distribution (T20D3.2MI1K)
Random Distribution (T20D3.2MI1K)
Original Distribution (T20D6.4MI1K)
Random Distribution (T20D6.4MI1K)

 10

 15

 20

 25

 30

 35

 10

 15

 20

 25

 30

 35

#Filters

#Filters

Figure 9. Parallel Performance of the Apriori.

Contention: After the itemset is considered a good candi-
date, it may wait in the processing queue of the counter
ﬁlter.

Counting: The counter ﬁlters may not start simultane-
ously, and the counting phase is characterized by
counter ﬁlters calculating the support of a candi-
date itemset in each partition.

Checking: The support counters of each counter ﬁlter may
not arrive at the same time in the support checker ﬁl-
ter, and the checking phase is the time period during
which the notiﬁcations arrive.

Next we are going to analyze the duration of these phases
in both speedup and scaleup experiments. The analysis of
the speedup experiments explains the efﬁciency achieved,
while the analysis of scaleup experiments shows the scala-
bility.

In Table 5 we show the duration of the phases we just de-
scribed for conﬁgurations employing 8, 16, and 32 proces-
sors. The rightmost column also shows the average process-
ing cost for counting an itemset, where we can see that this
cost reduces as the number of processors increase, as ex-
pected. The same may be observed for all phases, except for
the Activation phase, whose duration seems to reach a limit
around 1 second. The problem in this case is that the num-
ber of processors involved is high and the asynchronous na-
ture of the algorithm makes the reduction of the Activation
time very difﬁcult.

Verifying the timings for the scaleup experiments in Ta-
ble 6, we verify the scalability of our algorithm. We can
see that an increase in the number of processors and in the
size of the database does not affect signiﬁcantly the mea-
surements, that is, the algorithm implementation does not
saturate system resources (mainly communication) when
scaled.

Proc Activation
2.741046
2.628118
2.439369

8
16
32

Contention
5.564751
5.538353
5.021002

Counting Checking
8.469050
9.412093
9.349371
8.403360
8.906631
10.311501

Processing
0.001645
0.001596
0.001594

Table 6. Scaleup Experiments: Proﬁling of
Itemset Processing

5. Clustering

Cluster analysis partitions and determines groups of ob-
jects that are similar regarding a user-given similarity crite-
ria. In this section we discuss the parallelization of a popu-
lar clustering algorithm, k-means.

The algorithm is based on the concept of centroids,
which represent the objects that compose the cluster. Each
iteration of the algorithm assigns each object to the clos-
est centroid, updating its value properly. The algorithm ends
when no object changes cluster or a maximum number of it-
eractions is reached.

Since there is a single task that determines clusters, there
is no task graph. We express the algorithm using two reduc-
tions: assigner and centroid calculator. The assigner holds
the objects that must be clustered based on the centroids
and determines which centroid is the closest to each object.
The list of objects assigned to each centroid is then sent to
the centroid calculator that recalculates the centroids.

Our clustering evaluation is based on two synthetic
datasets, containing 400,000 and 800,000 points to be clus-
tered. Each point has 50 dimensions. We performed ex-
periments evaluating both the scaleup and the speedup.
The scaleup is linear and close to 1, that is, the appli-
cation scales perfectly. The execution times and respec-
tive speedups are shown in Figure 10, where we can see
the time per iteraction of the algorithm for the two datasets
and the speedup when varying the number of proces-
sors. In both cases, the speedup is almost linear for when
clustering the 400,000-point dataset and is super-linear
for the 800,000-point dataset. This super-linear behav-
ior comes from the reduction of memory requirements as
we increase the number of processors.

ming Languages and Operating Systems (ASPLOS VIII),
pages 81–91. ACM Press, Oct 1998.

[2] M. Beynon, C. Chang, U. atalyrek, T. Kur, A. Sussman,
H. Andrade, R. Ferreira, and J. Saltz. Processing large-scale
multi-dimensional data in parallel and distributed environ-
ments. Parallel Computing, 28(5):827–859, 2002.

[3] Michael Beynon, Renato Ferreira, Tahsin M. Kurc, Alan
Sussman, and Joel H. Saltz. Datacutter: Middleware for ﬁl-
tering very large scientiﬁc datasets on archival storage sys-
tems. In IEEE Symposium on Mass Storage Systems, pages
119–134, 2000.

[4] Michael Beynon, Tahsin Kurc, Alan Sussman, and Joel Saltz.
Design of a framework for data-intensive wide-area applica-
tions. In Heterogeneous Computing Workshop (HCW), pages
116–130. IEEE Computer Society Press, May 2000.

[5] I. Foster and C. Kesselman. The GRID: Blueprint for a New

Computing Infrastructure. Morgan Kaufmann, 1999.

[6] Philip Mucci. The performance API PAPI. White Paper of

the University of Tennessee, March 2001.

[7] Clark F. Olson. Parallel algorithms for hierarchical cluster-

ing. Parallel Computing, 21(8):1313–1325, 1995.

[8] Matthew Spencer, Renato Ferreira, Michael Beynon, Tahsin
Kurc, Umit Catalyurek, Alan Sussman, and Joel Saltz. Exe-
cuting multiple pipelined data analysis operations in the grid.
In Proceedings of the 2002 ACM/IEEE conference on Super-
computing, pages 1–18. IEEE Computer Society Press, 2002.
[9] A. Veloso, W. Meira Jr., R. Ferreira, D. Guedes, and

S. Parthasarathy. Asynchronous and anticipatory
item-
ﬁlter -stream based parallel algorithm for frequent
set mining.
In Proceedings of the 8th European Confer-
ence on Principles and Practice of Knowledge Discovery in
Databases (PKDD), 2004.

[10] M. Zaki, C. Ho, and R. Agrawal. Parallel classiﬁcation for
data mining on shared-memory multiprocessors.
In ICDE
’99: Proceedings of the 15th International Conference on
Data Engineering, page 198, Washington, DC, USA, 1999.
IEEE Computer Society.

[11] Mohammed Javeed Zaki and Ching-Tien Ho. Large-scale

parallel data mining. Springer-Verlag, 2000.

Speedup

Linear
800.000 points
400.000 points

 5

 10

 15

 20

 25

# Processors

Time per Iteration

800.000 points
400.000 points

p
u
d
e
e
p
S

s
d
n
o
c
e
S

 30

 25

 20

 15

 10

 5

 0

 0

 4.5

 4

 3.5

 3

 2.5

 2

 1.5

 1

 0.5

 0

 0

 5

 10

 15

 20

 25

# Processors

Figure 10. Parallel Performance of the k-
Means Algorithm.

6. Conclusions and Future Work

In this paper we have described a run-time sup-
port framework who was developed to support the efﬁcient
implementation of a signiﬁcant class of applications on het-
erogeneous distributed environments. We have also shown
our parallelization strategy, which is the approach used
to perform the decompostion on the applications. We be-
lieve that the approach can be applied for a large class of
applications.

Our experimental results have shown that two applica-
tions designed using our strategy and our run-time support
scale almost linearly to large number of nodes. Our experi-
ments, however, where only limited to the number of com-
pute nodes we had available for experimentation. In fact, we
see no reason why the applications should keep the same be-
havior for much larger conﬁgurations.

Our run-time support system is a signiﬁcant evolution on
top of Datacutter. In particular, we have implemented the la-
belled stream infrasture and the termination detection algo-
rithm. We still do not have an actual implementation of the
stable storage for the distributed state.

For futyre work, we are in the process of incorporating
fault tolerance on Anthill. A robust implementation of the
distributed state is a requirement for such system.

References

[1] Anurag Acharya, Mustafa Uysal, and Joel Satlz. Active
disks: Programming model, algorithms and evaluation. In In-
ternation Conference on Architectural Support for program-

