Data-Eﬃcient Information-Theoretic

Test Selection

Marianne Mueller1, R´omer Rosales2, Harald Steck2,
Sriram Krishnan2, Bharat Rao2, and Stefan Kramer1

1 Technische Universit¨at M¨unchen, Institut f¨ur Informatik, 85748 Garching, Germany
2 IKM CAD and Knowledge Solutions, Siemens Healthcare, Malvern PA 19335, USA

Abstract. We use the concept of conditional mutual information (MI)
to approach problems involving the selection of variables in the area of
medical diagnosis. Computing MI requires estimates of joint distribu-
tions over collections of variables. However, in general computing accu-
rate joint distributions conditioned on a large set of variables is expensive
in terms of data and computing power. Therefore, one must seek alter-
native ways to calculate the relevant quantities and still use all the avail-
able observations. We describe and compare a basic approach consisting
of averaging MI estimates conditioned on individual observations and
another approach where it is possible to condition on all observations at
once by making some conditional independence assumptions. This yields
a data-eﬃcient variant of information maximization for test selection.
We present experimental results on public heart disease data and data
from a controlled study in the area of breast cancer diagnosis.

1 Information Maximization for Medical Test Selection

Consider a collection of patient records containing data generally indicative of
various clinical aspects associated to the patient, e.g., patient demographics,
reported symptoms, results from laboratory or other tests, and patient dis-
ease/condition. Let us deﬁne each single element (source) of patient data as
a random variable Vm, e.g., patient age (demographics), presence of headache
(symptom), blood pressure (test result), or occurrence of diabetes (disease). In
this paper, we consider the set of variables V = {V1, . . . , VM } and we assume
each variable to be discrete with a ﬁnite domain. For a given patient, a few
of these variables may have been observed while others may have not. In some
cases, we know such values of the variables with some probability.

Let us now consider the time when a diagnosis needs to be made for a speciﬁc
patient, for which some of these variables have been observed, denoted as back-
ground attributes Zi ∈ V , for i ∈ {1, ..., k}; e.g., demographic information and
patient symptoms. The remaining M − k variables denoted Xj have not been
observed yet; e.g., the result of a lab test. Finally, for the patient, let Y denote
a variable in which we are ultimately interested, but that we have not observed,
such as the occurrence of cancer. This variable may not be observable directly

C. Combi, Y. Shahar, and A. Abu-Hanna (Eds.): AIME 2009, LNAI 5651, pp. 410–415, 2009.
c(cid:2) Springer-Verlag Berlin Heidelberg 2009

Data-Eﬃcient Information-Theoretic Test Selection

411

or it may be observable at a high cost. Thus, we prefer to rely on other sources
of information and try to infer the value of this variable.

Formally, we want to optimize X ∗ = arg max

I(Xj , Y |Z1 = z1, . . . , Zk = zk),

j

where the quantity I is the mutual information (MI) between our variable of
interest Y and the (test) variables whose values we could potentially obtain Xj,
conditioned on the fact that we already know Z1 = z1, . . . , Zk = zk. Using the
deﬁnition of MI [1] and the shorthand z = (z1, . . . , zk) to denote the assignment
of multiple variables, the function of interest is:

I(Xj, Y |z) =

P (xj , y|z) · log

(cid:2)

(cid:2)

xj

y

P (xj , y|z)

P (xj |z) · P (y|z)

(1)

Assuming the variables follow a multinomial joint probability distribution that
can be reliably estimated, this problem can be solved by testing each of the poten-
tial candidate variables individually to see which provides the most information.
In order to arrive at a diagnosis with high certainty, one observation may not
be enough. In some cases, we may be allowed to observe more than one variable.
Thus, this process can be repeated iteratively until a user-deﬁned precision or
conﬁdence level is achieved. For example, this limit can be deﬁned in terms
of the amount of information that is left in the variable of interest (entropy).
Once a variable Xi has been tested and observed, it can be incorporated as
part of the background knowledge and the maximization problem is updated:
arg max
j(cid:3)=i

I(Xj, Y |xi, z).

Ideally, the quantity to optimize is MI conditioned on all available data or
observed variables. However, in practice this may be diﬃcult because in general
the conditional joint probabilities P (xj , y|z1, z2, . . . , zk) cannot be properly esti-
mated from limited data for large k. The data required to properly estimate the
conditional joints may grow exponentially with k. In addition, the number of un-
observed variables plays an important role in terms of computational complexity
(which can also grow exponentially with the number of unobserved variables).

2 Combining All Available Background Information

Since with limited data our estimate of P (xj , y|z1, z2, . . . , zk) will not be accu-
rate, we seek a data-eﬃcient method – one whose data requirements do not grow
exponentially with k – to compute or approximate P and thus be able to use all
available background information to decide what test should be chosen.

2.1 Information Averaging

A simple heuristic consists of averaging the information conditioned on each
background variable Zi separately, I(Xj, Y |z) ≈ 1
zi α(zi)I(Xj , Y |zi),
k ·
where α(zi) is equal to the prior P (zi) if zi is not observed and α(zi) = 1(zi)
if observed. 1(zi) is equal to one if zi is the observed value for Zi and zero
otherwise. We will use this as our baseline method.

(cid:3)k

i=1

(cid:3)

412

M. Mueller et al.

Table 1. Bayes net and approximations of probability distribution and entropy
given z

Y

X

j

P (y|xj, z)

·

1
k

P (y|xj, zi)

(cid:3)

Joint Model (Q)
P (zi|x,y)
P (x,y)·

(cid:4) k

i=1
(cid:4) k

y∈Y

P (x,y)·

P (zi|x,y)

i=1

Z

1

Z

2

..................

Z

k

H(Y |xj , z) 1
k

HP (Y |xj, zi)

HQ(Y |xj, z)

Averaging
k(cid:3)

i=1

k(cid:3)

i=1

One way to think about this heuristic is to consider k independent models
involving Y, Xj, Zi of the form P (y, xj, zi) = P (zi|xj, y)P (xj , y). MI can be
computed for each model separately given the observed data. Similar to model
averaging, the MI of Xj about Y can be found by averaging the individual
information values, giving rise to the above equation.

2.2 Exploiting Conditional Independence Assumptions

We have so far assumed a very general model of the data, speciﬁcally a full multi-
nomial distribution with a large number of degrees of freedom. However, if we
relax this assumption, we can ﬁnd a family of models for which the computation
of the mutual information of interest is computationally and data eﬃcient. These
models make stronger conditional independence assumptions (simpler joint mod-
els), so that when the zi’s are observed, the computation of I(Xj , Y |z) does not
have large data requirements.

We consider the Bayes net in Table 1, where the background information Zi
depends on the test result Xj and the actual disease status Y . This network
should not be viewed as reﬂecting causality, but simply as a statistical model.
We obtain a new probability distribution Q:

Q(xj , y, z) = P (xj , y) ·

P (Zi = zi|xj, y).

(2)

k(cid:5)

i=1

The above Bayes network deﬁnes another multinomial model with the partic-
ular advantage that for the MI computations above, it only requires computing
joint distributions of at most three variables, even if we do not know what vari-
ables Zi will be observed beforehand. This is beneﬁcial since we indeed do not
know what variables will be observed for a particular case (patient).

For learning the model, we are interested in ﬁnding P (zi|xj , y)∀i ∈ {1, ..., k}
and P (xj , y) since these distributions fully deﬁne the model. Using the maximum
likelihood criterion we can see that: P (zi|xj , y) =
and

count(Zi=zi,Xj =xj ,Y =y)

count(Xj =xj ,Y =y)

count(Xj =xj,Y =y)

P (xj, y) =

count(Xj =any,Y =any) . Inference can be performed eﬃciently also [2].
In summary, we have found a method that allows us to use all the available
background information for deciding what test to perform. For this we have re-
laxed the model assumptions and use a class of models whose data requirements

Data-Eﬃcient Information-Theoretic Test Selection

413

are more practical. Inference and learning are computationally eﬃcient in these
models as well.

3 Validation and Results

First, we test our approaches on public heart disease data (HD) consisting of
920 patients and 14 attributes (two background attributes, 11 observable test
attributes, and one binary class attribute).1 On this dataset each patient is an
instance. The variable of interest Y expresses if the patient has heart disease (411
patients) or not (509 patients). In a second step, we perform experiments on the
breast cancer diagnosis data (BC) described in detail in the long version of this
paper [2] (16 background attributes, 4 observable test attributes, and one binary
class attribute). Here, we use lesions as instances. From 132 patients we analyze
216 biopsied lesions, 134 malignant and 82 benign. We use the biopsy result as
the variable of interest Y . Note that the number of data points is small given the
dimensionality of the data, which is quite common in controlled medical studies
where the cost of data gathering is usually high.

We validate the two approaches considered above for each instance in a
leave-one-out validation.2 First, we determine for each instance which test X ∗
maximizes the information given the patient speciﬁc attributes z. After ob-
serving the selected test X ∗ = xj, we decide for the most likely diagnosis
y∗ = arg max
P (y|xj , z). We say the instance is correctly assessed, if y∗ equals
y∈Y
the actual state of disease of the instance, and incorrectly assessed, if the diagno-
sis was diﬀerent. This accuracy measure could be easily improved by training a
classiﬁer on the features {Xj, Z1, · · · Zk} and predicting Y for each test instance.
The two approaches provide two diﬀerent estimations of I(X, Y |z). Our vali-
dation criteria (correctness, certainty, and information gain) additionally require
the computation of P (y|xj , z) and the conditional entropy H(Y |xj , z). The dis-
cussion in Section 2 showed that it is not possible to compute this for large k.
Therefore, we use the approximations shown in Table 1. HP (HQ) denotes the
entropy of the probability distribution P (Q). To get a better grading of the
results of our approaches, we compare it to two diﬀerent ways of test selection.
We evaluate: selecting a test proposed by information maximization, selecting
one of the possible tests at random and selecting the best3 test. Because of the
diﬀerent approximations (see Table 1), the performance of the random and best
methods diﬀers for each approach.

Correctness: Table 2 compares the ratio of instances that were assessed cor-
rectly: On both data sets it holds that if we select an examination at random,

1 http://archive.ics.uci.edu/ml/datasets/Heart+Disease
2 We only consider instances with complete information on the test attributes as test
instances (278 for HD and 138 for BC) because it is not possible to evaluate the
cases where the result value of the selected test is missing.

3 We determine the performances of all tests beforehand and select the test with the

best performance (note that this is only possible in this controlled experiment).

414

M. Mueller et al.

Table 2. Ratio of correctly assessed instances. On the left: when iterating the test
selection

Ratio of correctly assessed instances

Heart Disease

Breast Cancer

proposed best random proposed best random

Av.
J.M.

0.781
0.745

0.996 0.681
0.989 0.665

0.657
0.748

0.846 0.696
0.944 0.691

0.85

0.8

0.75

0.7

s
e
c
n
a

t
s
n

i
 

d
e
s
s
e
s
s
a

 
t
c
e
r
r
o
c
 
f

o

 

o

i
t

a
R

0.65

 
0

Heart Disease Data

 

Averaging

Joint Model

2

4

8
Number of selected tests

6

10

in two thirds of the cases the decision about the status of disease is correct.
On the HD data, selecting a test by information maximization leads to an im-
provement of about one tenth. On the BC data, selecting a modality by infor-
mation maximization leads to an improvement in the second approach where we
assume a simple joint model. Hence, the latter appears to give a more useful
estimate of I(X, Y |z). The diﬀerence of the two approaches on the HD data
only becomes apparent when iterating the test selection process and adding the
previously obtained test results as background knowledge, otherwise we have
only two background attributes (Table 2). The second approach performs more
stable and mostly outperforms the ﬁrst approach.

Certainty of Decision: Results [2] show that on both data sets the certainty
for the correctly classiﬁed lesions is higher (lower entropy) than for the incor-
rectly classiﬁed lesions. On the BC data, the diﬀerence is large for the joint model
approach, but for model averaging these quantities are very similar. This indi-
cates that the proposed joint model is better suited at modeling the information
content in the test/decision variables.

Actual Information Gain: We compare the entropy of P (Y |z) before per-
forming a test with the entropy of P (Y |xj , z) after observing the test result
Xj = xj (see [2]). Comparing both approaches to random, the joint model
approach achieves a better result than the baseline approach for both data
sets.

4 Conclusion

We have employed the concept of MI to address the problem of choosing tests
eﬃciently4. We applied this to a problem in medical diagnosis. While MI is
a well-understood concept, it is hard to calculate accurately for general prob-
ability models in practice due to small datasets and the underlying computa-
tional complexity. We have experimentally shown how certain model assumptions
can help circumventing these problems. Making these assumptions, we obtain a

4 Due to lack of space, the reader is referred to [2] for a discussion of related work.

Data-Eﬃcient Information-Theoretic Test Selection

415

comparatively data-eﬃcient variant of test selection based on information max-
imization. Results indicate that the proposed joint model outperforms the in-
formation averaging approach by comparing the performance of each approach
relative to a random and a best selection.

References

Hoboken (1991)

1. Cover, T.M., Thomas, J.A.: Elements of Information Theory. Wiley Interscience,

2. Mueller, M., Rosales, R., Steck, H., Krishnan, S., Rao, B., Kramer, S.: Data-Eﬃcient
Information-Theoretic Test Selection, Technical Report TUM-I0910, Institut f¨ur
Informatik, TU M¨unchen (2009)

