A Simple Polynomial-time Rescaling Algorithm

for Solving Linear Programs

John Dunagan
Microsoft Research
One Microsoft Way

Redmond, WA 98052

jdunagan@microsoft.com

∗
Santosh Vempala

Department of Mathematics

Massachusetts Institute of Technology

Cambridge, MA 02139

vempala@math.mit.edu

ABSTRACT
The perceptron algorithm, developed mainly in the machine
learning literature, is a simple greedy method for ﬁnding a
feasible solution to a linear program (alternatively, for learn-
ing a threshold function.). In spite of its exponential worst-
case complexity, it is often quite useful, in part due to its
noise-tolerance and also its overall simplicity. In this paper,
we show that a randomized version of the perceptron algo-
rithm with periodic rescaling runs in polynomial-time. The
resulting algorithm for linear programming has an elemen-
tary description and analysis.

Categories and Subject Descriptors
F.2 [Theory of Computation]: Analysis of Algorithms

Keywords
Perceptron, Linear Programming, Polynomial Time

1.

INTRODUCTION

Linear programming problems arise in many areas. The

standard form is

max cT x
Ax ≤ b
x ≥ 0

where b, c are in Rn, and A is an m × n matrix of reals.
It is often convenient to view the constraints as halfspaces
in Rn and the problem is to ﬁnd a point in their inter-
section of maximum objective value. The dual view is to
think of the rows of A as points in Rn, and then the goal is
to ﬁnd a threshold function (i.e., a halfspace) that satisﬁes
the given thresholds and maximizes the objective threshold.
∗

Supported by NSF CCR-6895000 and a Sloan foundation

fellowship.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
STOC’04, June 13–15, 2004, Chicago, Illinois, USA.
Copyright 2004 ACM 1-58113-852-0/04/0006 ...$5.00.

Polynomial-time algorithms for solving linear programs in-
clude the Ellipsoid method [13, 15, 22], interior point meth-
ods [14, 21] and the random walk method [2].

Another classical algorithm which is quite practical for
problems arising in machine learning is the perceptron al-
gorithm [1, 16, 18]. It was developed to solve the problem
of learning a half-space. The algorithm is a simple greedy
method that is guaranteed to converge to a feasible solution,
if one exists. It could take an exponential number of iter-
ations in the worst case. Nevertheless, it has many useful
properties, including certain types of noise tolerance [4, 5].
It has also been related to boosting in the PAC model of
learning [19, 20]. It was recently shown that the algorithm
is polynomial with high probability for randomly perturbed
linear programs [3].
It has been an open question as to
whether there is a variant of the perceptron algorithm that
is polynomial in the worst case. Besides suggesting a use-
ful modiﬁcation to the basic algorithm in practice, it would
give a noise-tolerant (in a speciﬁc sense) polynomial-time
algorithm.

To simplify matters, we focus on the problem of ﬁnding
a feasible solution to a given set of linear constraints. Poly-
nomial time reductions of the optimization problem to the
feasibility version of the problem are well-known [13]. A
typical approach is described in Section 4.

In this paper, we show that a randomized perceptron-like
algorithm along with periodic rescaling applied to a feasi-
ble linear program will return a feasible point in polyno-
mial time. As in all variants of the perceptron algorithm,
it does not use any matrix inversions or barrier functions.
Our main Theorem (Theorem 3.5) is that a strictly feasible
linear program with m constraints in Rn is solved in time
O(mn4 log n log(1/ρ)) where ρ is a parameter that roughly
corresponds to the radius of a ball that ﬁts in the feasible
region, and log(1/ρ) is guaranteed to be polynomial in the
input description. It should be noted that the complexity of
our algorithm is not as good as the current best algorithms
[10, 21]. On the other hand, it is rather simple and inherits
the noise-tolerance properties of the perceptron algorithm.
As a direct consequence, we get a simpler (and faster) solu-
tion to the problem of learning noisy linear threshold func-
tions [4, 6].

Here is the main idea. The perceptron algorithm main-
tains a halfspace that it updates using a constraint that is
currently violated. The convergence of the algorithm de-
pends on a separation parameter quantifying the amount of

“wiggle room” available for a feasible halfspace. This is in
the dual view described above. In the corresponding primal
view, when we think of constraints as halfspaces, the wiggle
room is the radius of the largest ball that ﬁts in the feasible
region. Roughly speaking, the analysis of the perceptron al-
gorithm says that if this ball is large, then the algorithm will
converge quickly. The work of [4] shows that even when this
ball is small, a simple variant of the perceptron algorithm
ﬁnds a nearly feasible solution, i.e., constraints might be vi-
olated but each is not violated by much. Here we show that
when the wiggle room is small, such a nearly feasible solu-
tion can be used to apply a linear transformation (in fact, a
rank 1 update) that expands the wiggle room (enlarges the
ball contained in the feasible region) by essentially a 1 + 1/n
factor. Thus, in O(n) iterations, we either ﬁnd a feasible
point or double the wiggle room.

2. THE ALGORITHM

In this section we present an algorithm for the linear fea-

sibility problem

Ax ≥ 0, x (cid:5)= 0

consisting of m constraints in n dimensions, i.e. x ∈ Rn and
A is m × n. In Section 4 we show how well-known methods
can be used to reduce the standard form to this homogenized
form.

The algorithm is iterative and each iteration consists of
three phases, a perceptron phase, a perceptron improvement
phase, and a rescaling phase. The perceptron phase uses
the classical perceptron algorithm. The perceptron improve-
ment phase uses a modiﬁed version of the basic perceptron
algorithm. This modiﬁed version was described earlier in
[4]. Figure 1 depicts the rescaling phase.

The classical perceptron algorithm for the linear feasibil-
ity problem is to ﬁnd a violated constraint, move the trial
solution x one unit in the direction normal to the violated
constraint, and repeat if necessary (this is step 2 in the al-
gorithm).

In the rest of the paper, we let ¯x denote the unit vector

in the direction of x.

3. ANALYSIS

3.1 Ideas

Let A0 denote the initial A input to the algorithm, and let
A∗ denote the A that the algorithm has when it terminates.
When the algorithm terminates, it produces a non-zero vec-
tor x(cid:2) = Bx such that A∗x = (A0B)x ≥ 0, i.e., A0(Bx) ≥ 0,
as desired.

During each outer iteration (steps 2-7), the perceptron im-
provement phase (step 4) may be re-run a number of times,
but it terminates quickly with high probability (Lemma 3.2).
Thus the main question is, how many iterations does the
algorithm make? To answer this, we deﬁne the following
quantity which measures the “roundness” of the feasible re-
gion:

ρ(A) =

max

min

(¯ai · x)

x:|x|=1,Ax≥0

i

were ai denotes the i’th row of A and ¯ai is the unit vector
along ai.

Algorithm.

Input: An m × n matrix A.
Output: A point x such that Ax ≥ 0 and x (cid:5)= 0.

1. Let B = I, σ = 1/(32n).

2. (Perceptron)

(a) Let x be the origin in Rn.
(b) Repeat at most 1/σ2 times:

If there exists a row a such that a · x ≤ 0,
set x = x + ¯a.

3. If Ax ≥ 0, then output Bx as a feasible solution

and stop.

4. (Perceptron Improvement)

(a) Let x be a random unit vector in Rn.
(b) Repeat at most ln n/σ2 times:

If there exists a row a such that ¯a · ¯x < −σ,
set x = x − (¯a · x)¯a.
If x = 0, go back to step (a).

(c) If there is still a row a such that ¯a · ¯x < −σ,

restart at step (a).

5. If Ax ≥ 0, then output Bx as a feasible solution

and stop.

6. (Rescaling)
“

”

Set A = A

I + ¯x¯xT

and B = B

I + ¯x¯xT

“

”

.

7. Go back to step 2.

Feasible
region

z

x

z

x

−a
2

−a
1

Figure 1: A constraint system before and after
rescaling.

We call ρ the radius of A, and z, the unit vector that
achieves the maximum, its center. Note that ρ is just the
radius of the largest ball that ﬁts in the feasible cone, such
that the center of the ball is on the unit sphere. To avoid
confusion, let ρ0 = ρ(A0) denote the roundness of the input.
See Section 4 for a further discussion of ρ.

The classical analysis of the perceptron algorithm [16] (re-
peated in lemma 3.1) shows that the classical perceptron

algorithm (our perceptron phase) applied to a linear feasi-
bility problem with radius ρ will terminate in at most 1/ρ2
iterations. Further, it is not hard to see that if ρ is initially
more than 0, there exists a linear transformation that takes
ρ arbitrarily close to 1. This transformation is deﬁned by
A(cid:2)
ν = A(I + νzzT ). As ν → ∞, a simple calculation shows
that ρ(A) goes to 1. So if we knew the transformation, we
could just apply it once and then run the standard percep-
tron algorithm!

But this is equivalent to the original problem, since z is a
feasible point. Instead, in our algorithm, we incrementally
transform A using near-feasible solutions, so that ρ increases
steadily. Our main lemma shows that in any iteration of our
algorithm where ρ is small, it will increase in expectation by
a multiplicative factor. Combining our main lemma with
the classical analysis will yield that if ρ is small, it gets big-
ger (guaranteed by the perceptron improvement and scaling
phases), and if ρ is big, the algorithm ﬁnds a feasible point
(guaranteed by the perceptron phase).

Each iteration of the algorithm consists a perceptron phase
and a perceptron improvement phase. Alternatively, one
could do just the perceptron improvement phase for a pre-
determined number of steps, and then check for completion
by running the perceptron phase once.

3.2 Proofs

perceptron algorithm.

We begin with the well-known analysis of the standard

Lemma 3.1

(Block-Novikoff [16]). The classical per-
ceptron algorithm (our perceptron phase) returns a feasible
point in at most 1/ρ2 iterations.

Proof. Consider the potential function x · z/ (cid:11)x(cid:11). The

numerator increases by at least ρ on each step:
(x + ¯ai) · z = x · z + ¯ai · z ≥ x · z + ρ

While the square of the denominator increases by at most
1:

(x + ¯ai) · (x + ¯ai) = x · x + 2x · ¯ai + ¯ai · ¯ai ≤ x · x + 1

since x · ¯ai ≤ 0. After t iterations, the potential function
is at least tρ√
t and thus the classical perceptron algorithm
must terminate before 1/ρ2 iterations. If the algorithm ter-
minates, it must have found a feasible point.

Next, we recall the analysis of the modiﬁed perceptron

algorithm (our perceptron improvement phase).

Lemma 3.2

(BFKV [4]). Let A be the constraint ma-
trix at the beginning of a perceptron improvement phase and
let z be any unit vector such that Az ≥ 0. With probability
8 , in at most ln n/σ2 steps, the perceptron improve-
at least 1
ment phase returns a vector x such that

Note that in each update step, z · x does not decrease

(x − (x · ¯ai)¯ai) · z = x · z − (x · ¯ai)(¯ai · z) ≥ x · z

because x · ¯ai had to be negative in order for ¯ai to be used
in an update step, and ¯ai · z ≥ 0 by assumption. (This also
n initially, x will never be set to
implies that if z · x ≥ 1/
zero.) On the other hand x · x does decrease signiﬁcantly
because

√

(x − (x · ¯ai)¯ai) · (x − (x · ¯ai)¯ai) = x · x − 2(¯ai · x)
2
= x · x − (¯ai · x)
≤ x · x(1 − σ2
).

2

+ (¯ai · x)

2

Thus after t iterations (cid:11)x(cid:11) ≤ (1 − σ2)t/2. If t > (ln n)/σ2,
we would have x·z
> 1, which cannot happen. Therefore,
(cid:7)x(cid:7)
every time we start through the algorithm, we ﬁnish with
probability at least 1/8 and we return x for which

x · z
(cid:11)x(cid:11)

≥ 1√
n

.

We are now ready to prove our main lemma about progress

in any iteration that does not ﬁnd a feasible solution.

Lemma 3.3. Suppose that ρ, σ ≤ 1/32n. Let A(cid:2) be ob-
tained from A by one iteration of the algorithm (one on
which the problem was not solved). Let ρ(cid:2) and ρ be the radii
of A(cid:2) and A respectively. Then,

(a) ρ(cid:2) ≥ (1 − 1
32n

− 1

512n2 )ρ.

(b) With probability at least 1

8 , ρ(cid:2) ≥ (1 + 1

3n )ρ.

Proof. The analysis will use Lemma 3.2. Part (a) of the
lemma says that with probability 1
8 , the vector x at the end
of step 4(b) satisﬁes ¯a·¯x ≥ −σ. Part (b) of the lemma asserts
that the vector x at the end of step 4(b) will simultaneously
satisfy z · ¯x ≥ 1/

n with probability at least 1/8.

Let ai, i = 1, . . . m be the rows of A at the beginning of
some iteration. Let z be a unit vector satisfying ρ = mini ¯ai ·
z, and let σi = ¯ai · ¯x. After a perceptron improvement phase,
we get a vector x such that

√

As in the theorem statement, let A(cid:2) be the matrix obtained
after the rescaling step, i.e.

¯ai · ¯x = σi ≥ −σ.

a(cid:2)
i = ai + (ai · ¯x)¯x.

z(cid:2)

= z + α(z · ¯x)¯x.

where α will be speciﬁed shortly. Although z(cid:2) is not nec-
essarily the center of A(cid:2), ρ(cid:2) is a maximum over a set, and
so considering one element (¯z(cid:2)) of the set suﬃces to lower
bound ρ(cid:2). We have

ρ(cid:2) ≥ min

¯a(cid:2)
i · ¯z(cid:2)

i

= min

i

i · z(cid:2)
¯a(cid:2)
|z(cid:2)|

.

for every row a of A and

Finally, deﬁne

(a)

(b)

¯a · x ≥ −σ
z · ¯x ≥ 1√
n

.

Proof. The proof of both parts is similar. A standard
computation shows that for a random unit vector x, z · x ≥
√
n with probability at least 1/8. We now show that if this
1/
is the case, we terminate in the desired number of iterations.

i · z(cid:2) ≥ ρ 1 + σi
¯a(cid:2)
1 + 3σ2
i

p

≥ ρ 1 − σ

√

.

1 + 3σ2

The Chernoﬀ bound gives,

(1)

Pr(X < (1 − (cid:27))E[X]) ≤ e−(cid:13)2E[X]/2.

where the second inequality follows from σi ∈ [−σ, 1]. Next,
observe that

Let ρT be the ρ value after T iterations. Let T = 2048n log(1/ρ0)
and (cid:27) = 1/16. Then

E[X] ≥

T

8

.

e−(cid:13)2T /8 ≤ e−n

We will ﬁrst prove that ¯a(cid:2)

¯a(cid:2)
i · z(cid:2)

„

i · z(cid:2) cannot be too small.
¯ai + (¯ai · ¯x)¯x
(cid:11)¯ai + (¯ai · ¯x)¯x(cid:11)

· z(cid:2)

«

[¯ai + (¯ai · ¯x)¯x][z + α(z · ¯x)¯x]

p

1 + 3(¯ai · ¯x)2
ρ + σi(z · ¯x)(1 + 2α)

p

1 + 3σ2
i

=

=

≥

We choose :

α =

1
2

(

ρ

¯x · z

− 1)

so that 2α+1 = ρ/(¯x·z). We have not ensured that ¯x·z (cid:5)= 0,
but substituting in for α(¯x · z) in the deﬁnition of z(cid:2) using
the value we have chosen for α would remove this boundary
case. We have chosen not to do this to aid the exposition.
We proceed to calculate

|z(cid:2)|2

= 1+(α2

+2α)(¯x·z)

2

= 1+

+(z · ¯x)

ρ2
4

„

ρ

2

− 3
4

«

(z · ¯x)

.

We consider two cases:

1. |z · ¯x| < 1√

n . This happens with probability at most

7/8.
Viewing |z(cid:2)|2 as a quadratic polynomial in (z(cid:2) · x), we
see that it is maximized when (z(cid:2) ·x) = ρ
3 . In this case,
we have

|z(cid:2)|2 ≤ 1 +

ρ2
4

+

ρ2
12

≤ 1 +

ρ2
3

.

Using the elementary inequality
β ∈ (−1, 1), we ﬁnd

1√

1+β

≥ 1 − β

2 for

ρ(cid:2) ≥ ρ

√

1 − σ

1 + 3σ2|z(cid:2)|

ρ2
6

)

)(1 −

≥ ρ(1 − σ)(1 − 3σ2
2
≥ ρ(1 − σ − 3σ2
2
− 1
≥ ρ(1 − 1
32n

ρ2
6
512n2 )

−

)

2. |z · ¯x| ≥ 1√

n . This happens with probability at least

since σ, ρ ≤ 1/32n.

1/8.
In this case,
ρ2
4

= 1+

|z(cid:2)|2

+(z· ¯x)

ρ

2

− 3
4

(z· ¯x)

2 ≤ 1− 3

ρ
√

4n +

2

n +

ρ2
4

.

Using the elementary inequality again, we ﬁnd

ρ(cid:2) ≥ ρ(1 − σ)(1 − 3σ2
2
„
1 − σ − 3σ2
2
„

≥ ρ

«

+

)(1 +

3
8n

−

3
8n

−

ρ
√

4

n

ρ
√

4

−

n
ρ2
8

ρ2
8

)

−
«

≥ ρ

1 +

1
3n

.

This proves both parts of the Lemma.

We can now bound the number of iterations. Recall that

ρ0 = ρ(A0) is the ρ value for the initial input matrix.

Theorem 3.4. With high probability, the algorithm ﬁnds

a feasible solution in O(n log(1/ρ0)) iterations.

Proof. It suﬃces to show that ρ will be at least 1/32n
in O(n log(1/ρ0)) iterations. Let Xi be a random variable
for the i’th iteration, with value 1 if ρ grows by a factor of
(1 + 1/3n) or more and value 0 otherwise. Let X be the sum
of the Xi’s over T iterations. Then by Lemma 3.3(b)

which satisﬁes the deﬁnition of high probability. Analyzing
ρT in the case that X is within (cid:27) of its expectation, we have

ρT ≥ ρ

1 +

„

„

„

1
3n

1
3n

«X „

« T
8

−(cid:13) T
8

« 15T
128

„

«T −X

1 − 1
32n

− 1

512n2

„
1 − 1
32n

− 1

512n2

« 7T
8

+(cid:13) T
8

« 113T
128

1 − 1
32n

− 1

512n2

≥ ρ

1 +

1 +

≥ ρ

1
3n
≥ ρeT /1000n.

We summarize: with probability at least 1 − e−n, in at most
T iterations, ρ grows to at least 1/(32n), at which point the
perceptron phase succeeds in ﬁnding a feasible point.

Finally, the time complexity is a matter of accounting.

Theorem 3.5. With high probability, the algorithm ﬁnds

a feasible solution in time O(mn4 log n log(1/ρ0)).

Proof. The inner loop of either the perceptron phase
or the perceptron improvement phase requires at most one
matrix-vector multiplication (time O(mn)), and a constant
number of vector manipulations (time O(n)). The number
of times we repeat the inner loop is at most 16n2 in the
perceptron phase, and at most log n/σ2 = O(n2 log n) in
the perceptron improvement phase. The bound on the to-
tal number of times through the perceptron improvement
phase is probabilistic, but it can be shown to be close to its
expectation using a Chernoﬀ bound just as in the previous
theorem. The scaling phase takes time O(n2). Calculating
Bx similarly takes time O(n2).

By the previous theorem, the number of iterations is at
most O(n log(1/ρ0)). This yields the overall time bound
O(mn4 log n log(1/ρ0)).

4. THE STANDARD FORM

6. REFERENCES

In this section we discuss how to reduce the standard lin-
ear programming problem to the one solved in this paper.
A typical approach to reduce optimization to feasiblity is to
replace max cT x by the constraint cT x ≥ c0 for some value
of c0. Binary search can be used to determine a nearly op-
timal value of c0. A solution that is feasible for the problem
with c0 suﬃciently close to optimal can be rounded to an
optimal vertex solution through basis reduction [13].

Next, we show how to reduce the standard form linear

feasibility problem

Ax ≤ b, x ≥ 0

into the linear feasibility problem we studied earlier. This
technique is typically referred to as homogenization. We
also relate ρ, the condition number, and the “bit-length” of
the problem before and after homogenization. We conclude
from this that the algorithm is polynomial in the traditional
sense [13].

Introduce the variable x0 and consider the problem

Ax ≤ bx0, x ≥ 0, x0 > 0

To convert a solution for the standard form to one for the
homogenized form, set x0 = 1. To convert a solution from
the homogenized form to a solution for the standard form,
divide x by x0. To rewrite the homogenized form as just

Let x(cid:2) = [x x0] and

A(cid:2)x(cid:2) ≥ 0, x(cid:2) (cid:5)= 0

»

–

−A b

I

A(cid:2)

=

A valid solution to A(cid:2)x(cid:2) ≥ 0 might have x0 = 0. However,
because the classic perceptron algorithm (our perceptron
phase) always produces solutions in the strict interior of the
feasible region, our algorithm will always return a solution
with x0 > 0.

The traditional measure of the diﬃculty of a linear pro-
gramming problem in the Turing model of computation is
called the “bit-length” and denoted by L. The quantity L is
essentially the input length of the linear program. The con-
dition number of a linear program was deﬁned by Renegar
as the normalized distance to ill-posedness [17]. By apply-
ing a small perturbation one can ensure that the log of the
condition number is upper-bounded by a polynomial in L,
and so linear programming algorithms that are polynomial
in the log of the condition number are also polynomial in
L. The quantity ρ was related to the condition number in
[11, 7] (it was called the minimum width by Freund) and
more recently in [9]. In particular, ρ of the homogenized
program is no more than n times the condition number of
a slight perturbation of the original program. We conclude
from this that the algorithm is polynomial in L.

5. ACKNOWLEDGEMENTS

We thank Dan Stefankovic and Adam Smith for helping
these ideas through their formative stages, and Adam Kli-
vans and Rocco Servedio for bringing [12] to their attention.
We are grateful to Rob Freund and Mario Szegedy for many
useful comments.

[1] S. Agmon, The relaxation method for linear

inequalities, Canadian J. of Math., 6(3), 382–392, 1954.
[2] D. Bertsimas and S. Vempala, Solving convex programs

by random walks, Proceedings of the Annual ACM
Symposium on the Theory of Computing, 109–115,
2002.

[3] A. Blum and J. Dunagan, Smoothed Analysis of the

Perceptron Algorithm for Linear Programming,
Proceedings of the Annual ACM-SIAM Symposium on
Discrete Algorithms, 905–914, 2002.

[4] A. Blum, A. Frieze, R. Kannan, and S. Vempala, A
polynomial-time algorithm for learning noisy linear
threshold functions, Algorithmica, 22(1), 35–52, 1998.

[5] T. Bylander, Learning linear threshold functions in the

presence of classiﬁcation noise, Proceedings of the
Workshop on Computational Learning Theory, 1994.

[6] E. Cohen, Learning noisy perceptrons by a perceptron

in polynomial time, Proceedings of the Annual IEEE
Symposium on the Foundations of Computer Science,
514–523, 1997.

[7] F. Cucker and D. Cheung, A new condition number for

linear programming, Mathematical Programming,
Series A, 91(1), 163–174, 2001.

[8] V. Chvatal, Linear Programming, W.H. Freeman, 1983.
[9] J. Dunagan, S. Teng, and D. A. Spielman, Smoothed

Analysis of Renegar’s Condition Number for Linear
Programming, SIAM Conference on Optimization,
2002.

[10] R. M. Freund and S. Mizuno: ”Interior Point

Methods: Current Status and Future Directions,” in
High Performance Optimization, H. Frenk et al. (eds.),
Kluwer Academic Publishers, pp. 441-466, 2000.

[11] R. M. Freund and J. R. Vera, Some characterizations

and properties of the ”distance to ill-posedness” and
the condition measure of a conic linear system, Math.
Programming, 86, 225–260, 1999.

[12] J. Forster, A Linear Lower Bound on the Unbounded

Error Probabilistic Communication Complexity,
Sixteenth Annual IEEE Conference on Computational
Complexity 2001,
http://citeseer.nj.nec.com/forster01linear.html

[13] L. Grotchel, L. Lovasz, and A. Schrijver, Geometric

algorithms and Combinatorial Optimization,
Springer-Verlag, Berlin, 1988.

[14] N. Karmarkar, A new polynomial-time algorithm for
linear programming, Combinatorica, 4, 373–396, 1984.

[15] L. G. Khachiyan, A polynomial algorithm in linear
programming, (in Russian), Doklady Akedamii Nauk
SSSR, 244, 1093–1096, 1979 (English translation:
Soviet Mathematics Doklady, 20, 191–194, 1979).

[16] M. L. Minsky and S. A. Papert, Perceptrons: An

introduction to computational geometry, 1969.

[17] J. Renegar, Incorporating condition measures into the

complexity theory of linear programming, SIAM
Journal on Optimization, 5(3), 506–524, 1995.

[18] F. Rosenblatt, Principles of Neurodynamics, Spartan

Books, 1962.

[19] R. Servedio. On PAC Learning using Perceptron,
Winnow and a Perceptron-Like Algorithm. SIAM
Journal on Computing, 31(5), 1358-1369, 2002.

[20] R. Servedio, Smooth Boosting and Learning with
Malicious Noise. Fourteenth Annual Conference on
Computational Learning Theory, 473-489, 2001.

[21] P. M. Vaidya, A new algorithm for minimizing convex
functions over convex sets, Mathematical Programming,
291–341, 1996.

[22] D. B. Yudin and A. S. Nemirovski, Evaluation of the
information complexity of mathematical programming
problems, (in Russian), Ekonomika i Matematicheskie
Metody 12, 128-142, 1976 (English translation:
Matekon 13, 2, 3-45, 1976).

