 A CDD-based Formal Model for Expert Finding 

Yupeng Fu 

State Key Lab of Intelligent 

technology & systems 
Tsinghua University 
Beijing, China P.R. 

 Rongjing Xiang, Yiqun Liu 
 Department of Computer Science 

 Min Zhang, Shaoping Ma 

 State Key Lab of Intelligent 

and Technology 

Tsinghua University 
Beijing, China P.R. 

technology & systems 
Tsinghua University 
Beijing, China P.R. 

Yupeng.Fu@gmail.com 

{jean.xrj,liuyiqun03}@gmail.com

{z-m, msp}@tsinghua.edu.cn 

ABSTRACT 
Searching an organization’s document repositories for experts is a 
frequently  faced  problem  in  intranet  information  management. 
This paper proposes a candidate-centered model which is referred 
as Candidate Description Document (CDD)-based retrieval model. 
The  expertise  evidence  about  an  expert  candidate  scattered  over 
repositories  is  mined  and  aggregated  automatically  to  form  a 
profile  called 
the  candidate's  CDD,  which  represents  his 
knowledge. We present the model from its foundations through its 
logical  development  and  argue  in  favor  of  this  model  for  expert 
finding.  We  devise  and  compare  the  different  strategies  for 
exploring  a  variety  of  expertise  evidence.  The  experiments  on 
TREC enterprise corpora demonstrate that the CDD-based model 
achieves  significant  and  consistent  improvement  on  performance 
through comparative studies with non-CDD methods. 

Categories and Subject Descriptors 
H.3.3 Information Search and Retrieval;  

General Terms 
Algorithms, Performance, Experimentation 

Keywords 
Expert finding, knowledge management, expertise modeling, 

1.  1. INTRODUCTION 
Finding  experts  in  a  particular  area  is  a  frequently  encountered 
problem  within  any  commercial,  educational  or  government 
organization.  There  are  a  number  of  situations  where  knowing 
"who  know  what"  within  an  organization  is  necessary,  including 
knowledge sharing, team formation, project launching, etc.  

Different from traditional document retrieval tasks, expert finding 
aims  at  finding  a  higher  semantic  and  abstract  concept  “person”, 
other  than  the  real  and  concrete  documents  in  the  collection. 
Simply  using  search  engine  to  shift  the  target  from  document  to 
expert  is  not  an  effective  approach.  The  reason  lies  in  that  for 
documents  retrieval,  the  words  in  a  document  are  explicit  and 
known  thus  can  be  indexed  for  retrieval.  However,  the  experts’ 

 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise,  or  republish,  to  post  on  servers  or  to  redistribute  to  lists, 
requires prior specific permission and/or a fee. 
CIKM’07, November 6--8, 2007, Lisboa, Portugal. 
Copyright 2007 ACM  978-1-59593-803-9/07/0011...$5.00. 
 

 

information  may  be  scattered  over  repositories  and  thus  not  be 
accurately and explicitly documented, so  it  needs  to  discover  the 
implicit expertise to estimate who is the expert.  

Generally  speaking,  there  are  two  alternative  expert  search 
models: the document-centered model and the candidate-centered 
model.  The  document-centered  model  is  a  traditional  prevailing 
model.  Source  corporate  documents  are 
retrieved  using 
information  retrieval  systems,  and  the  matching  sources  are  then 
mined 
In  candidate-centered  models,  expert 
candidates  are  represented  by  a  pre-constructed  or  dynamically 
generated document aggregated from the corporate documents. A 
typical  system  built  by  Nick  Craswell  and  David  Hawking  is 
P@NOPTIC Expert [1]. 

for  experts. 

We  propose  a  candidate-centered  model  which  builds  a  direct 
relationship  between  query  and  expert  by  retrieving  Candidate 
Description Document (CDD)s for each candidate. The CDD of a 
certain candidate is a profile to represent his knowledge, which is 
aggregated  from  his  automatically  identified  expertise  evidence 
that scattered over document repositories. Three natural heuristics 
is  considered  to  interpret  the  model  and  develop  formulae  for 
CDD  weighting.  We  argue  that  there  are  several  reasons  which 
account for preference of the candidate-centered model.  

2.  CDD-BASED FORM1AL MODEL 
2.1  Definitions and candidate-centered model 
Information  relevant  to  an  expert  is  distributed  across  the 
organization in heterogeneous sources. In most cases the expertise 
data is not fully documented and usually only parts of a document 
are  related  to  the  expert  whom  it  mentions.  In  order  to  better 
describe  the  knowledge  of  a  particular  candidate,  the  expertise 
representation  should  be  established  on  a  more  precise  level 
instead  of  the  document.  Here  we  adopt  the  concept  “expert 
evidence”  as  the  fundamental  element  in  representing  the 
expertise. We make the following definition: 

Definition 1: Let x be a text sequence obtained from document d, 
and  let  c  be  a  candidate.  If  x  can  represent  the  knowledge  of  c 
through a logical or natural association, then x is the evidence of 
candidate c, denoted

Evi x c . 

( , )

The text x can be professional and descriptive terms or phases like 
“Information  retrieval”.  All  pieces  of  expert  evidence  associated 
with  a  particular  expert  candidate  can  be  aggregated  as  a 
knowledge  description  to  represent  him.  We  give  this  another 
definition: 

Definition  2:  There  are  potential  pieces  of  expertise  evidence 
distributed in heterogeneous sources, which can be identified and 

extracted  automatically  to  form  a  document  that  describes  the 
particular candidate c. This refined document is called Candidate 
(CDD).  In  an  organization,  each 
Description  Document 
candidate may correspond to a particular CDD. 

The  approach  is  motivated  by  the  assumption  that  each  expert’s 
knowledge can be represented by a list of terms which are related 
to  him.  And  in  a  limited  document  collection,  this  ideal 
description is approximated by the aggregation of expert evidence 
which 
in  enterprise  repositories. 
Therefore the probability of a candidate to be the expert under the 
given  query  can  be  defined  as  the  probability  that  the  ideal 
description  of  candidate’s  knowledge  matched  to  the  query. 
Formally, this can be expressed as: 

is  extracted  automatically 

P c q

( |

DEF
) = (

P C q

|

)

≈

P CDD q

(

|

)

 

   

(1) 

where C denotes the ideal description of candidate c, and CDD is 
used to estimate the ideal knowledge representation.  

( ,

, )

to  exploiting 

2.2  Heuristics for Ranking Candidates 
CDD  is  a  knowledge  representation  formed  by  pieces  of  expert 
evidence. Each piece of evidence 
Evi x c a  conveys a particular 
knowledge  of  candidate  c  through  the  association  a.  Therefore, 
contrast 
term 
incidence  in  document  retrieval,  the  CDD-based  model  needs 
some  natural  interpretation  on  knowledge  representation  through 
expert  evidence.  We  find  three  intuitive  and  desirable  heuristics 
that determine the relevance of a specific CDD to a given query. 
These  heuristics  are  motivated  by  the  observations  on  some 
common characteristics of the judgment when people make to find 
experts. 

information  by  examining 

the 

The  first  heuristic  is  the  expertise  intensity  (EI)  on  the  required 
topic.  The  amount  of  the  required  information  that  a  candidate’s 
knowledge contains contributes to present how much the required 
knowledge  the  candidate  has.  We  assume  that  if  a  candidate 
possesses more knowledge, he is more likely to be the expert.  

The  next  intuitive  heuristic  is  expertise  discrimination  (ED).  If 
some  knowledge  that  a  candidate  possesses  can  distinguish  him 
from  other  candidates,  we  denote  such  knowledge  with  a  high 
degree  of  expertise  discrimination.  It  ensures  that  given  a  fixed 
number  of  candidates,  we  should  favor  the  candidates  who  have 
more  discriminative  knowledge  and  penalize  those  with  the 
common knowledge. 

The  third  heuristic  is  referred  as  effective  expertise  proportion 
(EEP). People usually possess knowledge in more than one field. 
In  expert  finding  problem,  the  information  on  the  required  topic 
may be only part of the candidates’ knowledge. And people prefer 
the  expert  who  focuses  his  attention  more  on  the  topic.  For 
example, under the query “Information retrieval”, an expert on IR 
is  more  likely  to  be  selected  than  another  one  who  labels  his 
interest  as  “Computer  Science”.  We  make  an  assumption  that 
among  those  candidates  with  the  same  expertise  intensity  on  the 
topic,  the  candidate  with  larger  effective  expertise  proportion  is 
more likely to be the expert since he concentrates more on it.  

2.3  Model Description  
We now present how to embody the three  basic  heuristics  in  our 
CDD framework and detail the ranking formula.  

( , )

The expertise  intensity  of  a  candidate’s  CDD  is  the  sum  over  all 
its  composing  evidence.  For  each  piece  of 
intensities  of 
evidence
Evi x c ,  the  frequency  of  query  term  in  x  is  the  most 
salient factor to represent expertise intensity. The weight of expert 
intensity  in  evidence  is  calculated  under  the  formula  given  by 
Robertson  and  Walker  who  model  the  term  frequencies  within 
documents  as  two  Poisson  distributions.  The  Poisson  model  is 
well satisfied by expert evidence that each evidence is associated 
with  one  topic  and  the  distribution  of  term  in  text  x  is  Poisson. 
Formally, the weight of each CDD is expressed as: 

EI

CDD

( )
t

=

EI

Evi

( )
j

( )
t

=

∑

j CDD
∈

TF

(

k

+

1)

∑

j CDD
∈

( )
j
k TF

Evi
+

Evi

( )
j

  (2) 

where

TF

Evi

( )
j

is  the  occurrences  of  term t  in  each  evidence  j  in 

CDD,  the  constant  k  controls  how  much  the  weight  reacts  to 
increasing 
.  Note  that  we  do  not  employ  a  length 

TF

Evi

( )
j

normalization  heuristic  for  each  piece  of  evidence  since  we 
assume  that  each  piece  of  evidence  relates  to  one  topic  and  the 
nature  of  evidence  ensures  that  they  will  be  succinct  rather  than 
wordy. 

The  expertise  discrimination  heuristic  depends  on  the  number  of 
the  CDDs  where  the  query  term  occurs  and  the  total  amount  of 
CDD  collection.  The  weighting  function  we  adopt  is  like  the 
inverse  document  frequency  (IDF)  weight  in  document  retrieval 
model.  Actually,  the  expertise  discrimination  exerts  the  same 
effort  like  IDF  in  estimating  which  query  term  is  more 
professional  to  differentiate  candidates.  A  plausible  weighting 
function is  

ED

=

       

 

(3) 

N
n

where N is  the  size  of  CDD  collection  and  n is  the  number  of 
CDDs containing the term t . 

The  effective  expertise  proportion  is  considered  as  the  ratio 
between  the  relevant  knowledge  to  query  and  the  whole 
knowledge that the candidate possesses. Specifically, in CDD this 
heuristic  is  weighted  by  the  proportion  between  the  relevant 
evidence and all the evidence in CDD. We adopt those pieces of 
evidence  whose  expertise  intensity  are  above  zero  as  relevant 
knowledge  and  count  their  text  length.  Formally,  the  weight  of 
effective expertise proportion of a CDD is defined as: 

EEP

= −

(1

b

)

+

b

 

(4) 

rL
L

 

where rL is  the  length  of  all  relevant  pieces  of  evidence  in  CDD 
and L is  the  length  of  CDD.  The  tuning  constant b is  used  to 
control the concentration effect. 

Finally,  we  get  the  last  weighting  function  that  encapsulates  the 
three heuristics.  

W EI ED EEP

=

⋅

⋅

=

(

)

⋅

⋅

((1

−

b

)

+

b

)

  (5) 

(

TF
+∑

( )
j
k TF

Evi

j CDD
∈

k

+

1)

Evi

( )
j

N
n

L
r
L

Note that though our function is very similar with BM25 function 
[3],  our  model  conceptually  and  formally  differs  from  it  because 
CDD  model  is  based  on  the  heuristics  for  finding  people. 

Particularly, in our model TF is weighted under 2-Possion model 
on  each  piece  of  expertise  evidence and  the  EI  is  the  sum  of  the 
weight over all pieces of evidence in CDD. Moreover, we do not 
normalize  the  EI  using  evidence  length.  Instead,  we  propose  an 
EEP factor which involves the total length of CDD and the length 
of relevant evidence in CDD. Therefore, the CDD-based model is 
not simply an adaptation of BM25. 

3.  THE ADVANTAGES OF USING CDD-
BASED MODEL FOR EXPERT FINDING 
Although 
the  document-centered  model  has  been  widely 
employed  in  the  past  to  tackle  the  problem,  we  believe  the 
candidate-centered  model  is  the  more  suitable  solution  to  expert 
finding.  One  of  the  reasons  for  using  candidate-centered  model 
rather than document-centered model is that “one should solve the 
problem  directly  and  never  solve  a  more  general  problem  as  an 
intermediate  step”  [4].  For  finding  experts,  representing  the 
candidates’  knowledge  directly  is  a  more  intuitive  solution 
contrast  to  the  more  general  issue  that  finding  the  distribution  of 
the documents which are relevant to both the query and candidate. 
Beyond  the  theoretical  consideration,  there  are  other  reasons 
specific  to  the  expert  finding  task  make  the  candidate-centered 
model more suitable. 

in 

document-centered  model, 

The  discriminating  power  of  query  term  is  important  in  retrieval 
task  to  penalize  popular  terms  in  the  documents.  The  expertise 
discrimination  heuristic  of  candidate-centered  model  ensures  that 
those  more  professional  and  discriminative  query  terms  will  be 
favored.  However, 
the 
discriminating power of query term is using document frequencies 
from the original collection. Imagine the cases that there are some 
query  terms  with  relatively  high  IDF  in  original  document 
collection  but  those  query  terms  are  uniformly  scattered  in  most 
CDDs, which means such query terms do not have high expertise 
discrimination  to  CDDs.  For  example,  the  term  “mentor”  may 
differentiate  documents  well  in  original  collection  but  it  is  quite 
popular  in  CDD  collection.  In  such  cases,  the  discrminability  of 
query  term  in  two  models  is  different  and  the  IDF  factor  in 
document-centered model cannot exert its effort in discriminating 
experts.  Therefore  we  believe 
that  employing  expertise 
discrimination is more rational. 

In  document-centered  model,  all  the  exploitation  processes  are 
operated  at  search  time  since  its  first  step  is  to  retrieve  relevant 
documents to given query. However, in candidate-centered model, 
the  generation  of  CDDs  is  an  offline  job.  Moreover,  the  CDDs 
merely consist of the extracted evidence which is a small part  of 
original  collection  in  amount.  Generally  speaking,  users  are 
affected more by query response time than indexing time and we 
only generate the CDDs once to handle any queries.  

4.   CDD CONSTRUCTION 
As the fundamental component of CDD, the expert evidence plays 
an  essential  role  in  representing  candidates’  knowledge  in  our 
model.  We  identify  three  kinds  of  association  for  expertise 
evidence as following: 

Context  evidence  for  an  expert  is  the  words  around  the  expert 
name which is identified in the document. Co-occurrence between 
text  and  candidate  can  be  used  as  evidence  and  we  extract  the 
terms that appear in the same window of text with the candidate.  

Block-based evidence is generated using markup terms in HTML 
documents, such as the Title, Heading, Bold, etc, which contribute 
to describing and summarizing web pages, contain good summary 
words, and have expressive force.  

is  based  on 

Semantic-group-based  evidence  extraction 
the 
phenomena that persons often co-occur in the context as a group. 
We  examine  a  mixture  of  patterns  that  group  information 
expressed.  For  example,  a  list  of  person  names  may  represent 
members  of  a  group;  in  some  tables,  the  left  column  lists  person 
names and in the right column gives the corresponding description 
information like the professional title. Correct recognition of such 
group patterns brings on highly credible associations. 

Due to the page limits, in this paper we concentrate on the CDD 
model presentation and in another paper [1] we have described the 
strategies of name identification and expertise evidence extraction 
in details.  

5.  EXPERIMENTS AND DISCUSSIONS 
Our CDD-based search model is evaluated on the dataset adopted 
in  TREC  enterprise  track  2005  and  2006  [5].  The  collection  is  a 
crawl  of  the  public  W3C  (*.w3c.org)  sites.  We  took  the  topics 
adopted by the expert finding task of TREC. The main evaluation 
measures  used  for  the  expert  finding  task  is  mean  average 
precision (MAP).  

5.1  Impact of Heuristics of CDD-based Model 
We  examine  the  three  two  heuristics  in  our  CDD-based  model 
presented  in  Section  2.2:  expertise  intensity  (EI)  and  expertise 
discrimination (ED). Table 1 shows the retrieval performances. In 
weighting  EI,  according  to  our  experiments,  changing  constant  k 
affect the MAP slightly and it takes 1 empirically. The reason lies 
in  that  each  piece  of  evidence  is  extracted  as  a  fragment  of  the 
original document and the times of the query term that appears in 
the  evidence  is  not  much,  therefore  varying  the  constant  k  does 
not affect much. 

The  experimental  results  confirm  our  assumptions  proposed  in 
Section 2.2. And note that using EI alone is already more effective 
than  the  average  performance  of  TREC  systems,  which  had  a 
MAP of 0.1969 in 2005 and 0.3863 in 2006.  

Table 1. Results of three heuristics in CDD-based model. 

Heuristics 

ENT 2005 

ENT 2006 

MAP 

p@10  MAP 

EI  

0.2274  0.3636  0.4667 

*EI ED  

0.2300  0.3682  0.4978 

p@10 

0.5851 

0.6149 

 

Varying  the  value  of  b  in  formula  (4)  allow  us  to  evaluate  the 
effect  of  using  EEP  on  the  test  sets.  Smaller  values  reduce  the 
EEP  effect.  In  TREC  2005  query  set,  the  curve  shows  that 
generally  the  average  precision  increases  as  b  rises,  which  is 
consistent with the effect on the training set. However, in the 2006 
query set, MAP increases slightly when b is less than 0.3, and then 
falls rapidly when EEP becomes larger than 0.55. The inconsistent 
observation in two years’ query sets can be explained by the facts 
that  in  TREC  2005,  the  search  topics  were  the  names  of  the  so-
called “working groups”, and  the  experts  were  members  of  these 

groups, which means that the relevant assessment are based on the 
ground  truth  of  W3C  people.  In  TREC  2006,  both  the  topics 
creation  and 
relevance  assessments  are  accomplished  by 
participants. 

 

Figure 1: The impact of varying the value of b in tuning the 
effect of effective expertise proportion (EEP) on query sets of 

TREC enterprise track 2005 (a) and 2006 (b). 

These  differences  indicate  that:  firstly,  finding  working  group 
member is a fundamentally different task with finding people who 
are  experts  in  an  ad-hoc  informational  subject.  Secondly,  the 
pooling method implies that to some extent, the experts are judged 
by  those  non-expert  assessors.  The  judgers  cannot  capture  a 
comprehensive  familiarity  with  all  those  candidates  and  their 
judgments  are  inevitably  merely  relied  on  those  documents 
gathered  in  the  pools.  Besides  the  inaccuracy  problem,  it  also 
brings  another  problem  which  may  reduce  the  effect  of  EEP. 
Assessors  may  choose  those  candidates  who  are  very  active  like 
directors  and  supervisors  of  a  department  or  an  institute,  where 
their  names  just  appear  in  almost  each  document  from  that 
department.  This  situation  contradicts  our  assumption  that  to 
prefer those candidates who focus on the topic more. 

5.2  Comparisons 

than 

To demonstrate our statement that the CDD-based model is more 
effective 
the  document-centered  model,  we  perform 
experiments  to  compare  expert  finding  performances  using  the 
two  models.  The  implementation  of  the  contrastive  document-
centered experiment employs the traditional approach adopted by 
many document-centered systems mentioned in Section 1 with the 
following steps: (i) retrieve documents relevant to the query using 
traditional  IR  model,  (ii)  calculate  the  candidates’  expert  degree 
using  voting  method  among  the  returned  documents.  Several 
voting ways are attempted, we find the most effective scheme is to 
calculate  the  candidate’s  score  according  to  the  ranking  of  the 
documents where he or she appears in step (i). 

Table 2. Comparative best results between CDD-based search 

model and our contrastive document-centered model 

Model 

Document-
centered model 
CDD-based model 

ENT 2005 

ENT 2006 

MAP 

p@10 

MAP 

p@10 

0.2201 

0.3776 

0.3903 

0.5896 

0.2716 

0.4091 

0.5077 

0.6128 

Improve 

23.4% 

8.3% 

30.1% 

3.9% 

Table  2  shows  the  improvement  of  the  CDD-based  model  upon 
the comparative document-centered model. The results illustrate a 
consistent and significant gap between the best results of the two 
models.  We  achieve  the  best  performance  in  TREC  enterprise 
track  2005  and  top  5  in  TREC  2006.  Among  the  participants 
during the two years, most approaches employ document-centered 
models.  But  we  should  note  that  in  order  to  make  a  fair 
comparison  it  is  important  to  take  into  account  how  others 
approached  the  task.  First,  unlike  most  participants,  we  only  use 
the  Web  pages  part  of  the  corpus  and  do  not  utilize  other 
documents  (such  as  mail  lists),  which  is  about  half  of  the 
collection  in  amount.  Further  more,  our  models  are  unsupervised 
which  means  no  manual  efforts  were  made  to  increase  the 
performance.  In  particular,  we  do  not  resort  to  some  special 
treatment  to  the  documents  like  some  participants  who  adopt 
extraction according to the template of the W3C website. 

6.  CONCLUSION AND FUTURE WORK 
In  this  paper,  we  propose  a  candidate-centered  formal  model  to 
solve the expert finding problem. The model is based on the view 
of representing knowledge of candidate by the evidence which is 
automatically  extracted 
from  an  organization’s  document 
repositories. Then we presented three basic heuristics determining 
the  knowledge  representation  to  detail  the  model  description  and 
explore the strategies to extract the expertise evidence.  

There  is  a  lot  of  space  for  further  improvement  through  more 
sophisticated strategies of expert evidence identification and  

extraction.  Another  issue  is  that  we  could  investigate  the 
relationships  between  the  knowledge  presentations  of  candidates 
to build up a social network. And as another part of future work, 
our model can be extended to other object-centered vertical search 
fields such as software search, MP3 search and so on. 

7.  ACKOWNLEDGEMENTS 
This work was supported by the Chinese National Key Foundation 
Research  &Development  Plan  (2004CB318108),  the  Chinese 
Natural  Science  Foundation  (60621062,  60503064)  and  the 
National 863 High Technology Project (2006AA01Z141). 

We  would  like  to  thank  Ian  Soboroff,  Le  Zhao,  and  the 
anonymous reviewers for their helpful suggestions. 

REFERENCES 
[1]  N. Craswell, D. Hawking, Anne-Marie Vercoustre,Peter 

Wilkins, P@NOPTIC Expert: Searching for Experts not just 
for Documents, CSIRO, Australia 2003 

[2]  Y. Fu, W. Yu, Y. Li, Y. Liu, M. Zhang, and S. Ma. THUIR at 

TREC 2005: Enterprise track. In Voorhees and Buckland . 

[3]  K. S. Jones, S. Walker, and S. E. Robertson. A probabilistic 

model of information retrieval: Development and 
comparative experiments. Information Processing and 
Management, 2000. 

[4]  V. N. Vapnik, Statistical Learning Theory, John Wiley & 

Sons, 1998. 

[5]  TREC. Enterprise track, 2005 and 2006. URL: 

http://www.ins.cwi.nl/projects/trec-ent/wiki/. 

