On Probabilistic Fixpoint and Markov Chain

Query Languages

Daniel Deutch
Tel Aviv University

danielde@post.tau.ac.il

Christoph Koch
Cornell University

koch@cs.cornell.edu

Tova Milo

Tel Aviv University
milo@cs.tau.ac.il

ABSTRACT
We study highly expressive query languages such as datalog,
ﬁxpoint, and while-languages on probabilistic databases. We
generalize these languages such that computation steps (e.g.
datalog rules) can ﬁre probabilistically. We deﬁne two possi-
ble semantics for such query languages, namely inﬂationary
semantics where the results of each computation step are
added to the current database and non-inﬂationary queries
that induce a random walk in-between database instances.
We then study the complexity of exact and approximate
query evaluation under these semantics.

Categories and Subject Descriptors
H.2.3 [Database Management]: [Languages]

; H.2.1 [Database Management]: [Logical Design]
; G.3 [Mathematics of Computing]: [Probability and

Statistics]

General Terms
Algorithms, Languages, Theory

1.

INTRODUCTION

Probabilistic databases have recently started to attract
considerable interest. A number of query languages that are
analogs of relational algebra or SQL have been studied for
probabilistic databases [6, 23, 8, 3, 4, 15, 16, 17, 12], but so
far there has been virtually no work on more expressive lan-
guages such as ﬁxpoint and while-languages beyond Fuhr’s
original proposal to use datalog on probabilistic databases
in the context of information retrieval [11].

Highly expressive query languages with an iteration con-
struct enable interesting new applications of probabilistic
databases and query language research. Iterating languages
with probabilistic changes to the database (state) can be
used to declaratively specify (queries over) Markov Chains,
random walks and stochastic processes [10]. This opens

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
PODS’10, June 6–11, 2010, Indianapolis, Indiana, USA.
Copyright 2010 ACM 978-1-4503-0033-9/10/06 ...$10.00.

up entirely new application areas for data management re-
search.

There are many applications of Markov Chains (MCs)
and Markov Chain Monte Carlo (MCMC) [19, 14] in ar-
eas such as bioinformatics and statistical physics, (cf. e.g.
[22, 5]), and their theory plays an increasingly important
role in theoretical computer science and algorithmics. So
far, few systems based on Markov Chains have been devel-
oped that are reusable, and none at all that are application
domain-independent and that allow to program MCMC us-
ing easy to use declarative languages. Declarative datalog-
like languages for deﬁning Markov Chains (and walks over
them) and systems that eﬃciently execute queries in such
languages, would allow to improve research productivity in
areas that use Markov Chains to solve computational tasks,
just like relational database management systems have greatly
improved productivity in the context of business software
and information systems. Declarative query languages for
Markov Chains would also allow to program MCMC appli-
cations on a higher level of abstraction, which may yield
interesting insights into commonalities among such applica-
tions, their componentization, and combination into more
sophisticated applications.

The main goals of this paper are to establish useful proba-
bilistic query languages based on highly expressive languages
in the database literature, and to study their expressiveness
and complexity. Speciﬁcally, we study probabilistic exten-
sions for ﬁxpoint / while query languages, and a probabilis-
tic extension for datalog, again with inﬂationary and non-
inﬂationary semantics. We show how classical examples such
as random walks over graphs, probabilistic reachability anal-
ysis and Bayesian Inference may be expressed in our query
languages.

The core of our complexity results is summarized in Ta-
ble 1. The languages in this table are ordered by increasing
expressive power, that is, each language is expressively sub-
sumed by the languages below it in Table 1. As we show,
exact evaluation and approximation with quality guarantees
relative to the sizes of the probability values to be computed
(“relative approximation”) are infeasible, but absolute ap-
proximation (i.e. approximation up to a constant factor) is
eﬃciently feasible for inﬂationary queries. The depicted NP-
hardness results relate to the corresponding decision prob-
lems, namely “does a given value p approximate the correct
probability value up to a given (cid:178)”, where “approximate” re-
lates to either relative or absolute approximation, according
to the corresponding problem.

We show that our hardness results apply even for very

215Language
(linear) datalog
without probabilistic rules
inﬂationary ﬁxpoint
with probabilistic rules
non-inﬂationary ﬁxpoint
with probabilistic rules

exact computation
(cid:93)P -hard,
in PSPACE
(cid:93)P -hard,
in PSPACE
(cid:93)P -hard,
in (2-)EXPTIME

NP-hard

NP-hard

relative approximation
NP-hard (Thm. 4.1)

absolute approximation
in PTIME

in PTIME (Thm. 4.3)

NP-hard; PTIME in input size
and mixing time (Thm. 5.1,5.6)

Table 1: Overview of complexity results (data complexity).

restricted variants of the query languages, and the algo-
rithms apply to the full-ﬂedged languages. We also discuss
noninﬂationary probabilistic datalog (omitted from the ta-
ble), whose expressive power is subsumed by that of non-
inﬂationary ﬁxpoint. Speciﬁcally, we show that our hardness
results for non-inﬂationary ﬁxpoint languages hold already
for non-inﬂationary probabilistic datalog.

The paper is organized as follows.

In Section 2 we re-
call the deﬁnitions of probabilistic databases as well as the
notions of complexity and approximations used to measure
the quality of query evaluation algorithms. In Section 3 we
formally deﬁne our query languages, in inﬂationary and non-
inﬂationary ﬂavors; query evaluation for inﬂationary and
non-inﬂationary queries is studied in Sections 4 and 5 re-
spectively. We conclude with an overview of related work in
Section 6.

2. PRELIMINARIES

This section provides common deﬁnitions that will be used
in the remainder of the paper. First, we recall some common
notions of computational complexity and approximation al-
gorithms. These notions will be used to analyze our algo-
rithms. Then, we give background on probabilistic databases.
Last, we recall deﬁnitions and important properties of Markov
Chains.
2.1 Complexity and Approximations
Complexity. At some parts of this paper we address the
exact computation of probabilities, which is essentially a
counting problem and its complexity analysis thus makes
use of counting complexity [24]. Speciﬁcally, (cid:93)P is the set
of counting problems associated with decision problems in
NP. More formally, a counting problem is in (cid:93)P if there is a
non-deterministic, polynomial-time Turing Machine whose
number of accepting computations, for each instance I of
the problem, is equal to the result count of I. A problem is
(cid:93)P -hard if and only if every problem in (cid:93)P can be reduced
to it in polynomial time.

We further consider probabilistic algorithms, and recall
in this context that BPP [18] (Bounded-error, Probabilistic,
Polynomial time) is the class of all decision problems solv-
able by a probabilistic Turing machine in polynomial time,
with an error probability of at most (cid:178) for all instances, for
some 0 ≤ (cid:178) < 0.5. Note that the choice of (cid:178) in this range
may be arbitrary; any polynomial-time algorithm A with er-
ror probability bounded by (cid:178) may be transformed into one
with error probability bounded by (cid:178)(cid:48), by executing A multi-
ple times and taking a “majority vote” of its answers. The
Chernoﬀ bound [7] guarantees that the number of required
iterations is logarithmic in 1
(cid:178) .

When analyzing the complexity of query evaluation, one
may consider data complexity and combined complexity [25].
Data complexity is the complexity of evaluating a query as a

function of the database size, while combined complexity is a
function of both the database and the query sizes. We focus
here on data complexity, as, even for restricted versions of
the query languages we study here, it has been shown that
the combined complexity is (cid:93)P -hard. Thus, whenever we
refer to the complexity of query evaluation, we mean data
complexity.

Approximations. We use two notions of approximation,
common in the literature, namely absolute and relative ap-
proximations [26]. An approximation algorithm A to a count-
ing problem C takes as input an instance I of C and a pa-
rameter (cid:178). Denote by C(I) the correct answer for I, and
by A(I) the output of A when executed over I. We say
that A is an absolute approximation if |A(I) − C(I)| ≤ (cid:178) for
every input instance I, (cid:178). A is a relative approximation if
C(I) ∗ (1 − (cid:178)) ≤ A(I) ≤ C(I) ∗ (1 + (cid:178)) for every I.

A randomized absolute approximation algorithm A re-

ceives as input an additional parameter δ, and satisﬁes P r(|A(I)−
C(I)| ≤ (cid:178)) > δ for every input instance I, where P r stands
for probability. Analogously, a randomized relative approx-
imation algorithm A satisﬁes P r(C(I) ∗ (1 − (cid:178)) ≤ A(I) ≤
C(I) ∗ (1 + (cid:178))) > δ.

The corresponding decision problems ask whether a given
value p is an absolute (relative) approximation of the correct
answer C(I), up to a given (cid:178); when we provide in the sequel
NP-hardness (data complexity) results for these problems,
we mean NP-hardness of the corresponding decision problem
(w.r.t. the database size).

2.2 Probabilistic databases

We use the deﬁnition of [16] for probabilistic databases, as
follows. The schema used is a relational database schema;
a probabilistic database over a schema with relation names
R1, ..., Rk is a ﬁnite set of possible worlds

{(R1

1, . . . , R1

k, p[1]), . . . , (Rn

1 , . . . , Rn

k , p[n])}

with positive rational weights p[i] s.t.

(cid:80)

i p[i] = 1.

We give here two examples for previously introduced mod-

els that allow the generation of probabilistic databases, namely
probabilistic c-tables [13] and relational algebra enriched with
a repair-key [16] construct.

Probabilistic c-tables. Probabilistic c-tables with ﬁnite vari-
able domains are deﬁned as follows.

Definition 2.1

([13]). A c-table is a relation in which
each tuple is associated with a condition. A condition is
a boolean combination of (in)equalities involving variables
and constants of some ﬁnite domain V .
In a probabilistic
c-table (pc-table), these variables are random variables. A
probabilistic c-table is a pair of a c-table and the repre-

216sentation of a joint probability distribution of the random
variables occurring in the c-table. The set of possible worlds
of a probabilistic c-table is the set of possible valuations
θ = (X1 = x1, . . . , Xk = xk) of its random variables. The
probability of a world is the probability of the valuation and
the database of the world is the set of tuples whose conditions
are true for θ.

The probabilistic c-tables deﬁned in this way are succinct
means of representing any ﬁnite probabilistic database. One
may ﬁx without loss of generality that the random variables
of a probabilistic c-table are independent. Thus, the joint
distribution can be given by individual distributions for each
of the random variable, assigning for each random variable
X and each possible value x of X, a probability Pr[X = x].
The joint distribution can be obtained as the product of the
distributions of the individual random variables.

Repair-key. Let (cid:126)A, P be column names from the schema
of a relation R, where (cid:126)A is a vector of columns and P is a
single column, containing only numerical values which are
all greater than zero.

The operation repair-key (cid:126)A@P (R) [16], samples one maxi-
mal repair of key (cid:126)A. That is, for each distinct value (cid:126)a of (cid:126)A
appearing in tuples of R, denote the set of tuples in which (cid:126)a
is the key value by T(cid:126)a. For each such (cid:126)a, we sample exactly
one tuple (cid:126)t from T(cid:126)a with the probability distribution given
by (normalized) column P 1. That is, the probability of (cid:126)t
to be chosen is
. The application of a repair-key

(cid:126)t.P

(cid:80)

(cid:126)t(cid:48).P

(cid:126)t(cid:48)∈T(cid:126)a

construct generates a set of possible worlds (samples) with
a single tuple for each key value; the probability of a possi-
ble world is the product of probabilities of the chosen tuples
within their groups T(cid:126)a, that is, the groups are assumed in-
dependent.

Example 2.2. Consider the simple relation R depicted
in Table 2. Each tuple in this relation corresponds to a
(possibly incorrect) fact regarding a basketball player and
the team for which he currently plays. The third column
represents the level of belief in this fact, i.e., that this player
plays for this and no other team, to be considered in relation
to the levels of belief in alternatives.
If this database is
constructed by accumulating the opinions of various users,
this belief value is possibly derived from the popular support
in the fact (i.e. the number of users that think that this fact
is correct). The Player column constitutes a primary key
here, but note that, still, there are multiple tuples sharing
the same value for this attribute. Thus, the key should be
repaired, meaning a single tuple (and thus, team) for each
player should be chosen.

3

By applying repair-keyP layer@Belief (R), this choice is per-
formed probabilistically, with probabilities determined by
the relative belief in each option. That is, the probability of
17
17+3 , and the
the tuple (Bryant, LA Lakers) to be chosen is
probability of the tuple (Bryant, NY Knicks) to be chosen is
17+3 ; similarly, for the tuples having “Iverson” as a player,
one of them is chosen according to their relative belief values
1We assume here that there is a functional dependency in
R : schema(R) − P → P . Alternatively, assume a seman-
tics of repair-key that ﬁrst replaces any group of tuples
((cid:126)b, p1), . . . , ((cid:126)b, pn) that violates this functional dependency
by a single tuple ((cid:126)b,

(cid:80)

i pi).

Team

Player
Bryant
Bryant
Iverson Philadelphia 76ers
Iverson Memphis Grizzlies

LA Lakers
NY Knicks

Belief

17
3
8
7

Table 2: Basketball Players Table

( 8
8+7 and 7
8+7 ). Each possible world database consists of a
single fact for each key value, and its probability is the mul-
tiplication of the probability values over all tuples chosen to
appear in the Database.
(cid:50)

We further exemplify the use of repair-key in Section 3.
The standard notion of relational algebra can be enriched
with the repair-key construct. Each application of the repair-
key generates a set of possible worlds, and further relational
algebra operations are applied in each possible world inde-
pendently. The result of evaluating such an enriched query
Q over a relation R is a probabilistic database, and we de-
note it by Q(R). Q(R) is thus a set of relations, each cor-
responding to a possible world and associated with a prob-
ability value. Note that the repair-key operator is the natu-
ral probabilistic generalization of the witness operator – see
e.g. [1]. Its expressive power was discussed in [16]. Any ﬁ-
nite probabilistic database can be constructed from certain
databases (that is, databases consisting of a single possi-
ble world with probability 1) using queries of this language.
Speciﬁcally, with the repair-key construct, pc-tables as de-
ﬁned above may be simply viewed as “macros”: the proba-
bilistic choices generating possible worlds may be simulated
by a polynomial number of repair-key construct applica-
tions. We further consider the connection between c-tables
and the repair-key construct in the sequel.

For ease of presentation, we will use the following abbre-
viations: we optionally omit the column parameter P and
write just repair-key (cid:126)A(R).
In that case, a tuple is chosen
from its group T(cid:126)a uniformly at random; that is,

repair-key (cid:126)A(R) := repair-key (cid:126)A@P (R × ρP ({1})).

Here × is the standard relational product, and ρ is renaming.
We also use

repair-key@P (R) := repair-key∅@P (R)

for the choice of a single tuple from R, regardless of key
values, with probability set for each tuple according to its
relative value of P with respect to the sum of P values over
all tuples of R. repair-key(R) chooses a single tuple out of
R, uniformly.

2.3 Markov Chains

We next provide, in short, some deﬁnitions for Markov
Chains and their properties. The reader is referred to [10]
for details.

Markov Chains. A Markov Chain (MC) is a ﬁnite state
machine (FSM) with transitions annotated by probabilities
such that the sum of the probability annotations of the out-
going transitions of a state is 1. The probability of each
transition in an MC does not depend on previous states of
the process. A random walk over an MC starts at some arbi-
trary state of the MC and at each point randomly chooses,

217according to the transition probabilities, a transition orig-
inating at its current state and continues from its target
state.

A Markov Chain is irreducible if a random walk starting at
any state i will eventually reach any state j with probability
greater than 0. The period of a state s in a Markov Chain is
a number k such that any return to a state i must occur in
multiples of k steps. Namely, k = gcd{n : P r(Xn = i|X0 =
i) > 0}, where Xi is the state after i steps of the walk. If
k = 1 for all states, then the MC is said to be aperiodic. A
state i is said to be positively recurrent, if, starting at i, the
probability of eventually getting back to i in a ﬁnite number
of steps is 1. An MC is positively recurrent if all of its states
are positively recurrent. An MC is ergodic if it is aperiodic
and positively recurrent.

Stationary Distributions. The transition matrix P is de-
ﬁned, for a given MC M , by P ij being the probability of
transition from state i to state j. The stationary distribu-
tion π over an MC M is then a distribution over the state
space of M , such that π = πP . Such distribution uniquely
exists for M if and only if M is irreducible and positively
recurrent.

Markov Chain Monte Carlo. Markov Chain Monte Carlo
(MCMC) algorithms [14, 19] sample from a probability dis-
tribution π by constructing an ergodic MC M whose sta-
tionary distribution corresponds to π, performing a random
walk over M , and using the distribution of nodes observed at
a random point of the walk as an estimate for the underly-
ing stationary distribution. To sample correctly, the Markov
chain must be ﬁrst mixed, meaning that the probability of
the walk being at a state i is independent of the initial state
of the walk, and is approximately πi (the stationary proba-
bility of state i). When M is ergodic, this is guaranteed to
occur if the walk is long enough.

The mixing time of an ergodic MC is thus deﬁned as the
number of steps it takes to “forget” the initial state, namely,
for some given (cid:178), it is the smallest t((cid:178)) such that |P r(St((cid:178)) =
i) − πi| < (cid:178) for each state i, where St((cid:178)) is the state of the
random walk after t((cid:178)) steps. For an ergodic MC there exists
such t((cid:178)) for every value of (cid:178).

3. LANGUAGE DEFINITIONS

In this section, we formally deﬁne our query languages

and provide some examples of their use.

3.1 Noninﬂationary language

We start by considering standard relational databases,
where ﬁrst-order interpretations are generalized by a sam-
pling extension based on the repair-key operation. Then we
deﬁne non-inﬂationary queries based on this interpretation.
We extend the discussion to probabilistic c-tables below.

Definition 3.1. A probabilistic ﬁrst-order interpretation
over relational schema R1, . . . , Rk is a tuple Q = (Q1, . . . , Qk)
of queries in relational algebra extended by the repair-key
operation such that the result schema of each query Qi is
the schema of Ri. Given a relational database A, such an
interpretation deﬁnes a probabilistic database Q(A) whose
worlds are all (A1, ..., Ak, P ) s.t. each Ai i = 1, ..., k is a
possible result (world) of Qi(A) and P is the multiplication
of the probability values associated with each Ai in Qi(A).

Next we introduce our probabilistic analog of (noninﬂa-

tionary) while-queries (cf. e.g. [1]).

Definition 3.2. A noninﬂationary query or forever-query
over a given database schema is a pair (Q, e), where Q is a
probabilistic ﬁrst-order interpretation of the schema, called
the transition kernel, and e is a low-complexity Boolean re-
lational database query, called the query event. We will
assume that query events are of the form (cid:126)t ∈ R, check-
ing whether a given tuple (cid:126)t is in a relation of the current
database state.

Conceptually, such a query is evaluated against an input
relational database – the initial state – by the following pro-
gram:

State := the input database;
forever {

State := Q(State);

}

The query language semantics is as follows. Note that
Q(state) is in general a probabilistic database, i.e.
is a set
of possible worlds; the loop body is applied in every possible
world, possibly generating new possible worlds etc.
Intu-
itively, the application of the forever-loop corresponds to
random walk over the database states, starting from the in-
put database state, with probabilities of walking from state
s to state s(cid:48) dictated by the probability of s(cid:48) among the
possible worlds of Q(s). The query result is the probability
that the query event is true at an arbitrary point in time
in the inﬁnite random walk, i.e., the probability that after
arbitrarily many steps, the current state satisﬁes (cid:126)t ∈ R.

More formally, a world sequence in the forever-loop is a
sequence of database states seq = [s1, ..., sk] such that s1
is the initial database state and si is a possible world of
Q(si−1), associated with its probability pi. We denote the
length of seq by len(seq). The probability of seq, denoted
P r(seq), is
i=1,...,k pi. The probability of being in a given
database state s, at an arbitrary point in time, in an inﬁnite
random walk over database instances, is then deﬁned as

(cid:81)

(cid:88)

P r(s) = lim
k→∞

{seq|len(seq)=k}

P r(seq)·

|{i|si = s, 1 ≤ i ≤ k}|

.

k

Following [10], the limit exists and is ﬁnite. Last, the query
result is the sum of probabilities P r(s) of all database states
s satisfying (cid:126)t ∈ R.

We note that Q, along with the initial database, deﬁne a
Markov Chain M over database states. When M is ergodic,
the query result is also the probability that (cid:126)t ∈ R according
to the stationary distribution of M .

Example 3.3

(Random walk in a graph). We show
how to express a random walk as a forever-query. Consider
a scenario in which the input database consists of two input
relations: a unary relation C(I), consisting of a single tuple
that stands for the start node of the walk, and a ternary
relation E(I, J, P ) reﬂecting graph edges that are annotated
with probabilities. That is, (i, j, p) ∈ E iﬀ there is an edge
with probability weight p from node i to node j in the graph.
p is the probability of performing a transition to node j,
given that we are at a node i. We can then deﬁne a random
walk by the interpretation Q:

218(cid:161)
(cid:162)
repair-keyI@P (C (cid:46)(cid:47) E)

C := ρI πJ
E := E % unchanged.

Recall that (cid:46)(cid:47) stands for the natural join, π for projection,
and ρ for renaming. In each iteration, if the current tuple in
C is i, then the query selects (by using repair-key) the next
node j out of those for which (i, j) ∈ E; j is then the new
tuple of C, while E remains constant in-between iterations.
If the query event is v ∈ C and E deﬁnes an ergodic Markov
chain M , we are asking for the probability of v according to
the stationary distribution of M .

To see a variant of this, let V denote the set of nodes in the
graph (or, if E is viewed as a Markov chain, the states). V is
obtained by a query over E, namely the union of projecting
E on I, and projecting it on J (we do not consider isolated
nodes). If we modify the ﬁrst equation in the interpretation
Q to be:

C := repair-key@P

(cid:161)
ρI (πJ (repair-keyI@P (C (cid:46)(cid:47) E))) × ρP ({1 − α})

(cid:162)
∪ πI (repair-keyI@P (V )) × ρP ({α})

then we compute the PageRank at node v where α is the
usual dampening factor, i.e., the probability that we aban-
don our current walk and jump uniformly to an arbitrary
node in the graph.

Forever-queries over Probabilistic Databases. Above,
query evaluation was deﬁned for the case where the input
database is a standard relational database. In some cases
it is useful to consider probabilistic databases as input, e.g.,
given as a collection of probabilistic c-tables. As mentioned
above, we can view such a pc-table as a macro for the corre-
sponding algebraic expression that uses the repair-key con-
struct. (To observe that this is possible see e.g. [16].) In
particular, under the non-inﬂationary semantics, when such
macros appear in the transition kernel, the probabilistic
choices of tuples in the pc-table are made in each iteration.
We will see examples for this in Section 5.

3.2

Inﬂationary queries

Inﬂationary queries are deﬁned as the counterpart of the
while+ queries [1]. Intuitively, with inﬂationary queries, as-
signment of the new database state is cumulative rather than
destructive: the query results are added to the current rela-
tions of the tuple, instead of replacing them as in the non-
inﬂationary case. Formally, inﬂationary queries are deﬁned
as the following fragment of the noninﬂationary ones:

Definition 3.4. A forever-query (Q, e) is called an in-
ﬂationary query if for any relational database A and any
possible world B of Q(A), B ⊇ A.

We can deﬁne inﬂationary queries through transition ker-
nels that deﬁne the new state as the union of the old state
with the result of a query on the old state.

Example 3.5

(Reachability in a Graph). We con-
sider the same input database as in Example 3.3, where
E(I, J, P ) is a ternary relation standing for the edge rela-
tion and C is an unary relation, initially consisting of a sin-
gle tuple a, standing for the start node of the walk. Now,

we express the query asking for the probability that node
v is eventually reached in a random walk starting from the
given start node of the walk. These nodes will be stored
in C. We further use an additional auxiliary relation Cold,
initially empty. In the inﬂationary language, Q is deﬁned by
the following probabilistic ﬁrst-order interpretation:

Cold

:= C

C := C ∪ ρI πJ (repair-keyI@P (C − Cold) (cid:46)(cid:47) E)
E := E

% unchanged.

The query event is v ∈ C.

Note that the value of the Cold relation used in the sec-
ond line is not the Cold value written in the ﬁrst line, but its
previous version. This is due to the semantics of query eval-
uation: at each point we ﬁre all rules “in parallel”, namely
all righthand side expressions are evaluated against the old
database state; only then the actual update takes place. (cid:50)

There is a subtlety here that does not arise in non-probabilistic

inﬂationary ﬁxpoint queries: we have to be careful about the
re-use of the same tuple multiple times, to generate new tu-
ples. We illustrate this next.

Example 3.6. Re-consider Example 3.3, and assume now
that E = {(a, b, 0.5), (a, c, 0.5)}. Now Pr[b ∈ C] = 0.5.
However, if we replace the update rule for C by

C := C ∪ ρI (πJ (repair-keyI@P (C (cid:46)(cid:47) E))),

then we forever try to add, for each node in C, one node
reachable from it via a single edge. Suppose C = {a, c}.
Then we can either add b or c (which is already in C, so we
add nothing) as successor of a. We may forever choose c as
successor of a; but, the probability of this world goes to 0 as
we continue iterating. In all other worlds, eventually b ∈ R.
Thus Pr[b ∈ C] = 1.
(cid:50)

The example demonstrates a general property:

if we do
not restrict the re-use of tuples for the generation of new
tuples, then all tuples that appear in the result of the query
without repair-key, appear in the query result with prob-
ability 1. The example also demonstrates that there are
computation paths in which we do not reach a ﬁxpoint in a
ﬁnite number of steps (but the probability of each such path
approaches 0).

Evaluating inﬂationary queries over Probabilistic
Databases. We have explained above (see bottom of Sec-
tion 3.1) that pc-tables are in fact only macros and may be
simulated via rules containing a repair-key. Consequently,
when such pc-tables (macros) appear in an inﬂationary query
the semantics is diﬀerent than in the case of non-inﬂationary
queries: the probabilistic choices of tuples from the pc-tables
now take place only once, at the beginning of query evalu-
ation, rather than being repeatedly made as for the non-
inﬂationary semantics. This is because, with inﬂationary
semantics, rules ﬁre only when there is a new valuations to
the rules right-hand side; since pc-tables are implemented as
repair-key application over ground facts, no such new valu-
ation occurs during query evaluation.

3.3 Probabilistic Datalog with probabilistic rules

Probabilistic datalog syntactically extends datalog [1] by
a repair-key construct. We use the following notation for

219the repair-key construct. In a rule head, the key columns
are underlined, and the head is optionally postﬁxed by @P ,
where P is the Datalog variable binding to the repair-key
weighting column (if omitted, the weighting is uniform, like
for the repair-key algebra operator).

Example 3.7. Consider a relation I with schema

R(A, B, C, D, E). The rule

H(X, Y , Z)@P ← R(X, Y, Z, P, W )

corresponds to πABC (repair-keyAB@D(πABCDR)) in relational
algebra extended by repair-key.

(cid:50)

Recall that each (standard) datalog rule can be compiled
to an expression in relational algebra that computes the rule
head [1]. For non-inﬂationary queries, given a probabilistic
datalog query, deﬁned by a probabilistic datalog program
Q and a query event e, we may use the same translation
mechanisms (with the addition of the @ operation, trans-
lated into the repair-key construct), to translate (Q, e) into
an equivalent non-inﬂationary query (as deﬁned in Def. 3.2).
Under inﬂationary semantics, it is easy to observe that if at
every step all possible valuations for the rule body are used
for application of repair-key, then every probabilistic dat-
alog program is equivalent to a conventional datalog pro-
gram without repair-key, as all tuples that may appear in
the output appear with probability 1 (see Example 3.6). We
thus deﬁne the inﬂationary semantics of probabilistic data-
log queries as follows.

Repeat forever
{

In parallel, for each rule r:

R( (cid:126)X, (cid:126)Y )@P ← B( (cid:126)X, (cid:126)Y , (cid:126)Z) do

newVals[r] := valuations of the body of r on

the old database state − oldVals[r];

oldVals[r] := oldVals[r] ∪ newVals[r];
R := R

repair key (cid:126)X@P (π (cid:126)X,(cid:126)Y ,P (newVals[r]));

(cid:83)

{

}

}

We recall that in datalog, the term IDB relation stands for
a derived relation, and an EDB relation is an input relation.
The above computation is applied over an initial database,
where the EDB relations contain the data, the IDB rela-
tions are empty, and for each rule r (where B stands for the
body of R), there are two auxiliary relations newVals[r] and
oldVals[r] that are initially empty. If the body of a rule is
empty, the single valuation of the body is the empty valua-
tion and the rule thus ﬁres only once, in the ﬁrst iteration.
A probabilistic Datalog query must reach a ﬁxpoint in
each possible computation path since there are only polyno-
mially many possible tuples over the active domain of the ini-
tial state. A rule in which all head variables are underlined
is essentially non-probabilistic: it deterministically adds all
the tuples that a classical Datalog rule would add.

Also note the similarly to the above explanations for the
inﬂationary semantics, when a probabilistic Datalog query
is evaluated over a pc-table, the pc-table may ﬁrst be simu-
lated by Datalog rules; these rules are ﬁred only once since
the bodies of these rules correspond to ground facts and
thus have no new valuations throughout the iteration (if

non-inﬂationary semantics is used, then the random choices
for the pc-table are made in each iteration).

It is not hard to show the following proposition.

Proposition 3.8. For every probabilistic datalog program,

there is an equivalent inﬂationary query.

We next express the reachability query (Example 3.5) in

probabilistic datalog.

Example 3.9

(Reachability in a graph revisited).
The query that computes Reachability of graph nodes from
a start node v (see Example 3.5) can be expressed in prob-
abilistic datalog simply as

C(v) ←

C2(X, Y ) ← C(X), E(X, Y ).

C(Y ) ← C2(X, Y ).

Consider the evaluation of the above query over an initial
database E = {(v, w, 0.5), (v, u, 0.5)}. It ﬁrst adds the tuple
v to C, as the (empty) valuation for the body of the ﬁrst
rule was not used yet. Then, there exist two new valuations,
{X = v, Y = w} and {X = v, Y = u} one of which is
chosen (with probability of 0.5 for each choice). Let W be
the world (bearing a probability of 0.5) where X = v, Y =
w (respectively, X = v, Y = u) was chosen. Now X =
v, Y = u (respectively, X = v, Y = w) is no longer a new
valuation (because it was a valid valuation in the previous
iteration as well), and then the third rule must ﬁre, leading
to the addition of the tuple u (w) to C in this world. Note
that the use of C2 is essential to enforce the application
of repair-key over each of the nodes appearing currently in
C, modeling the probabilistic choice of the next nodes. If
we would only write C(y) ← C(x), E(x, y), no probabilistic
choice of valuations of the body were made.
Instead, all
(cid:50)
valuations would be used as in classical datalog.

We next consider a more complicated example, namely
computation of marginal distributions for a given Bayesian
Network.

Example 3.10

(Bayesian Network). In this exam-
ple, we construct the joint distribution over a number of
Boolean random variables as deﬁned by a Bayesian Net-
work. We use probabilistic Datalog with repair-key. For
simplicity, we assume that there is an upper bound K on
the in-degree of each node in the Bayesian network, i.e., the
number of parent variables of each random variable. The in-
put database consists of two input relations that specify the
Bayesian network, a relation with schema Sk(N0, . . . , Nk)
which speciﬁes that the random variable named N0 has ex-
actly the parents N1, . . . , Nk and a relation with schema
Tk(N0, V0, V1, . . . , Vk, P ) that speciﬁes the tuples of the con-
ditional probability tables. That is, if the parent variables
of X are called Y1, . . . , Yk (i.e., (X, Y1, . . . , Yk) ∈ Sk) and
if tuple (X, x, y1, . . . , yk, p) is in Tk, where X is the name
of a random variable, x, y1, . . . , yk ∈ {0, 1} are the val-
ues of random variables X, Y1, . . . , Yk, and p ∈ [0, 1], then
Pr[X = x | Y1 = y1, . . . , Yk = yk] = p.

There is a single IDB predicate V (N, V ) which speciﬁes
a complete valuation of each random variable N in each
possible world.

220The probabilistic datalog program consists of K + 1 rules

Program. We deﬁne the following program Q:

(for 0 ≤ k ≤ K):

V (N0, V0)@P ← Tk(N0, V0, V1, . . . , Vk, P ),

Sk(N0, N1, . . . , Nk),
V (N1, V1), . . . , V (Nk, Vk).

Now, marginal probabilities such as Pr[X = x ∧ Y = y]

can be computed as the probability of event q if rule

q ← V (X, x), V (Y, y).

is added to the datalog program. Here X, x, Y, y are con-
stants, not datalog variables.

In the remainder of the paper, we will consider both inﬂa-
tionary and non-inﬂationary datalog. We also study datalog
restricted in one or both of the following ways: datalog with-
out repair-key applied over probabilistic c-tables, and linear
datalog, which is datalog in which each rule body contains
at most one IDB atom.

4. COMPLEXITY OF THE INFLATIONARY

LANGUAGES

We next discuss the complexity of query evaluation with
respect to the inﬂationary semantics.
It is easy to show
(following e.g. [20]) that exact query evaluation (i.e., asking
whether the probability of the given query event is exactly
p) is (cid:93)P -hard. We thus turn to approximations, and ﬁrst
consider relative approximation. Unfortunately we can show
that such approximation is infeasible as well, as the following
theorem holds.

Theorem 4.1. Unless P = N P (BP P = N P ), there ex-
ists no PTIME deterministic (randomized) relative approx-
imation scheme for the query evaluation under the inﬂa-
tionary semantics. This holds even if (1) the problem is
restricted to evaluation of Linear Datalog Programs and (2)
either repair-key is applied only on base relations, or (2’) the
queries are without repair key and applied over probabilistic
c-tables.

Proof. We prove the theorem for the case where condi-
tions (1) and (2’) above hold; the proof for the case where
(1) and (2) hold follows, as discussed below.

We use a reduction from 3-SAT. Given a 3-CNF formula
F consisting of clauses {c1, ..., cm} over a set {v1, ..., vn} of
variables, we construct a database D and a Datalog program
Q as follows.

Database. The database D consists of the following EDB
relations: C(C, L), O(C1, C2), A(L), and R(C), and its tu-
ples are initialized as follows. A(L) is a probabilistic c-table,
where tuples stand for all variables in V and their negation;
each tuple in A is associated with a predicate such that A(vi)
is associated with xi = 0, A(¬vi) is associated with xi = 1
for each variable vi ∈ V , with P r(xi = 0) = P r(xi = 1) =
0.5 for each i, and all xi variables are independent. The re-
lation O contains a tuple O(ci, ci+1) for each i = 1, ..., m −1,
and the relation C contains a tuple C(ci, lj) for each clause
ci and a literal lj that appears in ci.

R(c0) ←
R(c) ← R(c(cid:48)), O(c(cid:48), c), C(c, l), A(l)

Done(a) ← R(cn)

We next show that existence of PTIME relative approxi-
mation algorithms (deterministic and randomized) for eval-
uating (Q, a ∈ Done) over D implies a PTIME algorithm for
deciding whether F has a satisfying assignment. We start
with the following lemma:

Lemma 4.2. Denote by p the query result of (Q, a ∈ Done)
2n where n is the num-

over D. If F is satisﬁable, then p ≥ 1
ber of variables in F . Otherwise, p = 0.

Proof. Consider a probabilistic choice for the tuples of
A. Such choice must correspond to a consistent assignment,
as for each variable vi exactly one out of A(vi) and A(¬vi)
holds.

Assume now that F has no satisfying assignment. Thus,
for each probabilistic choice for the tuples of A, there exists
some ci ∈ C such that for all values of l, C(ci, l), A(l) does
not hold. Thus the rule for R(ci) will not ﬁre, and conse-
quently R(ci+1), ..., R(cn) will not appear in the database as
well, and neither will Done(a). This holds for all probabilis-
tic choices, thus p = 0.

Conversely, assume that F has at least one satisfying as-
signment, then there exists a choice for the tuples of A corre-
sponding to this assignment, and this choice bears the prob-
ability of 1
2n . For such choice, in the i-th step of evaluating
Q, R(ci) holds; to observe this, note that at the ﬁrst step
R(c0) holds, and assume that at the (i − 1)-th step R(ci−1)
holds. O(ci−1, ci) holds by the DB initialization, as well as
C(ci, l), A(l) for some literal l that satisﬁes ci (note that
the assignment is satisfying, thus such l must exist), thus in
at the i’th step R(ci) holds. Consequently, at the n’th step
R(cn) holds, thus Done(a) holds in the next step. This hap-
pens for each choice of tuples corresponding to a satisfying
assignment; each such satisfying assignment is chosen with
probability 1

2n , thus we obtain p ≥ 1
2n .

We next use Lemma 4.2 to prove Theorem 4.1. We note
that the proof is rather straightforward following Chernoﬀ’s
lower bound, but we repeat it for completeness. First, as-
sume the existence of a deterministic query evaluation algo-
rithm with relative error (cid:178), then we simply apply it and con-
clude that F is satisﬁable if and only if the algorithm’s out-
put was non-zero. For the second part of the Theorem, as-
sume that we have a randomized query evaluation algorithm
A; then we run it N times independently, and decide that
F is unsatisﬁable if the majority of the executions return 0.
We next show that the construction yields a BPP algorithm
for 3-SAT. We say that an invocation of A “succeeds” if it
returns 0 and the formula F is indeed not satisﬁable, or if it
returns a number other than 0 and F is indeed satisﬁable.
There exists a δ such that each invocation of A succeeds
with probability of at least 1 − δ, and fails with probabil-
ity of at most δ. Deﬁne Xi to be a binary random variable
that represents success or failure of the i’th invocation of A,
and let X = X1 + ... + XN . We next bound the probabil-
ity that X < N
2 . Since the invocations are independent, X
bears a binomial distribution, E(X) = N ∗ (1 − δ), and by
Chernoﬀ’s Lower bound P (X < k ∗ E(x)) < e−E(x)∗ (1−k)2

.

2

221(1− N

2∗E(x)

)2

2∗E(x) = 1 −

2 ) < e−E(x)∗

2∗E(x) to obtain P (X < N

Set k = N
.
1 − N
2∗(1−δ) , and denote this fraction by β. β
is positive as 1 − δ > 0.5. The bound now translates into
e−E(x)∗ β2
2 . To achieve any error bound Γ,
we simply set N such that −N ∗ (1 − δ) ∗ β2 < 2 ∗ lnΓ, i.e.

2 = e−N ∗(1−δ) β2

1

2

N >

ln 1
Γ2

(1−δ)∗β2 .

We have proven Theorem 4.1 for the case where conditions
(1) and (2’) speciﬁed in the Theorem hold. We next show
that the Theorem also holds for the case where (1) and (2)
holds: in this case, we change our construction by replacing
the c-table A by a similar table A(V, L, P ), whose tuples
are A(i, vi, 0.5), A(i, ¬vi, 0.5) for each i; using repair-key we
then choose a single such tuple for each i, and proceed as
above.

However, we may show that randomized absolute approx-

imation may be achieved in PTIME.

Theorem 4.3. Randomized absolute approximation is in
PTIME (data complexity) for the inﬂationary ﬁxpoint lan-
guage with repair-key, even when applied on probabilistic c-
tables.

Proof Sketch. We employ a sampling algorithm that for
every given (cid:178), δ, approximates the query result up to (cid:178) with
probability of at least δ, as follows. Each sample is done
by randomly choosing a single value for each independent
variable in the c-table according to its probability; then,
we consecutively apply the query rules, making probabilis-
tic choices for each application of the repair-key construct
that appear within these rules (i.e. we sample a possible
repair, according to its probability dictated by the current
database status and the repair-key operation), until reaching
a ﬁxpoint. At the end of each sample, we check for satisfac-
tion and declare the probability p to be the average number
of satisfactions over all samples.

Each such sample can be done in PTIME (data complex-
ity), as the applications sequence entails the same number of
steps as evaluation of non-probabilistic Datalog (with a lin-
ear time overhead incurred by the random choices of values
for the independent variables).

To bound the number of samples required for an (cid:178), δ-
approximation we use the Chernoﬀ bound. Denoting by
x the random boolean variable whose value indicates query
satisfaction or dissatisfaction, the output p of our algorithm
is the average of m samples of x. Denote by ˆp the correct
probability of x (the query probability), the (additive) Cher-
noﬀ bound gives P r(| p − ˆp |≥ (cid:178)) ≤ 2 ∗ e−2∗(cid:178)2∗m where m is
the number of samples. So choosing m s.t. −2∗(cid:178)2∗m ≤ ln(δ)
,

ln( 1
δ )
i.e. m ≥
4∗(cid:178)2 samples is suﬃcient. The overall complexity
is thus polynomial in the database size and in (cid:178), and loga-
rithmic in 1
(cid:50)
δ .

2

To complete the picture, we may exactly evaluate inﬂa-
tionary ﬁxpoint queries in PSPACE. (Recall that exact eval-
uation of even simple select-project-join queries over Prob-
abilistic Databases [20], and consequently of queries with
repair-key, even without recursion, is (cid:93)P − hard [16].)

Proposition 4.4. Exact evaluation of inﬂationary ﬁxpoint

queries with the repair-key construct (even over probabilistic
c-tables) is in PSPACE.

Proof Sketch. Consider the following algorithm for com-
puting the probability that a given tuple is in the ﬁxpoint of
a probabilistic datalog query with the repair-key construct.
We iterate through possible worlds of the input probabilis-
tic database (speciﬁed by a probabilistic c-table; to iterate
through the possible worlds we only need to iterate through
the valuations of the independent random variables, which
is easy to do in PSPACE).

For each possible world we iteratively evaluate the query.
In each iteration, the program may choose one out of (expo-
nentially) many increments to the database state. However,
due to the independence of choice across key valuations and
rules, we can iterate through these alternatives using only
a polynomial amount of memory. Thus we can make a full
traversal through the tree of possible computations down to
all the ﬁxpoints. This tree has exponentially many nodes,
but its depth is bounded by the number of tuples a ﬁxpoint
can consist of at most, which is polynomial in the active do-
main of the input database. We only have to store at most
a path in this computation tree from the root to a ﬁxpoint,
i.e., polynomially many databases.

The result probability is initially zero. While we traverse
this tree, whenever we reach a leaf (a ﬁxpoint), we test the
query event and, if it is true on that ﬁxpoint, add its prob-
ability weight to the result probability.
(cid:50)

5. COMPLEXITY OF THE

NON-INFLATIONARY LANGUAGE

We next consider the evaluation of non-inﬂationary que-
ries. We have shown in the previous section that, for inﬂa-
tionary queries, exact computation is (cid:93)P -hard with respect
to data complexity and that unless P = N P , a PTIME rel-
ative approximation is also impossible. From this, it follows
that the same is true for noninﬂationary queries, of which
inﬂationary queries are a special case. As for absolute ap-
proximation, we have shown above that such approxima-
tion is feasible for the inﬂationary semantics; unfortunately,
we may show that this is not the case for non-inﬂationary
queries, as the following theorem holds.

Theorem 5.1. Unless P = N P (BP P = N P ), there
is no PTIME deterministic (randomized) absolute approxi-
mation for non-inﬂationary queries. This holds even if (1)
the problem is restricted to evaluation of Datalog programs
and (2) either repair-key is applied only on base relations,
or (2’) the queries are without repair key and applied over
probabilistic c-tables.

Proof Sketch. Similarly to the proof of Theorem 4.1, we
use here a reduction from 3-SAT, but this time use the ex-
pressive power of non-inﬂationary queries to show that even
an absolute approximation is impossible. Again, we prove
the theorem for the case where conditions (1) and (2’) above
hold; the proof for the case where (1) and (2) hold follows
in exactly the same manner as explained for Theorem 4.1.
Similarly, we show the proof for the deterministic case; the
proof for the randomized case again follows that of Theorem
4.1.

Recall ﬁrst that under non-inﬂationary semantics, tuples

from pc-tables are repeatedly sampled, in each iteration.

Given a 3-CNF formula F consisting of clauses {c1, ..., cm}
over a set {v1, ..., vn} of variables, we construct a database
and a Datalog program as follows.

222Database. D consists of the following relations: C(C, L),
O(C1, C2), A(L), and R(C, X), and initialize its tuples as
follows. As in the proof of Theorem 4.1, A(L) is a prob-
abilistic c-table where tuples stand for all variables in V
and their negation; each tuple in A is associated with a
predicate such that A(vi) is associated with xi = 0, A(¬vi)
is associated with xi = 1 for each variable vi ∈ V , with
P r(xi = 0) = P r(xi = 1) = 0.5 for each i, and all xi vari-
ables are independent.

O(C1, C2) bears a tuple O(ci, ci+1) for each i = 1, ..., m−1;
and C(C, L) bears a tuple C(ci, lj) for each clause ci and a
literal lj that appears in ci.

Program. Consider the following program Q:

R(c0, l) ← A(l)
R(ck, l) ← R(ck−1, l), R(ck−1, l(cid:48)), O(ck−1, ck), C(ck, l(cid:48))
Done(a) ← R(cn, .)
Done(x) ← Done(x)

We employ an approximation algorithm for estimating the
probability of (Q, a ∈ Done) over D up to an absolute error
of 0.5 , and output that F is satisﬁable if and only if the re-
sult is greater than 0.5. The correctness of the construction
follows from the next lemma:

Lemma 5.2. Denote by p the result of evaluating (Q, a ∈
Done) over D. It holds that p = 1 if F is satisﬁable, and
p = 0 otherwise.

Proof Sketch. For each probabilistic choice of tuples for
A, the set of literals {l | R(c0, l)} corresponds to a randomly
chosen assignment α, to the variables {v1, ..., vn} (note that
for each variable x, a single literal out of x and ¬x is chosen
randomly). In what follows we relate to a set of literals α
(without contradictions, i.e., α does not include both a vari-
able and its negation) as an assignment, and say that such a
set α(cid:48) is consistent with α if the set of literals corresponding
to α(cid:48) is a subset of those corresponding to α.

We then use the following auxiliary proposition (proved

by induction on i).

Proposition 5.3. In the i-th iteration of evaluating Q
over D, {l | R(ci, l)} corresponds to an assignment α(cid:48) con-
sistent with α and satisfying c1, ..., ci, if such exists; if none
exists, R(ci, l) does not hold for any l.

It follows from Proposition 5.3 that after the n-th iter-
ation, {l | R(cn, l)} is non-empty iﬀ there is a satisfying
assignment consistent with the initial α, for c1, ..., cn, i.e.
for F . Then, in the (n + 2)-th iteration, Done(a) holds; the
last rule of the program guarantees that from this point on,
Done(a) remains in the database forever.

As the set of possible instantiations of the repair-key corre-
sponds to all possible consistent assignments, it follows that
if a satisfying assignment α exists, it will be generated by
repair-key at some step k of the evaluation; after additional
n + 2 iterations, as explained above, a ∈ Done holds. Thus
in all iterations from k +n+2 and on, a ∈ Done holds, hence
P r(a ∈ Done) = 1 if F is satisﬁable; conversely, if there is
no satisfying assignment then P r(a ∈ Done) = 0.

This completes the proof of Lemma 5.2.

(cid:50)

Thus, the existence of a PTIME (BPP) absolute approx-
imation algorithm, with (cid:178) < 0.5, provides a PTIME algo-

rithm for 3-SAT (F is satisﬁable iﬀ the algorithm returned
p > 0.5), and implies P = N P (BP P = N P ).
(cid:50)

However, we may show that under some restrictions on
the transition kernel of the query, an EXPTIME exact eval-
uation of non-inﬂationary queries is possible.

Proposition 5.4. Let q = (Q, e) and let D be the input
database, such that the Markov Chain of database instances,
deﬁned by Q, D, is irreducible and positively recurrent. Ex-
act evaluation of q over D is in EXPTIME.

Proof Sketch. There are polynomially many possible tu-
ples over the active domain of the input database and thus
only exponentially many states in the Markov chain deﬁned
by Q. Thus we can compute the stochastic matrix deﬁning
the transition relation of this Markov chain in EXPTIME by
evaluating Q on each of the states. For each state, we com-
pute a representation of the result of Q on that state as a
probabilistic c-table. This is feasible in polynomial time per
state. Then we extract the reachable states and their prob-
ability weights from this representation, yielding the matrix
of the Markov chain. Next we run Gaussian elimination
on this matrix to compute the principal eigenvector. This
is feasible in cubic time in the size of the matrix. Finally,
we sum up the weights in the eigenvector of those database
states on which the query event is true. This is the query
result. It is easy to see that this result can be computed in
exponential time overall.
(cid:50)

We may further generalize our query evaluation algorithm,

and obtain

Proof. We denote by M the Markov Chain induced by
the transition kernel and the input database, and consider
two cases. If M consists of a single strongly connected com-
ponent, then it is irreducible and positively recurrent [10],
and we may apply the same construction as in Proposi-
tion 5.4 to compute the probability of query satisfaction.
Otherwise, we can compute the DAG of its strongly con-
nected components. With probability 1, a random walk will
eventually (after a ﬁnite number of steps) get to a compo-
nent that is one of the leaves of this DAG and stay there
forever. We can thus compute probabilities of getting to
each of these leaves (by considering all paths that lead to
each such leaf). This computation may be exponential in
the size of the DAG, which in turn may be exponential in
the database size, leading to the 2-EXPTIME complexity.
Then we can perform Gaussian elimination on each of the
connected components that reside in the leaves, and com-
pute the probability of being at each individual node. This
probability is factorized by the probability of getting to the
connected component.

It is open if a lower complexity (e.g. EXPTIME) is pos-

sible in the general case.

5.1

Improving Performance

We next present two simple ideas that do not improve
the worst case complexity of non-inﬂationary query evalua-
tion in general but may improve its performance in real-life

Theorem 5.5. The exact evaluation problem for non-inﬂationary

queries is in 2-EXPTIME.

223cases. First, we consider the partitioning of query evalua-
tion into smaller instances that may be solved independently
using the techniques suggested above. Second, we consider
a diﬀerent technique for query evaluation that is based on
sampling.

Partitioning. In many real-life cases of large programs, many
derived tuples are “independent”, in the sense that the deriva-
tion of one tuple does not change the probability of deriving
another. We thus employ a pre-processing stage, as follows:
we start with the original database and set a unique identi-
ﬁer to each tuple, which is a singleton set. Then we evaluate
all rules in an inﬂationary manner (as in “regular” data-
log on non-probabilistic databases), keeping provenance for
each added tuple. That is, whenever a tuple is added to the
database due to an application over tuples with identiﬁers
I1, ..., Ik, the new tuple is set the identiﬁer I1
Ik.
At the end of the process, the sets of all identiﬁers that ap-
pear in the database and are not subsumed by any other
identiﬁer are the partition classes.

I2....

(cid:83)

(cid:83)

We now partition the database into tuple sets according to
the classes obtained above, and consider the Markov Chain
induced by each, as in Theorem 5.5 above. We indepen-
dently ﬁnd the probability of each state within it, and sum
up the probabilities of being at states where the query does
not hold. Last, the overall probability p that the query does
not hold is the multiplication of such probabilities over all
classes, and the query satisfaction probability is 1 − p.

Sampling. We have shown above that approximating query
results for non-inﬂationary queries is (cid:93)P -hard in general.
However, in some cases an approximation may be obtained
by sampling the possible worlds and computing their proba-
bility as the observed percentage of query satisfaction. The
diﬃculty lies in obtaining independent samples. To that
end, recall from Section 2 the deﬁnition of mixing time of a
Markov Chain. Given a non-inﬂationary query q = (Q, e)
and a database instance D, such that Q and D induce an er-
godic Markov Chain M , denote by T (q, D) the mixing time
of M . We can then prove the following proposition.

Theorem 5.6. A randomized absolute approximation al-
gorithm for evaluation of a non-inﬂationary q over D, such
that Q and D induce an ergodic Markov Chain, may be done
in Polynomial Time in the size of D and in T (q, D) (and
exponential in the size of q).

Proof Sketch. The algorithm generates independent sam-
ples as follows.
It applies the transition kernel Q step by
step, each time computing intermediate probabilities for query
results up until convergence. The number of steps required
for convergence is T (q, D). When convergence is achieved,
we omit all computed probabilities and start the actual sam-
pling; we re-start to obtain further samples. Once we have
independent samples in hand, the proof continues as in Propo-
sition 4.3.

(cid:50)

There are several techniques studied in the literature (e.g.,
conductance and coupling [19]) for characterizing Markov
Chains with mixing time that is polynomial in the number
of states of the chain. In such cases, approximated query
evaluation may be performed in PTIME. Identifying syntac-
tic restrictions on probabilistic Datalog that are the coun-
terparts of such characterizations is an intriguing topic of
future research.

6. CONCLUSION AND RELATED WORK

We conclude with a brief overview of related work.
Probabilistic Databases, in various ﬂavors, were studied
extensively (e.g.
[20, 13, 2, 21]). The probabilities there
are given as part of the database; [16] suggests a general-
ized model where randomization may be introduced as part
of the query, via the use of the repair-key construct, and
shows that a PTIME approximation is possible for (the pos-
itive fragment of) the query language studied. In contrast
to our work, the query language studied in [16] does not al-
low recursion, and is thus less expressive. In particular, it
cannot express probabilistic processes of unbounded length
(e.g. random walks) studied here.

A (restricted) use of Datalog over probabilistic input data
was studied in [11], as a tool for Information Retrieval ap-
plications. The setting studied in [11] allows to introduce
probabilities only over the ground facts, and consequently
the choice of “possible world” is in fact performed once, to
choose the set of ground facts. Consequently, the model is
less expressive than proposed here, where new worlds may be
generated arbitrarily many times. In particular, the model
of [11] does not allow to capture random walks in-between
database instances, and their applications depicted above.
Similarly, a restrictive probabilistic version of Prolog [9] al-
lows to specify, for each rule, the probability that it belongs
to a randomly sampled program. But again, the semantics
is that a program is sampled only once.

We have studied here highly expressive query languages
with an iteration construct that allow to perform probabilis-
tic changes to the database (state). We have illustrated how
these query languages may be used to declaratively spec-
ify random walks over complex Markov Chains, and other
stochastic processes, and studied the complexity of query
evaluation for the proposed query languages. Future work
includes the design of generic optimization techniques for
query evaluation, the study of restricted versions with lower
complexity of query evaluation, and speciﬁcally syntactic
counterparts of cases that allow for eﬃcient sampling algo-
rithms.

7. REFERENCES
[1] S. Abiteboul, R. Hull, and V. Vianu. Foundations of

Databases. Addison-Wesley, 1995.

[2] P. Agrawal, O. Benjelloun, A. Das Sarma,

C. Hayworth, S. U. Nabar, T. Sugihara, and
J. Widom. “Trio: A System for Data, Uncertainty, and
Lineage”. In VLDB, 2006.

[3] L. Antova, C. Koch, and D. Olteanu. “From Complete

to Incomplete Information and Back”. In Proc.
SIGMOD, 2007.

[4] L. Antova, C. Koch, and D. Olteanu. “Query

Language Support for Incomplete Information in the
MayBMS System”. In Proc. VLDB, 2007.

[5] V. Bansal. “Computational Methods for Analyzing

Human Genetic Variations”. PhD thesis, University of
California, San Diego, 2009.

[6] O. Benjelloun, A. D. Sarma, C. Hayworth, and

J. Widom. “An Introduction to ULDBs and the Trio
System”. IEEE Data Engineering Bulletin, 2006.

[7] D. P. Bertsekas and J. N. Tsitsiklis. Introduction to

Probability. MIT Press, 2008.

[8] N. Dalvi and D. Suciu. “Eﬃcient query evaluation on

224probabilistic databases”. VLDB Journal,
16(4):523–544, 2007.

[9] L. De Raedt, A. Kimmig, and H. Toivonen. “ProbLog:

A Probabilistic Prolog and Its Application in Link
Discovery”. In IJCAI, 2007.

[10] D. Freedman. Markov Chains. Springer-Verlag, 1983.
[11] N. Fuhr. “Probabilistic Datalog – A Logic For

[17] C. Koch. “A Compositional Query Algebra for

Second-Order Logic and Uncertain Databases”. In
Proc. ICDT, 2009.

[18] C. H. Papadimitriou. Computational complexity.

[19] D. Randall. “Mixing (a tutorial on Markov Chains)”.

Addison-Wesley, 1994.

In FOCS, 2003.

Powerful Retrieval Methods”. In Proc. SIGIR, pages
282–290, 1995.

[20] C. Re, N. Dalvi, and D. Suciu. “Eﬃcient Top-k Query

Evaluation on Probabilistic Data”. In ICDE, 2007.

[12] M. Goetz and C. Koch. “A Compositional Framework

[21] P. Sen and A. Deshpande. “Representing and

for Complex Queries over Uncertain Data”. In Proc.
ICDT, 2009.

Querying Correlated Tuples in Probabilistic
Databases”. In ICDE, 2007.

[13] T. J. Green and V. Tannen. “Models for Incomplete

[22] D. Sorensen and D. Gianola. “Likelihood, Bayesian,

and Probabilistic Information”. IEEE Data Eng. Bull.,
29(1):17–24, 2006.

and MCMC Methods in Quantitative Genetics”.
Springer-Verlag, New York, July 2002.

[14] M. Jerrum and A. Sinclair. “The Markov chain Monte
Carlo method: an approach to approximate counting
and integration”. Approximation algorithms for
NP-hard problems, 1997.

[15] C. Koch. “Approximating Predicates and Expressive
Queries on Probabilistic Databases”. In Proc. PODS,
2008.

[16] C. Koch. “On Query Algebras for Probabilistic

Databases”. SIGMOD Record, 37(4):78–85, 2008.

[23] Stanford Trio Project. “TriQL – The Trio Query

Language”, 2006.

[24] L. Valiant. “The complexity of computing the

permanent”. Theoretical Computer Science,
8(2):189–201, 1979.

[25] M. Y. Vardi. “The Complexity of Relational Query
Languages”. In Proc. STOC, pages 137–146, 1982.

[26] V. V. Vazirani. Approximation Algorithms. Springer,

2004.

225