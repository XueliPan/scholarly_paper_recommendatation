 

An Ontology-Based Information Retrieval Model 

David Vallet, Miriam Fernández, and Pablo Castells 

Campus de Cantoblanco, c/ Tomás y Valiente 11, 28049 Madrid 

{david.vallet, miriam.fernandez, pablo.castells}@uam.es 

Universidad Autónoma de Madrid 

Abstract.  Semantic  search  has  been  one  of  the  motivations  of  the  Semantic 
Web since it was envisioned. We propose a model for the exploitation of ontol-
ogy-based  KBs  to  improve  search  over  large  document  repositories.  Our  ap-
proach includes an ontology-based scheme for the semi-automatic annotation of 
documents, and a retrieval system.  The retrieval  model is based on an adapta-
tion of the classic vector-space model, including an annotation weighting algo-
rithm,  and  a  ranking  algorithm.  Semantic  search  is  combined  with  keyword-
based search to achieve tolerance to KB incompleteness. Our proposal is illus-
trated  with  sample  experiments  showing  improvements  with  respect  to  key-
word-based search, and providing ground for further research and discussion. 

1   Introduction 

The use of ontologies to overcome the limitations of keyword-based search has been 
put forward as one of the motivations of the Semantic Web since its emergence in the 
late 90’s. While there have been contributions in this direction in the last few years, 
most achievements  so  far either  make partial  use of the full expressive power of an 
ontology-based  knowledge representation, or are based on  boolean retrieval  models, 
and  therefore  lack  an  appropriate  ranking  model  needed  for  scaling  up  to  massive 
information sources.  

In the former case, ontologies provide a shallow representation of the information 
space, equivalent in essence to the taxonomies and thesauri used before the Semantic 
Web  was  envisioned  [ 3, 6, 7, 15].  Rather  than  an  instrument  for  building  knowledge 
bases, these light-weight ontologies provide controlled vocabularies for the classifica-
tion  of  content,  and  rarely  surpass  several  KBs  in  size.  This  approach  has  brought 
improvements over classic keyword-based search through e.g. query expansion based 
on class hierarchies and rules on relationships, or multifaceted searching and brows-
ing. It is not clear though that these techniques alone really take advantage of the full 
potential of an ontological language, beyond those that could be reduced to conven-
tional classification schemes. 

Other semantic search techniques have been developed that do exploit large knowl-
edge bases in the order of GBs or TBs consisting of thousands of ontology instances, 
classes  and  relations  of  arbitrary  complexity  [ 1, 2, 4, 12].  These  techniques  typically 
use  boolean  search  models,  based  on  an  ideal  view  of  the  information  space  as 

A. Gómez-Pérez and J. Euzenat (Eds.): ESWC 2005, LNCS 3532, pp. 455–470, 2005. 
© Springer-Verlag Berlin Heidelberg 2005 

456 

D. Vallet, M. Fernández, and P. Castells 

 consisting of  non-ambiguous,  non-redundant, formal  pieces  of  ontological  knowl-
edge.  In  this  view,  the  information  retrieval  problem  is  reduced  to  a  data  retrieval 
task. A knowledge item is either a correct or an incorrect answer to a given informa-
tion request, thus search results are assumed to be always 100% precise, and there is 
no  notion  of  approximate  answer  to  an  information  need.  This  model  makes  sense 
when  the  whole  information  corpus  can  be  fully  represented  as  an  ontology-driven 
knowledge base, so that search results consist of ontology entities.  

However, there are limits to the extent to which knowledge can or should be for-
malized in this way. First, because of the huge amount of information currently avail-
able  to  information  systems  worldwide  in  the  form  of  unstructured  text  and  media 
documents, converting this volume of information into formal ontological knowledge 
at an affordable cost is currently an unsolved problem in general.  

Second, documents hold a value of their own, and are not equivalent to the sum of 
their  pieces,  no  matter  how  well  formalized  and  interlinked.  The  replacement  of  a 
document  by  a  bag  of  information  atoms  inevitably  implies  a  loss  of  information 
value: the thread of thought behind the order of the sentences in free text, the choice 
of the words, etc., are a valuable, relevant, and necessary part of the conveyed mes-
sage. Therefore, although it is useful to break documents down into smaller informa-
tion  units  that  can  be  reused  and  reassembled  to  serve  different  purposes,  it  is  yet 
often appropriate to keep the original documents in the system. 

Third, wherever ontology values carry free text, boolean semantic search systems 
do  a  full-text  search  within  the  string  values.  In  fact,  if  the  string  values  hold  long 
pieces of free text, a form of keyword-based search is taking place in practice beneath 
the ontology-based query model since, in a way, unstructured documents are hidden 
within  ontology  values,  whereby  the  “perfect  match”  assumption  starts  to  become 
arguable, and search results may start to grow in size. While this may be manageable 
and sufficient for small knowledge bases, the boolean model does not scale properly 
for massive document repositories where searches typically return hundreds or thou-
sands results. Boolean search does not provide clear ranking criteria,  without  which 
the search system may become useless if the search space is too big. 

In this paper we propose an ontology-based retrieval model meant for the exploita-
tion  of  full-fledged  domain  ontologies  and  knowledge  bases,  to  support  semantic 
search  in  document  repositories.  In  contrast  to  boolean  semantic  search  systems,  in 
our perspective  full documents, rather than specific ontology  values  from a KB, are 
returned in response to user information needs. The search system takes advantage of 
both detailed instance-level knowledge available in the KB, and topic taxonomies for 
classification. To cope with large-scale information sources, we propose an adaptation 
of the classic vector-space model [ 16], suitable for an ontology-based representation, 
upon which a ranking algorithm is defined.  

The performance of our proposed model is in direct relation with the amount and 
quality of information within the KB it runs upon. The latest advances in automating 
ontology  population  and  text  annotation  are  promising  [ 5, 9, 11, 14].  While,  if  ever, 
ontologies and metadata (and the Semantic Web itself) become a worldwide commod-
ity, the lack or incompleteness of available ontologies and KBs is a limitation we shall 
likely have to live with in the mid term. In consequence, tolerance to incomplete KBs 

 

 

An Ontology-Based Information Retrieval Model 

457 

has been set as an important requirement in our proposal. This means that the recall 
and precision of keyword-based search shall be retained when ontology information is 
not available or incomplete. 

We have implemented our  model and done some low-scale experimentation  with 
real documents and data from a digital news archive from a local Spanish newspaper. 
The experiments build upon previous work in the Neptuno project [ 1], where an on-
tology and a knowledge base were built for the description of archive news.  

The rest of the paper is organised as follows. An overview of related work is given 
in  Section  2.  After  this,  our  scheme  for  semantic  annotation  is  described.  Section  4 
explains the retrieval and ranking algorithms. Some initial experiments with our tech-
niques  are  reported  in  Section  5.The  strengths,  weaknesses,  and  significance  of  our 
approach are summarized in Section 6, after which some conclusions are given. 

2   State of the Art 

Our  view  of  the  semantic  retrieval  problem  is  very  close  to  the  latest  proposals  in 
KIM  [ 11, 14].  While  KIM  focuses  on  automatic  population  and  annotation  of  docu-
ments, our  work  focuses on the ranking algorithms for semantic search.  Along  with 
TAP [ 8], KIM is one of the most complete proposals reported to date, to our knowl-
edge,  for  building  high-quality  KBs,  and  automatically  annotating  document  collec-
tions at a large scale. In their latest account of progress [ 11] a ranking model for re-
trieval is  hinted at but  has  not been developed in detail and evaluated. In  fact, KIM 
relies  on  a  keyword-based  IR  engine  for  this  purpose  (indexing,  retrieval  and  rank-
ing). Our work complements KIM with a ranking algorithm specifically designed for 
an ontology-based retrieval model, using a semantic indexing scheme based on anno-
tation weighting techniques. 

TAP [ 8] presents a view of the Semantic Web where documents and concepts are 
nodes alike in a semantic network, whereby the separation of contents and metadata is 
not as explicit as we propose here. The two main problems addressed by TAP are a) 
the development of a distributed query infrastructure for ontology data in the Seman-
tic  Web,  and  b)  the  presentation  of  query  execution  results,  augmenting  query  an-
swers with data from surrounding nodes. These issues are complementary to the ones 
addressed in this paper. However the expressive power of the TAP query language is 
fairly limited compared to ontology query languages  such  as RDQL,  RQL, etc. The 
supported search capability is limited to keyword search within the “title properties” 
of instances, and no ranking is provided.  

Mayfield  and  Finin  [ 13]  combine  ontology-based  techniques  and  text-based  re-
trieval in sequence and in a cyclic way, in a blind relevance feedback iteration. Infer-
ence  over  class  hierarchies  and  rules  is  used  for  query  expansion,  and  extension  of 
semantic  annotations  of  documents.  Documents  are  annotated  with  RDF  triples,  and 
ontology-based queries are reduced to boolean string search, based on matching RDF 
statements with wildcards, at the cost of losing expressive power for queries. We share 
with Mayfield et al the idea that semantic search should be a complement of keyword-
based  search  as  long  as  not  enough  ontologies  and  metadata  are  available.  Also,  we 

 

458 

D. Vallet, M. Fernández, and P. Castells 

believe that inferencing is a useful tool to fill knowledge gaps and missing information 
(e.g. transitivity of the locatedIn relationship over geographical locations). 

Semantic  Portals  [ 1, 2, 4, 12]  typically  provide  simple  search  functionalities  that 
may be better characterised as semantic data retrieval, rather than semantic informa-
tion  retrieval.  Searches  return  ontology  instances  rather  than  documents,  and  no 
ranking method is provided. In some systems, links to documents that reference the 
instances are added in the user interface, next to each returned instance in the query 
answer [ 4], but neither the instances, nor the documents are ranked. Maedche et al do 
provide a criterion for query result ranking in the SEAL Portal [ 12], but the princi-
ples on which the method is based – a similarity measure between query results and 
the original KB without axioms, is not clearly justified, and no testing of the method 
is reported. 

The ranking problem has been taken up again in [ 19], and more recently [ 15]. Ro-
cha et al propose the expansion of query results through arbitrary ontology relations 
starting from the initial query answer, where the distance to the initial results is used 
to compute a similarity measure for ranking [ 15]. This method has the advantage of 
allowing the user to express information needs with simpler, keyword-based queries 
but,  from  our  perspective,  it  introduces  an  unnecessary  loss  of  precision,  since  a 
more accurate result expansion can be achieved by including ontology relations ex-
plicitly in a structured query. From our point of view, Rocha’s techniques would be 
appropriate in  a  more browsing-oriented information  seeking context.  Stojanovic et 
al  propose  a  sentence  ranking  scheme  based  on  the  number  of  times  an  instance 
appears as  a  term  in a  relation  type,  and  the derivation tree by  which  a  sentence is 
inferred  [ 19].  Whereas  these  works  are  concerned  with  ranking  query  answers  (i.e. 
ontology  instances),  we  are  concerned  with  ranking  the  documents  annotated  with 
these answers. Since our respective techniques are applied in consecutive phases of 
the  retrieval  process,  it  would  be  interesting  to  experiment  the  integration  of  the 
query result relevance function proposed by Stojanovic et al into our document rele-
vance measures.  

3   Knowledge Base and Document Base 

In our view of semantic information retrieval, we assume a knowledge base has been 
built and associated to the information sources (the document base), by using one or 
several domain ontologies that describe concepts appearing in the document text. The 
concepts and  instances in the KB are linked to the documents by  means of explicit, 
non-embedded annotations to the documents.  

While  we  do  not  address  here  the  problem  of  knowledge  extraction  from  text 
[ 4, 5, 9, 10, 11, 14], we provide a vocabulary and some simple mechanisms to aid in the 
semi-automatic annotation of documents, once ontology instances have been created 
(manually or automatically).  These are described in Subsection 3.2. Our system can 
work  with any arbitrary domain ontology  with essentially  no restrictions, except for 
some minimal requirements that are explained next.  

 

 

An Ontology-Based Information Retrieval Model 

459 

3.1   Root Ontology Classes 

Our  system  requires  that  the  knowledge  base  be  constructed  from  three  main  base 
classes:  DomainConcept,  Taxonomy,  and  Document.  DomainConcept  should  be  the 
root  of  all  domain  classes  that  can  be  used  (directly  or  after  subclassing)  to  create 
instances that describe specific entities referred to in the documents. For example, in 
the Arts domain, classes like Artist, Sculptor, ArtWork, Painting, and Museum should 
be defined as (probably indirect) subclasses of DomainConcept. A small set of upper-
level open-domain classes like Person, Building, Event, Location, etc., is included in 
the base concept ontology, to be extended for specific domains. 

Document is used to create instances that act as proxies of documents from the in-
formation source to be searched upon. Two  subclasses,  TextDocument and MediaC-
ontent, are provided, which can be further subclassed, if appropriate for a particular 
application  domain,  to  provide  for  different  types  of  documents,  such  as  Report, 
News,  PurchaseOrder,  Invoice,  Message,  etc.,  with  different  fields  (e.g.  title,  date, 
subject, price, sender). The class  MediaContent is provided in anticipation of future 
extensions for multimedia retrieval, which we have not developed yet. Document has 
a location property that holds a dereferenceable physical address (in our current im-
plementation, a URL) from which the actual document contents can be retrieved. 

Taxonomy  is  the  root  for  class  hierarchies  that  are  merely  used  as  classification 
schemes,  and  are  never  instantiated.  These  taxonomies  are  expected  to be  used  as  a 
terminology to annotate documents and concept classes, using them as values of dedi-
cated properties. For instance, in a KB for news, classes like Culture, Politics, Econ-
omy, Sports, etc. (after the IPTC Subject Reference System standard1), could be used 
as values of a (probably multivalued) topic property of the News class. Furthermore, 
concept  classes  like  Athlete  and  Tournament  could  also  have  the  topic  property,  in 
this  case  with  the  value  Sports,  i.e.  concepts  can  also  be  classified  under  the  same 
scheme as documents. Several separate taxonomies can be used simultaneously on the 
same documents, thus providing for multifaceted classification. 

The  distinction  between  the  three  root  classes  DomainConcept,  Taxonomy,  and 
Document, arises from our own experience in previous Semantic Web projects [ 1, 2], 
and  many  other  observed  information  systems  where  this  (or  a  similar  distinction) 
seems  to  be  natural,  useful  and  recurrent  (see  e.g.  [ 17]).  In  our  system,  we  exploit 
taxonomies  for  multifaceted  search,  and  to  solve  word  ambiguities,  as  will  be  de-
scribed later. 

3.2   Document Annotation 

The  predefined  base  ontology  classes  described  above  are  complemented  with  an 
annotation  ontology  that  provides  the  basis  for  the  semantic  indexing  of  documents 
with  non-embedded  annotations.  In  many  respects,  our  scheme  for  semi-automatic 
annotation is similar to the one recently reported in [ 11].  

Documents are annotated with concept instances from the KB by creating instances 
of  the  Annotation  class,  provided  for  this  purpose.  Annotation  has  two  relational 

                                                           
1 http://www.iptc.org/NewsCodes 

 

460 

D. Vallet, M. Fernández, and P. Castells 

properties,  instance  and  document,  by  which  concepts  and  documents  are  related 
together. Reciprocally, DomainConcept and Document have a multivalued annotation 
property. 

Annotations  can  be  created  manually  by  a  domain  expert,  or  semi-automatically. 
The subclasses ManualAnnotation and AutomaticAnnotation are used respectively, to 
differentiate each case. We have found this distinction  useful for the system at least 
because a) manual annotations are more reliable than automatic ones, and when avail-
able should prevail, and b) while automatic annotations can be deleted for recalcula-
tion, manual annotations should be preserved. 

Our system provides a simple facility for semi-automatic annotation, which works 
as follows. DomainConcept instances use a label property to store the most usual text 
form  of  the  concept  class  or  instance.  This  property  is  multivalued,  since  instances 
may have several textual lexical variants. Close equivalents of our label property are 
used in systems like KIM [ 11] and TAP [ 8]. In our current experiments, the value of 
this property is set by hand by the ontology designer, but it could be set by automatic 
means, if an external instance generation system was plugged to our system. Similarly 
to KIM, instance labels are used by the automatic annotator to find potential occur-
rences of instances in text documents. Whenever the label of an instance is found, an 
annotation  is  created  between  the  instance  and  the  document.  In  our  system,  docu-
ments can be annotated with classes as well, by assigning labels to concept classes.  

This basic mechanism is complemented with heuristics to cope with polysemia, i.e. 
label coincidence between different instances or classes. First the system always tries 
to find the longest label, e.g. “Real Madrid” is preferred to “Madrid”. Second, classi-
fication  taxonomies  are  used  as  a  source  of  semantic  scope  for  disambiguation:  a 
similarity measure is defined to compare the respective classification of the document 
and candidate synonym instances for annotation, so that the instance that has the clos-
est  classification  to  the  document  is  chosen.  For  example,  the  word  “Irises”  in  a 
document classified under Arts would be linked to an instance of Painting that repre-
sents  Van  Gogh’s  famous  work,  rather  than  a  subclass  of  Flower,  provided  that  the 
painting instance exists in the knowledge base and has been correctly classified under 
Arts, or a taxonomic subclass thereof, and assuming that Flower is classified under a 
different taxonomic branch such as Botany or the like. Of course, if the Painting in-
stance  does  not  exist,  our  system  fails  because  it  would  incorrectly  annotate  the 
document with the botanic sense. 

Our semi-automatic annotation mechanisms can be further improved, but this is out 
of the extent of our undergoing research. More sophisticated annotation techniques, as 
have been reported in the literature [ 5, 9, 11, 14], would be complementary and benefi-
cial to our system. 

3.3   Weighting Annotations 

The annotations are used by the retrieval and ranking module, as will be explained in 
Section 4. The ranking algorithm is based on an adaptation of the classic vector-space 
model [ 16]. In the classic vector-space model, keywords appearing in a document are 
assigned  weights  reflecting  that  some  words  are  better  at  discriminating  between 

 

 

An Ontology-Based Information Retrieval Model 

461 

documents  than  others.  Similarly,  in  our  system,  annotations  are  assigned  a  weight 
that reflects how relevant the instance is considered to be for the document meaning. 
Weights are computed automatically by an adaptation of the TF-IDF algorithm [ 16], 
based on the  frequency of occurrence of the instances in each document. More spe-
cifically, the weight wi,j of instance Ii for document Dj is computed as: 

w
i

,

j

 

=

 

freq
i

,

j

max

k

freq

k j

,

×  

log

 

N

n
i

Where freqi,j is the number of occurrences of Ii in Dj, maxk freqk,j is the frequency 
of the most repeated instance in Dj, ni is the number of documents annotated with Ii, 
and N is the total number of documents in the search space.  

The number of occurrences of an instance in a document is primarily defined as the 
number of times the label of  the instance appears in the document text, if the docu-
ment is annotated with the instance, and zero otherwise. We realised in our first ex-
periments  that  quite  a  number  of  occurrences  were  missed  in  practice  with  this  ap-
proach,  since  pronouns,  periphrasis,  metonymy,  and  other  deixis  abound  in  regular 
written speech. Finding all the references to an individual in free text is a very com-
plex  natural  language  processing  problem  far  beyond  the  scope  of  our  current  re-
search.  Nonetheless  we  have  achieved  significant  improvements  by  extending  our 
labeling scheme and exploiting class hierarchies, as follows. 

First,  further  instance  occurrences  are  found  by  adding  more  labels  to  instances. 
However, the proliferation of labels tends to introduce further polysemic ambiguities 
that lead to incorrect annotations. To avoid this negative effect, our system provides a 
separate  keyword  property  to  be  used,  in  addition  to  label,  for  instance  frequency 
computation,  but  not  for  automatic  annotation.  As  a  general  rule,  label  should  be 
reserved  to  clearly  instance-specific  text  forms,  leaving  more  ambiguous  ones  as 
keywords. Since instance occurrences are only computed in the presence of an annota-
tion, very few or no ambiguities are caused in practice.  

Also,  synecdoche  is  a  frequent  rhetoric  figure  used  to  avoid  repetition,  where  an 
individual is referred to by its class (e.g. “the painter”), after the individual (e.g. “Pi-
casso”) has already appeared in the text. To cope with  this, the list of textual forms 
(labels and keywords) of an instance is automatically expanded (just for the computa-
tion of occurrences) with the textual forms of its direct and indirect classes. This in-
troduces a slight occurrence counting imprecision when more than one instance of the 
same class are annotating the same document, because the same class references are 
counted once  for each instance. However, in our experiments the improvements ob-
tained with this technique outweight the effect of the imprecision. 

4   Processing Queries 

Our approach to ontology-based information retrieval can be seen as an evolution of 
classic  keyword-based  retrieval  techniques,  where  the  keyword-based  index  is  re-
placed  by  a  semantic  knowledge  base.  The  overall  retrieval  process  is  illustrated  in 
Fig. 1. Our system takes as input a formal RDQL query. This query could be gener-

 

462 

D. Vallet, M. Fernández, and P. Castells 

ated from a keyword query, as in e.g. [ 8, 15, 18], a natural language query [ 4], a form-
based interface  where the user can explicitly select ontology classes and enter prop-
erty  values  [ 1, 11, 12],  or  more  sophisticated  search  interfaces  [ 7].  A  number  of  re-
search works have undertaken the construction of easy to use user interfaces for on-
tology query languages, and we do not address this problem here. The RDQL query is 
executed against the knowledge base, which returns a list of instance tuples that sat-
isfy the query. Finally, the documents that are annotated with these instances are re-
trieved, ranked, and presented to the user. 

Query UI
Query UI

Ranking
Ranking

Ranked
Ranked

Documents
Documents

RDQL
RDQL
Query
Query

Query
Query
Engine
Engine

RDF KB
RDF KB

Unordered
Unordered
Documents
Documents

Document
Document
Retriever
Retriever

Document
Document
Base
Base

 

List of instances
List of instances

Weighted
Weighted

annotation links
annotation links

Fig. 1. Our view of ontology-based information retrieval 

4.1   Query Encoding and Document Retrieval 

The RDQL query can express conditions involving domain ontology instances, docu-
ment  properties  (such  as  author,  date,  publisher,  etc.),  or  classification  values.  E.g. 
“cultural articles published by the Le Monde newspaper about European movies with 
Canadian actors in the cast.”  

In classic keyword-based vector-space models for information retrieval, the query 
keywords are assigned a weight that represents the importance of the concept in the 
information need expressed by the query. Analogously, in our model, the variables in 
the SELECT clause of the RDQL query can be weighted to indicate the relative inter-
est of the user for each of the variables to be explicitly mentioned in the documents. 
For instance, in the previous example, the user might be interested that both the mov-
ies and the Canadian actors are mentioned in the articles, or have a higher priority for 
either  the  movies  or  the  actors.  The  weights  can  be  set  explicitly  by  the  user,  or  be 
automatically derived by the system, e.g. based on frequency analysis, personalisation 
techniques, or other strategies [ 6]. 

Our  system  uses  inferencing  mechanisms  for  implicit  query  expansion  based  on 
class  hierarchies  (e.g.  organic  pigments  can  satisfy  a  query  for  colorants),  and  rules 
such as one by which the winner of a sports match might be inferred from the scoring. 

 

 

An Ontology-Based Information Retrieval Model 

463 

In fact, in our current implementation, it is the KB which is expanded by adding in-
ferred statements beforehand. 

The query execution returns a set of tuples that satisfy the query. It is the document 
retriever’s  task to obtain all the documents that correspond to the instance tuples. If 
the tuples are only made up of instances of domain concepts, the retriever follows all 
outgoing  annotation  links  from  the  instances,  and    collects  all  the  documents  in  the 
repository  that  are  annotated  with  the  instances.  If  the  tuples  contain  instances  of 
document  classes  (because  the  query  included  direct  conditions  on  the  documents), 
the same procedure is followed, but restricted to the documents in the result set, in-
stead of the whole repository.  

4.2   Ranking Algorithm 

N

)

}

v
k

v
1,...,

Once the list of documents is formed, the search engine computes a semantic similar-
ity value between the query and each document, as follows. Let 
be the set 
of all instances in the ontology, and  {
D =  be the set of all documents in the search 
space.  Let  (
  be  the  weights  of  the  variables  in  the  SELECT  clause  of  the 
RDQL query Q, and let T =  { }
T =  be the list of tuples in the query result set, where 
T
i

{
T
i
We define the document vector of Di  as 

 = (di,1, …, di,M), where di,j is the weight 
of the annotation of document Di with Ij, if such annotation exists, and zero otherwise. 
= ∑ , i.e. the 
We define the extended query vector as 

q
q
1,..., M

, where 

O∈ . 

, with 

{ }
I

=!
q

},

!
id

jT

M
=
1

q
l

O

=

=

v

(

)

=
1

,i

1

n

1

k

i

i

j

j

j

i

i

i

i

∃

=

i I T
|
i

l

,

j

query vector element corresponding to Il is added the variable weight vj if Il is a value 
of the variable j in some tuple Ti that satisfies the query Q. Note that the sum rarely 
has more than one term, since this would mean that the same instance appears more 
than once in the same result set tuple. If Il does not appear in any tuple, ql = 0.  

Now the similarity measure of Di for the query Q is computed as: 

sim D Q

(

,

)

i

=

! !
i
d q
×

i
|

|

!
d
i

|

!  
q
|

!
Because  of  the  way  q

!
  is  constructed,  | q

|  is  usually  quite  large,  and  as  a  conse-
quence the values of the similarity function are too low. For example, if the user que-
ries  for  special  offers  for  summer  holidays  in  the  Aegean  Islands,  a  document  that 
shows one such offer will get a similarity value in the order of 1/n, where n is the total 
number of registered offers in the knowledge base that match the query. Only a docu-
ment that displays nearly all offers could get close to similarity 1. To compensate for 
this,  in  practice  we  use  the  following  normalization  factor  instead  of 
|: 

!
| q

k

(

×∑

v

2

j

=
1

j

max #

T

l

l
j

, where 

T

l
j

)

{
= ∈

I O I

|

 annotates 

D
l

∧ ∃

=

i I T
,  
i

},

j

.  

If the knowledge in the KB is incomplete (e.g. there are documents about travel of-
fers in the knowledge source, but the corresponding instances are missing in the KB), 
the semantic ranking algorithm performs very poorly: RDQL queries will return less 

 

464 

D. Vallet, M. Fernández, and P. Castells 

results than expected, and the relevant documents will not be retrieved, or will get a 
much lower similarity value than they should. As limited as might be, keyword-based 
search could perform better in these cases. To cope with this, our ranking model com-
bines the semantic similarity measure with the similarity measure of a keyword-based 
algorithm. The final value for ranking is computed as t × sim (Di,Q) + (t – 1) × ksim 
(Di,Q),  where  ksim  is  computed  by  a  keyword-based  algorithm.  We  have  taken  t  = 
0.5, which seems to perform well in our experiments. As a further adjustment, if ksim 
returns 0, we take t = 1, and if sim returns 0, we take t = 0.2. For further testing, we 
have implemented a user interface where this parameter can be freely set by the user 
with a slider after the search has been executed, so that the user can see dynamically 
how the results are reranked as the value of t is moved. 

The  keywords  for  the  ksim  algorithm  could  be  extracted  directly  from  the  user 
query, if a keyword-based or even natural language interface was used. In our current 
implementation we extract the keywords from the RDQL query, which is suitable for 
testing,  and  would  be  appropriate  for  a  form-based  interface  as  well.  More  specifi-
cally, the value of the label property of a) the class of all query variables for which a 
rdf:type  clause  is  included  in  the  query,  and  b)  any  instances  explicitly  appearing 
within  the  RDQL  query,  are  taken  as  query  keywords.  In  practice,  since  the  label 
property can be multivalued, a separate property is used, which stores one of the label 
values, designated as a unique most common lexical form. For example, the query: 

SELECT  ?player ?team  
WHERE   (?player rdf:type sports:Player)  
 
 
 
 
 

(?player sports:sport sports:Basketball) 
(?player general:nationality geog:USA)  
(?player sports:playsIn ?team) 
(?team rdf:type sports:SportsTeam) 
(?team geog:locatedIn geog:Catalonya) 

would yield the query keywords “player”, “basketball” , “USA”, “team”, “Catalonia”. 
In sum, our method improves keyword-based search (actually outperforms it, as is 
shown in the next section) when the relevant information is available in the KB, and 
relies on keyword-based search otherwise. 

5   Early Experiments 

We  have  tested  our  system  with  a  document  base  taken  from  an  online  newspaper 
archive  [ 2].  For  this  application,  the  document  class  hierarchy  includes  News  (sub-
class of TextDocument), Photograph and CustomGraphic (subclasses of MediaDocu-
ment).  Only  one  classification  taxonomy  is  used,  based  on  the  IPTC  Subject  Refer-
ence  System,  with  which  all  documents  and  domain  classes  are  classified,  as  ex-
plained in Section 3.1. Our current implementation is compatible with both RDF and 
OWL. 

Building  appropriate  domain  ontologies  and  a  complete  KB  for  a  newspaper  ar-
chive  is  an  enormous  undertaking,  or  would  need  very  advanced  semi-automatic 
knowledge extraction techniques not yet available in current state of the art. However, 

 

 

An Ontology-Based Information Retrieval Model 

465 

as  stated  in  previous  sections,  our  system  tolerates  incomplete  ontologies  and  KBs. 
We have built three reduced domain ontologies for testing purposes, corresponding to 
the  Culture,  Economy,  and  Sports  domains,  with  classes  such  as  Artist,  Painter, 
Monument,  Company,  Bank,  Sportsman,  SportsTeam,  Stadium,  etc.,  and  a  few  in-
stances of each class. These ontologies  were built by reading 200 news articles, and 
defining classes and instances by hand for concepts found in the documents. In total, 
143  domain  classes  and  1,144  instances  were  created.  We  have  also  manually  set 
labels  and  keywords  for  concept  classes  and  instances.  Then  we  have  run  the  auto-
matic  annotation  and  weighting  algorithm  over  a  subset  of  the  archive  comprising 
2,039  news  articles,  generating  3,471 annotations, of  which 349  were 
manually
 created.  

Once the KB was built, we tested the retrieval algorithm with some examples, and 
compared  it  to  a  keyword-only  search,  using  the  Jakarta  Lucene  library.2  We  report 
next the observed results in four examples, showing different levels of performance of 
our method in different cases. The metrics are based on a manual ranking of all docu-
ments  for  each  query,  on  a  scale  from  0  to  5.  In  the  experiments,  all  the  query 
variables were given a weight of 1. The measurments are subjective and limited, yet 
indicative of the degree of improvement that can be expected, and in what cases, with 
respect to a keyword-based engine. The retrieval times are too low to draw any sig-
nificant observation regarding efficiency. The results are shown in Fig.2. 

a 

b 

c

d 

Keyword search
Semantic search

Keyword search
Semantic search

Keyword search
Semantic search

Keyword search
Semantic search

0,20

0,40

0,60

0,80

1,00

0,20

0,40

0,60

0,80

1,00

0,20

0,40

0,60

0,80

1,00

0,20

0,40

0,60

0,80

1,00

Recall

Recall

Recall

Recall

Keyword search
Semantic search

Keyword search
Semantic search

Keyword search
Semantic search

Keyword search
Semantic search

0,00

0,00

5,0

1,00

0,80

n
o

i
s
i
c
e
r
P

0,60

0,40

0,20

]
5
-
0
[
 

e
c
n
a
v
e

l

e
R

4,0

3,0

2,0

1,0
0

1,00

0,80

n
o

i
s
i
c
e
r
P

0,60

0,40

0,20

0,00

0,00

5,0

]
5
-
0
[
 

E
e
c
n
a
v
e

l

e
R

4,0

3,0

1,00

0,80

n
o

i
s
i
c
e
r
P

0,60

0,40

0,20

0,00

0,00

5,0

]
5
-
0
[
 

e
c
n
a
v
e

l

e
R

4,0

3,0

2,0

1,0

1,0
0

20

40
Documents Retriev ed

80

60

100

120

100
200
Documents Retriev ed

20

40

60

80

100

120

140

0

Documents Retriev ed

10

20

30

Documents Retrieved

300

2,0
0

40

 

Fig. 2. Evaluation of ontology-based search (combined with keyword-based) against keyword-
based only. The performance of both algorithms are shown for four different queries a, b, c, and 
d.  The  graphics on  top  show  the  precision  vs.  recall  figures  (as  defined  in  e.g. [ 16]),  and  the 
graphics below show the average relevance at different document cutoff values, for each query 

Query a. “News about players from USA playing in basketball teams of Catalonia.”  
In  this  example  the  semantic  retrieval  algorithm  outperforms  keyword-based  search 

                                                           
2 http://lucene.apache.org 

 

1,00

0,80

n
o

i
s
i
c
e
r
P

0,60

0,40

0,20

0,00

0,00

5,0

]
5
-
0
[
 

e
c
n
a
v
e

l

e
R

4,0

3,0

2,0

 

466 

D. Vallet, M. Fernández, and P. Castells 

because  the  KB  contains  many  instances  of  basketball  players  and  teams,  some  of 
which  match  the  query.  Keyword-based  search  only  recognizes  a  document  as  rele-
vant  if  it  contains  words  like  “player”,  “USA”,  “Catalonia”,  whereas  the  semantic 
search retrieves news about players and teams as soon as the name of the player or the 
team are mentioned in the document.  

These  are  typical  results  when  a  search  query  involves  a  region  of  the  ontology 
with some degree of completeness in terms of instances and annotations. These cases 
yield a high precision up to almost maximum recall. On the other hand, the relevance 
graph shows that here the semantic search gives high ranks to the relevant documents. 
For instance, the top 20 retrieved documents have a mean relevance value of 4.2 upon 
5, versus  2.7 in the keyword search. 

However, the KB does not contain all teams and players, which explains the col-
lapse of the precision at 100% recall. If more instances were created, precision values 
would stand at high levels for all the recall values. 

Query b. “News about sports team presidents.” 
In this example, the ontology KB has only a few instances of sports team presidents, 
so not all documents relevant to the query are annotated. This causes precision to drop 
to lower values when recall increases. Although the total recall of semantic search is 
low, it still has a good precision for the top-ranked documents, which are the few ones 
annotated  with  instances  in  the  KB.  A  few  more  documents  where  semantic  search 
alone  fails  are  still  given  a  high  ranking  thanks  to  the  combination  with  keyword-
search, which shows here a comparable behavior to example a. 

Query c. “News about basketball players.” 
In  this  case  the  performance  of  the  two  algorithms  is  similar.  For  this  example,  we 
have  intentionally  removed  most  instances  of  players  from  the  KB,  leaving  a  rela-
tively low  number. Moreover,  we have removed all lexical variants in the  label and 
keyword  properties  of  player  instances,  except  the  player’s  surname.  As  a  conse-
quence,  many  annotations  are  missing.  Under  these  conditions,  the  semantic  model 
alone  performs  much  worse  than  keyword-based  search.  However,  the  combined 
search yields a similar final behavior to keyword-based search. 

Query d. “News about the European Union.” 
This example shows a case where our method fails. The KB contains an instance for 
the European Union, with all the possible syntactic variants (in Spanish “UE”, “U.E.”, 
etc.). The problem is that many Catalan sports teams have the word “UE” (acronym 
for “Sports Union” in Catalan) in  their  names. If the  KB contained these teams, the 
disambiguation algorithm would solve the problem by favoring the sports interpreta-
tion,  whenever  appropriate,  because  “UE”  is  part  of  a  longer  matching  string  (the 
team name). In other examples where the labels could be totally coincident, the sys-
tem  would  use  the  classification  of  news  and  instances  as  context  information  for 
disambiguation. But because many such teams are missing in the KB, the automatic 
annotator incorrectly annotates the sports news with the European Union concept, and 
the  retriever  returns  them.  So  far,  the  keyword-based  search  behaves  similarly.  But 

 

 

An Ontology-Based Information Retrieval Model 

467 

the  semantic  ranking  places  these  wrong  documents  in  a  top  position,  whereas  the 
keyword-based  model  does  not  rank  them  particularly  higher  than  the  correct  docu-
ments.  

It can be seen that it is the automatic annotator, and not the retrieval system, which 
is failing here in the absence of the appropriate instances needed to solve ambiguities. 
One way to reduce the negative impact of incorrect annotations would be to introduce 
a  factor  in  the  automatic  weighting  algorithm  that  accounts  for  the  proximity  of  the 
respective  classifications  of  the  documents  and  the  instances.  In  this  example,  al-
though it is difficult to avoid annotating with the European Union concept the news 
about  Catalan  teams  whose  name  contains  “UE”  (in  fact,  some  sports  news  could 
properly  mention  the  EU),  at  least  the  weight  of  the  annotation  would  be  reduced 
because the classifications (Geography and Politics vs. Sports) do not match. Testing 
this and other possible improvements to the automatic annotation strategies are one of 
our planned tasks for the immediate future. 

6   Discussion 

The  added  value  of  semantic  information  retrieval  with  respect  to  traditional  key-
word-based retrieval, as envisioned in our approach, relies on the additional explicit 
information  –  type,  structure,  relations,  classification,  and  rules,  about  the  concepts 
referenced  in  the  documents,  represented  in  an  ontology-based  KB,  as  opposed  to 
classic flat keyword-based indices. Semantic search introduces an additional step with 
respect  to  classic  information  retrieval  models:  instead  of  a  simple  keyword  index 
lookup, the semantic search system processes a semantic query against the KB, which 
returns a set of instances. This can be seen as a form of query expansion, where the 
set  of  instances  represent  a  new  set  of  query  terms,  leading  to  higher  recall  values. 
Further implicit query expansion is achieved by inference rules, and exploiting class 
hierarchies.  The  rich  concept  descriptions  in  the  KB  provide  useful  information  for 
disambiguating the meaning of documents.  

In  summary,  our  proposal  achieves  the  following  improvements  with  respect  to 

keyword-based search: 

!  Better  recall  when  querying  for  class  instances.  For  example,  querying  for 
“presidents  of  the  Spanish  government”  would  return  documents  that  mention 
José  Luis  Rodríguez  Zapatero  and  other  former  presidents,  even  if  the  words 
“president”, “Spanish” and “government” are not present in the documents. 

!  Better precision by using structured semantic queries. Structured queries allow 
expressing  more  precise  information  needs,  leading  to  more  accurate  answers. 
For instance, in a keyword-based system, it is not possible to distinguish a query 
for  USA  players  in  Catalan  basket  teams  vs.  Catalan  players  in  USA  teams, 
which is possible with a semantic query. 

!  Better  precision  by  using  query  weights.  Variables  with  low  weights  are  only 
used to impose conditions on the variables which really matter. For example, the 
user  can  search  for  news  about  USA  players  in  Catalan  teams,  regardless  of 
whether the news mention the team at all, or the nationality of the player.  

 

468 

D. Vallet, M. Fernández, and P. Castells 

!  Better recall by using class hierarchies and rules. For example, a query for Wa-
terSports  in  Spain  would  return  results  in  ScubaDiving,  Windsurf,  and  other 
subclasses, in  Cádiz, Málaga, Almería, and other Spanish locations (by transi-
tivity of locatedIn). 

!  Better  precision  by  reducing  polysemic  ambiguities  using  instance  labels  and 

classifications of concepts and documents. 

As  explained  and  shown  along  this  paper,  the  degree  of  improvement  of  our  se-
mantic retrieval model depends on the completeness and quality of the ontology, the 
KB, and the concept labels. For the sake of robustness, the system resorts to keyword-
based search when the KB returns poor results. 

The combination of keyword ranking and semantic ranking is tricky. We have ob-
served that occasionally a good semantic ranking score is spoiled by a low keyword-
based value. A simple solution would be to set a minimum threshold for the keyword-
based score to be counted. Anyhow, these cases, albeit infrequent, suggest that more 
sophisticated  methods  than  the  linear  combination  of  both  values  should  be  re-
searched to improve our initial results.  

7   Conclusion 

The  research  presented  here  started  as  a  continuation  of  our  previous  work  on  the 
construction,  exploitation,  and  maintenance  of  domain-specific  KBs  using  Semantic 
Web technologies [1,2]. While some basic semantic search facilities were included in 
these prior proposals, room for improvement was acknowledged, because the level of 
semantic detail was insufficient, since it was essentially based on types of documents 
and taxonomic classifications. The aim of our current work is to provide better search 
capabilities  which  yield  a  qualitative  improvement  over  keyword-based  full-text 
search, by introducing and exploiting finer-grained domain ontologies. 

Our approach can be seen as an evolution of the classic vector-space model, where 
keyword-based indices are replaced by an ontology-based KB, and a semi-automatic 
document  annotation  and  weighting  procedure  is  the  equivalent  of  the  keyword  ex-
traction  and  indexing  process.  We  show  that  it  is  possible  to  develop  a  consistent 
ranking  algorithm  on  this  basis,  yielding  measurable  improvements  with  respect  to 
keyword-based search, subject to the quality and critical mass of metadata. Our pro-
posal  is  an  adaptation  of  the  vector-based  ranking  model  that  takes  advantage  of  an 
ontology-based knowledge representation. 

Our  proposal  inherits  all  the  well-known  problems  of  building  and  sharing  well-
defined ontologies, populating knowledge bases, and mapping keywords to concepts. 
Recent  research  on  these  areas  is  yielding  promising  results  [ 5, 11].  It  is  our  aim  to 
provide a consistent model by which any advancement on these problems is played to 
the benefit of semantic search improvements. 

Further  experimentation,  larger  KBs,  and  larger  document  sets  are  needed  to  test 
and improve our model. For instance, our annotation weighting scheme is not taking 
advantage  yet  of  the  different  relevance  of  structured  document  fields  (e.g.  title  is 
more important than body). Annotating documents with statements, besides instances, 

 

 

An Ontology-Based Information Retrieval Model 

469 

is another interesting possibility to experiment with. Also, we are currently extending 
our model with a profile of user interests for personalised search [ 6]. 

Acknowledgements 

This  research  was  supported  by  the  European  Commission  under  contract  FP6-
001765 aceMedia. The expressed content is the view of the authors but not necessar-
ily the view of the aceMedia project as a whole. The authors would like to thank the 
reviewers for their detailed, accurate and helpful coments. 

References 

1.  Castells, P., Foncillas, B., Lara, R., Rico, M., Alonso, J. L.: Semantic Web Technologies 
for Economic and Financial Information Management. In: Davies, J.,  Fensel, D., Bussler, 
C.,  Studer,  R.  (eds.):  The  Semantic  Web:  Research  and  Applications  –  1st  European  Se-
mantic  Web  Symposium  (ESWS  2004).  LNCS,  Vol.  3053.  Springer  Verlag,  Berlin  Hei-
delberg New York (2004) 473-487 

2.  Castells,  P., Perdrix,  F., Pulido, E.,  Rico,  M.,  Benjamins,  V.  R.,  Contreras,  J.,  Lorés,  J.: 
Neptuno: Semantic Web Technologies for a Digital Newspaper Archive. In: Davies, J. et 
al  (eds.):  The  Semantic  Web:  Research  and  Applications  –  1st  European  Semantic  Web 
Symposium  (ESWS  2004).  LNCS,  Vol.  3053.  Springer  Verlag,  Berlin  Heidelberg  New 
York (2004) 445-458 

3.  Christophides,  V.  et  al:  Optimizing  taxonomic  semantic  web  queries  using  labeling 

schemes. Journal of Web Sematics 1, Issue 2, Elsevier (2003) 207-228 

4.  Contreras, J., Benjamins, V. R., Blázquez, M., Losada, S., et al: A Semantic Portal for the 
International Affairs Sector. In: Motta, E., Shadbolt, N., Stutt, A., Gibbins, N. (eds.): En-
gineering Knowledge in the Age of the Semantic Web – 14th  Intl. Conference on Knowl-
edge  Engineering  and  Knowledge  Management  (EKAW  2004).  Lecture  Notes  in  Com-
puter Science, Vol. 3257. Springer Verlag, Berlin Heidelberg New York (2004) 203-215 

5.  Dill,  S.,  Eiron,  N.,  Gibson,  D.,  Gruhl,  D.,  Guha,  R.  et  al:  A  Case  for  Automated  Large 

Scale Semantic Annotation. Journal of Web Sematics 1, Issue 1, Elsevier (2003) 115-132 
6.  Gauch, S., Chaffee, J., and Pretschner, A.: Ontology-based personalized search and brows-

ing. Web Intelligence and Agent System 1, Issue 3-4 (2003) 219-234 

7.  Guarino, N., Masolo, C., Vetere, G.: OntoSeek: Content-Based Access to the Web. IEEE 

Intelligent Systems 14, Issue 3 (1999) 70-80 

8.  Guha,  R.  V.,  McCool,  R.,  Miller,  E.:  Semantic  search.  In  Proc.  of  the  12th  Intl.  World 

Wide Web Conference (WWW 2003), Budapest, Hungary, (2003) 700-709 

9.  Handschuh, S., Staab, S., and Ciravegna, F.: S-cream – Semi-automatic Creation of Meta-
data.  In:  A.  Gómez-Pérez  ,  V.  Richard  Benjamins  (eds.):  13th  Intl.  Conf.  on  Knowledge 
Engineering  and  Knowledge  Management  –  Ontologies  and  the  Semantic  Web 
(EKAW’02).  LNCS,  Vol.  2473.  Springer  Verlag,  Berlin  Heidelberg  New  York  (2002) 
358-372 

10.  Järvelin, K., Kekäläinen, J., and Niemi, T.: ExpansionTool: Concept-based query expan-

sion and construction. Information Retrieval 4, Issue 3-4  (2001) 231-255 

11.  Kiryakov, A., Popov, B., Terziev, I., Manov, D., Ognyanoff, D.: Semantic Annotation, In-

dexing, and Retrieval. Journal of Web Sematics 2, Issue 1, Elsevier (2004) 47-49 

 

470 

D. Vallet, M. Fernández, and P. Castells 

12.  Maedche, A., Staab, S., Stojanovic, N., Studer, R., Sure, Y.: SEmantic portAL: The SEAL 
Approach. In: Fensel, D., Hendler, J. A., Lieberman, H., Wahlster, W. (eds.): Spinning the 
Semantic Web. MIT Press, Cambridge London (2003) 317-359 

13.  Mayfield, J., and Finin, T.: Information retrieval on the Semantic Web: Integrating infer-
ence and retrieval. In: Workshop on the Semantic Web at the 26th Intl. ACM SIGIR Con-
ference on Research and Development in Information Retrieval, Toronto, Canada (2003) 

14.  Popov, B., Kiryakov, A., Ognyanoff, D., Manov, D., Kirilov, A.: KIM – A Semantic Plat-
form  for  Information  Extaction  and  Retrieval.  Journal  of  Natural  Language  Engineering 
10, Issue 3-4, Cambridge University Press (2004) 375-392 

15.  Rocha, C., Schwabe, D., de Aragão, M. P.: A Hybrid Approach for Searching in the Se-
mantic Web. In Proc. of  Intl. World Wide Web Conf. (WWW 2004), NY (2004) 374-383 
16.  Salton,  G.  and  McGill,  M.  Introduction  to  Modern  Information  Retrieval.  McGraw-Hill, 

New York (1983) 

17.  Sheth, A., Bertram, C., Avant, D., Hammond, B., Kochut, K., and Warke, Y.: Managing 

Semantic Content for the Web. IEEE Internet Computing 6, Issue 4 (2002) 80-87 

18.  Stojanovic,  N.:  On  Analysing  Query  Ambiguity  for  Query  Refinement:  The  Librarian 
Agent Approach. In: Song, I.-Y.; Liddle, S.W.; Ling, T.W.; Scheuermann, P. (eds.): Con-
ceptual Modeling – ER 2003, 22nd Intl. Conf. on Conceptual Modeling. LNCS, Vol. 2813. 
Springer Verlag, Berlin Heidelberg New York (2003) 490-505 

19.  Stojanovic, N., Studer, R., and Stojanovic, L.: An Approach for the Ranking of Query Re-
sults  in  the  Semantic  Web.  In:  Fensel,  D.,  Sycara,  K.  P.,  Mylopoulos,  J.  (eds.):  The  Se-
mantic Web – ISWC 2003, 2nd Intl. Semantic Web Conf. Lecture Notes in Computer Sci-
ence, Vol. 2870. Springer Verlag, Berlin Heidelberg New York (2003) 500-516 

 

