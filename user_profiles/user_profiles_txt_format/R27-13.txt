Is Wikipedia Link Structure Different?

Jaap Kamps1,2 Marijn Koolen1

1 Archives and Information Studies, University of Amsterdam

2 ISLA, Informatics Institute, University of Amsterdam

{kamps,m.h.a.koolen}@uva.nl

ABSTRACT
In this paper, we investigate the diﬀerence between Wikipe-
dia and Web link structure with respect to their value as in-
dicators of the relevance of a page for a given topic of request.
Our experimental evidence is from two IR test-collections:
the .GOV collection used at the TREC Web tracks and the
Wikipedia XML Corpus used at INEX. We ﬁrst perform a
comparative analysis of Wikipedia and .GOV link structure
and then investigate the value of link evidence for improv-
ing search on Wikipedia and on the .GOV domain. Our
main ﬁndings are: First, Wikipedia link structure is similar
to the Web, but more densely linked. Second, Wikipedia’s
outlinks behave similar to inlinks and both are good indica-
tors of relevance, whereas on the Web the inlinks are more
important. Third, when incorporating link evidence in the
retrieval model, for Wikipedia the global link evidence fails
and we have to take the local context into account.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval—relevance feedback, retrieval models;
H.3.4 [Information Storage and Retrieval]: Systems
and Software—performance evaluation (eﬃciency and eﬀec-
tiveness)

General Terms
Measurement, Performance, Experimentation

Keywords
Web information retrieval, link evidence, Wikipedia

1.

INTRODUCTION

The principal diﬀerence between Web retrieval and gen-
eral information retrieval, is the abundant link structure of
the Web which can been exploited to improve information
retrieval in algorithms like PageRank [25] and HITS [16].

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
WSDM’09, February 9–12, 2009, Barcelona, Spain
Copyright 2009 ACM 978-1-60558-390-7 ...$5.00.

Similar to the earlier use of citations in bibliometrics, a link
from a page A to a page B, can be considered as a vote by
the author of page A for page B as being authoritative [16].
Wikipedia’s links are a special case of the general hyper-
links that connect the World Wide Web. Internal links in
Wikipedia are typically based on words naturally occurring
in a page and link to another “relevant” Wikipedia page.
As it is put in http://en.wikipedia.org/wiki/Wikipedia:
Only_make_links_that_are_relevant_to_the_context:

Only make links that are relevant to the context. It is
counterproductive to hyperlink all possible words. ...
A high density of links can draw attention away from
the high-value links that readers would beneﬁt from
following. Redundant links clutter up the page and
make future maintenance harder. A link is analogous
to a cross-reference in a print medium.
Imagine if
every second word in an encyclopedia article were
followed by ”(see:)”. Hence, the links should not be
so numerous as to make the article harder to read.

Our conjecture is that the links in Wikipedia are diﬀerent
from links between arbitrary Web documents. Whereas in
Web documents, an author can arbitrarily link his page to
any other page, whether there is a topical relation or not, in
Wikipedia, links tend to be relevant to the local context. A
link from page A to page B shows that page B is semantically
related to (part of) the content of page A. It is tempting to
speculate about diﬀerences between the internal link struc-
ture of Wikipedia, and the link structure of the Web at large,
and how these may aﬀect the value of link based methods.
First, as suggested by the quote above, links seem to signal
a semantic relation between pages rather than serve pure
navigational purposes, and may therefore provide a strong
source of evidence for the relevance of a given page. Second,
due to the shared authorship and encyclopedic organization
of Wikipedia, we may expect a far more complete link graph
where all (or a large fraction of all) relevant links are present,
leading to higher link density and connectedness of the link
graph, and promoting the eﬀectiveness of the link evidence.
Third, due to the encyclopedic organization the Wikipedia
has relatively little redundant information. In addition, the
huge Wikipedia is dwarfed by the size of the Web at large.
This may have a number of consequences such as bounding
the number of directly related incoming and outgoing links,
as well as causing a quick loss of topical focus when travers-
ing the link graph. Fourth, given that we search within
a single domain, the authoritativeness of individual pages is
essentially the same, and the value of link evidence is primar-
ily to signal topical relevance. On the highly heterogeneous
Web, link evidence may be used to signal other aspects of

232

relevance, such as the general importance or authoritative-
ness of a site compared to other sites, or to indicate the best
entry-page or entry-pages of the site.

Our main research question in this paper is to ﬁnd out
if, and how, the link structure of Wikipedia diﬀers from the
Web at large with respect to its value for promoting retrieval
eﬀectiveness. That is, we work in an information retrieval
context where a user has a particular search request, and link
evidence may help promote the quality of the search results
on top of an eﬀective text retrieval algorithm. To investigate
our main research question, we need sets of search requests
and associated relevance judgments. We use two IR test
collections consisting of documents plus search requests and
associated relevance judgments. For Wikipedia, we use the
INEX 2006 and 2007 collections, together consisting of 217
ad hoc topics and an XML version of Wikipedia containing
over 650,000 articles. For the Web, we use the TREC 2004
Web track collection, consisting of 225 topics and the 1.2 mil-
lion documents .GOV collection. The Web track topics are
a mix of 75 Named Page ﬁnding, 75 home page ﬁnding and
75 Topic Distillation topics. Although this collection pro-
vides us with the necessary topics and relevance judgments,
and is reasonably comparable in size and number of topics
to the Wikipedia collection, it is a relatively small crawl of
a speciﬁc domain. We make no particular claims on the rep-
resentativeness of this data set for the current Web, which
is inﬁnitely large and highly heterogeneous, but expect it to
be a close enough approximation for our purposes [27].

Our main research question breaks down in two parts. We
start by investigating the Wikipedia link structure with an
extensive comparative analysis of the two IR test collections,
Wikipedia and .GOV. Speciﬁcally, we want to know:

• What is the degree distribution of Wikipedia and the

.GOV collections?

and outgoing links?

• Are there diﬀerences between distributions of incoming

• And, in particular, how does the link topology relate

to the relevance of retrieval results?

The second part of our main research question is about
the eﬀectiveness of link-based evidence. At TREC, we have
seen that link degree is not eﬀective for general ad hoc re-
trieval [10, 17]. However, for web-centric retrieval tasks such
as topic distillation and known-item search, link indegree
have been proved to improve retrieval performance [18, 30].
Link indegree can be considered on a global level, i.e.
in-
degree over the whole collection (similar to PageRank), or
on a local level, i.e.
indegree within the subset of articles
retrieved as results for a given topic (similar to HITS). And
there are various ways in which link evidence can be imple-
mented in the retrieval model. We continue our investigation
by doing a range of experiments on the eﬀectiveness of link
based evidence. More speciﬁcally, we want to know:

• How can global or local link evidence be incorporated

in our information retrieval models?

• What is the impact of link evidence on .GOV and Wi-
kipedia retrieval? And, in particular, does it lead to
improvement of retrieval eﬀectiveness?

To answer our second set of questions, we work in the lan-
guage modelling framework and build on and extend earlier

approaches [13, 18, 24]. We deﬁne a range of operational-
izations to incorporate link evidence into the retrieval model
and conduct retrieval experiments with them on the TREC
2004 Web track topics and on the combined INEX 2006 and
2007 Ad Hoc track topics.

The rest of the paper is structured as follows. Next, in
Section 2 we discuss earlier work on link structure and the
use of link evidence in information retrieval. In Section 3, we
perform a comparative analysis of the link structure of Wi-
kipedia and .GOV and the relation between the link topol-
ogy and the relevance of retrieval results. We continue in
Section 4 by discussing our retrieval model and principal
ways of incorporating link evidence into the model. Then,
in Section 5, we perform a range of retrieval experiments,
investigating the impact of link evidence on retrieval eﬀec-
tiveness. Finally, we end in Section 6 by summarizing our
ﬁndings, and discussing their impact.

2. RELATED RESEARCH

There are three broad strands of related research, which
we will discuss in turn. First, there is related research in
studying web structure and its potential role on improving
access to information. Various researchers have investigated
the structure of the web [9, 20], its growth [2], or the emer-
gence of ‘cyber’ communities [19]. The standard model of
Internet is the so-called Bowtie model of [4], based on the
link structure of 200 million pages and 1.5 billion links in
an Alta-Vista crawl. Broder et al. [4] ﬁnd a Strongly Con-
nected Component (SCC) of 56M pages (28%), a set IN
containing pages with a path to all SCC and a set OUT
containing pages with a path from all SCC. The Weakly
Connected Component (SCC+IN+OUT) contains 186 mil-
lion pages (91%). The link structure of the web invites social
network analysis [29], in particular notions of authority or
importance [15, 26]. Particularly intriguing is the question
whether such a link-based notion of importance can help
improve search results. This question has been addressed
by using either the global link structure, PageRank [25], or
the local link structure, HITS [16]. Amento et al. [1] showed
that link based approaches were eﬀective in picking out high-
quality results for a set of 5 queries, with indegree perform-
ing at least as well as PageRank and HITS authorities. They
also found that ranking results by the total number of pages
on their containing site performs nearly as well.

Second, there is currently emerging research in the na-
ture of Wikipedia. Bellomi and Bonato [3] analyse PageR-
ank and HITS on the Wikipedia link graph and provides
lists of most authoritative pages, countries and cities, his-
torical events, people and common nouns. Voss [28] anal-
yses a range of characteristics of Wikipedia, and provides
an analysis of Wikipedia link distributions. Buriol et al. [5]
analyse the Wikipedia link graph over time, and amongst
other things observe that the link density of Wikipedia is
increasing over time, and that a far greater fraction of pages
belongs to the strongly connected component than in earlier
studies of Web crawls.

Third, there is related research in studying web retrieval
within the narrower context of experimental IR test collec-
tions. Retrieval using Web data has been studied at TREC
since TREC-8 in 1999. Despite high expectations, TREC
experiments failed to establish the eﬀectiveness of link ev-
idence for general ad hoc retrieval [e.g., 10, 17]. Hawking
and Craswell [11, p.215] explain why Web search is diﬀerent

233

from traditional TREC ad hoc search: “Web searchers typi-
cally prefer the entry page of a well-known topical site to an
isolated piece of text, no matter how relevant. For example,
the NASA home page would be considered a more valuable
answer to the query ‘space exploration’ than newswire ar-
ticles about Jupiter probes or NASA funding cuts.” These
observations led to the deﬁnition of a range of Web-centric
tasks, like known-item (home page, named-page) search and
topic distillation.

Craswell et al. [6] investigated incoming anchor texts as
a document representation and showed its eﬀectiveness for
home page or entry-page ﬁnding. Kraaij et al. [18] inves-
tigated the importance of query independent evidence for
home page ﬁnding and show that document length is not
helping, but the number of incoming links and especially the
URL-form is promoting retrieval eﬀectiveness. The impor-
tance of various document representations, such as incom-
ing anchor texts and title-ﬁelds was further established by
Ogilvie and Callan [24] for more general known-item search
(home page ﬁnding and named-page ﬁnding). Craswell et al.
[7] studies query independent evidence for a mixed query
set of topic distillation, home page ﬁnding and named-page
ﬁnding topics, and ﬁnd that, in order of impact, PageR-
ank, indegree, URL length and click-distance improve the
eﬀectiveness over the mixed query set. Kamps [13] conducts
similar experiments and shows that indegree and URL evi-
dence promotes topic distillation and home page ﬁnding, but
gives mixed results on named-page ﬁnding. URL evidence
plays no role in Wikipedia searching, so we will focus in this
paper on link evidence.

There has been an important attempt to bridge the gap
between the scale of scientiﬁc IR test collections and the web
at large. Najork et al. [23] studies the eﬀectiveness of link-
based evidence on 464 million web pages, 28,043 queries and
evaluate on the top 10 results. They ﬁnd that combining
link-based features with the content based scores lead to
substantial improvements, with features based on incoming
links (PageRank, indegree, and HITS authorities) superior
to features based on outgoing links (outdegree and HITS
hubs).

3. COMPARATIVE ANALYSIS OF LINK

STRUCTURE

In this section, we look in close detail at the link struc-
tures of the Wikipedia and Web collections. We base our
analysis on two IR test collections, consisting of a collection
of documents, a large set of search requests and relevance
judgments. For the Web, we take the .GOV collection used
at the TREC Web tracks (2002-2004) which is based on a
crawl of the .gov domain in early 2002. For Wikipedia, we
take the Wikipedia XML Corpus used at INEX (2006-2007)
which is based on an XML’iﬁed version of the English Wi-
kipedia in early 2006 [8]. This collection is based on the
regular Wikipedia dumps provided by the Wikimedia foun-
dation, and includes all pages including stubs. However, the
pages do not include the side-bar with navigational links
present in the online rendition of the pages. Therefore, in
the online version of Wikipedia there will be more links on
a page than we report here.

3.1 Web and Wikipedia Graph

The .GOV collection contains 1,247,753 documents and

Table 1: Statistics of the .GOV and Wikipedia col-
lections

GOV Indegree

Wiki

Outdegree
Length
Indegree
Outdegree
Length

max mean median

44,228
653

min
8.90
0
0
8.90
2 102,069 6,345
0
74,937 20.63
5,098 20.63
0
16 281,150 2,473

stdev
1 126.00
4
16.61
1,892 13,377
4 282.94
36.70
4,238

12
1,309

11,110,989 unique links between these pages (we ignore links
which point to, or from, pages outside the collection). The
Wikipedia collection contains 659,304 documents and a to-
tal of 13,602,613 unique links between these pages. We have
also looked at how many of these links are reciprocal, i.e.,
a link from page A to B in combination with a link from
page B to A. There are 1,269,988 (11.4%) reciprocal links
in the .GOV collection, and 1,182,558 (8,7%) reciprocal links
in the Wikipedia collection. The higher fraction of recipro-
cal links in the .GOV collection is likely due to the presence
of navigational links within web-sites. Table 1 gives some
statistics on the incoming (indegree) and outgoing (outde-
gree) links and document lengths of both collections. We
calculate length in characters. The pages in .GOV have
mean length 6,345 characters (median 1,892) and the pages
in Wikipedia are shorter with a mean length of 2,473 char-
acters (median 1,309).

In .GOV, the average number of in- and outlinks per doc-
ument is 8.90, in Wikipedia 20.63. Recall that, here, we are
only using within-collection links, so every outgoing link is
also an incoming link. The median number of incoming links
is 1 in .GOV and 4 in Wikipedia and the median number of
outgoing links is 4 in .GOV and 12 in Wikipedia. Also the
maximal outdegree in Wikipedia (5,098) is much higher than
in the .GOV collection (653). Again, we make no particular
claims on the .GOV collection being a good representative
of the Web at large. On the one hand, the indegrees should
increase if we would consider a larger set of pages (since
we cannot detect incoming links from pages outside the col-
lection) leading us to underestimate the indegrees. On the
other hand, the limited crawl will likely have favored pages
with larger numbers of incoming links (e.g., how to crawl
pages with no incoming links?) leading us to overestimate
the mean indegree. To put these numbers in perspective,
Najork et al. [23] use a Web crawl of 464 million pages and
18 billion hyperlinks, and ﬁnd mean indegree of 6.10 and a
mean outdegree (not limited to pages in the crawl itself) of
38.11.

The Wikipedia collection is thus more densely linked. This
is surprising in the sense that the .GOV domain is much
older, and link density tends to increase over time [21, 22].
There are at least two eﬀects which help explain why the
Wikipedia link graph is more “complete” than the .GOV
link graph. First, due to the strongly structured nature of
Wikipedia and the existence of author guidelines, it is much
clearer for Wikipedia authors where to link to and when.
Second, due to peer editing and automatic link detection,
“missed” links will be added in a matter of time. With the
high link densities, we see a single giant component, i.e., a
large set of connected pages. The giant strongly connected
component (SCC) of the .GOV collection contains 912,794

234

V
O
G

.

a
i
d
e
p
i
k
i
W

V
O
G

.

a
i
d
e
p
i
k
i
W

V
O
G

.

a
i
d
e
p
i
k
i
W

Figure 1: Link indegree distribution of all pages (left), of relevant pages (middle) and prior probability of
relevance (right) for .GOV (top) and Wikipedia (bottom).

Figure 2: Link outdegree distribution of all pages (left), of relevant pages (middle) and prior probability of
relevance (right) for .GOV (top) and Wikipedia (bottom).

Figure 3: Article length distribution (left), relevant article length distribution (middle) and prior probability
of relevance (right) for .GOV (top) and Wikipedia (bottom).

235

 1 10 100 1000 10000 100000 1e+06 1 10 100 1000 10000 100000Number of articlesLink indegree 1 10 100 1000 1 10 100 1000 10000 100000Number of articlesLink indegree 0.0001 0.001 0.01 0.1 1 1 10 100 1000 10000 100000Probability of relevanceLink indegree 1 10 100 1000 10000 100000 1 10 100 1000 10000 100000Number of articlesLink indegree 1 10 100 1000 1 10 100 1000 10000 100000Number of articlesLink indegree 0.0001 0.001 0.01 0.1 1 1 10 100 1000 10000 100000Probability of relevanceLink indegree 1 10 100 1000 10000 100000 1e+06 1 10 100 1000Number of articlesLink outdegree 1 10 100 1 10 100 1000Number of articlesLink outdegree 0.0001 0.001 0.01 0.1 1 1 10 100 1000Probability of relevanceLink outdegree 1 10 100 1000 10000 100000 1 10 100 1000 10000Number of articlesLink outdegree 1 10 100 1000 1 10 100 1000 10000Number of articlesLink outdegree 0.0001 0.001 0.01 0.1 1 1 10 100 1000 10000Probability of relevanceLink outdegree 1 10 100 1000 10000 1 10 100 1000 10000 100000 1e+06Number of articlesArticle length 1 10 100 1000 1 10 100 1000 10000 100000Number of articlesArticle length 0.0001 0.001 0.01 1 10 100 1000 10000 100000 1e+06Probability of relevanceArticle length 1 10 100 1000 10 100 1000 10000 100000 1e+06Number of articlesArticle length 1 10 100 1000 10 100 1000 10000 100000 1e+06Number of articlesArticle length 0.0001 0.001 0.01 0.1 100 1000 10000 100000 1e+06Probability of relevanceArticle length(or 73.16%) documents and the giant weakly connected com-
ponent (WCC) contains 1,209,324 (or 96.92%). The gi-
ant SCC of the Wikipedia collection contains 605,952 (or
91.91%) and the giant WCC contains 657,601 (or 99.74%).
The WCC and especially the SCC of the Wikipedia collec-
tion contain a much larger part of the entire collection than
the SCC and WCC of the .GOV collection. For both the
.GOV and Wikipedia collection, the percentage of pages in
the SCC is considerably larger than in the large crawl of [4].
Soboroﬀ [27] ﬁnds that the .GOV collection structurally re-
sembles much larger web crawls but is very closely connected
due to either starting the crawl from a small number of seeds
or to the .gov domain being much more densely linked than
the Web in general. The Wikipedia collection is a complete
dump and the high link density, as also observed in [5], can-
not be a crawling artifact.

3.2 Degree Distributions

We now look at the indegree (the number of incoming
links) and the outdegree (the number of outgoing links).
More precisely, we count unique pages that link to a given
page, or are linked to by that page. If we look at the dis-
tribution of these degrees over the entire collections, in the
left of Figure 1 for indegree and Figure 2 for outdegree, we
see a power-law for all degree distributions. In .GOV, the
power-law distribution is especially clear for the indegrees
and less clear for the outdegrees. In Wikipedia, we see much
smoother distributions and surprisingly little diﬀerence be-
tween the incoming and outgoing links. This suggests that
outlinks in Wikipedia behave very much like inlinks. This is
consistent with a semantic nature of links in Wikipedia: if
a link from A to B means that B is relevant (in some sense)
to A, then it is also likely A is relevant (in some sense) to
B.

3.3 Relevant Link Distribution

Recall that we base our analysis on IR test collections and
hence also have available sets of search requests and associ-
ated sets of relevant pages. How are the link degrees of these
relevant pages distributed? For .GOV, we use the TREC
2004 Web track data consisting of 225 retrieval topics and
in total 1,763 relevant pages for .GOV. For Wikipedia, we
use the combined INEX 2006 and 2007 Ad Hoc track data,
consisting of 217 topics and in total 11,896 pages with rele-
vance. The INEX topics have relevance assessments on the
passage level, in this paper we only consider full Wikipedia
article retrieval and regard an article as relevant for a topic
if and only if some part of the article is judged relevant.

Since we are interested in generic query-independent fea-
tures, like the numbers of incoming or outgoing links, we
will simply accumulate all relevant pages over topics. We
will be stretching this argument to include features like the
local indegree amongst top ranked documents. Although
these degrees are not query-independent, and have to be
calculated speciﬁcally for a given topic at query time, they
are similar in character to global query-independent features
and will play a similar role in the retrieval models discussed
in Section 4.

The middle parts of Figures 1 (indegree) and 2 (outde-
gree) show the degree distributions over the relevant pages
(for any topic) of the collections. The indegree distribu-
tions still show a power-law, but the outdegrees—especially
in the .GOV collection—adhere less to a power-law distribu-

tion. It is not clear whether this is a true deviation from the
standard power-law distribution (since relevant documents
on average have a higher outdegree than non-relevant docu-
ments) or whether it is a consequence of the limited number
of relevant documents. The higher number of relevant pages
available in the Wikipedia collection also explains why these
curves are smoother than those of the .GOV documents.
What is interesting to see is that, for the Wikipedia collec-
tion, the outdegree distribution shows a clear upward trend
over relevant documents with the lowest degrees (between
1 and 10). Does this mean that documents with a higher
degree are more frequently relevant than documents with a
lower degree?

3.4 Prior Probability of Relevance

We will now analyse the prior probability of relevance of a
page with a particular degree. If the degrees of relevant doc-
uments deviate from the degrees of non-relevant documents
in the collection, they may possibly be used as indicators of
relevance. We have calculated the prior probability of rel-
evance as follows. The documents are sorted into bins of
equal size with ascending degree. Each bin contains 10,000
documents and the prior probability of relevance for these
documents is computed by dividing the number of relevant
documents in a bin by the total number of documents in that
bin. That is, the 10,000 documents with the lowest degrees
go into the ﬁrst bin, the next 10,000 in the second bin, etc.
Since there are many documents with an in- or outdegree of
0 or 1, they ﬁll up several bins. In calculating the degree
priors of these bins, we merge bins with the same maximal
degree and assign each of them the same prior.

The probabilities are shown on the right of Figures 1 (in-
degree) and 2 (outdegree). In the .GOV collection, the prob-
ability of a document being relevant increases with indegree.
For outdegree, the probability of relevance peaks somewhere
between 10 and 100 and then drops as the outdegree further
increases.

In the Wikipedia collection both in- and outdegree seem
to be good indicators of relevance: a higher degree corre-
sponds to a higher probability of relevance. Recall from
above that the fraction of reciprocal links in Wikipedia is
actually lower than that of .GOV; it is not a result of pages
linking back-and-forth. This, again, signals the diﬀerence in
the link structure of Wikipedia and the Web at large. For
the semantic links of Wikipedia, the diﬀerence between in-
coming and outgoing links seems to disappear and both can
be used as indicators of relevance.

3.5 Length

So far we have considered only link evidence. Another
type of evidence is document length. Figure 3 (left) shows
the length distribution for .GOV and Wikipedia. We see no
power-law distribution for .GOV and more of a log-normal
distribution for Wikipedia. The distribution of relevant pages
is too sparse to give an interpretable plot, and we crudely
bin it by rounding length to a single signiﬁcant digit. The
resulting plot is shown in Figure 3 (middle). The prior prob-
ability of relevance is calculated as the degree distributions
above, and shown in Figure 3 (right). For .GOV, there is
no evidence for the value of document length as indicator
of relevance. For Wikipedia, in contrast, the distribution
suggests that document length can be used as indicator of
relevance.

236

Table 2: Correlation between length and degrees for
Web and Wikipedia collections

Table 3: Titles with the highest indegrees in the
Wikipedia collection for INEX topic 339, “Toy Story”

Web

Wiki

Title

Variables
In
Out
Length

In Out Length
-0.01
-0.07
1.00

0.10
1.00
–

1.00
–
–

In Out Length
0.16
0.65
1.00

0.19
1.00
–

1.00
–
–

Test cricket
Nobel Prize in Physics
Sequel
1999 in ﬁlm
Jet Engine
Paciﬁsm
Unix-like
Portrait
Psychedelic music
Toy

Global Title

1,405 Toy Story

Local

557 Toy Story 2
529 Pixar
427 Buzz Lightyear
341 Cars (ﬁlm)
339 Toy Story 3
339
339
339
331

John Ratzenberger
John Lasseter
Sheriﬀ Woody
1755 Lisbon earthquake

33
22
20
8
6
6
5
5
5
3

where each of the document language models is estimated
as above [13].

4.2 Baseline

For the mixture model run, all three models are weighted
the same with λ1 = λ2 = λ3 = 0.1. For the Ad Hoc Wikipe-
dia task we use a standard language model run, with the de-
fault smoothing parameter setting λ = 0.15. We performed
the experiments discussed below against two baselines with
or without a length prior and found the same qualitative
patterns. Below, we will show only the experiment against
the highest scoring baseline, which is without length prior
for the Web and with length prior for the Wikipedia (as was
already suggested by Figure 3).

4.3 Link Evidence as Document Priors

We use global and local link evidence, which we will il-
lustrate by discussing in detail two topics. Wikipedia topic
339 has title Toy Story and is about the computer animated
movie from 1995.
.GOV topic 119 has as title Groundhog
day Punxsutawney and is about a celebration day in Punx-
sutawney, where groundhog Phil makes a weather forecast
for the whole year.

We ﬁrst look at global degrees, i.e. the total number of
incoming links, or outgoing links for a page. To illustrate the
eﬀect of global degrees, we took the top 1,000 articles from
the baseline run described above and list the 10 articles with
the highest global indegree in Table 3 (left hand side) for
Wikipedia and in Table 4 (left hand side) for .GOV. What
we see is that some pages with little bearing on the topic at
hand, for example the page on Toys in the case of Wikipedia,
have a very high global indegree, but most pages have no
relation to the topic at all. The same holds for the .GOV
pages. The only slightly related page is National Weather
Service Forecast Oﬃce - Memphis, TN. All the other pages
seem to be entirely unrelated to the topic, yet could inﬁltrate
the top ranks when too much weight is put on the degrees.
Hence, we also look at local degrees, i.e. the number of
incoming or outgoing links between the top 100 pages ac-
cording to the query-based retrieval score. To illustrate the
eﬀect of local degrees, we also list the 10 articles with the
highest local indegree in Table 3 (right hand side) for Wi-
kipedia and in Table 4 (right hand side) for .GOV. We see
that the local degrees keep better focus on the topic of re-
quest, although local links are also sparser and just a few
local links are all it takes to inﬁltrate the lower ranks.

For practical reasons, we implement the global document
priors to the top 1,000 retrieved pages and the local docu-
ment priors to the top 100 pages based on the content scores.

Document length might actually be correlated to the link
degree. Naively, we would expect that a document with
many links going out is longer than a document with very
few links going out. How is the length of documents re-
lated to the link degree? Moreover, we have seen above
similar behavior for Wikipedia indegree and outdegree: how
do these correlate? Table 2 gives the correlation between
the indegrees, the outdegrees and the document length for
both collections. For .GOV, we see a low correlation be-
tween indegree and outdegree and no correlation between
length and the degrees. For Wikipedia, we see a low corre-
lation between indegree and outdegree and between length
and indegree. However, there is a strong correlation between
outdegree and document length in the Wikipedia collection.
This makes sense, since pages containing more textual con-
tent will naturally give rise to more links inside Wikipedia.

4.

INCORPORATING LINK EVIDENCE

In this section, we will discuss how link evidence can be

incorporated in a state-of-the-art retrieval model.

4.1 Retrieval Model

We use a language model where the score for a document

d given a query q is calculated as:

P (d|q) = P (d) · P (q|d)

(1)

where P (q|d) can be viewed as a query generation process—
what is the chance that the query is derived from this docu-
ment—and P (d) a document prior that provides an elegant
way to incorporate link evidence and other query indepen-
dent evidence [12, 18].1

We estimate P (q|d) using Jelinek-Mercer smoothing against

the whole collection, i.e., for a collection D, document d and
query q:

P (q|d) =

((1 − λ) · P (t|D) + λ · P (t|d)) ,

(2)

Y

t∈q

where

P (t|d) =

P (t|D) =

freq(t, d)

|d|

freq(t, D)
P
d0∈D |d0|

(3)

(4)

For the Web collection, we use a mixture language model
over three document representations: document text, in-
coming anchor texts and title ﬁeld, i.e., for a collection D,
document d and query q:

P (q|d) = Q

t∈q((1 − λ1 − λ2 − λ3) · P (t|D)

+λ1 · Pdoc(t|d) + λ2 · Panchor(t|d) + λ3 · Ptitle(t|d)),

1Note that we are ranking here documents given a query
and can use this simpliﬁed version instead of the Bayesian
P (d|q) = (P (d) · P (q|d))/P (q).

237

Table 4: Titles with the highest indegrees in the .GOV collection for TREC topic 119, “Groundhog day
Punxsutawney”

Title
Site Map
Online Library - HUD
Bureau of Labor Statistics Home Page
AMS - Search
The United States Mint
NHGRI: In The News
Metadata Records By Catalog Title
FCC Universal Licensing System
The Embassy of the U.S.A., Ottawa - Canada - United
States Relations
National Weather Service Forecast Oﬃce - Memphis, TN

Global Title

3,119 Bureau of Labor Statistics Home Page
2,119 NTP Meetings & Events
1,119 Recalls and other Press Releases

730 What’s New
722 NCDC: Climate of 2001 - Climate Perspectives Reports
518 Youth Opportunity Movement Highlights
448 California Department of Motor Vehicles home page
348 Washington State Senate Democratic Caucus Home Page
256 Conferences and Events in California related to the Career

Development and Curriculum Leadership Unit

249 Hewitt celebrates Groundhog Day with ‘shadow’

from

2

Columbia High School

Local
61
58
5
3
3
3
2
2
2

That is, we compute the new score by multiplying the con-
tent score with the link degree prior.

First, we use a standard degree prior by multiplying the

retrieval score with 1+ the degree:

Pstandard(d) ∝ 1 + degree(d).

Here, the degree score for a page may be based on either
local or global, and either indegree or outdegree (leading to
four logical cases). We will, for convenience, refer to the link
evidence as prior, even though we do not actually transform
it into a probability distribution. Note that we can turn any
prior into a probability distribution by multiplying it with
Σd∈D prior(d) , leading to the same ranking.
a constant factor
Second, we use a log degree prior using the logarithm of

1

the degrees:

Plog(d) ∝ 1 + log(1 + degree(d)).

The logged degree values will reduce the impact of the de-
grees and hence may act as a safe-guard against the inﬁltra-
tion of loosely related pages with very high (global) degrees.
Again, the degree score may be based on local /global and
in-/outdegree.

In earlier work on XML element retrieval [14], we found
that weighting the local degree (the number of links to or
from pages in the relevant set) by the global degree (the
number of links to or from arbitrary pages) keeps more focus
on the topic by removing inﬁltrations in the local set from
pages with very high global degree. This is similar to the
well-known tf.idf weighting scheme used to determine term
importance. Our third prior is a combination of the global
and local link evidence computed as:

PLocGlob(d) ∝ 1 +

degreelocal(d)

1 + degreeglobal(d)

.

For the degree score we may take either indegree or outde-
gree. For the combined LocGlob prior, the logged version
uses only the log of the global degree.

5. EXPERIMENTS

In this section we experiment with using both indegree
and outdegree evidence, either with the standard or log in-
degree priors. First we will discuss the experiments with
the link evidence on the Web collection, then on the Wiki-
pedia collection. The Web collection uses the TREC 2004
Web track data: a mixed query set of 225 topics in equal
fractions of topic distillation, home page ﬁnding and named-
page ﬁnding topics. Here the known-item search topics tend

to have a single relevant document (possibly more due to
duplicates in the collection), and the distillation topics tend
to have a larger set of key results.2 The Wikipedia collection
uses the combined INEX 2006 and 2007 Ad hoc track data:
a set of 217 ad-hoc retrieval topics, and much larger sets of
topically relevant documents. The tables show Mean Av-
erage Precision (MAP) and Mean Reciprocal Rank (MRR)
scores. In our discussion we will mainly focus on MAP.

5.1 Length Prior

We choose our baseline runs based on experiments with
the document length priors. In line with the plots showing
the probability of relevance over document length, the best
run for the Web track collection uses no length prior (MAP
drops from 0.3970 to 0.3419 when using the length prior,
MRR drops from 0.4662 to 0.3868), whereas the best run for
the Wikipedia collection uses a document length prior (MAP
goes up from 0.2544 to 0.3069, MRR goes up from 0.6923
to 0.8102). We choose these best runs as baseline runs for
the experiments with the link priors. Note that the higher
MAP for the Web data can be attributed to diﬀerences in
the tasks, with a large fraction of known-item search topics
used on the Web collection.

5.2 Web

Table 5 shows the results for the link prior runs on the
Web track collection. We tested all the runs for the signif-
icance of the increase or decrease in performance over the
baseline using the bootstrap test, one-tailed, using 100,000
resamples. We report three signiﬁcance levels, p<.05 (◦),
p<0.01 (•◦) and p <0.001 (•).

If we look at the global degree prior, columns 2 (MAP)
and 5 (MRR), we see signiﬁcant improvements for both in-
and outdegree. The indegree prior leads consistently to a
greater improvement than the outdegree, which is in line
with the probability of relevance plots in Figures 1 and 2.
For the logged version we see a similar pattern.
Indegree
works better than outdegree, but the scores are lower than
with the standard priors.

The results for the local priors are given in columns 3 and
6. Again, the indegree is more eﬀective than the outdegree.
If we compare the local with the global priors, we see that the

2TREC experiments on Web data failed to establish the
eﬀectiveness of link evidence for general ad hoc retrieval [11].
Since we want to compare the impact of link evidence in
Wikipedia with that on Web data, we focus on a web-centric
retrieval task where link evidence is known to be eﬀective.

238

Table 5: Results of the diﬀerent link priors over in- and outdegree on the 225 topics of the Web track
collection

Table 6: Results of the diﬀerent link priors over in- and outdegree on the 217 topics of the Wikipedia collection

Run id Glob
baseline
in
out
log.in
log.out

0.4738•
0.4299•◦
0.4449•
0.4082•◦

Run id Glob
baseline
in
out
log.in
log.out

0.3018-
0.3016-
0.2865-
0.2890-

MAP
Loc
0.3970
0.4799•
0.4497•
0.4410•
0.4181•

MAP
Loc
0.3090
0.3190•◦
0.3199•
0.3176•
0.3156•

Loc/Glob

Glob

Loc/Glob

0.3966•
0.4042•
0.4395•
0.4289•

0.5885•
0.5046•
0.5209•
0.4789•

0.3140•◦
0.3123•◦
0.3234•
0.3203•

0.8139-
0.8262-
0.8322◦
0.8291•◦

MRR
Loc
0.4662
0.5655•
0.5199•
0.5148•
0.4879•

MRR
Loc
0.8121
0.8236-
0.8266-
0.8289◦
0.8225◦

0.4646•
0.4744•
0.5101•
0.4913•

0.8161-
0.8119-
0.8263-
0.8211-

Loc/Glob

Glob

Loc/Glob

Run id
baseline
Authority 100
Authority 200
Authority 100 prior
Authority 200 prior
Hub 100
Hub 200
Hub 100 prior
Hub 200 prior

Web

All links

Transverse

Wikipedia
All links

MAP MRR MAP
0.3970
0.3970
0.1014•
0.0391•
0.0348•
0.0601•
0.3960-
0.4056•
0.3958-
0.3990◦
0.0219•
0.0163•
0.0165•
0.0127•
0.3994-
0.3967-
0.3963-
0.4009-

0.4662
0.0638•
0.0571•
0.4657-
0.4656-
0.0303•
0.0207•
0.4663-
0.4662-

MRR MAP MRR
0.8121
0.4662
0.1063•
0.1801•
0.1262•
0.0803•
0.7982-
0.4758•◦
0.7987-
0.4690•◦
0.1161•
0.0495•
0.0585•
0.0337•
0.7990-
0.4687-
0.4706-
0.7955-

0.3090
0.0106•
0.0061•
0.2766•
0.2740•
0.0135•
0.0054•
0.2773•
0.2755•

Table 7: Results of HITS runs on the Web track collection (using all links or using only transverse links) and
on the Wikipedia collection

local degree priors tend to lead to a higher MAP, while the
global degree priors tend to lead to a higher MRR. In other
words, the global priors are more eﬀective for improving
early precision, while the local priors are more eﬀective for
overall precision.

The combined local/global priors are much less eﬀective.
Only the combined outdegree priors lead to a very small
improvement for both MAP and MRR, while indegree priors
lead to small decreases in performance. The logged version
fares somewhat better, with signiﬁcant improvements in all
cases.

In sum, the outdegree is clearly the least eﬀective of the
two degrees, whether used as a standard or log prior and
whether evaluated by MAP or MRR. For global link and
local link evidence, the standard prior works better than
the logged prior. The global priors are most eﬀective for
early precision, while the local priors are most eﬀective for
MAP.

5.3 Wikipedia

Now, we move to the Wikipedia collection and experi-
ment with the degree priors on the ad hoc topic set. Table 6
shows the results for the baseline and reranked runs on the
Wikipedia collection. The second (MAP) and ﬁfth (MRR)
columns show the results for the global prior. We see that
the global prior has a small positive eﬀect on MRR, but a
negative eﬀect on MAP. For the standard prior, none of the
diﬀerences are signiﬁcant. The positive eﬀect on MRR and
the negative eﬀect on MAP are stronger for the logged prior

and the improvements for MRR are signiﬁcant. The global
prior can be used to improve early precision, but is not ef-
fective for pushing up the lower scoring relevant documents.
There seems to be little diﬀerence between using either in- or
outdegree priors, as the scores are very close to each other.
The local prior results are in columns three and six. Like the
global prior, the local prior improves early precision, but also
boosts the MAP scores. The standard prior is more eﬀective
for MAP, while the logged prior is more eﬀective for MRR.
While the standard local degree priors generally lead to a
higher score than the log local degree priors, the log prior
improvements are more signiﬁcant. The local outdegrees
priors seem to perform at least as well as the local indegree
priors.The standard combined local/global prior (columns 4
and 7) shows signiﬁcant improvements for MAP, but the im-
provements are less than those of the standard local prior.
For MRR the combined priors have very little eﬀect. When
we use the logged version, the MAP scores improve further,
leading to the highest MAP scores overall.

To sum up, when using link degrees for reranking results in
the Wikipedia collection, both incoming and outgoing links
can be used as evidence but—compared to the Web track
collection—we have to be more careful when using it. The
global degrees alone seem to be ineﬀective for improving ad
hoc retrieval results, leading only to improvements in early
precision. The more informed local degree priors fare much
better, with a signiﬁcant improvement in MAP for ad hoc
retrieval. The even more careful, weighted local/global prior
can further improve MAP when using the log of the global

239

degree.

5.4 HITS

We also look at the eﬀectiveness of HITS [16]. Given that
the local degrees tend to be more eﬀective on Wikipedia than
the global degrees, we expect HITS to be more eﬀective than
PageRank [25]. Speciﬁcally, we look at the HITS authority
and hub scores in isolation and using them as a prior:

PHITS(d) ∝ 1 + HITS(d).

We use an initial base set of either 100 or 200 top ranked
pages and expand it with pages linking to a page in the base
set (maximally 50 pages per page in the base set) and with
all pages linked to from a page in the base set. In Wikipedia
most links are to semantically related pages, but on the Web
links may exist for a variety of reasons. We can try to distin-
guish between intrinsic web links (for example, navigational
links within a site) and transverse web links (for example, a
link to related content on a diﬀerent site). We ﬁrst identiﬁed
the site of a page as its base URL, with the removal of any
preﬁx starting with www and excluded links between pages
within the same domain. We further reduced the set by re-
moving links between base URLs when either is a substring
of the other. For example, a link between www.nih.gov and
www.nlm.nih.gov regarded as intrinsic, while a link between
www.nlm.nih.gov and www.nichd.nih.gov is regarded as
transverse. The resulting set of transverse links contains
1,693,477 links (or 15% of all links). For the Web collection,
we use either the full link graph, or the transverse links. We
used the transverse link graph for the degree priors above
as well, but while they improve performance, using the full
link graph is much more eﬀective.

The results for the HITS runs are shown in Table 7. What
we see is the following: On the Web collection, HITS hubs
or authorities alone perform poorly when compared to the
baseline, although authorities do much better than hubs.
The transverse links are more eﬀective than the full link
graph, which fails to improve upon the baseline. However,
the improvements with the transverse links are still much
lower than with the earlier discussed link degree priors. When
using HITS the transverse link graph is more useful. We
also did the experiments in Section 5.2 for the transverse
link graph (not reported here) and found out that the full
link graph is more eﬀective than the transverse link graph
for the indegree priors.

On the Wikipedia collection we also see that the HITS
scores alone perform well below the baseline. Interestingly,
the hubs (based on outgoing links) are performing better
than the authorities (based on incoming links). In Wikipe-
dia, the nature of the incoming and outgoing links is similar
making the diﬀerence between hubs and authorities disap-
pear. The results also show that using more results in the
base set quickly leads to topic drift and lower performance.

6. DISCUSSION AND CONCLUSIONS

In this paper, we investigated the diﬀerence between Wi-
kipedia and Web link structure. We ﬁrst performed a com-
parative analysis of Wikipedia and .GOV link structure and
then investigated the value of link evidence for improving
search on Wikipedia and on .GOV. Our experimental ev-
idence is from two IR test-collections consisting of docu-
ments, a large set of search requests and associated rele-
vance judgments. The ﬁrst is the .GOV collection used at

the TREC Web tracks consisting of a crawl of the .gov do-
main. The second is the Wikipedia XML Corpus used at
INEX consisting of a XML’iﬁed dump of the English Wiki-
pedia.

In our comparative analysis of Wikipedia and Web link

structure we hoped to ﬁnd out:

• What is the degree distribution of Wikipedia and the

Web at large?

• Are there diﬀerences between distributions of incoming

and outgoing links?

• How does the link topology relate to the relevance of

retrieval results?

Analysis of the link structures of the .GOV and Wikipedia
collections shows that the Wikipedia pages are more densely
interlinked and that their outdegree distribution is much
more similar to the indegree distribution than the .GOV
pages. The .GOV collection has a giant strong connected
component larger than general web crawls, but the giant
strong connected component of Wikipedia covers an even
larger part of the collection.

For the .GOV collection, the global indegree is a good in-
dicator of relevance. Pages with many incoming links have a
higher probability of being relevant than pages with few in-
coming links. The prior probability of relevance of the num-
ber of outgoing links is ﬁrst increasing but then drops again,
making the outdegree a less clear indicator of relevance than
the indegree. For the Wikipedia collection, both indegree
and outdegree are good indicators of relevance. More gen-
erally, we observe that Wikipedia inlinks and outlinks are
similar in character, leading to the conﬂation of the notions
of authority and hub [16].

In our retrieval experiments, we hoped to ﬁnd an answer

to the following questions:

• How can global or local link evidence be incorporated

in our information retrieval models?

• What is the impact of link evidence on Web and Wi-
kipedia retrieval? And, in particular, does it lead to
improvement of retrieval eﬀectiveness?

The language modelling framework allows for easy incorpo-
ration of document priors and we have experimented with
diﬀerent priors using the link degrees as evidence.

For the Web track collection, all global and local outde-
gree priors are less eﬀective than the corresponding indegree
priors. The Web task requires high precision, the global de-
gree prior is eﬀective to achieve this and no curbing is nec-
essary. The indegree leads to greater improvements than
the outdegree, supporting the claim that document impor-
tance is a major aspect in Web retrieval. The local degrees
are still very eﬀective for improving early precision, but are
even more eﬀective for general precision. The combined lo-
cal/global evidence is less eﬀective.

For the Wikipedia collection, the outdegree priors behave
very similar to the indegree priors. The brute force of the
global degree priors is too much for the task of ad hoc re-
trieval. Even the more subtle log degree prior is not eﬀective
for MAP. As in the Web collection, adding global link ev-
idence can improve early precision, but hurts performance
at lower ranks. The local degrees stay more on topic and

240

can improve early and later precision. The even more sub-
tle, log version of the combined local/global indegree prior is
most eﬀective, showing that link evidence has to be carefully
weighted and made sensitive to the local context.

[16] J. M. Kleinberg. Authoritative sources in a hyperlinked
environment. Journal of the ACM, 46(5):604–632, 1999.
[17] W. Kraaij and T. Westerveld. How diﬀerent are web
In TREC-9. NIST Special Publication,

documents?
May 2001.

[18] W. Kraaij, T. Westerveld, and D. Hiemstra. The im-
portance of prior probabilities for entry page search. In
SIGIR 2002, pages 27–34. ACM Press, 2002.

[19] R. Kumar, P. Raghavan, S. Rajagopalan,

and
A. Tomkins. Trawling the web for emerging cyber-
communities. In WWW8, pages 403–415. Elsevier Sci-
ence, Amsterdam, 1999.

[20] S. Lawrence and C. L. Giles. Accessibility of informa-

tion on the web. Nature, 400:107–109, 1999.

[21] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs
over time: densiﬁcation laws, shrinking diameters and
possible explanations.
In KDD ’05: Proceedings of
the eleventh ACM SIGKDD international conference
on Knowledge discovery in data mining, pages 177–187.
ACM Press, New York, NY, USA, 2005.

[22] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graph
evolution: Densiﬁcation and shrinking diameters. ACM
Transactions on Knowledge Discovery from Data, 1(1):
2, 2007.

[23] M. A. Najork, H. Zaragoza, and M. J. Taylor. HITS on
the Web: How does it compare? In SIGIR ’07, pages
471–478. ACM, New York, NY, USA, 2007.

[24] P. Ogilvie and J. Callan. Combining document repre-
sentations for known-item search. In SIGIR 2003, pages
143–150. ACM Press, 2003.

[25] L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: Bringing order to the web.
Technical report, Stanford Digital Library Technologies
Project, 1998.

[26] J. R. Seeley. The net of reciprocal inﬂuence. Canadian

Journal of Psychology, 3:234–240, 1949.

[27] I. Soboroﬀ. Do trec web collections look like the web?

SIGIR Forum, 36:23–31, 2002.

[28] J. Voss. Measuring wikipedia. In ISSI 2005, 2005.
[29] S. Wasserman and K. Faust. Social Network Analysis:
Methods and Applications, volume 8 of Structural Anal-
ysis in the Social Sciences. Cambridge University Press,
Cambridge MA, 1994.

[30] T. Westerveld, D. Hiemstra, and W. Kraaij. Retriev-
ing web pages using content, links, URL’s and anchors.
In The Tenth Text Retrieval Conference, TREC-2001,
pages 52–61, May 2002.

7. ACKNOWLEDGMENTS

Jaap Kamps was supported by the Netherlands Organi-
zation for Scientiﬁc Research (NWO, grants # 612.066.513,
639.072.601, and 640.001.501), and by the E.U.’s 6th FP for
RTD (project MultiMATCH contract IST-033104). Marijn
Koolen was supported by NWO (# 640.001.501).

8. REFERENCES

[1] B. Amento, L. Terveen, and W. Hill. Does ‘authority’
mean quality? predicting expert quality ratings of web
documents. In SIGIR 2000, pages 296–303. ACM Press,
2000.

[2] A.-L. Barab´asi and R. Albert. Emergence of scaling in

random networks. Science, 286:509–512, 1999.

[3] F. Bellomi and R. Bonato. Network analysis for wiki-

pedia. In Proceedings of Wikimania, 2005.

[4] A. Broder, R. Kumar, F. Maghoul, P. Raghavan, S. Ra-
jagopalan, R. Stata, A. Tomkins, and J. Wiener. Graph
structure in the web. In WWW9, pages 309–320. Else-
vier Science, Amsterdam, 2000.

[5] L. S. Buriol, C. Castillo, D. Donato, S. Leonardi, and
S. Millozzi. Temporal analysis of the wikigraph. In WI
’06: Proceedings of the 2006 IEEE/WIC/ACM Inter-
national Conference on Web Intelligence, pages 45–51.
IEEE Computer Society, Washington, DC, USA, 2006.
[6] N. Craswell, D. Hawking, and S. Robertson. Eﬀective
In SIGIR

site ﬁnding using link anchor information.
2001, pages 250–257. ACM Press, 2001.

[7] N. Craswell, S. Robertson, H. Zaragoza, and M. Taylor.
Relevance weighting for query independent evidence. In
SIGIR ’05, pages 416–423. ACM, New York, NY, USA,
2005.

[8] L. Denoyer and P. Gallinari. The Wikipedia XML Cor-

pus. SIGIR Forum, 40(1):64–69, June 2006.

[9] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On power-
In SIG-

law relationships of the internet topology.
COMM ’99, pages 251–262. ACM Press, 1999.

[10] D. Hawking. Overview of the trec-9 web track.

In

TREC, 2000.

[11] D. Hawking and N. Craswell. Very large scale retrieval
and web search. In E. Voorhees and D. Harman, edi-
tors, TREC: Experiment and Evaluation in Information
Retrieval, chapter 9. MIT Press, 2005.

[12] D. Hiemstra. Using Language Models for Information
Retrieval. PhD thesis, Center for Telematics and Infor-
mation Technology, University of Twente, 2001.

[13] J. Kamps. Web-centric language models. In CIKM’05,

pages 307–308. ACM Press, 2005.

[14] J. Kamps and M. Koolen. The importance of link
evidence in Wikipedia.
In Advances in Information
Retrieval: 30th European Conference on IR Research
(ECIR 2008), volume 4956 of Lecture Notes in Com-
puter Science, pages 270–282. Springer Verlag, Heidel-
berg, 2008.

[15] L. Katz. A new status index derived from sociometric

analysis. Psychometrika, 18:39–43, 1953.

241

