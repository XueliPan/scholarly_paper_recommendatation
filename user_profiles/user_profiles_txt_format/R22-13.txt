Combining Source-to-Source Transformations and Processor
Instruction Set Extensions for the Automated Design-Space

Exploration of Embedded Systems

Richard Vincent Bennett

Alastair Colin Murray

Bj¨orn Franke

Nigel Topham

University of Edinburgh
School of Informatics

Institute for Computing Systems Architecture (ICSA)

{r.v.bennett,a.c.murray}@sms.ed.ac.uk

{bfranke,npt}@inf.ed.ac.uk

Abstract
Industry’s demand for ﬂexible embedded solutions providing high
performance and short time-to-market has led to the develop-
ment of conﬁgurable and extensible processors. These pre-veriﬁed
application-speciﬁc processors build on proven baseline cores
while allowing for some degree of customization through user-
deﬁned instruction set extensions (ISE) implemented as functional
units in an extended micro-architecture. The traditional design ﬂow
for ISE is based on plain C sources of the target application and, af-
ter some ISE identiﬁcation and synthesis stages, a modiﬁed source
ﬁle is produced with explicit handles to the new machine instruc-
tions. Further code optimization is left to the compiler. In this paper
we develop a novel approach, namely the combined exploration of
source-level transformations and ISE identiﬁcation. We have com-
bined automated code transformation and ISE generators to explore
the potential beneﬁts of such a combination. This applies up to 50
transformations from a selection of 70, and synthesizes ISEs for
the resulting code. The resulting performance has been measured
on 26 applications from the SNU-RT and UTDSP benchmarks.
We show that the instruction extensions generated by automated
tools are heavily inﬂuenced by source code structure. Our results
demonstrate that a combination of source-level transformations and
instruction set extensions can yield average performance improve-
ments of 47%. This outperforms instruction set extensions when
applied in isolation, and in extreme cases yields a speedup of 2.85.

Categories and Subject Descriptors B.8 [Performance and Re-
liability]: Performance Analysis and Design Aids; C.3 [Special-
Purpose and Application-Based Systems]: Real-time and embed-
ded systems; D.3.4 [Processors]: Optimization

General Terms Design, Performance

Keywords Customizable Processors, ASIPs, Source-Level Trans-
formations, Compilers, Instruction Set Extension, Design Space
Exploration

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior speciﬁc permission and/or a fee.
LCTES’07
Copyright c(cid:13) 2007 ACM 978-1-59593-632-5/07/0006. . . $5.00

June 13–15, 2007, San Diego, California, USA.

Introduction

1.
High performance and short time-to-market are two of the major
factors in embedded systems design. The goal is to deliver the best
performance for a given cost and with the shortest possible design
time. In recent years, processor IP vendors have addressed these
goals by developing conﬁgurable and extensible processors such
as the ARC 600 and 700, Tensilica Xtensa, ARM OptimoDE, and
the MIPS Pro series. These cores provide system designers with
pre-veriﬁed solutions, thus reducing risk involved in and cost of a
new processor design. Also offered are large degrees of ﬂexibil-
ity through custom-speciﬁc instruction set extensions (ISE), which
may help improve performance of compute-intensive kernels. As a
result of this specialization an optimized application-speciﬁc pro-
cessor is derived from a generic processor template.

In order to explore different ISEs during the design stage and
to trade off various, partially contradictory design goals (e.g. per-
formance, power, chip area) tool support is indispensable. Exist-
ing commercial (e.g. [1]) and academic (e.g. [2]) tools analyze an
application written in C, identify candidate instruction templates,
modify the application’s source code and insert handles to the
newly created instructions. In general, the overall effectiveness of
this approach depends on the designer’s ability to generate com-
plex instruction templates that (a) can replace a sufﬁciently large
number of simple machine instructions, (b) are frequently executed
and (c) can be efﬁciently implemented. This paper addresses prob-
lems (a) and (b), and we show that the selection of “good” instruc-
tion templates is strongly dependent on the shape of the C code
presented to ISE generation tool. We propose a novel methodol-
ogy that combines the exploration of high-level program transfor-
mations and low-level instruction templates. Using a probabilistic
search algorithm and a source-level transformation tool we gener-
ate many different – but semantically equivalent – versions of the
input program. We present all of these generated programs to an
integer linear programming (ILP) based ISE tool. For each pro-
gram a set of new instructions is generated along with proﬁling
based estimates of the execution time and code size resulting from
the exploitation of the new instructions. Using such an approach
we achieve remarkable performance improvements – on average a
1.47x speedup across 26 computationally intensive embedded ap-
plications. We demonstrate that our approach enables the genera-
tion of more powerful ISEs, unachievable by traditional techniques,
with no additional ISE tool effort.

83{

}

{

u n s i g n e d s h o r t

i c r c 1 ( u n s i g n e d s h o r t c r c ,

u n s i g n e d char o n e c h )

i ;

i n t
u n s i g n e d s h o r t a n s = ( c r c ˆ o n e c h << 8 ) ;

f o r ( i = 0 ; i <8; i ++) {
( a n s & 0 x8000 )

i f

a n s = ( a n s <<= 1 )

ˆ 4 1 2 9 ;

e l s e

a n s <<= 1 ;

}
r e t u r n a n s ;

u n s i g n e d s h o r t

i c r c ( u n s i g n e d s h o r t c r c ,

u n s i g n e d l o n g l e n ,
s h o r t

j i n i t

i n t

,

j r e v )

/ ∗ Some v a r i a b l e d e c l a r a t i o n s ∗ /
/ ∗

. . .

∗ /

i f

( ! i n i t ) {

i n i t = 1 ;
f o r ( j = 0 ; j <=255; j ++)
{

i c r c t b [ j ] = i c r c 1 ( j << 8 , ( u c h a r ) 0 ) ;
r c h r [ j ] = ( u c h a r ) ( i t [ j & 0xF ] << 4 |

i t [ j >> 4 ] ) ;

}

}

i f

( j i n i t >= 0 )

cword = ( ( u c h a r )

j i n i t )

|

( ( ( u c h a r )

j i n i t ) << 8 ) ;

e l s e
i f

( j r e v < 0 )

cword = r c h r [ HIBYTE ( cword ) ]

|
r c h r [LOBYTE( cword ) ] << 8 ;

f o r ( j = 1 ; j <=l e n ; j ++)
{

i f

( j r e v < 0 )

tmp1 = r c h r [ l i n [ j ] ] ˆ HIBYTE ( cword ) ;

tmp1 = l i n [ j ] ˆ HIBYTE ( cword ) ;

cword = i c r c t b [ tmp1 ]

ˆ LOBYTE( cword ) << 8 ;

e l s e

}

i f

( j r e v >= 0 )

tmp2 = cword ;

e l s e

tmp2 = r c h r [ HIBYTE ( cword ) ]

|

r c h r [LOBYTE( cword ) ] << 8 ;

r e t u r n ( tmp2 ) ;

}

i c r c 1 ( u n s i g n e d s h o r t c r c ,

/ ∗ . . . ∗ / )

( a n s & 0 x8000 ) a n s = ( a n s <<= 1 )

ˆ 4 1 2 9 ;

u n s i g n e d s h o r t
{

/ ∗ . . . ∗ /

/ ∗ Loop u n r o l l i n g ∗ /
f o r ( i = 0 ; i <8; i +=2) {

i f
e l s e a n s <<= 1 ;
/ ∗ . . . ∗ /

}
r e t u r n a n s ;

}

u n s i g n e d s h o r t
{

/ ∗ . . . ∗ /

i c r c ( u n s i g n e d s h o r t c r c ,

/ ∗ . . . ∗ / )

/ ∗ B i t p a c k i n g ∗ /
s u i f

t m p = ( cword / ∗ . . . ∗ / )

|
/ ∗ . . . ∗ / ) >> / ∗ . . . ∗ /

( j i n i t
( j r e v & / ∗ . . . ∗ / ) >> / ∗ . . . ∗ /
( l e n & / ∗ . . . ∗ / ) >> / ∗ . . . ∗ / ;

|

|

cword = 1u & s u i f

t m p ;

i f

( ! i n i t ) {

i n i t = 1 ;
/ ∗ Loop l o w e r i n g ∗ /
j = 0 ;
do {

/ ∗ C o m p u t a t i o n o f
} w h i l e ( j <= 2 5 5 ) ;

}
/ ∗ B i t u n p a c k i n g ∗ /
( 0 <= ( ( 2 u & s u i f
i f

cword = ( ( 2 u & s u i f

t m p ) >> 1u ) )
t m p ) >> 1u )

|

( ( ( 2 u & s u i f

t m p ) >> 1u ) << 8u ) ;

( ( ( 4 u & s u i f

t m p ) >> 2u ) < 0 )

cword = / ∗ . . . ∗ /

i c r c t b & r c h r

. . . ∗ /

( 1 u l <= ( ( 8 u & s u i f

t m p ) >> 3u ) ) {

/ ∗ Move l o o p i n v a r i a n t
i f

( ( ( 4 u & s u i f

t m p ) >> 2u ) < 0 ) {

c o n d i t i o n a l s ∗ /

/ ∗ Loop l o w e r i n g ∗ /
do {

/ ∗ C o m p u t a t i o n o f cword . . .

∗ /

} w h i l e ( j <= ( ( 8 u & s u i f

t m p ) >> 3u ) ) ;

/ ∗ S i m i l a r

l o w e r e d l o o p a s b e f o r e

. . .

∗ /

e l s e
i f

j = 1 ;
i f

}
e l s e {

}

}

( 0 <= ( 4 u & s u i f

i f
e l s e tmp2 = / ∗ . . . ∗ / ;

t m p ) >> 2u )

tmp2 = cword ;

r e t u r n tmp2 ;

}

(a) Original SNU-RT CRC implementation

(b) CRC after transformation

Figure 1. Original SNU-RT CRC implementation (a) and after application of source-level transformations resulting in best combined
performance (b).

1.1 Motivating Example

As an example, consider the code excerpt in ﬁgure 1(a). The two
functions icrc1 and icrc are part of the SNU-RT CRC benchmark
and implement a cyclic redundancy check for an input string stored
in the array lin[]. The key features of the code are small for loops in
both functions, which contain conditional branches and perform a
larger number of bit-level manipulation operations. Presented with
this plain code current instruction set extension technology (see
Section 4) generates new instruction templates, which result in a
25% performance improvement over the baseline code.

In ﬁgure 1(b) the main differences due to source-level transfor-
mations of the code in ﬁgure 1(a) are shown. While the code is
functionally equivalent, it outperforms the code in ﬁgure 1(a) by a
factor of 1.63. Loop unrolling has been applied to the for loop in the
icrc1 function. This reduces the loop overhead and improves ﬂexi-
bility for instruction scheduling. In the icrc function the effects of
source-level transformation are more fundamental. for loops in the
code have been lowered into do-while loops and, most important,
bit-packing and hoisting of loop invariant conditionals transforma-
tions have been applied. Bit-packing packs multiple variables into
a single variable of type integer and, on its own, usually degrades
performance. When combined with ISE generation, however, oth-
erwise expensive bit-level manipulation operations for packing and
unpacking can be encoded as complex, but fast instructions and
yield an overall performance improvement. In fact, the instruction
templates generated for example 1(b) are generally more complex
than those generated from the baseline code. An example of such
an instruction is shown in ﬁgure 1 and it implements the mentioned
packing/unpacking operation. Moving loop invariant conditional
outside the loop eliminates redundant comparisons and jumps and
further increases performance.

ISE generation based on the transformed code in ﬁgure 1(b)
result in a further 23% improvement (over just transformed code),
or a total combined speedup of 2.02x over the baseline. Only a
certain part of the performance gain can be directly attributed to
code transformations, the rest is due to the enabling effect of the
source-level transformations on the ISE generation.

This short example demonstrates how difﬁcult it is to predict
the best source-level transformation and instruction set extension
for a given application. It also shows that high-level code and low-
level architecture optimization cannot be separated, but are tightly
coupled. Combined exploration of both the software and hardware
design spaces generate a signiﬁcantly better solution than isolated
optimization approaches could produce. In this paper we present
an empirical evaluation of this HW/SW design space interaction
and show that a probabilistic search algorithm is able to examine
a small fraction of the optimization space and still ﬁnd signiﬁcant
performance improvements.

The rest of the paper is organized as follows. In section 2 we
discuss the large body of related work. Section 3 presents the back-
ground to our research and we discuss the problem of combined
HW/SW design space exploration. In section 4 we describe our
methodology and the experimental setup. Section 5 discusses our
results, while section 6 concludes this paper.

2. Related Work
This paper seeks to broaden the understanding of the potential
for known transformation techniques to improve the quality of
automated instruction set selection. The current state of the art in
Instruction Set Extension is described in section 2.1, followed by a
description of the Source-to-Source Transformations in section 2.2.
The large ﬁeld of HW/SW Codesign is summarized in 2.3.

Figure 2. Complex instruction template generated for the trans-
formed CRC code in ﬁgure 1(b).

Figure 3. The Compiler-in-loop methodology for ASIP design
space exploration.

2.1 Automated Instruction Set Extension

The automation of ISE exploration has been actively studied in re-
cent years, leading to a number of algorithms [3, 4, 5, 6] which
derive the partitioning of hardware and software under micro-
architectural constraints. Work is still being formed in deﬁning the
full space of exploration even in purely arithmetic instruction set
design [7]. Work to include better models in tools has allowed for
better decisions about the performance and feasibility of extensions
[8].

The current exploration approach of using a range of tools oper-
ating on a canonical system-level ADL, is described as “Compiler-

in-Loop Design-Space Exploration” [9]. It was originally moti-
vated [10] through the discovery that iterative and methodical ex-
ploration of ASIP design is very beneﬁcial in decreasing time-to-
market. CoSy [11] and LISATek [12] tools feature in many such
frameworks; Figure 3 illustrates such a combination.

Earlier efforts [13] to combine code transformation and ISE
have been targeted at CDFG transformation towards a more ef-
ﬁcient arithmetic structure. This operates post automated ISE
(AISE), so does not directly contribute to the design space search
but improves upon the result.

In [14] it is shown that an exploration of if-conversion and
loop-unrolling source-to-source transformations is successful in
enabling better performing AISE. We are motivated by this ap-
proach to perform the comprehensive and systematic study of this
paper, as it demonstrates the effectiveness of ISE-targeted heuris-
tics in transformation.

2.2 Source-to-Source Transformations

Due to their inherent portability and large scope source-level trans-
formations have been used for various ﬁelds such as code optimiza-
tions targeting I/O performance [15] or energy efﬁciency [16, 17],
formal veriﬁcation [18], and, most notably, for single- and multi-
core performance optimization of computationally intensive em-
bedded applications (e.g. [19, 20, 21] and [22], respectively).

ROSE [23] and Transformers [24] are tools for building source-
to-source transformation tools for the optimization of C and C++
object-oriented applications.

An empirical study of source-level transformations for digital
signal processing applications is subject of [20], and more compre-
hensive studies in the context of machine-learning based adaptive
compilation can be found in [25] and [26].

2.3 HW/SW Codesign

HW/SW Codesign was an active research area in the 90’s and has
inspired subsequent work on Electronic System Level Design. A
comprehensive summary of research directions, approaches and
tools can be found in e.g. [27]. This work covers a broad scope
of issues, typically ranging from the analysis of constraints and
requirements down to system evaluation and design veriﬁcation. In
contrast, our work focuses on a more speciﬁc, individual problem,
namely that of HW/SW partitioning in the context of extensible
application-speciﬁc processors.

3. Background
3.1 Extensible Processors

Extensible processors contain a number of variable components,
essentially opening up design spaces inside the processor core for
exploration by the designer of an ASIP-based system. Extensions to
registers and supporting arithmetic logic are implemented outside
of a prefab baseline core, the latter implementing all of the expected
basic RISC functionality. In this manner users may make the best
use of the degrees of freedom provided, with the knowledge that
their extensions will not make unpredictable timing changes to the
core as a whole. Some cores allow for reconﬁguration through
FPGA fabrics, whereas others are provided as well-documented
IP-blocks. Either is extended through implementing the extensions
in SystemC or Verilog with respect to the architecture’s extension
interface.

3.2 Design-Space Exploration

Design-Space Exploration (DSE) is an optimization process in the
design ﬂow of a System-on-Chip (SoC), typically operating under
multiple constraints (performance, power & energy, cost & com-
plexity etc.), and targeting an often multi-dimensional and highly

Figure 4. A simpliﬁed system-level view of ARC700 family ar-
chitecture, demonstrating the pre-veriﬁed baseline core and its con-
nection to an instruction set extension through custom registers and
arithmetic units.

non-linear optimization space. Multiple dependent levels (algo-
rithm, SW, and HW design space exploration) of interaction make
it difﬁcult to employ isolated local search approaches, but require a
combined effort crossing the traditional boundaries between design
domains, providing feedback paths and integrating tools into larger
frameworks.

Conﬁgurable and extensible processor cores such as the ARC
600 and 700 have a number of capabilities to allow their instruction
set and micro-architecture to be optimized for a particular applica-
tion. Design concerns guiding DSE are often reduced to metrics
such as execution speed, power usage, and die area; each of these
metrics has an accompanying relevant design space in the conﬁgu-
ration and extension domain.

Meeting this requirement means that no further increase in
speed is generally useful, other than to provide an overhead for
development. Application deadlines will be met and the system
built around the core will be able to communicate and process data
without stalling due to system-level deadlines missed by the core.
Once execution speed requirements have been met the focus of
designers may be switched to secondary axes of design concern,
such as power usage. Efforts in addressing one axis of design con-
cern may make use of excesses in other axes. For example if perfor-
mance exceeds requirements the clock speed of the ASIP may be
reduced, reducing the power consumption. These secondary con-
cerns have additional design spaces of the conﬁgurable core avail-
able to be explored for satisfactory areas; for example clock gating,
dynamic voltage scaling, and unit pruning. These are however out-
side the scope of instruction set extension and not covered here.

Unfortunately the “second order” effects of core extension are
not always beneﬁcial and often hard to predict with any accuracy.
Adding more logic to a core can for example increase the critical
path and force a reduction in the overall clock speed. Such a com-
plicated web of non-orthogonal trade-offs forms a space which can
only be explored efﬁciently through the aid of iterative automated
means.

Instruction set extensions affect all three of the mentioned axes
of design concern. The guiding metric in deriving extensions is
often still application execution speed; designers will add instruc-
tions that “cover” the hottest (most frequently executed) sections of
their application code. The intention is that by partitioning of the
application code into areas covered and not by ISE, subsections

of micro-architecture can be dedicated to the servicing of these
new instructions. In this highly application-speciﬁc design space,
several sources of micro-architectural optimization are currently
brought to bear on the hardware performance of the new instruc-
tion:

• Operation-level/Spatial parallelism; parallel instances of arith-
metic hardware in order to perform multiple operations at-once,
as allowed by dependencies.

• Reduced register-transfer overhead, due to the increased local-
ity of communication within the functional unit used to repre-
sent the new instruction.

• Aggregation of clock period surplus present in most arithmetic
functions. In particular, bitwise functions have a hardware la-
tency far below the clock period in most cases.

This growing catalog of optimization aims to ensure that the
“hot-spot” represented by the new instruction achieves the maxi-
mum speed possible, by trading off die area for an increase in ex-
ecution speed, a decrease in power usage, and a decrease in code-
size. Often these extensions correlate to very frequently executed
sections of code, and so the beneﬁts for a relatively small increase
in die-size can be very tempting to designers. The problem remains
to ﬁnd a way to accurately model both the existing architecture and
the full range of potential extensions in such a way as to efﬁciently
automate exploration.

It has been shown [14] that new search methods and heuristics
can be developed to control the application of transformations, with
respect to the new set of goals inherent in ISE as compared to code
generation. Transformations once targeted at the back-end would
attempt to limit increasing basic block size due to register pressure.
Now in instruction set extension the drive is towards the largest
possible basic block size for analysis.

3.3 Combined Design Space

The combined design space in question here is that of transfor-
mation and ISE, with the intention of demonstrating that there is
promise for automated techniques to manage the design in such a
large space. Also important, that the results of a cooperative auto-
mated framework can outweigh the sum of their separated compo-
nents.

The hope is, as with compilers, that the actual efforts of the
search of the combined space can remain a phased searching of
each space individually. The most important factors in this scenario
are the accuracy and detail of the modeling employed in any deci-
sion making. This work attempts to contribute to the understanding
of which transformations will need to be made extension-aware,
and which are invariantly beneﬁcial under extension.

The use of compiler transforms when developing automated
design space exploration must be very carefully considered, so
as not to disturb the context in which design-space decisions are
made. Transformations which are run prior to an automated ISE
tool must be re-applied with the same parameters to the areas in
which the tool identiﬁed mappings. Otherwise, the ISE will not
ﬁnd the same mapping in code-generation without having the areas
explicitly deﬁned by manual means.

4. Experiment Methodology
The primary concern of our experiment was to determine which
transformations or combinations thereof infer the greatest execu-
tion speed improvement to application-speciﬁc software under ISE
automation. Secondly, the experiment was to ﬁnd limits for perfor-
mance gain and loss from the combined design space deﬁned by
transformation and ISE over a baseline design employing neither.

With this information, we are well equipped to properly focus the
efforts of future research towards the most beneﬁcial transforma-
tions for ISE.

Figure 5. The combined but phased searching of transform and
ISE design spaces; our experiment methodology as a ﬂow diagram.

To represent the transformation design space in this experiment,
we use a source to source transformation tool built upon the SUIF1
[28] compiler framework. Samples are taken with uniform prob-
ability, at random point across the entire space of potential trans-
formation. A sample in this sense represents a single point in the
transformation space, and results in the ordered set of transforma-
tions selected at that sample point to be applied to the code. The
tool generates large volumes of transformed source code samples
rapidly from a deﬁnition of:

• The source code, in C; for our purposes a variety of single-

function benchmarks are tested.

• The Transform Space Deﬁnition, as the boolean inclusion or
exclusion of transforms permitted in the space, plus the max-
imum number of transformation phases for each sample. The
tool supports a wide array of source to source transformations
to be used in the exploration [25]. We allowed a maximum of
50 phases in our samples.

• The number of samples to take from the transformation space,
and hence the number of transformed source codes to produce.
In our case this was set to 10,000, however some sequences
of transformation produced invalid code and hence were culled
from the results. The number of valid transformation sequences
is covered in Section 5.

The benchmarks used in this experiment were taken from SNU-

RT [29] and UTDSP [30] suites. Those taken were as follows:

• SNU-RT; adpcm, crc, fft1, fft1k, ﬁr, jfdctint, lms, ludcmp,

matmul, minver, qsort-exam, qurt, select.

• UTDSP; edge detect, fft 1024, fft 256, ﬁr 256, ﬁr 32 1, his-
togram, iir 4 64, latnrm 32 64, latnrm 8 1, lmsﬁr 32 64, lms-
ﬁr 8 1, mult 10 10, mult 4 4.

We store for each benchmark the entire set of transformed
source codes representing that benchmark after sample points in the
transformation space are applied to it. The set of transforms applied
at each sample is also stored for later correlation in analysis.

This set of transformed source codes forms a representative
sampling of the entire search space for that benchmark, each sam-
ple is then processed by an automated proﬁling ISE tool based on
the Atasu et al. Integer Linear Programming method of derivation
[5]. The tool operates in three phases:

• Instrumentation; wherein the ISE tool augments the intermedi-
ate representation of the application with counters for proﬁling.
The CoSy-based tool emits the i686 assembly for this proﬁling
executable which is then assembled and run using the standard
GNU tool chain.

• Execution; running the instrumented binary records per-basic-
block execution frequencies, which are stored in a ﬁle for use
by the extension phase.

• Extension; The IR is augmented with proﬁling statistics, which
are then used to select the top four instructions using the
Atasu ILP AISE algorithm [5]. The ISE tool’s proﬁler com-
bined with a latency table for the given target architecture
produces runtime and code-size performance metrics for the
original transform-space sample. These metrics and the gener-
ated instructions are stored alongside the transformed code and
transform-point deﬁnition.

4.1 Algorithms

The algorithm controlling the source-level transformation of the in-
put program is a probabilistic algorithm derived from [25]. Com-
bining a space exploration component with machine-learning fo-
cused search this algorithm maintains probability vector represent-
ing the selection probability of each transformation. Starting with a
uniform probability distribution the selection probabilities are up-
dated after each iteration based on the speedup of the transformed
program.

The ILP AISE algorithm used generates data-ﬂow-graph tem-
plates through conversion of basic blocks to a set of constraints
in an Integer Linear Program (ILP) and solution of that program.
For our implementation a tool built into a CoSy compiler uses the
lp solve library to solve such problems and generate a set of candi-
date templates for an entire program. Constraints are declared from
each basic block to generate a template such that:

• The template is convex (i.e. does not have any holes), so that it

may be scheduled.

• Input and output port constraints are met (i.e. the number of
register input and output ports are sufﬁcient), so that it may be
implemented.

In addition to the constraints, a goal function is also expressed. For
this algorithm the goal is the estimated serial time of execution in
cycles of the instructions covered by the template, minus the esti-
mated critical path of the template. The former is denoted the “Soft-
ware” execution time, and is indicative of the time the instruction
would take to execute on the unextended architecture. The latter is
denoted the “Hardware” execution time, and is a real-valued factor
of the cycle time taken to execute the template as a single instruc-
tion. A cycle time for each Software and Hardware operation is
speciﬁed to the tool a-priori to ILP construction, to allow for the
constraints to be generated. The per-template difference between
Software and Hardware execution time is the per-execution gain

in cycles to an architecture implementing that template. Follow-
ing the generation of templates from basic blocks, the templates
are checked for isomorphism with one another using the NAUTY
graph isomorphism library, then ranked using the product of their
estimated usage and per-execution gain. The top four of these in-
structions are then recorded alongside their performance estimates
for inclusion in results.

4.2 Experimental Setup

For the purposes of this experiment, we conﬁgured our latencies
to those of an Intel XScale PXA270 processor, a current high-
performance embedded micro-architecture based upon the ARM7
instruction set. An input/output port constraint of 8/8 is set, to
allow a wide range of potential ISE and avoid limitations on our
results due to the synthetic micro-architectural constraints set in
the ISE algorithm. It has been shown [8] that pipelining of ISE
extensions is possible to reduce per-cycle register ﬁle I/O to suit
actual requirements.

We therefore have for each benchmark, for each of up to 10,000

transformation-space sample points:

• Source code after transformation.
• Instruction Set Extensions deﬁned as data-ﬂow templates.
• A record of performance in cycles (runtime) and instructions
(code-size) before and after the transformations are applied to
the benchmark.

• A likewise record of the improvement to each of the perfor-
mance metrics for each of the instructions generated by auto-
mated ISE for the transformed source.

• Aggregation of the results of the top four of these instructions

to calculate the overall beneﬁt to the transformed code.

So that there is a control point for reference, we ensure that a
baseline utilizing no transforms is sampled from the transforma-
tion space. Our tool produces as many ISE templates as it can ﬁnd
within the source code. However, we limit the number used in our
results to four, in order to allow only the inclusion of the largest and
best performing ISE’s such as we expect to reveal through trans-
formation. Current commercial approaches such as the Tensilica
XPRES [31] tend to use large numbers of small instructions to pre-
serve generality; our work assumes a very application-speciﬁc core
is desired.

This entire experiment was run on a quad-core machine running
Linux 2.6, over the course of several days in order to allow for the
large-scale sampling. Our tools are “pipelined” in their operation to
speed up results generation, as illustrated in Figure 5.

With these results recorded, we go on to make observations on
the correlation of transformation and ISE performance, in how the
spaces combine to form the more relevant performance measure:
overall performance.

5. Results
Figures 6 and 7 show the runtime improvements achieved on a
selection of benchmarks from the SNU-RT and UTDSP suites. For
each benchmark the three bars represent the best improvement seen
in the search space for each technique. Peak runtime improvements
of 2.70x (SNU-RT ludcmp), 1.46x and 2.85x (both SNU-RT FFT)
are seen, for transformations alone, ISE alone and the combination
of the two, respectively. Average runtime improvements across
both benchmark suites are 1.35x, 1.09x and 1.47x respectively.
It can also be seen that of the 26 benchmarks considered 5 of
them see a combined transformation and ISE runtime performance
improvement of over 2.0x and only 6 see an improvement of less
than 1.15x.

Figure 6. Runtime Improvements achieved on the SNU-RT benchmarks.

Figure 7. Runtime Improvements achieved on the UTDSP benchmarks.

Figure 8. Code-size Improvements achieved on the SNU-RT benchmarks.

Figure 9. Code-size Improvements achieved on the UTDSP benchmarks.

adpcmcrcfft1fft1kfirjfdctintlmslud-cmpmatmulminverqsort-examqurtselectAVG0.7511.251.51.7522.252.52.753Transformation ScoreISE ScoreCombined ScoreBenchmarkRuntime Improvementedge detectfft 1024fft 256fir 256fir 32_1his-to-gramiir 4 64latnrm 32_64latnrm 8 1lmsfir 32_64lmsfir 8_1mult 10_10mult 4_4AVG0.9511.051.11.151.21.251.31.351.41.45Transformation ScoreISE ScoreCombined ScoreBenchmarkRuntime Improvementad-pcmcrcfft1fft1kfirjfdctintlmslud-cmpmatmulminverqsort-examqurtselectAVG0.911.11.21.31.41.51.61.71.81.92Transformation ScoreISE ScoreCombined ScoreBenchmarkCode-size Improvementedge detectfft 1024fft 256fir 256fir 32_1his-to-gramiir 4 64latnrm 32_64latnrm 8 1lmsfir 32_64lmsfir 8_1mult 10_10mult 4_4AVG0.970.991.011.031.051.071.091.111.13Transformation ScoreISE ScoreCombined ScoreBenchmarkCode-size Improvement(a) SNU-RT CRC (based on 7896 runs)

(b) SNU-RT FFT1k (based on 4892 runs)

(c) UTDSP Edge Detect (based on 1470 runs)

(d) UTDSP Latnrm 8 1 (based on 8882 runs)

Figure 10. Runtime improvements achieved for every transformation sequence in the search space for a selection of benchmarks. For each
version of the program (x-axis) three speedup values are shown: speedup after ISE only (raw ISE performance), speedup after source-level
transformation only (raw transform performance), and speedup after combined ISE and source-level transformation (combined performance).
The baseline points are the performance of each technique on unmodiﬁed code. The code versions are ordered by increasing combined
performance along the x-axis.

Figures 8 and 9 show the code-size improvements achieved on
the same benchmarks. These graphs are not based on the same
sample points that runtime improvement ﬁgures are, but separate
transformation sequences that were found to be effective at re-
ducing code-size. Peak code-size improvements of 1.18x (SNU-
RT minver), 1.46x and 1.95x (both SNU-RT CRC) are seen, for
transformations alone, ISE alone and the combination of the two,
respectively. Average code-size improvements across both bench-
mark suites are 1.05x, 1.08x and 1.15x respectively.

It can be seen that in ﬁgures 6, 7, 8 and 9 that the average re-
sults for the SNU-RT benchmarks are noticeably higher than for
UTDSP. The primary reason for this is that the SNU-RT bench-
marks are smaller, so the potential selection space is smaller and
thus better suited to uniform sampling. Although we only explore
a tiny fraction of the overall search space we still obtain very good
results, however it seems likely that exploring a larger portion of
the search space will yield even better results, especially for larger
programs. Larger programs are also likely to beneﬁt from a more

directed search technique that can quickly focus on the promising
areas on the search space, such as the one described in [25].

This shows that in many cases simply choosing transforma-
tions that allow effective use of ISE will not give good overall per-
formance. Strong examples of this are the UTDSP FIR-256 and
FIR-32 1 benchmarks, where the optimal combined performance
is given by a set of transformations that did not allow any runtime
improvement through ISE at all. Examples where combined per-
formance is signiﬁcantly better than either transformations or ISE
alone are SNU-RT CRC and the SNU-RT FFT benchmark.

The graphs in ﬁgure 10 show the performance for each indi-
vidual technique and the combination of the two for every sample
point in the search space, for a small selection of benchmarks. The
samples are sorted by the performance of combining transforma-
tions and ISE. This allows the ratio of transformation to ISE per-
formance to be seen and also shows where there are correlations
between the performance of the two individual techniques. These
correlations are seen where either the performance of both individ-

(a) SNU-RT jfdctint

(b) UTDSP FIR-256

Figure 11. The maximum performance found so far for each point in the sample space and all points that were evaluated before it, ie. the
development of the best performing program so far over the program versions generated by the source-level transformation tool.

ual techniques improve at the same point or where one gets better
but the other gets worse.

An example of this correlation can be seen on the left side of ﬁg-
ure 10(c) which shows the separated performance for sets of trans-
formations which allow good ISE performance but perform poorly
overall due to the performance decrease seen with transforms alone.
A more useful example of the correlation between transformations
and ISE is shown in our motivating example, SNU-RT CRC, with
the bit packing transformation. Sequences that make use of this
transform are marked as short vertical bars in ﬁgure 10(a). It can be
seen that all the best performing sequences make use of this trans-
formation. At the points where it changes from being turned off to
turned on there is dip in ISE performance and a rise of about the
same magnitude in transformation performance. It can be seen that
transformation performance improves greatly (from negligible im-
provement without it to up to 1.63x in a sequence with it turned
on) and ISE performance recovers. So with the correct surround-
ing transformations the bit packing transformation allows both code
performance on its own and good ISE performance for this bench-
mark.

Figure 10(b) shows an almost ideal set of results (for SNU-
RT FFT1k), where the best set of transformation sequences when
considered alone also allow the most gain from ISE. When the
optimal sequences overlap in this way the combined performance is
very high (e.g. going from peaks of 1.11x and 1.14x with individual
techniques to a peak of 1.28x with combined techniques for SNU-
RT FFT1k.) Not all sequences give such clean results though,
ﬁgure 10(a) (for our motivating example, SNU-RT CRC) shows
patterns that are visible in several benchmarks. Speciﬁcally, the
best performance is given by ﬁnding a transformation sequence that
both improves the runtime on the code while not damaging the ISE
potential. The optimal sequence actually gives ISE performance
slightly below that which was achieved on the baseline code, but
overall performance is high due to good runtime improvements
from the transforms themselves. Figure 10(d) show the results from
a benchmark where almost none of the overall improvement comes
from transformations but almost entirely from ISE (UTDSP latnrm-
8 1). However, the graph still shows that poor-code shape can limit
ISE.

Figure 11 shows the performance of the best transformation se-
quence found so far as each point in the sample space is evaluated.

Figure 11(a) shows an example (for the SNU-RT jfdctint bench-
mark) that has the kind of characteristics that led to evaluating such
a high number of samples in the transformation space. It contains
several steps in the performance of the best sequence found so far,
with the very best not being found until after several thousand sam-
ples were evaluated. However, this was not typical of most bench-
marks, ﬁgure 11(b) is an example (for UTDSP FIR-256) that shows
the typical behavior. It also has steps in the performance of the best
sequence found so far, but they are much closer together and the
very best is found in about ﬁve hundred runs, with none of remain-
ing sequences evaluated doing better. This suggests that consider-
ing a smaller number of samples should still give acceptable results,
though considering a larger number of samples may ﬁnd more steps
leading to even greater performance.

Regarding the number of samples considered in the results it
can be seen in ﬁgures 10 and 11 that the number varies between
benchmarks. This is because some of transformation sequences
either caused internal correctness checks in the SUIF compiler to be
triggered, or in a few cases generated incorrect code. These samples
are discarded, but there are still a great many remaining, these are
used to generate the results here.

6. Conclusions
In this paper we have described a methodology for improved ISE
generation that combines the exploration of high-level source trans-
formations and low-level ISE identiﬁcation. We have demonstrated
that source-to-source transformations are not only very effective on
their own, but provide much larger scope for performance improve-
ment through ISE generation than any other isolated low-level tech-
nique. We have integrated both source-level transformations and
ISE generation in a uniﬁed framework that can efﬁciently optimize
both hardware and software design spaces for extensible proces-
sors.

The empirical evaluation of our design space exploration frame-
work is based on a model of the Intel XScale processor and
compute-intensive kernels and applications from the SNU-RT and
UTDSP benchmark suites. We have successfully demonstrated that
our approach is able to outperform any other existing approach and
gives an average speedup of 1.47x. Compared to previous work
[14], we have covered a much broader array of existing transfor-

mations to get a more global picture of the potential for transfor-
mation in improving instruction set extension. In addition, we have
empirically demonstrated that there exists a non-trivial dependence
between high-level transformations and the generated instruction
set extensions justifying the co-exploration of the HW and SW
design spaces.

Future work will investigate the integration of machine learning
techniques based on program features into our design space ex-
ploration algorithm and target a commercial extensible processor
platform.

References

[1] ARC International. ARChitect product brief, 2007.

[2] R. Leupers, K. Karuri, S. Kraemer, and M. Pandey. A design ﬂow for
conﬁgurable embedded processors based on optimized instruction set
extension synthesis. In Proceedings of Design Automation & Test in
Europe (DATE), Munich, Germany, 2006.

[3] Armita Peymandoust, Laura Pozzi, Paolo Ienne, and Giovanni De
Micheli. Automatic instruction set extension and utilisation for
In Proceedings of the 14th International
embedded processors.
Conference on Application-speciﬁc Systems, Architectures and
Processors, The Hague, The Netherlands., 2003.

[4] Partha Biswas, Sundarshan Banerjee, Nikil D. Dutt, Laura Pozzi,
ISEGEN: An iterative improvement-based ISE
IEEE

and Paolo Ienne.
generation technique for fast customization of processors.
Transactions on VLSI, 14(7), 2006.

[5] Kubilay Atasu, Gunhan Dundar, and Can Ozturan. An integer linear
programming approach for identifying instruction-set extensions. In
Proceedings of the 3rd IEEE/ACM/IFIP international conference on
Hardware/software codesign and system synthesis (CODES+ISSS
’05), 2005.

[6] Laura Pozzi, Kubilay Atasu, and Paolo Ienne. Exact and approximate
algorithms for the extension of embedded processor instruction sets.
IEEE Transactions on Computer-Aided Design of Integrated Circuits
and Systems, 25(7):1209–1229, 2006.

[7] Ajay K. Verma and Paolo Ienne. Towards the automatic exploration

of arithmetic circuit architectures.
Design Automation Conference, San Francisco, California, 2006.

In In Proceedings of the 43rd

[8] Laura Pozzi and Paolo Ienne. Exploiting pipelining to relax register-
ﬁle port constraints of instruction-set extensions. In In Proceedings
of the International Conference on Compilers, Architectures, and
Synthesis for Embedded Systems, San Francisco, Calif, pages 2–10,
2005.

[9] M. Hohenauer, H. Scharwaechter, K. Karuri, O. Wahlen, T. Kogel,
R. Leupers, G. Ascheid, and H. Meyr. Compiler-in-loop architecture
exploration for efﬁcient application speciﬁc embedded processor
design. In Design & Elektronik, Munich, Germany, WEKA Verlag,
2004.

[10] T. Glokler, A. Hoffmann, and H. Meyr. Methodical low-power ASIP

design space exploration. VLSI Signal Processing, 33, 2003.

[11] ACE CoSy Website - http://www.ace.nl/compiler/cosy.html.

[12] CoWare LISATek Datasheet -

http://www.coware.com/PDF/products/LISATek.pdf.

[13] Paolo Ienne and Ajay K. Verma. Arithmetic transformations to

maximise the use of compressor trees. In Proceedings of the IEEE
International Workshop on Electronic Design, Test and Applications,
Perth, Australia, 2004.

[14] Paolo Bonzini and Laura Pozzi. Code transformation strategies for

In CASES ’06: Proceedings of
extensible embedded processors.
the 2006 international conference on Compilers, architecture and
synthesis for embedded systems, pages 242–252, New York, NY,
USA, 2006. ACM Press.

[15] Yijian Wang and David Kaeli. Source level transformations to

improve I/O data partitioning. In Proceedings of the International
Workshop on Storage Network Architecture and Parallel I/Os, 2003.

[16] E. Chung, L. Benini, and G. De Micheli. Energy efﬁcient source
code transformation based on value proﬁling. In Proceedings of the
International Workshop on Compilers and Operating Systems for
Low Power, Philadelphia, USA, 2000.

[17] C. Kulkarni, F. Catthoor, and H. De Man. Code transformations for
low power caching in embedded multimedia processors. In Proceed-
ings of the 12th. International Parallel Processing Symposium on
International Parallel Processing Symposium, pages 292–297, 1998.

[18] B.D. Winters and A.J. Hu. Source-level transformations for improved

formal veriﬁcation.
Conference on Computer Design, 2000.

In Proceedings of the IEEE International

[19] Heiko Falk and Peter Marwedel.

Source Code Optimization

Techniques for Data Flow Dominated Embedded Software. Kluwer
Academic Publishers, Dordrecht, The Netherlands, 2004.

[20] Bj¨orn Franke and Michael O’Boyle. Array recovery and high-

level transformations for DSP applications. ACM Transactions on
Embedded Computing Systems (TECS), 2(2):132–162, May 2003.

[21] Victor De La Luz and Mahmut Kandemir. Array regrouping and
IEEE

its use in compiling data-intensive embedded applications.
Transactions on Computers, 53(1):1–19, 2004.

[22] Bj¨orn Franke and Michael O’Boyle. Combining program recov-
ery, auto-parallelisation and locality analysis for C programs on
multi-processor embedded systems. In Proceedings of the 12th In-
ternational Conference on Parallel Architectures and Compilation
Techniques (PACT’03), New Orleans, September/October 2003.

[23] Markus Schordan and Daniel J. Quinlan. A source-to-source

architecture for user-deﬁned optimizations. In Proceedings of the
Joint Modular Languages Conference, 2003.

[24] Alexandre Borghi, Valentin David, and Akim Demaille. C-

Transformers - a framework to write C program transformations.
ACM Crossroads, 2004.

[25] Bj¨orn Franke, Michael O’Boyle, John Thomson, and Grigori Fursin.

Probabilistic source-level optimisation of embedded programs. In
Proceedings of the 2005 Conference on Languages, Compilers and
Tools for Embedded Systems (LCTES’05), 2005.

[26] Felix Agakov, Edwin Bonilla, John Cavazos, Bj¨orn Franke,

Michael F.P. O’Boyle, John Thomson, Marc Toussaint, and Christo-
pher K.I. Williams. Using machine learning to focus iterative opti-
mization. In Proceedings of the 4th Annual International Symposium
on Code Generation and Optimization (CGO), 2006.

[27] Jerzy Rozenblit and Klaus Buchenrieder. Codesign - Computer-Aided

Software/Hardware Engineering. IEEE Press, New York, 1995.

[28] Robert P. Wilson, Robert S. French, Christopher S. Wilson, Saman P.
Amarasinghe, Jennifer M. Anderson, Steve W. K. Tjiang, Shih-Weui
Liao, Chau-Wen Tseng, Mary W. Hall, Monica S. Lam, and John L.
Hennessy. SUIF: An infrastructure for research on parallelizing and
optimizing compilers. SIGPLAN Notices, 29(12), 1994.

[29] SNU-RT Real-Time Benchmarks -

http://archi.snu.ac.kr/realtime/benchmark/.

[30] Corinna G. Lee. UTDSP Benchmarks -

http://www.eecg.toronto.edu/ corinna/DSP/infrastructure/UTDSP.html,
1998.

[31] Tensilica Inc. The XPRES compiler: Triple-threat solution to code

performance challenges. Tensilica Inc Whitepaper, 2005.

