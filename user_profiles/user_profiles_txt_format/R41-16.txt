Predicted and Observed User Behavior in the Weakest-Link Security Game

Jens Grossklags

UC Berkeley/School of Information

Nicolas Christin
CMU/CyLab Japan

John Chuang

UC Berkeley/School of Information

jensg@ischool.berkeley.edu

nicolasc@cmu.edu

chuang@ischool.berkeley.edu

Abstract

We aim to advance the understanding of individual
security decision-making, by combining formal and
behavioral analysis. We sketch a game-theoretic
model of security decision-making that general-
izes the “weakest link” game, and describe a con-
trolled laboratory experiment to reveal differences
between predicted and observed user behavior. Re-
sults of a pilot study yield possible explanations for
behaviors observed in the wild: users show some
willingness to experiment with parameters, rarely
converge to a ﬁxed behavior, and face difﬁculties
isolating the impact of individual parameters.

1 Introduction

Collective awareness of the need for information
security has considerably risen in the past few
years. Yet, user behavior toward security in net-
worked information systems remains obfuscated by
complexity, and may seem hard to rationalize [1].
This observation is perhaps not surprising, consid-
ering that users’ security decisions appear often in
contradiction with their own stated attitudes and de-
sires.
Indeed, when asked in surveys, computer
users say they are interested in preventing attacks
and mitigating the damages from computer and in-
formation security breaches [1]. On the other hand,
studies (e.g., [3, 9]) evidence the low levels of pri-
vacy and security precautions taken by a vast ma-
jority of users.

Academic research has isolated the misalignment
of user incentives as a root cause for the observed
dichotomy between behavior and stated attitudes
and low overall system security. Speciﬁcally, users
often fail to internalize the impact of their own de-
cisions on 1) the motivation of other users to secure;
and on 2) the level of security that can be achieved
in an interconnected network [2, 6].

This paper proposes to explore the relationship be-
tween economic and psychological-behavioral in-
centives for improved or declining system security.
We aim to enhance the understanding of the of-
ten puzzling and frustrating security and privacy
decision-making of individuals and groups to ad-
vance institutional and policy responses.

As a ﬁrst step, we focus here on a weakest-link se-
curity scenario. For instance, consider a single un-
patched system being infected by a worm, which, as
a result, allows an attacker to assail (e.g., deny ser-
vice to) the rest of the network without facing addi-
tional defenses. The incentives other users have to
protect their own systems against security breaches
are weakened, since irrespective of their individ-
ual decisions, they still suffer the consequences in-
duced by the existence of the infected host.

The weakest-link scenario has been formalized as
an economic game [7, 8] and applied to system se-
curity and reliability [10]. We generalize the model
by allowing users to not only protect their resources
(e.g., by installing a ﬁrewall), but also to self-insure
against the consequences of security breaches (e.g.,
by backing up valuable data) [6].

Applying game-theoretical analysis, such as com-
putation of Nash equilibria, requires several as-
sumptions regarding user behavior. All users are
supposed to have all information about potential
actions and associated payoffs available, to infal-
libly select actions that are proﬁt-maximizing, and
to perfectly take into consideration other users’ op-
timizing decisions [4].
In the context of security
games, these assumptions can be challenged, and
individuals frequently deviate from perfect rational-
ity, and do not always select purely selﬁsh actions.

In an effort to better understand the origin of these
departures from optimality, we have started to sys-
tematically study the actual behavior of individuals
in the weakest-link security game. We contrast the
behavior predicted by game-theoretic analysis with
the behavior we observe in a a pilot study of a con-
trolled laboratory experiment. Participants have to
select protection and recovery strategies in an envi-
ronment with non-deterministic attacks and a lack
of information about parameters of the game.

2 Model and theoretical predictions

Formal description. The game is played amongst
N players, denoted by i ∈ (1, . . . , N ) who are all
potential victims of a security threat. The attacker is
exogenous to the game. The game consists of mul-
tiple rounds. In each round, security attacks occur
probabilistically, according to a ﬁxed, exogenous
probability p, which determines the baseline rate
of security attacks. For instance, p = 0.5 means
that the attacker attempts to compromise the net-
work half of the time, and is idle the rest of the
time. All attempted compromises are not necessar-
ily successful, however; the success or failure of
an attempted attack depends on the defensive mea-
sures put in place by the players, as we discuss be-
low. Successful security compromises will result in
all players incurring losses. Indeed, in a weakest-
link game, compromising one player (the so-called
weakest-link) means compromising the whole net-

work. However, the extent of each player’s losses,
Li, is dependent on the choices made by that player.

More precisely, each player i receives an endow-
ment Mi > 0 in each round. The endowment can
be utilized for two security actions: self-protection
(0 ≤ ei ≤ 1) and self-insurance (0 ≤ si ≤ 1) with
linear associated (positive) effort costs bi and ci, re-
spectively. Self-protection acts to probabilistically
block attacks. Self-insurance deterministically low-
ers the penalty occurred during an attack that is not
blocked. So, each player can face three states in
each round: 1) no attack occurs, 2) an attack takes
place but it is blocked due to self-protection (and
self-protection of all other players), and 3) an attack
happens and it is not blocked. Self-protection inﬂu-
ences the likelihood of occurrence of states 2 and 3.
Self-insurance lowers the hurt in state 3. Formally,
we express the payoff πi to a player i as:

πi = Mi−pLi(1−si)(1−min[ei, e−i])−biei−cisi ,
(1)
where e−i denotes the set of protection levels
picked by players other than i.

In practice, many security mechanisms combine
features of both protection and insurance as we
have deﬁned them. For example, a spam ﬁlter might
not automatically block all dubious messages but
redirect some of them into a special folder. Review-
ing these messages separately from the main mail-
box will often result in lower cognitive cost to the
individual. Hence, the spam ﬁlter lowers both the
probability of spam and the magnitude of the asso-
ciated cost if spam passes the ﬁlter. Even though
protection and insurance are often intertwined in
practice, for the purposes of this research study we
chose to clearly separate both actions in order to be
able to dissociate their effects.

Nash equilibrium. Considering the payoff func-
tion in Eq. 1, if we assume symmetric costs ho-
mogeneous across users, that is, if for all i, bi =
ci = b = c, and Li = L, the weakest-link security

game has two Nash equilibria that are not Pareto-
ranked: Either all individuals protect with a cer-
tain effort but neglect insurance (protection equi-
librium), or everybody fully insures and decides not
to protect (insurance equilibrium). Both Nash equi-
libria yield identical payoffs. We sketch the proof
in Appendix A, where we also show that these re-
sults extend to the asymmetric case where individ-
ual players face different bi, ci and Li.

3 Focus of experimental observation

the analytic ﬁndings outlined
We next contrast
above with actual player behaviors evidenced
through preliminary laboratory experiments. At a
high level, we want to focus on equilibrium selec-
tion and learning behavior of players. We aim in
particular to obtain answers to the following set of
questions.

Will the game converge to a Nash equilibrium
outcome? Prior experimentation centered on non-
continuous and non-probabilistic versions of the
weakest-link game with or without limited infor-
mation about important parameters of the game
[8]. Data shows that experiments usually converge
and individuals are able to tacitly coordinate on
a Nash equilibrium outcome. Disagreements be-
tween players usually disappear quickly with all
players focusing on one Nash strategy.

Does the self-insurance equilibrium dominate
other outcomes? Because the protection equi-
librium is sensitive to defection by even a single
player, we expect this equilibrium to be observed
less frequently, in particular as the group size in-
creases [6]. From a behavioral perspective, how-
ever, we would expect individuals to at ﬁrst attempt
to protect their resources.

periment. Similar to the ﬁndings of [5], we suggest
that players in security games will systematically
probe the action space. In contrast to [8], partici-
pants in our experiments are unaware of the type of
security situation they are facing, i.e., they do not
know that it is a weakest-link game, creating a fur-
ther incentive for experimentation.

4 Experimental observations

Setup. We recruit participants from a student sub-
ject pool at UC Berkeley, and have them participate
in the experiment in a special computer laboratory,
isolated from each other by separation walls. Af-
ter reading and signing consent forms, they receive
instructions for the experiment that set the context,
explain the two main user actions (self-protection
and self-insurance) and introduce the user interface.

The user interface provides individuals with two
slider-type input devices that allow them to mod-
ify their security settings. Feedback is given both
numerically and in graphical panels to help users
recognize patterns and trends in the data.

The experiment proceeds continuously, without
pause between payoff rounds. The length of a
round is 5 seconds. The whole experiment lasts 150
rounds. The average attack probability is p = 0.33,
i.e., attacks occur about every 3 rounds. Protection
and insurance costs are symmetric (b = c).

To capture the low-information feature of security
decisions, participants do not receive any speciﬁc
information about the structure of the model or its
parametrization. We do not inform them about the
number of players in their group, other players’ ac-
tions, or payoffs. Participants, however, do receive
feedback on the attack state of the past round.

Is experimentation a prominent part of players’
strategies? We expect that the limited information
environment of the game stimulates players to ex-

Results. We describe the outcomes of two 2-player
games, and one 3-player game. Fig. 1 displays the
data for two 2-player games. All four players exper-

(a) First game

(b) Second game

Figure 1: Experimental data for two-player games.

iment with parameter settings throughout the whole
duration of the session.

In the ﬁrst game (Fig. 1(a)) both players follow
different approaches in search of rewarding strate-
gies. Player A’s strategy selection resembles a
heartbeat pattern with values kept for less than 5
periods. Protection and insurance levels are often
modiﬁed in unison. Player B, on the other hand,
usually keeps one parameter ﬁxed while modify-
ing the other. Furthermore, Player B keeps settings
constant for longer periods on average. This ﬁrst
2-player game does not converge to a Nash equilib-
rium.

The players in the second 2-player game (Fig. 1(b))
follow a different experimentation and convergence
pattern. After an initial phase of exploration with
relatively sudden, and sometimes extreme, changes
in both parameters, the two players settle on a more
moderate pattern of change. Both players converge
to settings with high protection efforts. Surpris-
ingly, even though few attacks beyond round 50 are
successful, both players keep up a relatively high
insurance effort.

We also provide data for a 3-player game (Fig. 2).
Most remarkable is the strategy play by Player B,
who quickly settles on a low protection and high

insurance strategy with little experimentation. At
round 65 we observe a short-termed complete re-
versal of this strategy for experimentation, during
which the subject suffers from one security com-
promise that might be the cause for the quick return
to the prior strategy. Player C experiments thor-
oughly with parameter settings that pit protection
and security against each other. For most of the
game beyond round 50 player C plays close to the
individually rational strategy to insure and not pro-
tect. Player B selects a lower insurance level but ap-
proximately follows the same strategy from round
30 on. Surprisingly, player A never adapts, even
though at least one player selects low protection set-
tings from round 30 until the end of the game.

5 Conclusions

We consider the pilot experiments presented here
as preparation for a larger study that compares the
economic determinants of different organizational
structures and attack patterns analytically and ex-
perimentally. We also plan to conduct experiments
with different modes of intervention to improve
convergence to a desirable equilibrium.

The initial results we report here suggest that the
weakest-link security game has several properties
that distinguish it from the classical weakest-link

 80Insurance levelInstantaneous payoff 100 0Successful AttacksThwarted Attacks 20 40 60 80 100Rounds 0 20 40 60 80 100 120 140Player BPlayer A 0 20 40 60Protection level 80Insurance levelInstantaneous payoff 100 0Successful AttacksThwarted Attacks 20 40 60 80 100 120 140RoundsPlayer BPlayer A 0 20 40 60 80 100 0 20 40 60Protection levelAcknowledgments

We thank the anonymous reviewers and Paul
Laskowski for their valuable comments and edi-
torial guidance, and Neal Fultz for his contribu-
tions to the software used in the experiments. This
work is supported in part by the National Science
Foundation under awards ANI-0331659 and CCF-
0424422, and by the Air Force Ofﬁce for Scientiﬁc
Research under award #FA 9550-06-1-0244.

References

[1] A. Acquisti and J. Grossklags. Privacy and rationality in
IEEE Security & Privacy,

individual decision making.
3(1):26–33, January–February 2005.

[2] R. Anderson. Why information security is hard - an eco-
In Proc. ACSAC’01, New Orleans,

nomic perspective.
LA, Dec. 2001.

[3] AOL/NSCA. Online safety study, December 2005.
http://www.staysafeonline.

Available at:
info/pdf/safety_study_2005.pdf.

[4] N. Christin, J. Grossklags, and J. Chuang. Near rational-
ity and competitive equilibria in networked systems. In
Proc. ACM SIGCOMM’04 PINS Workshop, pages 213–
219, Portland, OR, August 2004.

[5] E. Friedman, M. Shor, S. Shenker, and B. Sopher. An
experiment on learning with limited information: non-
convergence, experimentation cascades, and the advan-
tage of being slow. Games and Economic Behavior,
47(2):325–352, May 2004.

[6] J. Grossklags, N. Christin, and J. Chuang. Secure or in-
sure? A game-theoretic analysis of information security
games. In Proc. WWW’08, Beijing, China, April 2008.

[7] J. Hirshleifer.

From weakest-link to best-shot:

the
voluntary provision of public goods. Public Choice,
41(3):371–386, January 1983.

[8] J.B. Van Huyck, R.C. Battallio, and R.O. Beil. Tacit co-
ordination games, strategic uncertainty, and coordination
failure. American Econ. Rev., 80(1):234–248, 1990.

[9] S. Spiekermann, J. Grossklags, and B. Berendt. E-
privacy in 2nd generation e-commerce: privacy prefer-
ences versus actual behavior. In Proc. ACM EC’01, pages
38–47, Tampa, FL, October 2001.

[10] H.R. Varian. System reliability and free riding. In L.J.
Camp and S. Lewis, editors, Economics of Information
Security (Advances in Information Security, Volume 12),
pages 1–15. Kluwer Academic Publishers, Dordrecht,
The Netherlands, 2004.

Figure 2: Three-player game.

game (with non-probabilistic payoffs and without
self-insurance). First, individuals experiment fre-
quently and often thoroughly. Second, convergence
to a Nash equilibrium is not achieved within a few
periods.
In fact, in the data gathered so far, we
do not observe convergence to any of the predicted
equilibria at all. Given that each game lasted 150
rounds (i.e., 12.5 mins), this result is surprising.

We ﬁnd initial evidence that the individual ap-
proach to experimentation has a distinct impact on
whether a player will ﬁnd an individually rational
strategy and the game will converge to a Nash equi-
librium. Our results further evidence that some
players hesitate to try strategies that require them to
decouple the protection and self-insurance parame-
ters from each other.

We contribute to a better understanding of the psy-
chology of security decision-making, by providing
economic models that capture important aspects of
organizational structure and add a so far overlooked
aspect of decision complexity, i.e., the difference
between protection and self-insurance [6]. Our ex-
periments aim to uncover how well individuals can
follow economic incentives, and where complexity
impedes the realization of good security outcomes.

 0Thwarted Attacks 20 40 60 80 100 120 140 100Player APlayer BProtection levelInsurance levelInstantaneous payoffRoundsPlayer C 0 20 40 60 80 100 0 20 40 60 80 100 0 20 40 60 80Successful AttacksA Appendix: Game-theoretical analysis

A Nash equilibrium is a “best response” equilib-
rium, where each player i picks the pair (ei, si)
which maximizes his/her own payoff, given the set
of values (e−i, s−i) chosen by all other players.
Nash equilibria are expected to be observed under
the assumption that all players are perfectly ratio-
nal, and know all strategies available to all players,
as well as the associated payoffs.

Let us assume that all players have identical param-
eters (i.e., for all i, Mi = M , Li = L, bi = b, and
ci = c). If we denote by ˆe0 the minimum of the
protection levels initially chosen by all players, a
study of the variations of πi as a function of ei and
si yields that three types of equilibria exist [6].

First, a protection equilibrium (ei, si) = (ˆe0, 0) oc-
curs, when pL > b and either 1) pL < c or 2)
pL ≥ c and ˆe0 > (pL−c)/(pL−b). That is, every-
body picks the same minimal security level, and no
one has any incentive to lower it further down. This
equilibrium can only exist for low protection costs
(b ≤ c), and may be inefﬁcient, as it could be in
the best interest of all parties to converge to ei = 1,
to have a higher chance of deﬂecting incoming at-
tacks [6]. This protection equilibrium depends on
the cooperation of all players, and is therefore very
unstable. It requires only a remote possibility that
any of the n − 1 players will not select the full-
protection equilibrium for the remaining player to
defect. In the second type of equilibrium, all play-
ers will self-insure themselves completely (ei = 0
and si = 1 ∀i), when pL > c and either 1) pL < b
or 2) pL ≥ b and ˆe0 < (pL − c)/(pL − b). Es-
sentially, if the system is not initially secured well
enough (by having all parties above a ﬁxed level),
players prefer to self-insure. The effectiveness of
this security measure does not depend on the coop-
eration of other players. A third, trivial equilibrium,
is a passivity equilibrium, where all players choose
(ei, si) = (0, 0), when pL < b and pL < c.

Figure 3: Reaction functions for a two-player
weakest-link game. Bold lines and dots indicate
potential Nash equilibria.

We can extend the presentation to an asymmetric
case, where different players have different valua-
tions Li, ci, and bi. For simplicity, consider ﬁrst
a two-player game. By deﬁnition, Nash equilibria
are characterized by the reaction functions e2(e1)
and e1(e2) reaching a ﬁxed point, that is e2(e1) =
e1(e2).
Indeed, the effects of self-insurance on
the payoffs received is independent of the other
player’s actions, and is therefore not a factor here.
In Fig. 3, we see that a ﬁxed-point is attained when
e1 = e2 = 0 (self-insurance-only equilibria, as
discussed before), and when both e1 and e2 are
greater than max{(pL1 − c1)/(pL1 − b1), (pL2 −
c2)/(pL2 − b2)}.

Generalizing to N players, we obtain the follow-
if, for all i, pLi > bi, and ei-
ing distinction:
ther 1) pLi < ci, or 2) pLi ≥ ci and ˆe0, the
minimum initial protection level, is greater than
max1≤i≤N {(pLi − ci)/(pLi − bi)}, then we have
a Nash equilibrium where everyone picks ( ˆe0, 0).
Otherwise, all players select ei = 0. The value
of self-insurance they select depends on their re-
spective valuations. Players for whom insurance
is too expensive (pLi < ci) do not insure, with
si = 0, while others choose full self-insurance, that
is si = 1. This result extends observations made by
Varian [10] in the absence of self-insurance strate-
gies.

(pL −c )/(pL −b )1e2e2e  (   )1e1e  (   )211011222211(pL −c )(pL −b )e