High Durability in NAND Flash Memory through Effective

Page Reuse Mechanisms

Department of Computer Science and

Department of Computer Science and

University of California, San Diego

University of California, San Diego

Kwangyoon Lee

Engineering

La Jolla, CA, USA

kwl002@cs.ucsd.edu

Alex Orailoglu

Engineering

La Jolla, CA, USA

alex@cs.ucsd.edu

ABSTRACT
In this paper, we introduce a highly eﬀective page reuse
mechanism to reduce the amount of block erasures and page
programming in NAND based primary memory architec-
tures. The proposed techniques provide a very high rate
of page reuse by eﬀectively incorporating bit diﬀerences in
page updates along with a reduction in bit unprogramma-
bility by minimizing programming interference among adja-
cent pages. We also propose an eﬀective block reclamation
scheme to alleviate overall programming stress in a block so
as to reduce the probability of run-time cell defects. The
page reordering scheme can further increase page reusabil-
ity by reducing run-time programming disturbance. The
experimental results show that our proposed techniques sig-
niﬁcantly diminish the amount of block reclamation and con-
sequently enhance the durability of the NAND ﬂash based
storage systems. Furthermore, by alleviating overall bit
stress in NAND ﬂash memory, the probability of bit failure
of each cell is also signiﬁcantly reduced, enabling the con-
struction of more reliable and durable NAND ﬂash based
memory.

Categories and Subject Descriptors: C.3 [Special-
Purpose and Application-Based Systems]: Real-Time and
Embedded Systems

General Terms: Performance, Design, Experimentation

Keywords
NAND Flash, Primary Memory, Durability, Memory Archi-
tecture

1.

INTRODUCTION

Embedded systems are serving diverse functionalities and
the design of embedded systems is impacted by the conse-

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CODES+ISSS’10, October 24–29, 2010, Scottsdale, Arizona, USA.
Copyright 2010 ACM 978-1-60558-905-3/10/10 ...$10.00.

quent diversity in requirements, such as power, performance,
reliability, cost, capacity and non-volatility. Memory subsys-
tems are one of the most critical components in embedded
systems design; highly customized memory system design
for the dedicated systems constitutes a dominant practice
in ensuring eﬀective satisfaction of the aforementioned re-
quirements, consequently. Memory system design can be far
more simpliﬁed and eﬀective when a single memory device
can serve all the requirements.

DRAM has been a dominant memory solution for most
embedded systems for several decades. However, DRAM’s
decade long dominance in embedded systems is signiﬁcantly
weakened due to its power consumption characteristics as
the importance of low-power consumption is ever increasing
for various types of embedded systems and especially for
mobile systems for which the power budget is highly limited.
As a complete substitute of low-power primary memory
for DRAM, various alternative memory technologies such
as NAND, FeRAM, MRAM and PRAM [11, 7, 14, 3] have
been developed and introduced but none of the alternative
memories except for NAND ﬂash memory have successfully
permeated the memory market until now. There exist mul-
tiple common barriers such as cost, capacity, manufactura-
bility and durability that have precluded the elevation of
these devices to a mainstream primary memory. By success-
fully overcoming imposed cost, capacity, and manufactura-
bility barriers for the last two decades, NAND ﬂash memory
has emerged as the most popular secondary memory device
in embedded systems. However, the strict durability limits
in NAND ﬂash memory constitute one of the most critical
factors in precluding its more aggressive adoption as a pri-
mary memory. Therefore, eﬃcient mechanisms to extend
the durability of the NAND ﬂash memory are required to
promote a NAND-based primary memory.

In this paper, we introduce an eﬀective NAND ﬂash page
reuse mechanism to construct a durable NAND based pri-
mary memory. The durability of the proposed primary mem-
ory is signiﬁcantly enhanced by boosting cell programmabil-
ity and minimizing the bit screening eﬀect. Furthermore, the
probability of a cell defect due to cell aging is also reduced
through the eﬀective reduction of bits in a block. The pro-
posed mechanism only requires minimal hardware overhead.
Extensive simulation using the SimpleScalar simulator with

205Table 1:
Memory Technology

ITRS 2009 Roadmap for NAND Flash

Device
NAND Technology (nm)
Write/Erase Cycles
Data Retention (years)
Max. Bits/Cell

2010
32
1E+05
10-20
3

2014
22
1E+04
10
4

2018
14
1E+04
5-10
4

Spec2000 benchmark suites illustrates the signiﬁcant reduc-
tion in page replacements and the associated extension in
lifespan of the NAND ﬂash memory.

The rest of the paper is organized as follows. Section 2
brieﬂy presents NAND ﬂash based memory systems. Sec-
tion 3 introduces background and motivational ideas. Sec-
tion 4 delivers an in-depth introduction of the proposed page
reuse mechanism including the page diﬀerence update, the
bit programming mask and the page reordering scheme. Sec-
tion 5 provides experimental results based on simulation and
analysis. In section 6, an overall summary of the proposed
mechanism is oﬀered.

2. RELATED WORK

Over a decade, a signiﬁcant amount of research has been
undertaken aimed at the eﬀective use of NAND ﬂash mem-
ory in various storage architectures. In practice, the adop-
tion of NAND ﬂash memory has been limited to a certain
extent and is typically consigned to secondary or tertiary
data storage where the aforementioned limitations of NAND
ﬂash memory could be eﬀectively tolerated. However, a sig-
niﬁcant amount of research has been performed to overcome
these intrinsic limitations of NAND ﬂash memory [9, 10] and
extend the areas of applicable memory/storage systems such
as primary memory and system buﬀers. Moreover, many re-
searchers and developers still envision NAND ﬂash memory
as the most plausible uniﬁed memory device in embedded
systems.

Park et al.

in [13] employs NAND ﬂash memory as a
primary memory. The authors add a simple direct mapped
uniﬁed cache between a processor and the NAND ﬂash mem-
ory. However, this system requires a relatively large cache
and it suﬀers from overall performance degradation. In [1],
OneNANDTM, a hybrid NAND ﬂash memory, has been in-
troduced as a high-performance non-volatile memory for em-
bedded systems. In [12, 6, 5], the authors develop a NAND
ﬂash memory based code storage system by incorporating
the virtual memory. However, it requires a considerable
amount of VM page buﬀers. In [9], the authors introduce a
NAND ﬂash memory based code storage system by employ-
ing application speciﬁc hotspot information to eﬀectively
relieve the extremely long access time of the NAND ﬂash
memory.
[10] reduces the number of reclamations through
the use of an accurate run-time block utilization ratio but
fails to reduce the actual amount of page programming. In
[4], the authors introduce a new bit encoding scheme en-
abling two in-place page programs but the critical impact of

Figure 1: The NAND Cell Architecture and Bit Or-
ganization

the possible bit disturbances during the page updates is not
explored.

3. BACKGROUND AND MOTIVATION

Unlike conventional memory devices whose address space
is designed to be accessed randomly in byte granularity,
NAND ﬂash memory exposes pages and blocks as its basic
granularity of access and it further requires both program
and erase operations to write data. To represent a bit sta-
tus, a ﬂoating gate of the NAND cell should be charged or
discharged with respective operations named program and
erase and high voltage should be applied during these oper-
ations. Consequently, the stringent limitation on the total
amount of valid erasure/programming is guidelined by each
NAND ﬂash manufacturer. The technological advancement
in NAND ﬂash memory is mostly dedicated not to enhance
bit characteristics or performance but to enlarge capacity by
introducing a new fabrication technology or cell technology.
However, based on the ITRS ’09 report as can be seen in
table 1, gradual degradation in durability is expected in the
coming decade [2].

Most critical durability problems in NAND ﬂash mem-
ory are imposed by cell-architectural and bit-organizational
characteristics. NAND ﬂash memory has a quite simple
but eﬀective hardware cell architecture as seen in ﬁgure 1
with the ﬂoating gate architecture engendering a highly scal-
able memory device. Furthermore, the cell organization is
also highly eﬀective in providing low-power and high per-
formance. However, it displays certain levels of problems
and constraints. First of all, NAND ﬂash cells age over
program/erase operations due to the high applied voltage
needed to charge/discharge the ﬂoating gate [8]. While
the integrity of up to 100,000 times is guaranteed in the
current generation of SLC NAND ﬂash memory, this con-
straint causes signiﬁcant impact on the durability of the
NAND based memory system. Secondly, there exist mul-
tiple sources of disturbances to the adjacent cells when high
voltage is applied during the page programs. To minimize
the impact of run-time program disturbances, page program-
ming should be performed in sequential order within a block
(generally, in ascending order of page number) and a page
can be reprogrammed only up to 4 NOPs (Number of Par-
tial Programs) in most SLC NAND ﬂash memories. As a

206Table 2: Timing Characteristics of Memory Devices

Device
Access Unit (byte)
Read Bandwidth (MB/s)
Write Bandwidth (MB/s)
Guaranteed Erase Cycles

SRAM DRAM NAND FLASH OneNANDTM
2K
108
9.4
100,000

2K
17
6.8
100,000

1
1,000
1,000
N.A.

1
2,500
2,500
N.A.

result, the durability of NAND ﬂash memory is signiﬁcantly
exacerbated by this combination of constraints.

To enhance the durability problem in NAND ﬂash mem-
ory, page reuse can be the most promising and eﬀective way
to reduce the overall amount of programmed pages and re-
sult in a consequent reduction of block erasures. However, in
most systems, page reuse cannot be eﬀectively incorporated
due to the overly strict guidelines of the NAND manufactur-
ers that only permit the sequential order page programming
within a block, which is mandated so as to ensure no eﬀec-
tive bit disturbance among cells in a bit-line. The already
reset cells in a bit-line whose location is closer to the com-
mon source as seen in ﬁgure 1 than the cell currently being
reset may impact the ﬁdelity of the resetting operation due
to the signiﬁcant voltage shift imposed. This run-time ef-
fect is deﬁned as bit screening in the paper and may cause
dynamic bit errors during programming.

As a general page programming guideline, pages can be
reprogrammed and random order page programming can be
conditionally allowed provided all the three programmability
criteria are met:

1. NOP constraint - the number of page programming

should not exceed the NOP limitation.

2. Bit programmability - set bits can be reset but already

reset bits cannot be set.

3. Bit screening - non-sequential order (random order)
page program is only permitted when no bit screening
eﬀect is imposed during the programming.

In ﬂash-based memory systems, there exist various map-
ping mechanisms to utilize pages and blocks in a ﬂexible
manner. Each mapping mechanism explores a distinct op-
timization goal and ways of re-placing pages and blocks at
run-time. However, all the mapping mechanisms require a
common NAND ﬂash memory speciﬁc operation, namely,
block reclamation, which is an inevitable but extremely im-
portant and complex operation in NAND ﬂash memory to
enable reuse of the blocks already programmed. Block recla-
mation can be initiated when no further available pages are
found on the block.

In addition to the limited physical block-level durabil-
ity, NAND ﬂash memory also diﬀers from other traditional
memory components such as SRAM and DRAM in that it
requires a larger granularity of access and displays highly
unbalanced access characteristics between reads and writes
as shown in Table 2. The physical unit of read/write access
of NAND ﬂash memory is 2KB and it is in general the op-
timal cache line size due to the extremely long write access

latency in NAND ﬂash memory. However, this can induce
elevated cache replacements due to the increased conﬂict
misses on the cache, which results in performance and dura-
bility degradation.

On-demand page requests are issued when fresh new data
arrives or existing data are updated. During run-time, page
update constitutes the major traﬃc; yet the page update
frequency over the given ﬂash devices is highly skewed as
some pages experience a quite elevated rate of consecutive
updates while others remain unchanged for a long period
of time. Frequent page updates can easily consume all the
available pages in a block and consequently trigger a high
volume of block reclamations. In our previous work [10], the
number of reclamations is signiﬁcantly reduced by adjusting
each block utilization ratio using dynamic application infor-
mation. However, the total amount of page consumption
remains the same.

Page reuse is the most eﬀective technique to reduce the
total amount of page consumption. However, it is extremely
unlikely to reuse pages by purely updating upcoming traﬃc
just in place. If we can incorporate though the incremental
diﬀerence of the updates, there exists a high probability of
page reuse provided no spatial conﬂict occurs in consecutive
updates. We observed many page updates dealing with large
regular data sets display the aforementioned behavior.

In previous research on NAND ﬂash memory, a programmed

page is considered to be in a terminal state that can be no
longer utilized unless the block that contains it is reclaimed.
However, these pages can be reused by removing the run-
time inhibiting factors such as bit unprogrammability and
bit screening by restructuring data contents, reorganizing
page distribution based on its update frequency and reorder-
ing page location on reclamation. Along with previous re-
search to minimize the reclamation amount and overhead,
the page reuse technique can further enhance the usability of
page resources and consequent durability of the device. Fur-
thermore, by minimizing the number of programmed bits,
the overall probability of the generation of run-time faulty
cells is also signiﬁcantly reduced, resulting in higher dura-
bility.

4. PROPOSED ARCHITECTURE

The page updates in the NAND ﬂash memory layer ex-
hibit highly non-overlapping bit patterns over iterations and
the total number of bit changes in a page update of the
Spec2000 benchmark programs fails to exceed 15%. Conse-
quently, by isolating the bit changes in each page update,
the total number of page writes can be signiﬁcantly reduced
by reusing already programmed pages or by incorporating

207Figure 2: The Proposed Memory Architecture

Figure 3: Bit Diﬀerence Tracking Mechanism

bit transitions in additional pages. However, the sequential
order page programming constraints signiﬁcantly hinder this
approach by precluding random order page programming in
a block. The major contributions of the proposed mech-
anisms lie in the introduction of the eﬀective page reuse
mechanisms. We attain this by allowing random order page
programming under the fulﬁllment of the aforementioned
bit screening constraint and by minimizing the impact of
bit screening in block reclamation through eﬀective page re-
ordering.

The detailed architectural ideas are introduced in the sub-
sequent subsections; the overall hardware architecture can
be seen in ﬁgure 2.

4.1 Page Update Through Bit Difference Track-

ing

Data accesses to memory pages generally exhibit diverse
access frequency and patterns. More importantly, the access
frequency is highly skewed and only a small portion of pages
are frequently accessed while most of the rest of the pages
are rarely accessed. Furthermore, we have identiﬁed diﬀer-
ent types of bit change patterns in page updates, (1) random
bit change, (2) same bit update, and (3) non-overlapping bit
update. While all three types of page updates can be ob-
served in most programs, for the frequently updated pages,
the non-overlapping bit updates are the most commonly
observed patterns as the big arrays in a program are in
general updated partially for a given time frame. Most of
these gradually changing memory arrays that are frequently
evicted from cache layers constitute signiﬁcant portions of
the NAND ﬂash memory write traﬃc.

There exist two major constraints in NAND ﬂash memory
that preclude the reuse of pages that are frequently updated:
sequential order page programming and bit screening eﬀect.
However, the sequential order page programming constraint
can be avoided when there is no bit screening violation as
discussed in section 3. Consequently, pages can be eﬀectively
reused up to the NOP count speciﬁed by the manufacturers.
The most eﬀective way of page reuse is to update the
page in place. However, in most cases, it violates the unidi-
rectionality constraint of bit change in page programming.
Consequently, a more eﬀective way of page update by in-
corporating bit diﬀerences in each page update can be ex-
tremely beneﬁcial. As discussed, the page update that only

changes a small fragment of the page with no overlapped bits
is the most ideal candidate for the diﬀerence update. These
page updates can be seamlessly converted into a diﬀerence
update that completely satisﬁes the three page programma-
bility criteria resulting in eﬀective page reuse.

As seen in ﬁgure 3, the diﬀerence between the original
page A and the updated page ˙A is represented by ¯A1, the
result of the simple arithmetic operation, ¯A1 = A(cid:2) ˙A, where
(cid:2) represents the XNOR operation. Due to the behavioral
characteristics, ¯A1 will be mostly ﬁlled with set bits except
for the bits that are being modiﬁed as a result of the up-
date. For the subsequent page ¨A, which is updated from
˙A, the updated diﬀerential page, ¯A2, is calculated by ap-
plying A (cid:2) ¨A, unless the update from ¯A1 to ¯A2 violates the
unidirectional page programming constraints. Subsequent
page updates up until ¯A4 can be performed in an identi-
cal manner. During the updates, original pages can be also
updated when the unidirectionality conﬂicts occur in the
diﬀerence pages. However, the eﬃciency of the dual update
scheme, the combination of the in-place update and diﬀer-
ence update, directly depends on the number of ’0’ bits in
the original page.

For example, to retrieve a page that has already been
updated 4 times with the aforementioned mechanism, the
....
B , can be obtained as
most up-to-date version of the page,
....
B = B (cid:2) ¯B4, whereB is the original page and ¯B4
follows:
is the most recently updated diﬀerence page; the procedures
¯B4 contains the aggregated
also can be seen in ﬁgure 3.
non-overlapping bit diﬀerence.

However, the page updates both in the data block and
the diﬀerence block may cause bit screening violations due
to the allowance of the random order page programming in-
side a block. Thus, the page updatability check should be
examined before the actual update. Any ’0’ programmed
bit (reset bit) in adjacent pages triggering a bit screen-
ing eﬀect prohibits correct programming of the same bit
of the page under programming. Consequently, all the pro-
grammed pages in a block whose page number is greater than
the page under programming should be read and examined
for possible bit screening. This scheme may cause signif-
icant overhead when a page to be programmed has many
programmed pages that may introduce potential bit screen-
ing. Thus, limiting the maximum amount of neighbor page
comparisons can eﬀectively guarantee reasonable overhead
of the updatability check. For this purpose, each page is

208When a page is read, the read data also go through the
masking process to revert the transformed data back to the
original data. To simply achieve this transformation, the
masking process applies a simple XOR operation both for
reading and writing pages.

This scheme is only applicable to data blocks to enhance
the in-place page update possibility. However, the diﬀerence
block does not require the masking mechanism because it
maintains already transformed data contents that are vary-
ing at run-time. To calculate a mask during a block reclama-
tion, a NAND block-sized reclamation buﬀer and a physical
NAND ﬂash page per block should be allocated to store the
block-level mask information. To further minimize the per-
formance degradation of accessing masks, a small cache to
hold the most recent block-level masks should be incorpo-
rated.

4.3 Effective Trafﬁc Classiﬁcation

As discussed in Section 3, the page access frequency can be
highly skewed. Even in a single block, pages of highly vary-
ing frequency of access may cohabit, ranging from highly fre-
quently accessed to quite infrequently accessed pages. While
the mechanisms discussed in subsection 4.1 reduce the amount
of page programming due to frequently accessed pages, the
infrequently accessed pages in a block continuously produce
unnecessary page writes when the block is reclaimed. Al-
though these pages are not updated, they should be copied
to the new block during reclamation because they still hold
valid data. Consequently, the amount of infrequently ac-
cessed pages in a block directly aﬀects block usage eﬃciency.
The negative impact of this aspect is accentuated when the
block also contains highly frequently accessed pages.

To minimize this impact, pages should be classiﬁed and
spatially clustered based on their access frequency. In sub-
section 4.1, we proposed a two block scheme to maintain
original data and the diﬀerence data. When a page update is
required, the update should be preferably processed only in
the diﬀerence block instead of utilizing both the data block
and the diﬀerence block simultaneously. Consequently, data
blocks should hold infrequently accessed pages and diﬀer-
ence blocks should hold frequently accessed pages in the long
run. When a diﬀerence block is reclaimed, the valid pages
in the block should be moved back to the associated data
block. Signiﬁcant reduction in page programs during recla-
mations can be attained by utilizing this method of traﬃc
classiﬁcation.

4.4 Reduction of Cell Defect Probability

The durability of the NAND ﬂash memory is directly af-
fected by the amount of block erasures. Although a certain
threshold of block erasures and page programs is guaranteed
by manufacturers, the actual probability of the faulty cells
due to these operations is predicated on the accumulated
number of programmed ’0’ bits. The process of program-
ming of a NAND ﬂash cell causes physical damage to the
thin oxide layer and the damage is accumulated over con-
secutive operations. As the voltage threshold window that
separates the programmed state and the erased state nar-

Figure 4: Block-Level Bit Masking and Reordering

augmented with additional Updatability information deter-
mined by the amount of updates that have already taken
place in that page and by the distance between the page
and the most distant programmed page.

4.2 Reduction of Bit Screening Through Block-

Level Masking

As the pages in a data block are consumed by page writes
and updates, the amount of available empty pages shrinks.
When no empty page remains or no update is allowed for
an upcoming write/update traﬃc, the block should be re-
claimed for future use. The reclamation operation is com-
prised of two phases; (1) copying all the valid pages to a new
block, and (2) erasing the block.

When valid pages are copied to a new block, full informa-
tion on the pages such as bit contents and update counts
can be obtained and utilized towards further optimizations.
Consequently, we can perform extensive optimization in this
phase to enhance page reuse by transforming the bit infor-
mation inside a page and reordering the page locations. The
page content transformation is beneﬁcial when the trans-
formed data has reduced the number of ’0’ bits, thus af-
fording increased updatability. The page reordering process
helps minimize the bit screening eﬀect by incorporating page
access patterns. In general, a well-tuned technique combin-
ing the two mechanisms is required to achieve maximum
beneﬁts.

The page content transformation can be easily performed
by introducing a block-level bit mask in which the ’0’ bit
in each column is counted and the associated mask bit is
set when the number of ’0’ bits exceeds a given threshold.
The overall number of ’0’ bits in a page can be reduced but
page updatability may not be signiﬁcantly improved due to
possible bit screening by the preceding pages. Thus, the
frequently updated pages are programmed last in sequential
page program order and the weighted counts of ’0’ bits in
each column are applied to decide the bit mask of the column
as can be seen in ﬁgure 4.
A mask bit is set when

i Wi · Zi > δ, where Wi
denotes the weight of the ith page representing the amount
of page updates before the reclamation, Zi, the inverse of
the bit on the ith page, and δ, the threshold value to ﬂip
the bit. This scheme should be applied for all the 2K bits of
the valid pages and the mask value can be determined and
should be stored in the ﬁrst page of the new block.

i Zi/

P

P

2095.1 Experimental Framework

5.3 System Overhead

Table 3: Spec2000 Benchmark Applications Sum-
mary

Application Type
Game
CRAFTY
Interpreter
GAP
GCC
Compiler
Compressor
GZIP
VPR
Circuit placement

Code Size Data Space
1150KB
1025KB
303KB
398KB
1192KB

432KB
912KB
1956KB
345KB
79KB

rows due to the accumulated damage, read sensing errors
can be generated when the window excessively narrows, re-
sulting in turn in drastic increases in run-time cell defect
rate. For cell programming, the bits that are programmed
to ’0’ experience high stress due to the applied high voltage.
In addition to the reduction in the number of page programs
through the advocated page reuse, the proposed mechanisms
also reduce the total number of ’0’ bit programs to minimize
the run-time probabilistic cell defects. Furthermore, bit dis-
turbances caused by neighboring ’0’ programmed cells are
also greatly relieved.

5. EXPERIMENTAL RESULTS

We have extensively utilized the SimpleScalar toolset to
perform experiments under various conditions. The experi-
mental architecture is equipped with two distinct 32KB di-
rect mapped L1 I/D caches and a 128KB 4way set associa-
tive uniﬁed L2 cache with 2KB cache line size to eﬃciently
interact with the NAND ﬂash memory. To acquire the L1
miss penalty of the NAND based primary memory, we model
the timing of the proposed architecture based on the opera-
tional timing of the SAMSUNG K9K8G08U0A NAND ﬂash
memory for the NAND access and the advanced SRAM for
the interface with the processor. A setup comprised of a to-
tal 2GB of ﬂash memory with two 8Gbit NAND ﬂash mem-
ory is simulated. We perform simulation runs of 1 billion in-
structions per program. We simulate a set of representative
programs from Spec2000, which approximate the behavior
and complexity of real-life embedded applications. Table 3
outlines the benchmarks used for the experiments.

5.2 Expected Device Life-Cycle

The total number of replacement blocks and the conse-
quent rate of block replacements directly impacts the life-
cycle of the NAND ﬂash memory device along with the dis-
tribution of the block replacements over the blocks. The
proposed architecture signiﬁcantly enhances page reuse fre-
quency and associated block replacements. The experimen-
tal results observed in ﬁgure 5 demonstrate that the pro-
posed architecture experiences on the average a 3.3 times
reduction in block replacement compared to the baseline
conﬁguration, which already has achieved reductions in ex-
cess of 95% compared to the ﬁxed block utilization. For
crafty, gap and gzip, the proposed architecture shows more

Figure 5: Number of Replacement Blocks per 1 Bil-
lion Instructions

than 3.5 times of page replacement reduction due to eﬀec-
tive page reuse schemes. However, gcc shows a relatively
low improvement. Gcc shows a signiﬁcant amount of over-
lapping updates that cannot be handled by the proposed
bit diﬀerence tracking scheme but traﬃc classiﬁcation and
block-level bit masking still seem to be beneﬁcial. Further-
more, the proposed architecture minimizes the amount of ’0’
bits in programmed pages and the probability of bit defects
caused by page programs can thus also be attenuated.

Compared to the baseline, the proposed architecture shows
a slight performance degradation as can be seen in ﬁgure 6
even though the overall number of reclamations is signiﬁ-
cantly reduced. For a page read, it requires an additional
XOR operation.
If a page is updated, additional time to
read the diﬀerence page with additional XNOR operations
is required. However, both page reads from the data block
and the diﬀerence block can be accessed simultaneously if
these blocks are located in physically distinct NAND ﬂash
chips. For a page write, additional updatability checks read-
ing multiple pages depending on the updatability of the pre-
ceding pages are required. However, the impact of the sys-
tem level performance degradation is very limited and fur-
ther alleviated when parallel NAND ﬂash memory accesses
are employed.

The proposed architecture highly relies on the optimal

Figure 6: Average Access Time Comparisons

210page reuse and associated reduction of block replacements.
The block utilization ratio is determined based on the appli-
cation behavior as in the previous work. Additionally, each
block should consume one page to store block-level mask in-
formation. Blocks that are updated also require additional
diﬀerence blocks but the total amount of diﬀerence blocks
can be controlled. Along with this space overhead, the pro-
posed architecture exhibits some degree of overhead in its
logic and internal memory. Under the current experimental
conﬁguration, it consumes 256KB+64KB of SRAM for the
read cache/write buﬀer and reclamation buﬀer. It further
requires a small SRAM space for maintaining information
in the block-level mask cache and additional housekeeping
information. The logic overhead is mainly dedicated to the
cache/memory steering logic and binary tree based address
controlling logic. The overhead of additional XOR/XNOR
logic is insigniﬁcant and the degree of the memory and logic
overhead is already quite small, with its importance slated
to diminish further in the near future as semiconductor tech-
nology continues to evolve.

6. CONCLUSION

In this paper, we have proposed a highly eﬀective NAND
ﬂash memory page reuse mechanism to achieve high dura-
bility by aggressively applying a partial programming ca-
pability. The proposed architecture provides unique mech-
anisms to alleviate the page programming and associated
block reclamation overhead through the reduction of block
reclamations. Furthermore, the overall stress on each cell
during page programming is signiﬁcantly reduced by trans-
forming the bit representations of the valid data into new
bit streams. The beneﬁt of the cell stress reduction may
not be observed directly but the impact on the endurance
of the NAND ﬂash based memory could be signiﬁcant. We
believe that the proposed mechanisms can be applied to all
NAND ﬂash based memory systems and provide signiﬁcant
enhancement on the durability of the memory directly and
indirectly. The experimental results show that the proposed
architecture signiﬁcantly prolongs the device life-cycle by
minimizing the program/erase operations with slight degra-
dation on average memory access time.

7. REFERENCES
[1] OneNANDTM. http://www.samsungsemi.com.
[2] International Technology Roadmap for

Semiconductors, 2009. http://www.itrs.net.

[3] Ahn, S., Song, Y., Jeong, C., Shin, J., Fai, Y.,

Hwang, Y., Lee, S., Ryoo, K., Lee, S., and Park,
J. Highly manufacturable high density phase change
memory of 64Mb and beyond. In IEDM Technical
Digest ’04: Proceedings of the IEEE International
Electron Devices Meeting (2004), pp. 907–910.

[4] Grupp, L. M., Caulfield, A. M., Coburn, J.,
Swanson, S., Yaakobi, E., Siegel, P. H., and
Wolf, J. K. Characterizing ﬂash memory: anomalies,
observations, and applications. In MICRO 42:

Proceedings of the 42nd Annual IEEE/ACM
International Symposium on Microarchitecture (2009),
pp. 24–33.

[5] In, J., Shin, I., and Kim, H. SWL: a

search-while-load demand paging scheme with NAND
ﬂash memory. In LCTES ’07: Proceedings of the 2007
ACM SIGPLAN/SIGBED Conference on Languages,
Compilers, and Tools (2007), pp. 217–226.

[6] Joo, Y., Choi, Y., Park, C., Chung, S. W.,

Chung, E., and Chang, N. Demand paging for
OneNANDTMFlash eXecute-in-place. In
CODES+ISSS ’06: Proceedings of the 4th
International Conference on Hardware/Software
Codesign and System Synthesis (2006), pp. 229–234.

[7] Kaufman, A. B. An expandable ferroelectric random
access memory. IEEE Transactions on Computers 22,
2 (1973), 154–158.

[8] Lee, J., Lee, C., Lee, M., Kim, H., Park, K., and
Lee, W. New programming disturbance phenomenon
in NAND ﬂash memory by source/drain hot-electrons
generated by GIDL current. In NVSMW ’06:
Proceedings of the 21st Non-Volatile Semiconductor
Memory Workshop (2006), pp. 31–33.

[9] Lee, K., and Orailoglu, A. Application speciﬁc low

latency instruction cache for NAND ﬂash memory
based embedded systems. In SASP ’08: Proceedings of
the 2008 Symposium on Application Speciﬁc
Processors (2008), pp. 69–74.

[10] Lee, K., and Orailoglu, A. Application speciﬁc

non-volatile primary memory for embedded systems.
In CODES+ISSS ’08: Proceedings of the 6th
IEEE/ACM/IFIP International Conference on
Hardware/Software Codesign and System Synthesis
(2008), pp. 31–36.

[11] Masuoka, F. New ultra high density EPROM and
ﬂash with NAND structure cell. In EDM Technical
Digest ’87: Proceedings of the IEEE International
Electron Devices Meeting (1987), pp. 552–555.

[12] Park, C., Lim, J., Kwon, K., Lee, J., and Min,

S. L. Compiler-assisted demand paging for embedded
systems with ﬂash memory. In EMSOFT ’04:
Proceedings of the 4th ACM International Conference
on Embedded Software (2004), pp. 114–124.

[13] Park, C., Seo, J., Bae, S., Kim, H., Kim, S., and
Kim, B. A low-cost memory architecture with NAND
XIP for mobile embedded systems. In CODES+ISSS
’03: Proceedings of the 1st IEEE/ACM/IFIP
International Conference on Hardware/Software
Codesign and System Synthesis (2003), pp. 138–143.
[14] Tehrani, S., Slaughter, J. M., Deherrera, M.,
Engel, B. N., Rizzo, N. D., Salter, J., Durlam,
M., Dave, R. W., Janesky, J., Butcher, B.,
Smith, K., and Grynkewich, G. Magnetoresistive
random access memory using magnetic tunnel
junctions. In Proceedings of the IEEE (2003),
pp. 703–714.

211