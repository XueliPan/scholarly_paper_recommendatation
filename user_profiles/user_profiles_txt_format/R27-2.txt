89

OverviewoftheINEX2010BookTrack:AttheMercyofCrowdsourcingGabriellaKazai1,MarijnKoolen2,AntoineDoucet3,andMonicaLandoni41MicrosoftResearch,UnitedKingdomv-gabkaz@microsoft.com2UniversityofAmsterdam,Netherlandsm.h.a.koolen@uva.nl3UniversityofCaen,Francedoucet@info.unicaen.fr4UniversityofLuganomonica.landoni@unisi.chAbstract.ThegoaloftheINEX2010BookTrackistoevaluateap-proachesforsupportingusersinreading,searching,andnavigatingthefulltextsofdigitizedbooks.Theinvestigationisfocusedaroundfourtasks:1)theBookRetrieval(BestBookstoReference)taskaimsatcomparingtraditionalandbook-speciﬁcretrievalapproaches,2)theFo-cusedBookSearch(ProveIt)taskevaluatesfocusedretrievalapproachesforsearchingbooks,3)theStructureExtractiontasktestsautomatictechniquesforderivingstructurefromOCRandlayoutinformation,and4)theActiveReadingtaskaimstoexploresuitableuserinterfacesforeBooksenablingreading,annotation,review,andsummaryacrossmul-tiplebooks.Wereportonthesetupandtheresultsofthetrack.1IntroductionTheINEXBookTrackwaslaunchedin2007,promptedbytheavailabilityoflargecollectionsofdigitizedbooksresultingfromvariousmass-digitizationprojects[1],suchastheMillionBookproject5andtheGoogleBooksLibraryproject6.Theunprecedentedscaleoftheseeﬀorts,theuniquecharacteristicsofthedigitizedmaterial,aswellastheunexploredpossibilitiesofuserinteractionspresentexcitingresearchchallengesandopportunities,seee.g.[4].TheoverallgoaloftheINEXBookTrackistopromoteinter-disciplinaryresearchinvestigatingtechniquesforsupportingusersinreading,searching,andnavigatingthefulltextsofdigitizedbooks,andtoprovideaforumfortheexchangeofresearchideasandcontributions.Towardthisgoal,thetrackaimstoprovideopportunitiesforexploringresearchquestionsaroundthreebroadtopics:–Informationretrievaltechniquesforsearchingcollectionsofdigitizedbooks,5http://www.ulib.org/6http://books.google.com/90

–Mechanismstoincreaseaccessibilitytothecontentsofdigitizedbooks,and–Users’interactionswitheBooksandcollectionsofdigitizedbooks.Basedaroundthesemainthemes,thefollowingfourtasksweredeﬁned:1.TheBestBookstoReferencel(BB)task,framedwithintheusertaskofbuildingareadinglistforagiventopicofinterest,aimsatcomparingtradi-tionaldocumentretrievalmethodswithdomain-speciﬁctechniques,exploit-ingbook-speciﬁcfeatures,e.g.,back-of-bookindex,orassociatedmetadata,e.g.,librarycatalogueinformation,2.TheProveIt(PI)taskaimstotestthevalueofapplyingfocusedretrievalapproachestobooks,whereusersexpecttobepointeddirectlytorelevantbookparts,3.TheStructureExtraction(SE)taskaimsatevaluatingautomatictechniquesforderivingstructurefromOCRandlayoutinformationforbuildinghyper-linkedtableofcontents,and4.TheActiveReadingtask(ART)aimstoexploresuitableuserinterfacesenablingreading,annotation,review,andsummaryacrossmultiplebooks.Inthispaper,wereportonthesetupandtheresultsofeachofthesetasksatINEX2010.First,inSection2,wegiveabriefsummaryoftheparticipatingorganisations.InSection3,wedescribethecorpusofbooksthatformsthebasisofthetestcollection.Thefollowingthreesectionsdetailthefourtasks:Section4summarisesthetwosearchtasks(BRandFBS),Section5reviewstheSEtask,andSection6discussesART.WecloseinSection7withasummaryandplansforINEX2010.2ParticipatingOrganisationsAtotalof82organisationsregisteredforthetrack(comparedwith84in2009,54in2008,and27in2007).Asofthetimeofwriting,wecounted10activegroups(comparedwith16in2009,15in2008,and9in2007),seeTable1.3TheBookCorpusThetrackbuildsonacollectionof50,239out-of-copyrightbooks7,digitizedbyMicrosoft.Thecorpusismadeupofbooksofdiﬀerentgenre,includinghis-torybooks,biographies,literarystudies,religioustextsandteachings,referenceworks,encyclopedias,essays,proceedings,novels,andpoetry.50,099ofthebooksalsocomewithanassociatedMAchine-ReadableCataloging(MARC)record,whichcontainspublication(author,title,etc.)andclassiﬁcationinformation.Eachbookinthecorpusisidentiﬁedbya16characterlongbookID–thenameofthedirectorythatcontainsthebook’sOCRﬁle,e.g.,A1CD363253B0F403.7AlsoavailablefromtheInternetArchive(althoughinadiﬀerentXMLformat)91

Table1.ActiveparticipantsoftheINEX2009BookTrack,contributingtopics,runs,and/orrelevanceassessments(BR=BookRetrieval,FBS=FocusedBookSearch,SE=StructureExtraction,ART=ActiveReadingTask)IDInstituteTopicsRunsJudgedtopics(book/pagelevel)6UniversityofAmsterdam19-20,222BB,4PI7OsloUniversityCollege02-065PI14Uni.ofCalifornia,Berkeley4BB54MicrosoftResearchCambridge00-01,07-09,24-2586UniversityofLugano15-18,21,2398UniversityofAvignon9BB,1PI386UniversityofTokyo662IzmirInstituteofTechnology663IIIT-H10-14732WuhanUniversityTheOCRtextofthebookshasbeenconvertedfromtheoriginalDjVufor-mattoanXMLformatreferredtoasBookML,developedbyMicrosoftDe-velopmentCenterSerbia.BookMLprovidesadditionalstructureinformation,includingmarkupfortableofcontentsentries.ThebasicXMLstructureofatypicalbookinBookMLisasequenceofpagescontainingnestedstructuresofregions,sections,lines,andwords,mostofthemwithassociatedcoordinateinformation,deﬁningthepositionofaboundingrectangle([coords]):<document><pagepageNumber="1"label="PTCHAPTER"[coords]key="0"id="0"><regionregionType="Text"[coords]key="0"id="0"><sectionlabel="SECBODY"key="408"id="0"><line[coords]key="0"id="0"><word[coords]key="0"id="0"val="Moby"/><word[coords]key="1"id="1"val="Dick"/></line><line[...]><word[...]val="Melville"/>[...]</line>[...]</section>[...]</region>[...]</page>[...]</document>BookMLprovidesasetoflabels(asattributes)indicatingstructureinforma-tioninthefulltextofabookandadditionalmarkerelementsformorecomplexstructures,suchasatableofcontents.Forexample,theﬁrstlabelattribute92

intheXMLextractabovesignalsthestartofanewchapteronpage1(la-bel=“PTCHAPTER”).Othersemanticunitsincludeheaders(SECHEADER),footers(SECFOOTER),back-of-bookindex(SECINDEX),tableofcontents(SECTOC).Markerelementsprovidedetailedmarkup,e.g.,fortableofcon-tents,indicatingentrytitles(TOCTITLE),andpagenumbers(TOCCHPN),etc.Thefullcorpus,totalingaround400GB,wasmadeavailableonUSBHDDs.Inaddition,areducedversion(50GB,or13GBcompressed)wasmadeavailablefordownload.Thereducedversionwasgeneratedbyremovingthewordtagsandpropagatingthevaluesofthevalattributesastextcontentintotheparent(i.e.,line)elements.4InformationRetrievalTasksFocusingonIRchallenges,twosearchtaskswereinvestigated:1)BestBookstoReference(BB),and2)ProveIt(PI).BoththesetasksusedthecorpusdescribedinSection3,andsharedthesamesetoftopics(seeSection4.3).4.1TheBestBookstoReference(BB)TaskThistaskwassetupwiththegoaltocomparebook-speciﬁcIRtechniqueswithstandardIRmethodsfortheretrievalofbooks,where(whole)booksarereturnedtotheuser.Theuserscenariounderlyingthistaskisthatofausersearchingforbooksonagiventopicwiththeintenttobuildareadingorreferencelist,similartothoseappendedtoanacademicpublicationoraWikipediaarticle.Thereadinglistmaybeforresearchpurposes,orinpreparationoflecturematerials,orforentertainment,etc.Participantsofthistaskwereinvitedtosubmiteithersinglerunsorpairsofruns.Atotalof10runscouldbesubmitted,eachruncontainingtheresultsforallthe83topics(seeSection4.3).Asingleruncouldbetheresultofeitherageneric(non-speciﬁc)orabook-speciﬁcIRapproach.Apairofrunshadtocontainbothtypes,wherethenon-speciﬁcrunservedasabaseline,whichthebook-speciﬁcrunextendeduponbyexploitingbook-speciﬁcfeatures(e.g.,back-of-bookindex,citationstatistics,bookreviews,etc.)orspeciﬁcallytunedmethods.Oneautomaticrun(i.e.,usingonlythetopictitlepartofatopicforsearchingandwithoutanyhumanintervention)wascompulsory.Aruncouldcontain,foreachtopic,amaximumofonly100books(identiﬁedbytheirbookID),rankedinorderofestimatedrelevance.Atotalof15runsweresubmittedby3groups(2runsbyUniversityofAmsterdam(ID=6);4runsbyUniversityofCalifornia,Berkeley(ID=14);and9runsbytheUniversityofAvignon(ID=98)),seeTable1.4.2TheProveIt(PI)TaskThegoalofthistaskwastoinvestigatetheapplicationoffocusedretrievalap-proachestoacollectionofdigitizedbooks.Thescenariounderlyingthistask93

isthatofausersearchingforspeciﬁcinformationinalibraryofbooksthatcanprovideevidencetoconﬁrmorrejectagivenfactualstatement.Usersareassumedtoviewtherankedlistofbookparts,movingfromthetopofthelistdown,examiningeachresult.Nobrowsingisconsidered(onlythereturnedbookpartsareviewedbyusers).Participantscouldsubmitupto10runs.Eachruncouldcontain,foreachofthe83topics(seeSection4.3),amaximumof1,000bookpagesestimatedrelevanttothegivenaspect,orderedbydecreasingvalueofrelevance.Atotalof10runsweresubmittedby3groups(4runsbytheUniversityofAmsterdam(ID=6);5runsbyOsloUniversityCollege(ID=7);and1runbytheUniversityofAvignon(ID=98)),seeTable1.4.3TopicsThisyearweexploredtheuseofAmazon’sMechanicalTurk(AMT)servicetoaidinthecreationoftopicsforthetestcollection.ThisismotivatedbytheneedtoscaleuptheCranﬁeldmethodforconstructingtestcollectionswherethesig-niﬁcanteﬀortrequiredtocreatetesttopicsandtocollectrelevancejudgementsisotherwiseinhibiting.Byharnessingthecollectiveworkofthecrowds,crowd-sourcingoﬀersanincreasinglypopularalternativeforgatheringlargeamountsofdatafeasibly,atarelativelylowcostandinarelativelyshorttime.Weareinterestedinusingcrowdsourcingtocontributetothebuildingofatestcollec-tionfortheBookTrack,whichhasthusfarstruggledtomeetthisrequirementbyrelyingonitsparticipants’eﬀortsalone.Withthisaim,weexperimentedwithgatheringtopicsboththroughAma-zon’sMechanicalServiceandfromthetrackparticipants.Ouraimwastocom-parethequalityofthecollectedtopicsandassessthefeasibilityofcrowdsourcingtopics(andrelevancejudgementslateron).Tothisend,weﬁrstredeﬁnedthesearchtasks,simplifyingtheminordertomaketopiccreationforthemsuitableasaHumanIntelligentTask(HIT).Asmentionedalready,intheProveIttasksystemsneedtoﬁndevidenceinbooksthatcanbeusedtoeitherconﬁrmorrefuteafactualstatementgivenasthetopic.IntheBestBookstasksystemsneedtoreturnthemostrelevantbooksonthegeneralsubjectareaofthetopic.Tocollectthetesttopicsforthetwotasks,wecreatedthefollowingtwoHITs:–FactsinbooksHIT(BookHIT):“Yourtaskistofndageneralknowledgefactthatyoubelieveistrueinabookavailableathttp://booksearch.org.uk.BoththefactandthebookmustbeinEnglish.Thefactshouldnotbelongerthanasentence.Forexample,thefactthat‘TheﬁrstElectricRailwayinLondonwasopenedin1890andrunbetweenthestations:BankandStockwell’canbefoundonpage187ofthebooktitled‘WestLondon’byGeorgeBosworth”.Workerswereaskedtorecordthefactualstatementtheyfound,theURLofthebookcontainingthefact,andthepagenumber.–FactsinbooksandWikipediaHIT(WikiHIT):“Yourtaskistoﬁndagen-eralknowledgefactthatappearsBOTHinaWikipediaarticleANDina94

bookavailableathttp://booksearch.org.uk.YoucanstarteitherbyﬁndingafactonWikipediaﬁrst,thenlocatingthesamefactinabook,oryoucanstartbyﬁndingafactinabookandtheninWikipedia.Forexample,theWikipediapageonBeethoven’sSymphonyNo.3claimsthat‘Beethovended-icatedthesymphonytoNapoleon,butwhenNapoleonproclaimedhimselfemperor,Beethoventoreupthetitle’.Page144ofthebooktitledBeethovenbyRomainRollanddescribesthisveryfact”.Workersneededtorecordthefactualstatement,theURLandpagenumberofthebookwherethefactisfound,aswellastheWikipediaarticle’sURL.Wecreated10WikiHITs,paying$0.25perHIT,andissuedtwobatchesofBookHITs,with50HITsineachbatch,paying$0.10perHITintheﬁrstbatchand$0.20inthesecondbatch.All10WikiHITswerecompletedwithinaday,whileonly32FactHITswerecompletedin11daysoutoftheﬁrstbatch.Thesecondbatchof50BookHITswascompletedfullyin14days.TheaveragetimerequiredperBookHITwas8minutesintheﬁrstbatchand7minutesinthesecondbatch(hourlyrateof$0.73and$1.63,respectively),whileWikiHITstookonaverage11minutestocomplete(hourlyrateof$1.31).ThesestatisticssuggestthatworkersfoundtheWikipediataskmoreinteresting,despiteittakinglonger.However,asweshowlater,theattractivenessofaHITdoesnotguaranteegoodqualitytopics.Atthesametime,INEXparticipantswereaskedtocreate5topicseach,2ofwhichhadtocontainfactualstatementsthatappearsbothinabookandinWikipedia.Atotalof25topicsweresubmittedby5groups.Ofthese,16factsappearbothinbooksandinWikipedia.AllcollectedtopicswerecarefullyreviewedandthosejudgedsuitablewereselectedintothesetoftesttopicsthatiscurrentlybeingusedbytheINEXBookTrack.AlltopicscontributedbyINEXparticipantswereselected,whileﬁlteringwasnecessaryfortopicscreatedbyAMTworkers.Outofthe10WikiHITs,only4topicswereselected.Ofthe32BookHITsintheﬁrstbatch,18wereacceptable,while36wereselectedfromthe50BookHITsinthesecondbatch.HITswererejectedforanumberofreasons:theinformationgivenwassimplyanextractfromabook,ratherthanafact(20),thefactwastoospecialised(5),ornonsensical(5),theHIThadmissingdata(3),ortheworkersubmittedtheexamplegiveninthetaskdescription(1).Ofthetotal58acceptedHITs,18hadtobemodiﬁed,eithertorephraseslightlyortocorrectadateorname,ortoaddadditionalinformation.Theremaining40HITswerehighqualityandreﬂectingrealinterestorinformationneed.Fromtheabove,itseemsclearthatcrowdsourcingprovidesasuitablewaytoscaleuptestcollectionconstruction:MTurkworkerscontributed58topics,whileINEXparticipantscreatedonly25topics.However,thequalityofcrowdsourcedtopicsvariesgreatlyandthusrequiresextraeﬀorttoweedoutunsuitablesubmis-sions.Wenotethatselectingworkersbasedontheirapprovalratehadapositiveeﬀectonquality:batch2oftheBookHITsrequiredworkerstohaveaHITapprovalrateof95%.Inaddition,payingworkersmorealsoshowscorrelationwiththeresultingquality.95

4.4RelevanceAssessmentSystemTheBookSearchSystem(http://www.booksearch.org.uk),developedatMi-crosoftResearchCambridge,isanonlinetoolthatallowsparticipantstosearch,browse,read,andannotatethebooksofthetestcorpus.Annotationincludestheassignmentofbookandpagelevelrelevancelabelsandrecordingbookandpagelevelnotesorcomments.Thesystemsupportsthecreationoftopicsforthetestcollectionandthecollectionofrelevanceassessments.ScreenshotsoftherelevanceassessmentmoduleareshowninFigures1and2.Inpreparationfortherelevancegatheringstage,whichwillruninparal-lel,collectingjudgementsfromINEXparticipantsandfromAMTworkers,wesimpliﬁedtheassessmentprocessfrompreviousyears.Fig.1.ScreenshotoftherelevanceassessmentmoduleoftheBookSearchSystem,showingthelistofbooksintheassessmentpoolforaselectedtopicingame1.Foreachbook,itsmetadata,itstableofcontents(ifany)andasnippetfromarecommendedpageisshown.4.5CollectedRelevanceAssessmentsThisisstillinprogressatthetimeofwriting.96

Fig.2.ScreenshotoftherelevanceassessmentmoduleoftheBookSearchSystem,showingtheBookViewerwindowwithRecommendedtablistingthepooledpagestojudgewithrespecttotopicaspectsingame2.Thetopicaspectsareshownbelowthepageimages.4.6EvaluationMeasuresandResultsWewillreportontheseoncesuﬃcientamountofrelevancelabelshavebeencollected.5TheStructureExtraction(SE)TaskThegoaloftheSEtaskwastotestandcompareautomatictechniquesforex-tractingstructureinformationfromdigitizedbooksandbuildingahyperlinkedtableofcontents(ToC).ThetaskwasmotivatedbythelimitationsofcurrentdigitizationandOCRtechnologiesthatproducethefulltextofdigitizedbookswithonlyminimalstructuremarkup:pagesandparagraphsareusuallyiden-tiﬁed,butmoresophisticatedstructures,suchaschapters,sections,etc.,aretypicallynotrecognised.The2010taskwasrunasafollow-upoftheconjointINEXandICDAR2009competition[2,3].Participantswereabletoreﬁnetheirapproacheswiththehelpofthegroundtruthbuiltin2009.Onlyoneinstitution,theUniversityofCaen,participatedinthisrerunofthe2009task,while2contributedtotheextensionofthegroundtruthdata,sincetheUniversityofFirenzejoinedtheeﬀort.Thegroundtruthnowcoversanadditional114booksandreachesatotalof641annotatedToCs.97

Theperformanceofthe2010runisgiveninTable2.Asummaryoftheperformanceofthe2009runswiththeextended2010groundtruthdataisgiveninTable3.PrecisionRecallF-measureTitles18.03%12.53%12.33%Levels13.29%9.60%9.34%Links14.89%7.84%7.86%Completeexceptdepth14.89%10.17%10.37%Completeentries10.89%7.84%4.86%Table2.ScoresheetoftherunsubmittedbytheUniversityofCaenduringthe2010rerunoftheSEcompetition2009RunIDParticipantF-measure(2010)F-measure(2009)MDCSMDCS43.39%41.51%XRCE-run2XRCE28.15%28.47%XRCE-run1XRCE27.52%27.72%XRCE-run3XRCE26.89%27.33%NoopsisNoopsis8.31%8.32%GREYC-run1UniversityofCaen0.09%0.08%GREYC-run2UniversityofCaen0.09%0.08%GREYC-run3UniversityofCaen0.09%0.08%Table3.Summaryofperformancescoresforthe2009runswiththeextended2010groundtruth-rerun;resultsareforcompleteentries.Naturally,thesmallincreaseinthesizeofthegroundtruthdoesnotmaketheresultsvarymuch(mostofthegroundtruthdatawasbuiltforthe2009experiments:527out641annotatedbooks).6TheActiveReadingTask(ART)ThemainaimofARTistoexplorehowhardwareorsoftwaretoolsforreadingeBookscanprovidesupporttousersengagedwithavarietyofreadingrelatedactivities,suchasfactﬁnding,memorytasks,orlearning.Thegoaloftheinvesti-gationistoderiveuserrequirementsandconsequentlydesignrecommendationsformoreusabletoolstosupportactivereadingpracticesforeBooks.Thetaskismotivatedbythelackofcommonpracticeswhenitcomestoconductingusabil-itystudiesofe-readertools.Currentuserstudiesfocusonspeciﬁccontentandusergroupsandfollowavarietyofdiﬀerentproceduresthatmakecomparison,98

reﬂection,andbetterunderstandingofrelatedproblemsdiﬃcult.ARTishopedtoturnintoanidealarenaforresearchersinvolvedinsucheﬀortswiththecrucialopportunitytoaccessalargeselectionoftitles,representingdiﬀerentgenres,aswellasbeneﬁtingfromestablishedmethodologyandguidelinesfororganisingeﬀectiveevaluationexperiments.ARTisbasedontheevaluationexperienceofEBONI[5],andadoptsitseval-uationframeworkwiththeaimtoguideparticipantsinorganisingandrunninguserstudieswhoseresultscouldthenbecompared.Thetaskistorunoneormoreuserstudiesinordertotesttheusabil-ityofestablishedproducts(e.g.,Amazon’sKindle,iRex’sIlaidReaderandSony’sReadersmodels550and700)ornovele-readersbyfollowingthepro-videdEBONI-basedprocedureandfocusingonINEXcontent.ParticipantsmaythengatherandanalyseresultsaccordingtotheEBONIapproachandsubmittheseforoverallcomparisonandevaluation.Theevaluationistask-orientedinnature.Participantsareabletotailortheirownevaluationexperiments,insidetheEBONIframework,accordingtoresourcesavailabletothem.Inordertogatheruserfeedback,participantscanchoosefromavarietyofmethods,fromlow-eﬀortonlinequestionnairestomoretimeconsumingonetooneinterviews,andthinkaloudsessions.6.1TaskSetupParticipationrequiresaccesstooneormoresoftware/hardwaree-readers(al-readyonthemarketorinprototypeversion)thatcanbefedwithasubsetoftheINEXbookcorpus(maximum100books),selectedbasedonparticipants’needsandobjectives.Participantsareaskedtoinvolveaminimumsampleof15/20userstocomplete3-5growingcomplexitytasksandﬁllinacustomisedversionoftheEBONIsubjectivequestionnaire,allowingtogathermeaningfulandcomparableevidence.Additionalusertasksanddiﬀerentmethodsforgath-eringfeedback(e.g.,videocapture)maybeaddedoptionally.Acribsheetisprovidedtoparticipantsasatooltodeﬁnetheusertaskstoevaluate,providinganarrativedescribingthescenario(s)ofuseforthebooksincontext,includingfactorsaﬀectinguserperformance,e.g.,motivation,typeofcontent,stylesofreading,accessibility,locationandpersonalpreferences.Ouraimistorunacomparablebutindividualizedsetofstudies,allcon-tributingtoelicituserandusabilityissuesrelatedtoeBooksande-reading.Thetaskhassofaronlyattracted2groups,noneofwhomsubmittedanyresultsatthetimeofwriting.7ConclusionsandplansFortheevaluationofourtwosearchtasks(bestbooksandproveit),wearecurrentlycollectingrelevanceassessmentsfromINEXparticipants.ThiswillbeusedasgoldsetforcollectingjudgementsfromworkersonAmazon’sMechanical99

Turk(AMT).ResultswillthenbedistributedaroundFebruary2011.TheARTandSEtaskswereoﬀeredaslastyear.Thisyearthefocusedsearchtask(proveit)wasbasedonfactualstatementsforwhichsystemswereaskedtoﬁndbookpagesthateitherconﬁrmedorrefutedthefact.70TheSEtaskwasrun(thoughnotadvertised),usingthesamedatasetaslastyear.Oneinstitutionparticipatedandcontributedadditionalannotations.UnlesswegetaLOTmoreACTIVEparticipants,2011willprobablybethelastyearofthebooktrack.Wehopethatwiththeburdenoftopiccreationandrelevanceassessmentsremoved,wewillhowevergethigherparticipationnextyear.Wealsoplantore-shapetheresearchagendabysigniﬁcantlyincreasingthesizeofthecollectionontheonehand,andbydeﬁningmorechallengingtasksthatarefocusedonuserinteractionontheotherhand,placingtheARTinthecentre.References1.KarenCoyle.Massdigitizationofbooks.JournalofAcademicLibrarianship,32(6):641–645,2006.2.AntoineDoucet,GabriellaKazai,BodinDresevic,AleksandarUzelac,BogdanRadakovic,andNikolaTodic.ICDAR2009BookStructureExtractionCompe-tition.InProceedingsoftheTenthInternationalConferenceonDocumentAnalysisandRecognition(ICDAR’2009),pages1408–1412,Barcelona,Spain,july2009.3.AntoineDoucet,GabriellaKazai,BodinDresevic,AleksandarUzelac,BogdanRadakovic,andNikolaTodic.Settingupacompetitionframeworkfortheevalua-tionofstructureextractionfromocr-edbooks.InternationalJournalonDocumentAnalysisandRecognition,pages1–8,2010.4.PaulKantor,GabriellaKazai,NatasaMilic-Frayling,andRossWilkinson,editors.BooksOnline’08:Proceedingofthe2008ACMworkshoponResearchadvancesinlargedigitalbookrepositories,NewYork,NY,USA,2008.ACM.5.RuthWilson,MonicaLandoni,andForbesGibb.Thewebexperimentsinelectronictextbookdesign.JournalofDocumentation,59(4):454–477,2003.