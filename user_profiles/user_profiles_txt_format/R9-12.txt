Combating Imbalance in Network Intrusion Datasets

1

David A Cieslak, Nitesh V Chawla, Aaron Striegel
Department of Computer Science and Engineering

University of Notre Dame

Notre Dame, IN 46556 USA

Email:fdcieslak, nchawla, striegelg@nd.edu

Abstract— An approach to combating network intrusion is the
development of systems applying machine learning and data
mining techniques. Many IDS (Intrusion Detection Systems)
suffer from a high rate of false alarms and missed intrusions.
We want to be able to improve the intrusion detection rate at
a reduced false positive rate. The focus of this paper is rule-
learning, using RIPPER, on highly imbalanced intrusion datasets
with an objective to improve the true positive rate (intrusions)
without signiﬁcantly increasing the false positives. We chose
RIPPER to induce the comprehensibility in the model as is
required by humans using the system. To counter imbalance
in data, we implement a combination of oversampling (both
by replication and synthetic generation) and undersampling
techniques. We also propose a clustering based methodology for
oversampling by generating synthetic instances. We evaluate our
approaches on two intrusion datasets — destination and actual
packets based — constructed from actual Notre Dame trafﬁc,
giving a ﬂavor of real-world data with its idiosyncracies. Using
ROC analysis, we show that oversampling by synthetic genera-
tion of minority (intrusion) class outperforms oversampling by
replication and RIPPER’s loss ratio to inherently counter class
imbalance. Additionaly, we establish that our clustering based
approach is more suitable for the detecting intrusions.

Index Terms— Computer Network Security,

Imbalanced

Datasets, Classiﬁcation, ROC Curves

I. INTRODUCTION

Network intrusion detection refers to the set of techniques
used to isolate attacks against computers and networks. An
Intrusion Detection System (IDS) thus detects hostile activities
in a network. In addition to detection of attacks, such a system
must prevent their malicious effects, or assist a human in
a system or network administrator role in this prevention.
By nature, even basic networks are very complex systems
and the further evolution of the Internet has made it dif(cid:2)cult
to construct a total understanding of the system. However,
work by Leland et al. suggests that network traf(cid:2)c may
contain complex, yet self-similar patterns [1]. Later, multi-
fractal scaling was discovered and reported by Levy-Vehel et
al. [2]. The results of the 1998 DARPA Off-line Intrusion
Detection Evaluation indicated that further research should be
performed focusing on techniques to (cid:2)nd new attacks [3].

Data-mining applications to network security can be broadly
categorized into two sets, anomaly detection and signature
detection. Anomaly detection constructs models of normal data
and then detects deviations from this norm (anomalous logins,
traf(cid:2)c to source port > X), typically using outlier detection.
The dif(cid:2)culty in this method is differentiating (cid:147)normal(cid:148) behav-
ior from (cid:147)abnormal(cid:148) behavior causing these techniques tend

to suffer from high false positive rates. However, there has
been work in reducing the false positive rate by using multiple
data streams [4]. Other avenues of false positive rate improve-
ment includes hierarchical aggregation of speci(cid:2)ed portions of
total activity [5]. Alternatively, the signature-based approach
searches for speci(cid:2)c patterns (strings) that denote suspicious
behavior. While this approach is suf(cid:2)cient for known attacks,
it becomes insuf(cid:2)cient when the attack signature or normal
traf(cid:2)c makeup is unknown. This breakdown leads signature-
based approaches to suffer from the high false positive rate
problem that anomaly detection faces. Thus, it is imperative to
design methods of classi(cid:2)cation with low false positive rates.

the expense of false alarms, as it will

Going hand in hand is the compelling and inherent problem
of learning such classi(cid:2)ers from highly imbalanced network
intrusion datasets. Typically, network intrusions and malicious
behavior will represent a very small subset of all network
traf(cid:2)c. However, their detection is highly critical for the health
of a network. We cannot afford a high intrusion detection
rate at
lead to a
loss of relevant packets. Thus, learning classi(cid:2)ers from such
unbalanced datasets faces a number of relevant problems:
improper classi(cid:2)cation evaluation metrics, absolute or relative
lack of data, data fragmentation, improper inductive bias,
and noise [6]. Not only does an imbalanced dataset skew
the accuracy and probability measures employed by classi(cid:2)er
constructors, but the overpopulation of majority class examples
makes it diffcult to induce proper class boundaries. The con-
(cid:3)uence of these factors make accurate classi(cid:2)er construction
on imbalanced datasets a dif(cid:2)cult procedure that requires both
specialized methods to enhance learning and speci(cid:2)c metrics
to measure performance.

Axelsson [7] demonstrated that the primary limitation of an
intrusion detection system is not the ability to identify behavior
as intrusive, rather its effectiveness stems from its abilities to
limit false alarms. Therefore, it is the purpose of this paper
to study the effectiveness of several
techniques to reduce
false positives in intrusion datasets. We chose to construct
our own (cid:147)real-world(cid:148) intrusion dataset by tapping the Notre
Dame traf(cid:2)c to avoid the various limitations of the DARPA
traf(cid:2)c [8]. Moreover, we constructed two different types of
datasets (cid:151) packet based and destination based. This allowed
us to evaluate the ef(cid:2)cacy of the approaches on datasets
with different features and class distribution. We will then
use RIPPER [9] and several sampling methods to construct
classi(cid:2)ers on these datasets.

a) Contribution: The main contributions of our work
include a) effective evaluation and comparison of sampling
methods,
including oversampling by replication, SMOTE
(Synthetic Minority Over-sampling TEchnique) [10], and un-
dersampling, on real-world intrusion datasets; b) comparisons
with RIPPER’s loss ratio implementation for reweighting rel-
ative minority and majority class weights; and c) a clustering
based implementation of SMOTE (Cluster-SMOTE) that fur-
ther improves the performance over all the sampling methods.
Our hypothesis is that by generating synthetic intrusion
cases, particularly in the localized clusters, to populate the
dataset, we will evoke the notion of (cid:147)similarities(cid:148) in network
traf(cid:2)c. SMOTE generates new instances based on the (cid:147)known(cid:148)
distribution, thus improving the generalization capacity of the
learned classi(cid:2)er. SMOTE adds these instances in the space
between minority examples, emphasizing the class border in
favor of the minority class. To learn ef(cid:2)cient discriminative
learners it is important to emphasize on such class borders.
To demonstrate our claim, we (cid:2)rst compare SMOTE to other
techniques using ROC curve analysis and demonstrate the
success of its emphasis on class borders by comparison to a
pure random replication oversampling method. In addition, we
will also present a new technique of Cluster-SMOTE, which
applies unsupervised learning to partition datasets into regions
that will enable SMOTE to deliver enhanced results and we
will present results indicating that this method may be used
as an improvement over SMOTE.

The rest of the paper is organized as follows. Section 2
outlines the approach used to construct our datasets. Section
3 discusses the data mining approaches utilized in our study.
Section 4 presents the experimental results. Section 5 draws
conclusions and discusses future work.

II. DATA EXTRACTION

Many efforts have used the DARPA’98 dataset for testing
and training purposes. While this is a benchmark for intrusion
detection methods, it has a number of shortcomings. The
validity of DARPA’98 was questioned by McHugh [8] for its
use of synthetic traf(cid:2)c for generating normal data and using
attacks generated from scripts and programs. Additionally, the
normal data does not contain natural but noisy traf(cid:2)c behavior
such as packet storms or strange fragments. Ultimately, this
dataset is not representative of contemporary network traf(cid:2)c.
Thus, it was imperative to construct our own dataset based on
a collection of contemporary network traf(cid:2)c.

Many other approaches construct a data model based on

network connections [11](cid:150)[15].

We operated using real network data from the University
of Notre Dame. This network runs at 100 Mbps and is
comprised of over 10,000 primarily residential computers, the
majority of which run Windows. Traf(cid:2)c was collected during
the summer of 2004. During this collection, a number of on-
campus machines fell victim to a trojan horse style attack and
became (cid:147)zombie(cid:148) hosts in a distributed denial service attack.
Thus, the data sample used in our experiments represents a
fairly (cid:147)interesting(cid:148) segment of network traf(cid:2)c.

In order to extract new classi(cid:2)ers for network intrusion
detection, we must construct a dataset which further entails

2

a packet labeling method must be elected and applied. Many
stored network traf(cid:2)c (cid:2)les were processed using the SNORT
open source intrusion detection system and received labeling
based on the appropriate rule set [16]. This set makes a
wide sweep on potential attacks such as viruses, portscans,
MYSQL attacks, and DoS and DDoS attacks. One limitation
with this approach is that SNORT can only apply one label
per packet, for instance SNORT performs telnet checking prior
to DDoS; thus, a packet violating both rules will only re(cid:3)ect
the attack for which it is (cid:2)rst scanned. We can accommodate
this limitation by focusing our approach and treating this
as a 2-class problem. Rather than associating the type of
intrusion with the packet, we merely label whether a packet
was intrusive. This simpli(cid:2)es our approach in our packet
analysis and allows for other (cid:3)exibility.

Thus, we construct a dataset comprised of collected packets
and their SNORT labels. The set of attributes for each element
denotes the packet’s type, the status of its (cid:3)ags, values of
other pertinent (cid:2)elds, and a basic summary of the packet’s data
payload. The set of characteristics summarizing the payload
calculate the percentages of bytes representing printable and
unprintable characters, as well as the percentage of digits,
white space, punctuation, upper case, and lower case char-
acters within the payload. Such a set of features truncates
the total amount of information yielded by a packet capture
and provides ample means to differentiate between attack and
normal traf(cid:2)c. While the total number of packets studied will
be signi(cid:2)cantly higher than that of the destinations set and the
packet dataset should contain less noisy examples, accurate
classi(cid:2)er construction may be even more problematic as the
the imbalance ratio of this dataset is even less favorable than
that of the destinations dataset, as can been seen in Table I.
The packet dataset should therefore produce an even more
compelling case for SMOTE and our Cluster-SMOTE method.

dataset
Destinations
Packets

attributes
25
43

alerts
147
2106

nonalerts
3933
344,514

total size
4080
346,620

TABLE I

DATA DISTRIBUTIONS IN THE DATASETS.

We elected to construct another novel dataset. Instead
of a connection model, we elected for the construction a
destination-based model in which packets are organized by
their destination. Attributes are constructed by noting the
number, type, and rate of packets received in addition to
the number of connections on a given host. Other attributes
summarize the overall make-up of the packets themselves and
standard deviation calculations are used to note high or low
levels of variance in these characterstics. Thus, each dataset
member represents a separate host that we have recorded as
have received traf(cid:2)c and its attributes represent the composite
of traf(cid:2)c received. We use SNORT to identify intrusion packets
and label hosts receiving such packets as compromised. This
will enable us to perform a survey of compromised and
uncompromised hosts and to induce a set of rules for both
groups. Studying destination traf(cid:2)c allows for a separate, host-

3

Fig. 1. The attribute space in (a) features a sparse majority class, a minority class region, and several minority outliers. In (b), Cluster-SMOTE detects two
clusters of minority points and uses this information to generate new synthetic examples, as seen in (c)

based analysis that is useful to network managers and intrusion
detection systems by isolating systems that are likely to have
received attack traf(cid:2)c. While adminstrators are privy to a
substantial amount of traf(cid:2)c passed on their networks, it is
unlikely that even this wealth of information is enough to
supply number of examples required to accurately forecast,
even via data-mining, the relatively rare case of intrusion.
Thus, we anticipate that SMOTE will assist us by generating
synthetic examples of compromised hosts,
improving our
classi(cid:2)er performance.

III. MINING FOR SIGNATURES

The intrusion datasets are highly unbalanced in nature, as
revealed in Table I. A dataset is unbalanced if the classi(cid:2)cation
categories are not approximately equally represented. While
our main goal is to correctly identify the intrusive instances
based on the signatures, the classi(cid:2)cation techniques can be
easily biased towards the majority class (non-intrusive). We
are more interested in the trade-offs between true positives and
false positives, that is how many false positives are potentially
caused as we increase the intrusion detection rate. One can
potentially con(cid:2)gure the signature based system depending
on the system speci(cid:2)c tradeoffs. We used SMOTE [10] and
our proposed Cluster-SMOTE along with RIPPER [9] as our
classi(cid:2)cation technique and each method is brie(cid:3)y outlined in
the following subsections.

A. RIPPER

RIPPER is a fast, highly noise tolerant rule learner, orig-
inally targeting learning problems involving very large and
noisy datasets [9]. While this application is used heavily in
many, text-driven data-mining experiments, its noise tolerance
makes it very useful in many other studies, such as our own.
This method deduces a set of if-then rules for the minority
class(es), and a default (cid:147)true(cid:148) rule for the remaining majority
class. Thus, RIPPER will produce a set of rules outlining
intrusive traf(cid:2)c and assume all other traf(cid:2)c to be nonintrusive.
Comprehensibility of a classi(cid:2)er can be key for network
security for post-analysis by a human expert.

B. SMOTE: Synthetic Minority Oversampling TEchnique

Sampling methods are very popular in balancing the class
distribution before learning a classi(cid:2)er, which uses an error

based objective function to search the hypothesis space. Over
and under-sampling methodologies have received signi(cid:2)cant
attention to counter the effect of imbalanced datasets [10],
[17](cid:150)[20].

The random under and over-sampling methods have their
various short-comings. The random undersampling method
can potentially remove certain important examples, and ran-
dom oversampling by replication can lead to over(cid:2)tting.
Oversampling by replication can also lead to similar but more
speci(cid:2)c regions in the feature space as the decision region for
the minority class. This can potentially lead to over(cid:2)tting on
the multiple copies of minority class examples.

To overcome the over(cid:2)tting and broaden the decision region
of the minority intrusion class cases, SMOTE can be used to
generate synthetic examples by operating in (cid:147)feature space(cid:148)
rather than (cid:147)data space(cid:148) [10]. The minority class is over-
sampled by taking each minority class sample and introducing
synthetic examples along the line segments joining any/all
of the k minority class nearest neighbors. Depending upon
the amount of over-sampling required, neighbors from the k
nearest neighbors are randomly chosen. Synthetic samples are
generated in the following way: Take the difference between
the feature vector (sample) under consideration and its near-
est neighbor. Multiply this difference by a random number
between 0 and 1, and add it
to the feature vector under
consideration. This causes the selection of a random point
along the line segment between two speci(cid:2)c features. This
approach effectively forces the decision region of the minority
class to become more general. For the nominal cases, we take
the majority vote for the nominal value amongst the nearest
neighbors. We use the modi(cid:2)cation of Value Distance Metric
(VDM) [21] to compute the nearest neighbors for the nominal
valued features.

The synthetic examples cause the classi(cid:2)er to create larger
and less speci(cid:2)c decision regions, rather than smaller and
more speci(cid:2)c regions, as typically caused by over-sampling
with replication. More general regions are now learned for
the minority class rather than being subsumed by the majority
class samples around them. The effect
is that classi(cid:2)ers
generalize better. The generalization capacity of a classi(cid:2)er
can be very pertinent for intrusion detection.

4

P
T
%

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

P
T
%

0.7

1

0.9

0.8

0.6

0.5

0.4

0

0.01

0.02

0.03

0.04

0.06

0.07

0.08

0.09

0.1

0.01

0.02

0.03

0.04

0.06

0.07

0.08

0.09

0.1

0.05
%FP

500 SMOTE

Loss Ratio

0.05
%FP

500 SMOTE

500 Replication

RIPPER

Fig. 2. ROC Curves depicting the optimal SMOTE and random replication
methods applied on the Packets Dataset from rules learned by RIPPER.

Fig. 3. ROC Curves depicting 500 SMOTE against RIPPER loss ratio on
the Packets dataset

C. Cluster-SMOTE

Our intuition into the class imbalance problem is that having
a small group of minority examples makes it dif(cid:2)cult
to
establish proper class borders. Thus, the ability to correctly
de(cid:2)ne the class regions and hence their borders would allow
for trivial classi(cid:2)cation. As these regions are unknown and
even in the best cases may be impossible to deduce from
given data, we believe only an approximation of these regions
may be inferred. Even approximations may enhance classi(cid:2)er
construction.

To develop these minority region approximations, we have
applied simple k-means clustering to the set of minority ex-
amples in each dataset. We then apply SMOTE to each cluster
and then reform the dataset by reinserting the set of original
minority examples and the synthetic examples as well. This
process allows for focused improvements on a localization
basis for the minority class and should improve SMOTE’s per-
formance on imbalanced datasets. Leland’s observation of self-
similar patterns suggests that clustering enable the detection of
such distinct patterns and that generating synthetic examples
focusing on localizations will enhance global classi(cid:2)cation [1].

IV. EXPERIMENTS

Our experiments demonstrate the success of SMOTE in
improving the detection of intrusive packets and compromised
hosts, with an acceptable relative increase in the rate of false
alarms. We show the ef(cid:2)cacy of SMOTE both when used
globally and locally (Cluster-SMOTE). As SMOTE generates
additional synthetic examples for the training set by empha-
sizing the alert and nonalert class borders, it was important
to establish that SMOTE’s contribution was this emphasis,
rather than its creation of a more balanced dataset. Therefore,
experiments were performed in which examples of the alert
class were replicated at the same rate used by SMOTE and
were likewise added to the training set. As this method
improves the class imbalance ratio, we expect an improvement
over an unaugmented training set. However, as replication
does not emphasize the class borders, we expect SMOTE’s
performance to dominate.

It is further possible to establish that SMOTE’s effective-
ness stems from the emphasis on class borders rather than
rebalancing the class ratios by undersampling the majority
class. In this case, a given percentage of majority examples
are randomly removed from the training set. As with mi-
nority class oversampling via replication, random majority
class undersampling improves classi(cid:2)cation performance by
essentially emphasizing the minority class by reducing the
ratio of majority to minority examples. Experiments varied
undersampled 1% and 5% of the majority class and 10% to
100% incrementally by 10%.

An alternative to SMOTE is adjusting RIPPER’s loss ratio,
L, which speci(cid:2)es the relative cost of a false positive against a
false negative. Hence, a ratio L < 1 penalizes more heavily for
missing minority examples, while a ratio L > 1 increasingly
penalizes for false alarms. As opposed to the more complicated
cost-sensitivity matrix which assigns point values to each of
the four types of classi(cid:2)cation: true positives, true negatives,
false positives, and false negatives,
loss ratio provides a
simpler progressive method for adjusting the minority class
true positive rate. The effects of this adjustment on RIPPER
in producing rules were compared against those of SMOTE.
a) ROC Curves Receiver Operating Characteristic (ROC)
Curves provide an effective basis for comparison between
classi(cid:2)ers of imbalanced datasets by tracing the increase in
the rate of false alarms as the classi(cid:2)er is tuned to increase
the rate of correct alarms raised [22]. Visualization of ROC
curves also enables an understanding of the interplay between
the rates of generation of false and true positives. Depending
on the nature of system, one can choose an operating point
from the ROC curve. Thus, an ROC curve study is important
to understanding SMOTE’s effectiveness in these experiments.
Our experimental framework is to generate separate points
for ROC curve analysis through varying the level of majority
class undersampling, moving from the entire set to 1% of
the majority examples. This establishes a chain of points
that track the progress of the classi(cid:2)er as more and more
majority examples are removed from the training set. Separate
curves are constructed for each SMOTE level applied and
also for each level of replication oversampling. The best

P
T
%

0.75

1

0.95

0.9

0.85

0.8

0.7

0.65

0.6

0.55

0.5

0

5

1

0.95

0.9

0.85

0.75

0.7

0.65

P
T
%

0.8

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

0.45

0

0.01

0.02

0.03

0.04

0.06

0.07

0.08

0.09

0.1

%FP

500 SMOTE

100 Replication

RIPPER

500 5 clusters SMOTE

500 3 clusters SMOTE

500 SMOTE

0.05
%FP

Fig. 4.
replication on the destinations dataset using RIPPER.

ROC Curves showing the performance of SMOTE and random

Fig. 5. ROC Curves comparing the performance of SMOTE and Cluster-
SMOTE using rules learned by RIPPER.

classi(cid:2)ers are represented by those points closest to the upper-
left corner of the graph, the optimal point representing perfect
minority detection with no false alarms raised. The SMOTE
and replication curves are then plotted on the same graph
for comparison purposes. There was an additional group of
experiments charting the effects of varying the loss ratio from
1 to .01 used in classi(cid:2)er construction. Each point on these
ROC tracks each separate classifer.

b) Training and testing sets The task of classi(cid:2)cation
requires two separate datasets: one for training and one for
testing. The learning algorithm generates rules on the training
dataset and its performance is measured by its classi(cid:2)cation
results on the testing set. Given the very large size of the
packets dataset, we split the dataset with 75% of the examples
used in training and 25% used for testing with a stratifying
method that maintained the original class balance ratio in both
produced sets. Considering the low number of alerts in the
destinations dataset, a simple split method was insuf(cid:2)cient and
the 10-folds cross-validation, which splits data into 10% folds
constructing 10 separate classi(cid:2)ers on 9 folds and testing on
1 fold and uni(cid:2)es results, was required.

A. Results

We (cid:2)rst applied the RIPPER rule learning program to the
packets dataset. As seen in Figure 2, both replication oversam-
pling and SMOTE provide signi(cid:2)cate improvements over an
unenhanced training set of alert cases as both curves clearly
dominate. In both cases, as the level of generation of additional
minority examples increases, the general improvement of the
area under the curve (AUC) for the curve produced implies
that these methods are successful in enabling better classi(cid:2)er
construction. That stated, it is also important to note that
the SMOTE curves completely dominate those of replication
oversampling. Thus,
the additional emphasis on the class
borders placed by SMOTE must be effective in generating
a superior AUC and thus allows RIPPER to generate a better
classi(cid:2)er.

As an additional baseline, SMOTE’s performance was com-
pared against that of RIPPER’s loss ratio. Figure 3 displays
the results of this comparison. The loss ratio’s sudden halt
precludes its use in cases where more generous false alarm
rates are allowed. Additionally, the SMOTE curve dominates
the loss ratio curve from start to (cid:2)nish. Therefore, SMOTE is
a more effective method than varying loss ratio.

Likewise,

the effectiveness of the SMOTE technique is
demonstrated through our destinations dataset experiments.
The visual tradoff between true positives and false positives is
presented as an ROC in Figure 4. Given the unstable nature
of the rules formed by RIPPER, there will tend to be certain
points in the ROC space that will slightly deviate from the
trend, but in general, the trend of the curves is as one might
expect. Another deviation is that the best ROC curve for
replication was at 100% level, indicating that more amount
of replication led to severe over(cid:2)tting. However, SMOTE suc-
cessively improved performance as we added more synthetic
examples, giving best performance at 500 %. As this dataset
features an extremely low number of alert examples,
the
ROC curves produced are especially prone to drastic sudden
changes, as can be seen in Figure 4. However, the same
general observations hold from the destinations dataset as they
did from packets: the SMOTE curve dominates the random
replication curve.

Our results indicate that high levels of SMOTE have
improved ROC curves on both datasets. However, we can
improve results further by applying our outlined Cluster-
SMOTE technique. We applied simple k-means clustering to
the minority examples of the packets dataset and performed
two experiments using three and (cid:2)ve centroids, values seeded
by the user. Oversampling varied at the rates in the previous
experiments on individual clusters and RIPPER was applied
to the entire dataset. Figure 5 depicts some of the best results
along with a 500-SMOTE baseline for comparison purposes.
Among these curves, there is no single classi(cid:2)er that clearly
dominates. However, it is possible to (cid:2)t a convex hull to
the curves presented on an ROC graph. This allows for

the approximation of the optimal classi(cid:2)er, based on known
classi(cid:2)ers. When this procedure is applied to Figure 5, all
but one point within this convex hull come from classi(cid:2)ers
based on the Cluster-SMOTE method. Therefore, the optimal
classi(cid:2)er for a given acceptable false-positive rate will be
selected from Cluster-SMOTE classi(cid:2)ers in all but one case.
Hence, Cluster-SMOTE is shown to be an effective method of
classi(cid:2)er enhancement on the packets dataset. Clustering on
the destinations alert examples yielded a single cluster, indi-
cated that the alerts within destinations fall within a compact
region of the total feature space; thus, Cluster-SMOTE would
be unable to generate improved classi(cid:2)ers on this dataset.

V. CONCLUSION

Ef(cid:2)cient intrusion detection is a dif(cid:2)cult problem because
of the dif(cid:2)culty inherent
in identifying intrusive behavior
while maintaining the ability to limit false alarms. Thus, we
have conducted an investigation into methods of false positive
limitation. We began by outlining a procedure for building
a dataset from collected network traf(cid:2)c. Using basic payload
analysis and destination address grouping, we generated two
imbalanced datasets featuring a large set of attributes. Using
an open source IDS, SNORT, we were able to label examples
from each dataset as alert and normal.

These datasets were then used in our investigation of
applications of SMOTE and a new method, Cluster-SMOTE,
in terms of restricting false positive rates while generating
rules using RIPPER. ROC curves were presented establishing
that SMOTE’s emphasis on class borders in rule learning im-
proves classi(cid:2)ers beyond the level of class balance restoration
through simple random minority example replication. These
experiments held true through both datasets. An additional
experiment on the packets dataset demonstrated SMOTE’s
effectiveness over RIPPER loss ratio.

In addition, we have investigated the effectiveness of
Cluster-SMOTE as a technique for imbalanced class learning
above SMOTE within the scope of these datasets. We have
concluded that Cluster-SMOTE provides an improvement on
SMOTE for the packets dataset, but cannot be used on destina-
tions due to the limited feature space size of the minority class.
Our success with the packets dataset indicates that Cluster-
SMOTE is a techinique which may be useful in application
settings outside of intrusion detection, but within the set of
class imbalance problems.

Looking forward, we will further pursue Cluster-SMOTE
through a thorough examination of its effectiveness on other
datasets. Additionally, the simple k-means method employed
in this paper is at best limited in its effectiveness and it is our
goal to develop superior localizations of the minority class
through an approach using hyperrectangles. In conjunction
with this investigation of methods for localizing class imbal-
anced datasets, we will investigate new methods of synthetic
point generation that yield superior class boundary de(cid:2)nition.
This in turn will enable us to strike at the heart of the class
imbalance problem: class region de(cid:2)nintion.

6

ACKNOWLEDGMENT

We would like to thank Chad Mano for his work in
collecting network data and for allowing us to use this data
for the experiments outlined in this paper.

REFERENCES

[1] W. Leland, M. Taqqu, W. Willinger, and D. Wilson, (cid:147)On the self-
similar nature of Ethernet traf(cid:2)c (extended version),(cid:148) IEEE/ACM Trans.
Networking, vol. 2, pp. 1(cid:150)15, 1994.

[2] J. Vehel, E. Lutton, and C. Tricot, Fractals in Enginnering: From Theory

to Industrial Applications. New York:Springer-Verlag, 1997.

[3] R. Lippmann, D. Fried, I. Graf, J. Haines, K. Kendall, D. McClung,
D. Weber, S. Webster, D. Wyschogrod, R. Cunningham, and M. Zissman,
(cid:147)The 1998 DARPA Off-line Intrusion Detection Evaluation,(cid:148) in Pro-
ceedings DARPA Information Survivability Conference and Exposition
(DISCEX) 2000, Los Alamitos, CA, 2000, pp. 12(cid:150)26.

[4] M. Roughan, T. Grif(cid:2)n, Z. Morley Mao, A. Greenberg, and B. Free-
man, (cid:147)IP Forwarding Anomalies and Improving their Detection Using
Multiple Data Sources,(cid:148) ACM SIGCOMM 2004 Workshop on Network
Troubleshooting, 2004.

[5] Y. Zhang, S. Singh, S. Sen, N. Duf(cid:2)eld, and C. Lund, (cid:147)Online Iden-
ti(cid:2)cation of Hierarchical Heavy Hitters: Algorithms, Evalutaion, and
Applications,(cid:148) in Proceedings of ACM SIGCOMM Internet Measurement
Conference, Sicily, Italy, October 2004.

[6] G. Weiss, (cid:147)Mining with Rarity: A Unifying Framework,(cid:148) SIGKDD

Explorations, vol. 6, no. 1, pp. 7(cid:150)19, 2004.

[7] S. Axelsson, (cid:147)The Base-Rate Fallacy and the Dif(cid:2)culty of Intrusion
Detection,(cid:148) Information and System Security, vol. 3, no. 3, pp. 186(cid:150)
205, 2000.

[8] J. McHugh, (cid:147)The 1998 Lincoln Laboratory IDS Evaluation (A Cri-
tique),(cid:148) in Proceedings of the Recent Advances in Intrusion Detection,
Toulouse, France, 1998, pp. 145(cid:150)161.

[9] W. Cohen, (cid:147)Fast effective rule induction,(cid:148) in Machine Learning: the 12th

International Conference, Lake Taho, CA, 1995.

[10] N. Chawla, K. Bowyer, L. Hall, and W. Kegelmeyer, (cid:147)SMOTE: Synthetic
Minority of Over-sampling TEchique,(cid:148) Journal of Artiﬁcial Intelligence
Resarch, vol. 16, pp. 341(cid:150)378, 2002.

[11] A. Lazarevic, L. Ertoz, V. Kumar, A. Ozgur, and J. Srivastava, (cid:147)A
Comparative Study of Anomaly Detection Schemes in Network Intrusion
Detection,(cid:148) in 3rd SIAM Conference on Data Mining, San Francisco,
CA, January 2003.

[12] M. Thottan and C. Ji, (cid:147)Anomaly Detection in IP Networks,(cid:148) IEEE

Transactions on Signal Processing, vol. 51, pp. 2191(cid:150)2204, 2003.

[13] W. Lee and S. S., (cid:147)Data Mining Approaches for Intrusion Detection,(cid:148)
in Proceedings of the 7th USENIX Security Symposium, San Antonio,
Texas, January 1998.

[14] E. Bloedorn, (cid:147)Data Mining for Network Intrusion Detection: How to

Get Started,(cid:148) Mitre Technical Report, 2001.

[15] H. Javitz and A. Valdes, (cid:147)The NIDES Statistical Copmponent: Descrip-
tion and Justi(cid:2)cation,(cid:148) Technical Report, Computer Science Laboratory,
SRI Interational, 1993.

[16] Source(cid:2)re, Snort Users Manual: The Snort Project, 2005.
[17] N. Japkowicz, (cid:147)The Class Imbalance Problem: Signi(cid:2)cance and Strate-
gies,(cid:148) in Proceedings of the 2000 International Conference on Artiﬁcial
Intelligence (IC-AI’2000): Special Track on Inductive Learning, Las
Vegas, Nevada, 2000.

[18] G. Weiss and F. Provost, (cid:147)Learning when Training Data are Costly: The
Effect of Class Distribution on Tree Induction,(cid:148) Journal of Artiﬁcial
Intelligence Research, vol. 19, pp. 315(cid:150)354, 2003.

[19] N. V. Chawla, N. Japkowicz, and A. Kolcz, Eds., Special Issue on
Learning from Imbalanced Data sets, SIGKDD Explorations. ACM
SIGKDD, 2004.

[20] J. Laurikkala, (cid:147)Improving Identi(cid:2)cation of Dif(cid:2)cult Small Classes by
Balancing Class Distribution,(cid:148) University of Tampere, Tech. Rep. A-
2001-2, 2001.

[21] S. Cost and S. Salzberg, (cid:147)A Weighted Nearest Neighbor Algorithm for
Learning with Symbolic Features,(cid:148) Machine Learning, vol. 10, no. 1,
pp. 57(cid:150)78, 1993.

[22] J. Swets, (cid:147)Measuring the Accuracy of Diagnostic Systems,(cid:148) Science,

vol. 240, pp. 1285(cid:150)1293, 1988.

