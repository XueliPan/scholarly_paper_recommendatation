CoreGenesis: Erasing Core Boundaries for Robust and

Conﬁgurable Performance

Shantanu Gupta, Shuguang Feng, Amin Ansari, Ganesh Dasika and Scott Mahlke

Advanced Computer Architecture Laboratory

University of Michigan - Ann Arbor, MI

{shangupt, ansary, shoe, gdasika, mahlke} @umich.edu

ABSTRACT
Single-thread performance, power eﬃciency and reliability
are critical design challenges of future multicore systems. Al-
though point solutions have been proposed to address these
issues, a more fundamental change to the fabric of multi-
core systems is necessary to seamlessly combat these chal-
lenges. Towards this end, this paper proposes CoreGenesis,
a dynamically adaptive multiprocessor fabric that blurs out
individual core boundaries, and encourages resource sharing
across cores for performance, reliability and customized pro-
cessing. Further, as a manifestation of this vision, the paper
provides details of a uniﬁed performance-reliability solution
that can assemble variable-width processors from a network
of (potentially broken) pipeline stage-level resources.

Categories and Subject Descriptors
B.8.1 Hardware [Performance and Reliability]: Reliabil-
ity, Testing, and Fault-Tolerance; C.1.4 Computer System
Organization [Processor Architectures]: Parallel Archi-
tectures

General Terms
Performance, Reliability, Design

Keywords
Chip Multiprocessors, Fault Tolerance, Conﬁgurable Perfor-
mance, Reconﬁgurable Architectures

INTRODUCTION

1.
Motivation. As a result of growing power, thermal and
complexity concerns in monolithic processors, major hard-
ware vendors have lead a migration to multicore processors
composed of relatively simple cores. Today, the sizes of mul-
ticores vary from 2-6 cores in desktop systems to 16-64 cores
in throughput-oriented computing domains, e.g. SUN Ul-
traSparc T1/T2, Intel Larrabee and Tilera TILE64. De-
spite having been attenuated, several challenges pertaining
to performance, power and reliability still remain in the
multicore paradigm. First, multiple cores are eﬀective for
throughput computing, but they provide little to no gains
for sequential applications. Even if a major transition to-
wards parallel programming occurs in the future, Amdahl’s
law dictates that the sequential component of an applica-
tion will present itself as a performance bottleneck. Second,
power constraints limit the number of cores / resources that

Copyright is held by the author/owner(s).
PACT’10, September 11–15, 2010, Vienna, Austria.
ACM 978-1-4503-0178-7/10/09.

can be kept active on a chip, motivating the need for cus-
tomized and power-proportional processing. Finally, the in-
creasing vulnerability of transistors with each passing tech-
nology generation, can jeopardize the objective of through-
put sustainability over the lifetime of a multicore chip.

Prior Work.
In this landscape of multicore challenges,
prior research eﬀorts have focused on addressing these issues
in isolation. For example, to tackle single-thread perfor-
mance, a recent article by Hill and Marty [2] introduces the
concept of dynamic multicores (Figure 1(a)) that can allow
multiple cores on a chip to work in unison while executing
sequential codes. This notion of conﬁgurable performance al-
lows chips to eﬃciently address scenarios requiring through-
put computing, high sequential performance, and anything
in between. Core Fusion [3], Composable Lightweight Pro-
cessors and Federation are representative works with this
objective. However, the scope of present day dynamic mul-
ticore solutions is limited as they cannot provide customized
processing, as in [4], or better throughput sustainability,
as achieved by techniques in [1]. The customized process-
ing is typically accomplished by introducing heterogeneity
of types and number of functional units, execution models
(in-order, OoO), prediction structures, etc., into diﬀerent
cores (Figure 1(b)), in order to run workloads in a power-
proportional fashion [4]. Whereas, better throughput sus-
tainability can be provided by ﬁne-grained reliability solu-
tions like StageNet [1], that disable broken pipeline stages,
instead of entire cores (Figure 1(c)), within a multicore.

Despite their abundance, by virtue of being independent
eﬀorts, combining existing performance, power and relia-
bility solutions for multicores is neither cost-eﬀective nor
straightforward. The overheads quickly become prohibitive
as the changes required for each solution are introduced,
with very little that can be amortized across multiple tech-
niques. Conﬁgurable performance requires dedicated cen-
tralized structures (adding drawbacks such as access con-
tention/latency, global wiring, single point of failure), cus-
tomization requires a variety of static core designs, and ﬁne-
grained reliability requires either large amounts of area for
cold spares or the ﬂexibility to share resources across cores.

2. COREGENESIS

Instead of targeting one challenge at a time, the goal of
this proposal is to devise a design philosophy that can nat-
urally be extended to handle a multitude of multicore chal-
lenges seamlessly, while overlapping costs, maintaining ef-
ﬁciency and avoiding centralized structures. Towards this
end, we propose the CoreGenesis (CG) architecture (see
Figure 1(d)), an adaptive computing substrate that is in-
herently ﬂexible, and can best align itself to the immediate

571Targeted Single-point Solutions

Adaptive Multipurpose Substrate

C: core

Centralized 
resources

Distributed resources

B: A block can be a pipeline stage 

or a  group of pipeline stages

C

C

C

C

C

C

C

C

C

C

C

C

C

C

C

C

(b) Static design for a 
heterogeneous multicore

C

C C

C

C

CC

C C

C C C

C C C

C C C

B0

B0

B0

B0

B0

B0

B1

B1

B1

B1

B1

B1

B2

B2

B2

B2

B2

B2

Bn

Bn

Bn

Bn

Bn

Bn

 

s
u
o
n
e
g
o
r
e
t
e
H

 

i

e
d
w
-
2

e
r
o
C

e
r
o
C

 

i

e
d
w
-
1

e
r
o
C

(a) Dynamic multicore with 

centralized resources

(c) Core disabling for 

fault tolerance

(d) CoreGenesis: A sea of building blocks (B) that can be 

configured for throughput computing, single-thread 

performance, fault tolerance, customized processing, etc. 

Figure 1: Contemporary solutions for multicore challenges (a,b,c) and vision of this work (d). In (a), centralized resources are used to
assist in fusing neighboring cores. In (b) and (d), diﬀerent shapes/sizes denote heterogeneity. In (c) and (d), dark shading marks broken
components.

system needs. CG eliminates the traditional core bound-
aries and organizes the chip multiprocessor as a dynami-
cally conﬁgurable network of building blocks. This sea of
building blocks can be symmetric or heterogeneous in na-
ture, while varying in granularity from individual pipeline
stages to groups of stages. Further, the CG pipeline mi-
croarchitecture is decoupled at block boundaries, providing
full ﬂexibility to construct logical processors from any com-
plete set of building blocks. Another key feature of the CG
proposal is the use of distributed resources to coordinate
instruction execution across decoupled blocks, without any
signiﬁcant changes to the ISA or the execution model. This
is a major advancement over prior eﬀorts, and addresses the
shortcomings of centralized resources.

Resources from CG’s sea of blocks can be ﬂuidly allocated
for a number of performance, power and reliability require-
ments. Throughput computing can be optimized by forming
many single-issue pipelines, whereas sequential performance
can be accelerated by forming wider-issue pipelines. Power
and performance characteristics can be further improved by
introducing heterogeneous building blocks in the fabric, and
appropriately conﬁguring them (dynamically or statically)
for active program phases or entire workloads. This enables
a dynamic approach to customized processing. Finally, fault
tolerance in CG can be administered at the block granular-
ity, by disabling the broken components over time.

To better understand the beneﬁts and challenges in real-
izing this architectural vision, we designed and evaluated a
CG instance that targets conﬁgurable performance and ﬁne-
grained reliability. For the fabric, an in-order pipeline model
is used with single pipeline stages as its building blocks. As
a ﬁrst step, we deﬁned mechanisms for decoupling pipeline
stages from one another (inspired by the StageNet architec-
ture [1]). This enabled salvaging of working stages from dif-
ferent rows of the fabric to form logical processors, thereby
tackling the throughput sustainability challenge. To address
conﬁgurable performance, we generalized the notion of log-
ical processors to form processors of varying issue widths.

The engineering of distributed resources to support the
assembly of decoupled pipeline stages into a wide-issue pro-
cessor is especially hard due to the heavy co-ordination and
communication requirements of an in-order superscalar. We
adopted a best eﬀort strategy here, speculating on control
and data dependencies across pipeline ways, and falling back
to a light-weight replay in case of a violation. To register
these violations, hardware schemes were formulated for dis-
tributed control, register and memory data ﬂow manage-
ment. The frequency of data ﬂow violations from instruc-

tions executing on two diﬀerent pipeline ways was found to
be a leading cause of performance loss. This was addressed
by incorporating compiler hints for instruction steering in
the program binary.

Overall, this manifestation of CG relies on interconnection
ﬂexibility, microarchitectural innovations, and compiler di-
rected instruction steering, to provide a uniﬁed performance-
reliability solution. The chip consists of a pool of pipeline
stage-level resources that can be ﬂuidly allocated for ac-
celerating single-thread performance, throughput comput-
ing, or tolerating failures. Performance simulations show
that merging pipelines within CoreGenesis improves single-
thread IPC by 1.5X, on average, over a standalone pipeline.
On the other hand, lifetime reliability experiments demon-
strate that an 8-core CoreGenesis chip increases the cumu-
lative work done by 41% over a traditional 10-core CMP
(area-neutral comparison).

3. ACKNOWLEDGMENTS

The authors acknowledge the support of the Gigascale
Systems Research Center, one of ﬁve research centers funded
under the Focus Center Research Program, a Semiconductor
Research Corporation program. This research was also sup-
ported by National Science Foundation grants CCF-0916689
and ARM Limited.

4. REFERENCES
[1] S. Gupta, S. Feng, A. Ansari, J. A. Blome, and

S. Mahlke. The stagenet fabric for constructing resilient
multicore systems. In Proc. of the 41st Annual
International Symposium on Microarchitecture, pages
141–151, 2008.

[2] M. D. Hill and M. R. Marty. Amdahl’s law in the
multicore era. IEEE Computer, 41(1):33–38, 2008.

[3] E. Ipek, M. Kirman, N. Kirman, and J. Martinez. Core

fusion: Accommodating software diversity in chip
multiprocessors. In Proc. of the 34th Annual
International Symposium on Computer Architecture,
pages 186–197, 2007.

[4] R. Kumar, K. I. Farkas, N. P. Jouppi, P. Ranganathan,

and D. M. Tullsen. Single-ISA Heterogeneous
Multi-Core Architectures: The Potential for Processor
Power Reduction. In Proc. of the 36th Annual
International Symposium on Microarchitecture, pages
81–92, Dec. 2003.

572