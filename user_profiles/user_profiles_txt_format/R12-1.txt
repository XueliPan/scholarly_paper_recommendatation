2010 12th International Asia-Pacific Web Conference

Efﬁcient Common Items Extraction from Multiple

Sorted Lists

Wei Lu 1,2, Chuitian Rong 1,2, Jinchuan Chen 2, Xiaoyong Du 1,2, Gabriel Pui Cheong Fung 3, Xiaofang Zhou 4

1School of Information, Renmin University of China

{uqwlu,rct682,jcchen,duyong}@ruc.edu.cn

2Key Labs of Data Engineering and Knowledge Engineering, Ministry of Education, China

3School of Computing Informatics, Arizona State University

g.fung@asu.edu

4School of ITEE, The University of Queensland, Australia

zxf@itee.uq.edu.au

Abstract—Given a set of lists, where items of each list are
sorted by the ascending order of their values, the objective of
this paper is to ﬁgure out the common items that appear in
all of the lists efﬁciently. This problem is sometimes known
as common items extraction from sorted lists. To solve this
problem, one common approach is to scan all
items of all
lists sequentially in parallel until one of the lists is exhausted.
However, we observe that if the overlap of items across all lists
is not high, such sequential access approach can be signiﬁcantly
improved. In this paper, we propose two algorithms, MergeSkip
and MergeESkip, to solve this problem by taking the idea of
skipping as many items of lists as possible. As a result, a large
number of comparisons among items can be saved, and hence
the efﬁciency can be improved. We conduct extensive analysis of
our proposed algorithms on one real dataset and two synthetic
datasets with different data distributions. We report all our
ﬁndings in this paper.

I. INTRODUCTION

Given a set of sorted lists, where items of each list are
sorted by the ascending order of their values, our objective is
to ﬁgure out common items that appear in all of the sorted
lists efﬁciently. This problem is sometimes known as common
items extraction from sorted lists.

Common items extraction from sorted lists is a classical
problem in computer science and has a wide range of appli-
cations in many different disciplines [1], [2], [3], [4], [5], [6],
[7], such as:

(cid:129) Joins using sorted indexes Assuming that we have n
relations R1(X, Y1), . . ., Rn(X, Yn) with indexes on X
for all relations, we want to compute R1(X, Y1) (cid:2)(cid:3) . . . (cid:2)(cid:3)
Rn(X, Yn). Notice that each item of the indexes is an
X-value and indexes on X for all relations have been
sorted. We then ﬁgure out the common items that appear
in all indexes for join operation.

(cid:129) Information Retrieval Assuming there exist a collection
of documents and a query, our objective is to extract a
set of documents, each of which contains all words in the
query. In order to ﬁgure out the documents efﬁciently,
we will always create a set of inverted lists ﬁrst. Each
inverted list represents the documents that contain a
speciﬁc word. It usually contains a set of document ID’s
sorted in ascending order. Based on these inverted lists,

978-0-7695-4012-2/10 $26.00 © 2010 IEEE
DOI 10.1109/APWeb.2010.16

219

2
5
8
12
50
80
100
400

3
6
9
12
80
100
300
350

result
100

80
100
150
200
320
800

5
20
34
56
100
300
800

Fig. 1. An example

we can obtain the required documents by ﬁguring out
the common ID’s of those inverted lists that represent
the words in the query.

Example 1: Suppose there exist four ordered lists, shown
in Figure 1. According to the algorithm described in [1], in
order to obtain the common items of the lists, we start with
the ﬁrst items of the lists, which are 2, 3, 80, 5. If the current
items are equal, then we know that the current item is one
of the common items. Otherwise, we select the item with the
minimum value and move to its next item. We repeat doing
this judgement, selection and move until any of the lists is
exhausted. Finally, the common item is 100.

As described in Example 1, each items of the lists needs to
be accessed once before we ﬁnish scanning any of the lists.
Moreover, comparisons among items of lists are required in
order to obtain the items with the minimum value at each step.
Actually, from Figure 1, we can observe that the maximum
value of the ﬁrst items of these lists is 80, from the third list.
Clearly, items of the other lists, with values less than 80 cannot
belong to the common items. As a result, we move to the ﬁrst
items of the other lists, with values greater than or equal to 80
instead of scanning items of lists one by one. Such strategy
can be applied at each selection. As a result, performance can
be of great improved if a large number of items are skipped
such that comparisons among items of the lists can be saved.

To sum up, we make the following contributions:
(cid:129) We propose two algorithms, MergeSkip and MergeESkip,
to extract the common items from a set of sorted lists. For
MergeSkip, it skips the items which are obvious not in
the common items. For MergeESkip, we further improve

TABLE I

SYMBOLS AND THEIR DEFINITIONS

Symbol Deﬁnition
L
|L|
Li
|Li|
Li[j]

a set of sorted lists, L = {L1, . . . , L|L|}
the number of lists in L
a sorted list, 1 ≤ i ≤ |L|
the number of items of Li
the item in position j of list Li, 1 ≤ j ≤ |Li|

Algorithm 1: M ergeAll(L)
input : L: A set of lists
output: R: Common items of L
initialize an array pos with size |L|;
for i ← 1 to |L| do

pos[i] ← 1;
while TRUE do

the performance of MergeSkip by skipping as many items
of each list as possible;

(cid:129) We conduct extensive experimental evaluation of our
proposed algorithms on one real dataset and two synthetic
datasets. The synthetic datasets are generated with differ-
ent data distributions. The experimental results demon-
strate the efﬁciency of our proposed algorithms.

II. PROBLEM DEFINITION

Let L be a set of lists. We use |L| to denote the number
of lists and Li to denote the ith list in L, where 1 ≤ i ≤ |L|.
Given a list Li, we use Li[j] to denote the item in position j of
list Li and |Li| to denote the number of items of Li. An item
can be an integer, a string or any other data structure provided
that a total order relationship can be derived. For reference,
Table I shows a set of symbols that will be used throughout
this paper.

Deﬁnition 1 (Sorted List): Given a list Li, Li is said to be
a sorted list if and only if: ∀m, n, 1 ≤ m < n ≤ |Li|, Li[m] ≤
Li[n].

For the ease of presentation, we assume that any list men-
tioned in this paper is a sorted list, formalized by Deﬁnition
1, and there is no duplication in any list. Dealing with non-
ordered list is beyond the scope of this paper. Given a set of
lists, our objective is to extract the common items that appear
in all lists.

III. PROPOSED WORK

In this section, we ﬁrst give a basic algorithm, MergeAll
[1], to solve our problem. Then, we present our two proposed
algorithms, MergeSkip and MergeESkip.

A. Existing Work: MergeAll

1) An Example: Assume there exist 4 lists shown in Figure
1. MergeAll begins by selecting the ﬁrst items of four lists
(L = {L1, L2, L3, L4}), which are 2, 3, 80, 5. Since 2 is the
item with the minimum value, we discard 2 of list L1 and look
at its next item, 5. Now, the current item of list L2, 3, has the
minimum value. As a result, we discard 3 of list L2, and move
to its next item, 6. Now, items of lists L1 and L4, have the
minimum value, 5. Similarly, we discard items, 5’s, of both L1
and L4, and move to the next items, 8 and 20, respectively. At
each step, we choose items with the minimum value, and move
to their next items. At the time when we reach the 7th of L1,
6th of L2, 2nd of L3, 5th of L4, we come across the common
item, 100, and insert it to the result. Having dispensed with
100’s, we move to items 400 of L1, 300 of L2, 150 of L3,

if L1[pos[1]] = L2[pos[2]] = . . . = LL[pos[L]] then

R ← R ∪ L1[pos[1]];
for i ← 1 to |L| do

if pos[i] = |Li| then return R;
pos[i] ← pos[i] + 1;

else

min ← Min (L1[pos[1]], . . . , LL[pos[L]]);
foreach Li ∈ L do

if Li[pos[i]] = min then

if pos[i] = |Li| then return R;
pos[i] ← pos[i] + 1;

300 of L4. We repeat selecting items with minimum value, and
moving to their next items. At the point when we reach items
400 of L1, 350 of L2, 800 of L3, 800 of L4, since 350 of L2
has the minimum value, we move to its next item. However,
L2 is now exhausted, and we know there are no more items,
belonging to the result.

2) Description of MergeAll: The details of MergeAll are
described in Algorithm 1. We ﬁrst initialize an array pos to
store positions of current items (lines 1–3). If values of current
items are equal (line 5), then we insert the item to the result
set (line 6) and all of the lists will be advanced to the next
item (lines 7–9). Notice that if any of lists is exhausted, then
it is safe to return the result R (line 8). If values of the current
items are not all equal, then we will identify items with the
minimum value (line 11), and only those lists of which current
items with values are equal to the minimum value will be
advanced to the next items (line 12–15). The whole process
continues until any of the lists is exhausted (lines 4–15).

In order to compare with our proposed algorithms later,
Figure 2 shows the number of iterations and the number of
scans using the dataset in Example 1. The algorithm terminates
in the 19th iteration and the number of scanned items is 29.

B. Proposed Work 1: MergeSkip

In algorithm MergeAll, at each iteration, we choose items
with the minimum value and move to their next items. We
need to scan each list sequentially. Clearly, before any of the
lists is exhausted for being scanned, items of each list are
accessed one by one continuously. We cannot skip any of
the items. Moreover, identifying the minimum key requires
comparisons among items of all lists at each iteration. This
is also a time consuming process. In order to improve the

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

220

2 ← iteration 1
5 ← iteration 2
8 ← iteration 4
12 ← iteration 6
50 ← iteration 8
80 ← iteration 11
100 ← iteration 13
400 ← iteration 14

3 ← iteration 1
6 ← iteration 3
9 ← iteration 5
12 ← iteration 7
80 ← iteration 8
100 ← iteration 13
300 ← iteration 14
350 ← iteration 17

80 ← iteration 1
100 ← iteration 13
150 ← iteration 14
200 ← iteration 15
320 ← iteration 16
800 ← iteration 18

5 ← iteration 1
20 ← iteration 4
34 ← iteration 9
56 ← iteration 10
100 ← iteration 12
300 ← iteration 14
800 ← iteration 17

Fig. 2. Number of iterations and scans in Example 1 by using MergeAll. The algorithm terminates at Iteration 19 and 29 items are scanned.

2 ← iteration 1
5
8
12
50
80 ← iteration 2
100 ← iteration 3
400 ← iteration 4

3 ← iteration 1
6
9
12
80 ← iteration 2
100 ← iteration 3
300 ← iteration 4
350

80 ← iteration 1
100 ← iteration 3
150 ← iteration 4
200
320
800

5 ← iteration 1
20
34
56
100 ← iteration 2
300 ← iteration 4
800

Fig. 3. Number of iterations and scans in Example 1 by using MergeSkip. The algorithm terminates at Iteration 5 and 14 items are scanned.

performance, we develop an algorithm MergeSkip based on
the following observation:

Observation 1: Given any iteration of MergeAll, let min-
Value and maxValue be the minimum value and maximum
value of current items of all lists, respectively. Then, an item
with value greater than or equal to minValue and strictly
smaller than maxValue cannot be a common item.

1) A Motivating Example: Let us consider the set of lists
in Figure 1 again. At the ﬁrst iteration, we move to the ﬁrst
items of each lists, which are 2, 3, 80 and 5 and ﬁgure out the
item with the maximum value, 80, from list L3. According to
Observation 1, items with values less than 80 cannot be in the
common items. At the second iteration, we can immediately
move to the item 80 of L1 (position 6), item 80 of L2 (position
5) and item 100 of L4 (position 5). As a result, ideally, we
can skip 10 items. The whole process continues until any one
of the lists is exhausted. Figure 3 shows the general idea of
this algorithm. Ideally, the total number of iterations is only
5, and the total number of items we need to scan is only 14,
which are both much fewer than these of MergeAll.

2) Description of MergeSkip: The details of MergeSkip
are described in Algorithm 2. The main difference between
MergeAll and MergeSkip is shown in lines 11 – 15. If values
of the current items are not all equal, then we will calculate
the maximum value (maxValue) among the current items of
all lists (line 11). For each list Li, if the value of its current
item is not equal to maxValue, then we will issue a binary
search from the current position pos[i] to the end of list Li,
and identify the ﬁrst item of Li with its value greater than
or equal to maxValue (lines 13–14). If values of all items of
Li are less than maxValue, then we stop the algorithm and
immediately return R (line 15). The whole process continues
until any one of the lists is exhausted (lines 4–15).

3) Discussion of MergeSkip: Comparing with MergeAll,
MergeSkip offers a major advantage that items of the lists with
their values less than maxValue are skipped at each iteration.
This advantange is obvious if the overlap among all lists is low.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

221

Algorithm 2: M ergeSkip(L)
input : L: a set of lists
output: R: Common items in L
initialize an array pos with size |L|;
for i ← 1 to |L| do

pos[i] ← 1 ;
while TRUE do

if L1[pos[1]] = L2[pos[2]] = . . . = LL[pos[L]] then

R ← R ∪ L1[pos[1]];
for i ← 1 to |L| do

if pos[i] = |Li| then return R;
pos[i] ← pos[i] + 1;

else

maxValue ← Max (L1[pos[1]], . . . , LL[pos[L]]);
foreach Li ∈ L do

if Li[pos[i]] (cid:7)= maxValue then

biSearch (Li, &pos[i], |Li|,maxValue);
if pos[i] = −1 then return R;

However, if all lists are very similar, using the binary search
cannot derive too much beniﬁt. In order to tackle this issue,
we slightly modify the binary search based on the observation
that in most cases, the item, which we try to search of each list
Li, is actually near the current position pos[i]. Thus, we try
to shrink the search range which begins from pos[i] to |Li|.
The modiﬁed binary search is conducted as follows:

We ﬁrst check the item at position pos[i] of Li. If the value
of the item is not less than maxKey, then this search of Li is
ﬁnished. Otherwise, we check the item at position pos[i] + 2.
If the value of the item is greater than maxKey, then we only
check the item at position pos[i] + 1. Otherwise, we check the
item at position pos[i] + 4. Generally, at the jth (j ≥ 1) step

, if we verify that the value of item at position pos[i] + 2j
is less than maxKey, then we issue a binary search begining
from pos[i] + 2j−1 + 1 to pos[i] + 2j − 1. The performance
can be improved as the search range is shrinked for the binary
search.

C. Proposed Work 2: MergeESkip

the next

In this part, we develop another enhanced version of
MergeSkip, called MergeESkip, to solve our common items
extraction problem. As described in MergeSkip, at each itera-
tion, we select the item with the maximum value (maxValue)
such that at
iteration we can skip items of the
other lists with their values less than maxValue. Notice that
maxValue does not change throughout the same iteration, i.e.
during the loop in lines 12 – 15 of Algorithm 2, maxValue
is always the same for the same iteration. In contrast, in
MergeESkip maxValue will be reﬁned continuously even in
the same iteration. This will be more effective and efﬁcient if
the distribution of values among the list is sparse.

1) A Motivating Example: Again, let us take an example,
which is shown in Figure 4, using the lists in Figure 1 before
we formally present the algorithm. We start by selecting the
ﬁrst item, 2, of list L1 and set maxValue to 2. When we access
list L2, according to Observation 1, items with values less
than 2 are skipped. Thus, we select the ﬁrst item 3 of L2, and
update maxValue to 3. Similarly, we move to the ﬁrst item 80
of L3, and update maxValue to 80. When we access list L4,
we move to the item 100, which is the item at the 5th position,
and update maxValue to 100. Hence, the ﬁrst four items of L4
are skipped. We continue the whole process until any one of
the lists is exhausted. Eventually, we only need to access 8
items and there are totally 4 iterations involved.

2) Description of MergeESkip: The details of algorithm
MergeESkip are described in Algorithm 3. We ﬁrst set max-
Value as the value of the ﬁrst item of L1 and set counter to
store how many current items of lists have the same value with
maxValue (lines 1 – 3). In the manner similar to Algorithm 2,
given a list Li, we issue a binary search to obtain the item
of Li with the minimum value among all items, whose values
are greater than or equal to maxValue (line 5). If any item
of Li has the value less than maxValue, then the algorithm
terminates, and the result R is returned immediately (line 6).
Otherwise, if the value of the current item of Li is greater than
maxValue, we update maxValue and reset counter immediately
(lines 7 – 9); otherwise, we increase the counter by 1 (line 13)
so as to denote how many number of items has values equal
to maxValue. If counter is equal to the number of lists (line
14), this implies current items of all lists have the same values
of maxValue. We therefore union maxValue into the result R,
and reset necessary parameters in lines 11 – 17, which is self-
explained. The whole process continues until any one of the
lists is exhausted (lines 4 – 18).

3) Further Discussion of MergeESkip:

In MergeESkip,
taking different precedence of selecting lists can affect the
performance. Taking Figure 4 for example, if we take the ﬁrst
item, 80, of L3 to access ﬁrst, then 2 of L1, 3 of L2 can

Algorithm 3: M ergeESkip(L)
input : L: a set of lists
output: R: Common Items in L
initialize an array pos with the size |L|;
pos[1] ← 1;
maxValue ← L1[pos[1]]; counter ← 1; i ← 2;
while TRUE do

biSearch (Li, &pos[i], |Li|, maxValue);
if pos[i] = −1 then return R ;
if Li[pos[i]] > maxValue then

maxValue ← Li[pos[i]];
counter ← 1;

else

counter ← counter + 1;
if counter = |L| then

R ← R∪ maxValue;
if pos[i] = |Li| then return R ;
pos[i] ← pos[i] + 1;
maxValue ← Li[pos[i]];
counter ← 1;

i ← i = L ? 1 : i + 1;

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

be skipped, while these two items are accessed if we select
L1 and L2 ﬁrst. Thus, several strategies to take precedence of
selecting lists can be adopted.

(cid:129) Selection in a Token Ring Method: As described in the
previous part, we always take the next list
to reﬁne
maxV alue. If we reach the last list, then the ﬁrst list
is taken as the next list;

(cid:129) Random Selection: We randomly select list as the next

list to reﬁne maxV alue;

(cid:129) Selection by Size of List: We select the list, which has
the minimum length beginning from the current position
to the end of the list.

(cid:129) Selection by Statistical Information: We select the next
list according to some statistical information of the list,
which can be updated during the access.

In this paper, we apply strategy 1 to algorithm MergeESkip.
Studying other strategies will be regarded as our future work.

IV. EXPERIMENTAL EVALUATION

A. Experiment Setup

All experiments are conducted on a PC with Intel 2.0GHz
dual core CPU and 1GB memory under Ubuntu 8.04.2 operat-
ing system. All programs are implemented in C as in-memory
algorithms, with all lists loaded into memory before they are
run, and compiled using GCC 4.2.4. We use the following
commonly used real data set and two synthetic data sets. They
cover a wide range of distributions and application domains.
(cid:129) DBLP: DBLP is a computer science bibliography web-
site1, where each article is taken as a record, including

1http://www.informatik.uni-trier.de/∼ley/db/

222

2 ← iteration 1
5
8
12
50
80
100 ← iteration 2
400 ← iteration 3

3 ← iteration 1
6
9
12
80
100 ← iteration 2
300
350

80 ← iteration 1
100 ← iteration 2
150
200
320
800

5
20
34
56
100 ← iteration 1
300
800

Fig. 4. Number of iterations and scans in Example 1 using MergeESkip. The algorithm terminates at Iteration 3 after scanning List 2 and 8 items are
scanned.

list

Max

Min

Mean S.D

1

2

3

4

5
6

7

8

9

769175

769179

769183
769172

769174
769172

769183

769178

769183

10

769174

18

70

43

1

4
14

20

14

7
5

389810 221664

400000

223967

400200

221634

388000
394000

388000

221411

222789
222294

400200

222852

386000

222236

390000

223683

400200

223047

 0.004

 0.003

 0.002

 0.001

(0,100)
(100,100)
(200,100)
(300,100)

(0,100)
(0,150)
(0,200)
(0,250)

 0.004

 0.003

 0.002

 0.001

 0

(a) DBLP

(b) different mean, the same variance

(c) the same mean, different variance

 0
-400 -200

 0

 200  400  600  800

-400

-200

 0

 200

 400

Fig. 5. Distribution of Different Data Sets

 400
 200
 100
 50

)
s
m

(
 
e
m
T

i

 
l
a
n
o
i
t
a
t
u
p
m
o
C

MergeAll
MergeSkip
MergeESkip

 1

 400
 300

 100

 50

)
s
m

(
 
e
m
T

i

 
l
a
n
o
i
t
a
t
u
p
m
o
C

MergeAll
MergeSkip
MergeESkip

 50

 100

 150

 200

 250

 50

 100

 150

 200

 250

Offset of Mean

Offset of Variance

(a) different mean, the same variance

(b) the same mean, different variance

Fig. 6. Computational Time of Different Data Distributions

authors’ names, the title, and so on. In this paper, we
pre-construct the inverted index for the author’ name,
and randomly select ten inverted lists to ﬁgure out the
common items extraction. The statistic information of
such inverted lists is shown in Figure 5(a);

(cid:129) Normal distribution with the same variance, but different
mean: We generate a set of lists, where items of each list
follow the normal distribution. For the ﬁrst list, we set
parameters, mean (0) and variance (100). For any other
list, we set parameters, the same variance, but the mean
is equal to that of previous list plus an offset. We control
the overlap between these lists by the value: offset. An
example of this data set is shown in Figure 5(b);

(cid:129) Normal distribution with the same mean, but different
variance: We generate a set of lists, where items of each
list follow normal distribution. For the ﬁrst list, we set
parameters, mean (0) and variance (100). For any other
list, we set parameters, the same mean but the variance
is equal to that of previous list plus an offset. We control
the overlap between these lists by the value: offset. An
example of this data set is shown in Figure 5(c).

B. Effect of Data Distribution

We investigate the performance of identifying the common
items extraction problem on the two synthetic data sets, where
|L|=4 and ∀Li ∈ L, |Li|=1M, and plot the results in Figure 6.
We initialize the mean to 0, variance to 100, and set an offset
in {50,100,150,200,250} for both two data sets.

From Figure 6, we can observe that MergeESkip performs
the best, followed by MergeSkip, and MergeAll. To be spe-
ciﬁc, MergeESkip runs about 1.5 times faster than MergeSkip,
and MergeSkip runs 3–4 times faster than MergeAll. Compar-
ing with MergeSkip, MergeESkip reaches a item in a further
position of the list such that more number of items can be
skipped. Comparing with MergeAll, which scans items of
lists one by one continuously before any list is exhausted,
MergeSkip skips items, which cannot obvious be in the
common items. When the value of offset increases, which
means that the overlap across lists becomes smaller, all three
algorithms run much faster. The reason that the efﬁciency of
MergeAll improves is that some list ﬁnishes being scanned at
a earlier time when the overlap decreases (notice that the size
of all lists is 1M). For both MergeSkip and MergeSkip, when

223

MergeAll
MergeSkip
MergeESkip

MergeAll
MergeSkip
MergeESkip

 4e+007

 3e+006

 700000

 500

 500
 300
 150

 50

 10

 6e+007

 2e+007
 1e+007

 3e+006
 2e+006

 600000

 60000

n
o
s
i
r
a
p
m
o
C

 
f

o
 
r
e
b
m
u
N

)
s
m

(
 
e
m
T

i

 
l

a
n
o

i
t

t

a
u
p
m
o
C

s
n
o
s
i
r
a
p
m
o
C

 
f

o
 
r
e
b
m
u
N
e
h
T

 

n
o
s
i
r
a
p
m
o
C

 
f

o
 
r
e
b
m
u
N

)
s
m

(
 
e
m
T

i

 
l

a
n
o

i
t

t

a
u
p
m
o
C

s
n
o
s
i
r
a
p
m
o
C

 
f

o
 
r
e
b
m
u
N
e
h
T

 

 4e+007

 8e+006

 4e+006

 300000

 2000

 1000

 500

 300
 200

 100

 50

 2

 3e+008

 1e+008
 5e+007

 5e+006

 500000

 50

 100

 150

 200

 250

 50

 100

 150

 200

 250

Offset of Mean

Offset of Variance

(a) different mean, the same variance

(b) the same mean, different variance

Fig. 7. Number of Comparison of Different Data Distributions

MergeAll
MergeSkip
MergeESkip

MergeAll
MergeSkip
MergeESkip

 2

 4

 6

 8

 10

 4

 6

 8

 10

The Number of Lists
(a) DBLP

The Number of Lists

(b) the same mean, different variance

Fig. 8. Computational Time by Effect of Number of Lists

MergeAll
MergeSkip
MergeESkip

MergeAll
MergeSkip
MergeESkip

 2

 4

 6

 8

 10

 2

 4

 6

 8

 10

The Number of Lists

(a) DBLP

The Number of Lists

(b) different mean, the same variance

Fig. 9. The Number of Comparisons by Effect of Number of Lists

the overlap decreases, the ability of skip becomes much more
powerful.

In order to further illustrate the advantage that this skip
strategy brings, we count the number of comparisons in each
algorithm, which is shown in Figure 7. We can observe that,
basically, no matter what the distribution is, the trend of com-
putational time is in accordance with the trend of the number
of comparisons, which demonstrates the computational time
is dependent on the number of comparisons.

C. Effect of Number of Lists

We study the performance of identifying the common items
extraction problem on the real data set and the synthetic data
set 2, where |L| in {2,4,6,8,10} and ∀Li ∈ L, |Li|=1M, and
plot the results in Figure 8. In the synthetic data set, we
initialize the mean to 0, variance to 100, and offset to 100.

Still, MergeESkip performs

followed by
MergeSkip and MergeAll. When the number of
lists
increases, the computational time of the algorithms increases

best,

the

linearly, and the gaps between MergeAll and MergeSkip,
MergeSkip and MergeESkip become larger. The reason for
MergeAll is that we need to access items of the new added
lists. For MergeSkip and MergeAll, although new lists are
added, more number of items of old lists can be skipped,
since maxV alue may be reﬁned in the new added lists, and
items of new lists can be skipped as well. We also count the
number of comparisons in each algorithm, which is shown
in Figure 9. We can observe that, the trend of computational
time is in accordance with that of the number of comparisons.

D. Effect of Size of Lists

We measure the performance of identifying the common
items extraction problem on the synthetic data set 1, where
|L| = 4 and ∀Li ∈ L, |Li| in {1M, 2M, 3M, 4M,5M}, and
plot the results in Figure 10(a). In synthetic data set 1, we
initialize the mean to 0, variance to 100, and offset to 100.

From the ﬁgure, we can observe that MergeESkip performs
the best, followed by MergeSkip and MergeAll. When the

224

)
s
m

(
 

e
m
T

i

 
l

a
n
o

i
t

a

t

u
p
m
o
C

 1500

 400

 60
 40

 20

 1

MergeAll
MergeSkip
MergeESkip

n
o
s
i
r
a
p
m
o
C

 
f

o

 
r
e
b
m
u
N
e
h
T

 

 1.9e+008
 1e+008

 6e+006

 2e+006
 1e+006

 300000

MergeAll
MergeSkip
MergeESkip

 2
 4
The Size of Each List (M)

 3

 5

(a) Computational Time

 1

 2

 3

 4

 5

The Size of Each List (M)
(b) The Number of Comparisons

Fig. 10. Effect of Size of Lists

increases,

size of each list
the computational time of the
algorithms increases linearly. However, when the size of each
list increases, the gaps between MergeAll and MergeSkip,
MergeSkip and MergeESkip keep the same. This ﬁnding
shows that when the size of the list increases, the power of skip
keeps nearly the same for the same data distribution. We also
count the number of comparisons in each algorithm, which
is shown in Figure 10(b). We can observe that, the trend of
computational time is in accordance with that of the number
of comparisons as well.

V. RELATED WORK

Common items extraction problem is widely applied not
only in the database community, but also in many other
communities of the computer science.

In database community, the common items extraction prob-
lem has been studied in [1], [8], [9], [10]. In [1], they propose
an algorithm to perform join operation on two ordered lists (it
can also be extended and applied to multiple ordered lists,
which is described by MergeAll algorithm). Our proposed
algorithms are based on their proposed algorithm and are more
efﬁcient because of the skip technique. In [8], [10], [9], they
focus on the problem of how to efﬁciently ﬁgure out items,
appearing in a given number of lists, rather than all the lists,
which has different motivations with ours.

Common items extraction problem is also studied in [11],
[12], [13]. In [11], [12], Hollaar studies how to construct a
specialized processor to speed up the calculation of common
items from the instruction level of CPU. In [13], Stellhorn
describes a specialized computer system, which is capable of
performing common items extraction, which takes information
retrieval as application scenario, in hardware. This architecture
can derive signiﬁcant improvement of performance. Different
from the previous work, we focus on the efﬁciency of the
common items extraction problem by decreasing the number
of comparisons as many as possible.

VI. CONCLUSION

In this paper, we study the problem of identifying a set of
common items that appear in all of the sorted lists efﬁciently.
Existing work, which handles this problem, needs to scan the
items of all lists until any one of the lists is exhausted for being
scanned. In this paper, we propose two algorithms, MergeSkip

and MergeESkip, that try to solve this problem by taking the
idea of skipping as many items of lists as possible. Based
on this skip strategy, a large number of comparisons among
items of lists can be saved, and the efﬁciency is improved.
We conduct a set of comprehensive experiments on a real
dataset and two large-scale synthetic datasets. The results
demonstrate that our proposed approaches are effective and
efﬁcient especially when the overlap across all lists is not high.

VII. ACKNOWLEDGEMENTS

This research is partially supported by the National Natural
Science Foundation of China under Grant No.60873017, Grad-
uate Research Fund Project of Renmin University of China
under Grant No.10XNH097.

REFERENCES

[1] H. Garcia-Molina, J. D. Ullman, and J. Widom, Database System

Implementation. Prentice-Hall, 2000.

[2] I. H. Witten, A. Moffat, and T. C. Bell, Managing Gigabytes: Com-
pressing and Indexing Documents and Images, Second Edition. Morgan
Kaufmann, 1999.

[3] C. Weiss, P. Karras, and A. Bernstein, “Hexastore: sextuple indexing for
semantic web data management,” PVLDB, vol. 1, no. 1, pp. 1008–1019,
2008.

[4] M. Stonebraker, D. J. Abadi, A. Batkin, X. Chen, M. Cherniack,
M. Ferreira, E. Lau, A. Lin, S. Madden, E. J. O’Neil, P. E. O’Neil,
A. Rasin, N. Tran, and S. B. Zdonik, “C-store: A column-oriented dbms,”
in VLDB, 2005, pp. 553–564.

[5] A. L. Holloway and D. J. DeWitt, “Read-optimized databases, in depth,”

PVLDB, vol. 1, no. 1, pp. 502–513, 2008.

[6] D. J. Abadi, S. Madden, and M. Ferreira, “Integrating compression and
execution in column-oriented database systems,” in SIGMOD Confer-
ence, 2006, pp. 671–682.

[7] S. Al-Khalifa, H. V. Jagadish, J. M. Patel, Y. Wu, N. Koudas, and
joins: A primitive for efﬁcient xml query

D. Srivastava, “Structural
pattern matching,” in ICDE, 2002, pp. 141–.

[8] Y. L. Chen Li, Jiaheng Lu, “Efﬁcient merging and ﬁltering algorithms

for approximate string searches,” in ICDE, 2008, pp. 257–266.

[9] C. Li, B. Wang, and X. Yang, “Vgram: Improving performance of
approximate queries on string collections using variable-length grams,”
in VLDB, 2007, pp. 303–314.

[10] S. Sarawagi and A. Kirpal, “Efﬁcient set joins on similarity predicates,”

in SIGMOD, 2004, pp. 743–754.

[11] L. A. Hollaar, “An architecture for the efﬁcient combining of linearly

ordered lists,” SIGIR Forum, vol. 10, no. 4, pp. 16–21, 1976.

[12] L. Hollaar, “A list merging processor for inverted ﬁle information
retrieval systems,” in University of Illinois at Urbana-Champaign, 1975.
[13] W. Stellhorn, “An inverted ﬁle processor for information retrieval,” IEEE

Transactions on Computers, vol. 26, pp. 1258–1267, 1977.

225

