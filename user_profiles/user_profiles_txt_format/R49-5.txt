Show me the Money! Deriving the Pricing Power of Product

Features by Mining Consumer Reviews

Nikolay Archak

Anindya Ghose

narchak@stern.nyu.edu

aghose@stern.nyu.edu

Panagiotis G. Ipeirotis

panos@nyu.edu

Department of Information, Operations, and Management Sciences

Leonard N. Stern School of Business, New York University

ABSTRACT
The increasing pervasiveness of the Internet has dramatically
changed the way that consumers shop for goods. Consumer-
generated product reviews have become a valuable source of
information for customers, who read the reviews and decide
whether to buy the product based on the information pro-
vided. In this paper, we use techniques that decompose the
reviews into segments that evaluate the individual character-
istics of a product (e.g., image quality and battery life for a
digital camera). Then, as a major contribution of this paper,
we adapt methods from the econometrics literature, specif-
ically the hedonic regression concept, to estimate: (a) the
weight that customers place on each individual product fea-
ture, (b) the implicit evaluation score that customers as-
sign to each feature, and (c) how these evaluations aﬀect
the revenue for a given product. Towards this goal, we de-
velop a novel hybrid technique combining text mining and
econometrics that models consumer product reviews as ele-
ments in a tensor product of feature and evaluation spaces.
We then impute the quantitative impact of consumer re-
views on product demand as a linear functional from this
tensor product space. We demonstrate how to use a low-
dimension approximation of this functional to signiﬁcantly
reduce the number of model parameters, while still provid-
ing good experimental results. We evaluate our technique
using a data set from Amazon.com consisting of sales data
and the related consumer reviews posted over a 15-month
period for 242 products. Our experimental evaluation shows
that we can extract actionable business intelligence from the
data and better understand the customer preferences and ac-
tions. We also show that the textual portion of the reviews
can improve product sales prediction compared to a baseline
technique that simply relies on numeric data.

Categories and Subject Descriptors
I.2.7 [Artiﬁcial Intelligence]: Natural Language Process-
ing—text analysis; H.2.4 [Database Management]: Sys-
tems—Textual databases; H.2.8 [Database Applications]:
Data mining

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
KDD’07, August 12–15, 2007, San Jose, California, USA.
Copyright 2007 ACM 978-1-59593-609-7/07/0008 ...$5.00.

General Terms
Algorithms, Measurement, Economics, Experimentation

Keywords
consumer reviews, e-commerce, econometrics, electronic com-
merce, electronic markets, hedonic analysis, Internet, opin-
ion mining, product review, sentiment analysis, text mining,
user-generated content

1.

INTRODUCTION

Consumer product reviews are now widely recognized to
have a signiﬁcant impact on consumer buying decisions [6].
Moreover, prior research on consumer decision making has
established that consumer-generated product information on
the Internet attracts more product interest than vendor in-
formation [2]. In contrast to product descriptions provided
by vendors, consumer reviews are, by construction, more
user-oriented: in a review, customers describe a product in
terms of usage scenarios and evaluate the product from a
user’s perspective [4]. Despite the subjectivity of consumer
evaluations in the reviews, such evaluations are often con-
sidered more credible and trustworthy by customers than
traditional sources of information [2].

The rapid growth of the number of consumer reviews on
the Web gave birth to several interesting opinion mining
problems. Early work in this area was targeted primarily
at evaluating the polarity of the reviews: review sentiments
were classiﬁed as positive or negative by looking for occur-
rences of speciﬁc sentiment phrases. Diﬀerent sources of
sentiment phrases were proposed, including manually con-
structed dictionaries [7], WordNet [15], and search engine
hit counts [28]. Machine learning methods were also applied
to sentiment-based classiﬁcation of consumer reviews [22];
all methods performed relatively well but failed to achieve
high accuracy that is typical for topic-based document clas-
siﬁcation. Results suggested that sentiment classiﬁcation of
consumer reviews is complicated since consumers may pro-
vide a mixed review, praising some aspects of a product but
criticizing others. Such heterogeneity stimulated additional
research on identifying product features on which consumers
expressed their opinions [9, 15–17, 26, 27]. After identify-
ing the product features, it is then possible to use identiﬁ-
cation techniques to extract consumer opinions about each
feature [3, 8, 15, 23].

Ultimately, though, we want to identify not only the opin-
ions of the customers, but also want to examine the impor-
tance of these opinions. What features do customers value
most? What is the relative importance of battery life vs.

Research Track Paper56image quality in a digital camera? Customers may praise or
criticize the zoom capabilities of a digital camera, but these
discussions may not really aﬀect their decision to buy the
product. Current work in opinion mining has not focused on
capturing such behavior. Furthermore, current opinion min-
ing systems cannot capture reliably the pragmatic meaning
of the customer evaluations. For example, is “good battery
life” better than “nice battery life”? How can we deﬁne an
objective measure for ranking evaluations?

Towards answering questions of this nature, we propose
utilizing the economic context in which the opinions are eval-
uated to estimate both the intensity and the polarity of the
opinion. In particular, we investigate how product feature
evaluations contained in consumer reviews aﬀect product de-
mand. Then, by tracing the respective changes in demand,
we derive both the weight of the diﬀerent product features,
and the pragmatic “meaning” of these evaluations, providing
actionable intelligence to the manufacturers that are trying
to understand consumer behavior. We illustrate the intu-
ition behind our approach with this (simpliﬁed) example:

Example 1.1. Consider two reviews rA and rB for two
similar digital cameras A and B on Amazon.com: review
rA states that the “ lenses” of camera A are “ excellent”,
while review rB states that the “ lenses” of camera B are
“ good”. To understand both the polarity and the strength
of these evaluations, we observe the changes in sales asso-
ciated with these reviews, all other things being equal. We
observe that the evaluation “ excellent lenses” increases sales
by 5%, while the evaluation “ good lenses” causes sales to
drop by 1%. Therefore, we assign the score +5% to the
evaluation “ excellent” and the score -1% to the evaluation
“ good.” In a similar manner, we also observe that the evalu-
ations “ excellent battery life” and “ good battery life” cause
a respective change in sales of +2.5% and -0.5%. By com-
paring the sales changes associated with the evaluation of
“ battery life” with the respective changes associated with
“ lenses,” we infer that the weight of the “ lenses” feature
is twice as high as the weight of “ battery life.” (cid:2)

Our approach is conceptually similar to the hedonic regres-
sions that are commonly used in econometrics to identify the
weight of individual features in determining the overall price
of a product. For example, hedonic regressions are used to
identify the marginal value of an extra megapixel in digi-
tal cameras.1 As an important research contribution, we
show how to incorporate in a hedonic-like framework qual-
itative features, such as “ease of use” or “image quality,”
that are not directly measurable and are ignored in exist-
ing economics and marketing research. Towards adapting
a hedonic-like framework, we model qualitative consumer
opinions as quantitative evaluation scores and then model
consumer reviews as elements in a tensor product of feature
space and evaluation space. To study the impact of con-
sumer reviews on the product demand, we represent review
impact as a linear functional in this tensor product. Finally,
we show how to use a rank constraint for this functional to
signiﬁcantly reduce the number of model parameters, while
still providing good experimental results. Our experimental
evaluation over a real data set of 242 products monitored
over a 15-month period on Amazon.com shows the valid-

1

Hedonic regressions are also commonly used by the U.S. Bureau of
Labor Statistics (BLS) to take into account product quality adjust-
ments when recalculating the consumer price index (CPI).

ity of our approach and provides signiﬁcant insights on the
behavior of consumers who buy products online.

The rest of the paper is organized as follows. Section 2
gives the background for the paper. Section 3 presents our
hybrid model that combines econometrics and text mining
for analyzing consumer reviews using product demand. Sec-
tion 4 discusses our experimental setting and results, ob-
tained over two big product categories. Finally, Section 5
discusses related work and Section 6 provides further dis-
cussion and concludes the paper.

2. BACKGROUND

In this section, we give the necessary background for this
paper. In Section 2.1, we give a brief description of hedo-
nic regressions, which can be considered as the microeco-
nomic framework in which our model is embedded in. Then,
Section 2.2 describes existing techniques for product feature
identiﬁcation from consumer reviews and Section 2.3 brieﬂy
discusses existing approaches for identifying consumer opin-
ions from product reviews.

2.1 Hedonic Regressions

The hedonic model assumes that diﬀerentiated goods can
be described by vectors of objectively measured features and
the consumer’s valuation of a good can be decomposed into
implicit values of each product feature [24]. Hedonic mod-
els are designed to estimate the value that diﬀerent product
aspects contribute to a consumer’s utility.
Implicit in the
hedonic price framework is the assumption that a particular
product can be viewed as consisting of various bundles of a
small number of characteristics or basic attributes [1]. For
instance, a backpacking tent can be decomposed to charac-
teristics such as weight (w), capacity (c), and pole mate-
rial (p), and the tent utility can be represented as a function
u(w, c, p, . . .). Various restrictions can be put on the utility
function. For example, it is often assumed that the utility
function is monotonic, increasing, and concave to satisfy the
“law of diminishing marginal utility” [25]. In brief, the he-
donic hypothesis is based on the notion that heterogeneous
goods are an aggregation of individual characteristics.
It
is important to point out that not all product categories
are consistent with the assumptions of the hedonic frame-
work. For example, while consumer appliances ﬁt well into
the hedonic model, products such as movies or books do not
have clear utilitarian characteristics and are not typically
classiﬁed as hedonic products. In order to avoid potential
complexities arising from applying the model to non-hedonic
products, in this paper we consider hedonic goods only.

The primary weakness of the existing hedonic models is
the need to identify manually product features and mea-
surement scales for them. In traditional hedonic regressions
(i.e., those used by the BLS2 to calculate the CPI) the de-
cision of what features to include and how to measure them
is made by individuals. This can lead to a bias from subjec-
tive judgments of these individuals. Furthermore, features
that cannot be easily measured (e.g., image quality, style)
are commonly ignored.

2.2 Product Feature Identiﬁcation

In an orthogonal direction to economic research, the prob-
lem of identifying product features has been studied exten-
sively in the last few years in the data mining and natu-
ral language processing communities. Many techniques use
2

U.S. Bureau of Labor Statistics.

Research Track Paper57a part-of-speech tagger to annotate each review word with
its part-of-speech (POS), identifying whether the word is
a noun, an adjective, a verb and so on. Nouns and noun
phrases are popular candidates for product features, though
other constructs (like verb phrases) can be used as well.
Alternative techniques search for statistical patterns in the
text, for example, words and phrases that appear frequently
in the reviews [8]. For example, Hu and Liu [16] use asso-
ciation rule mining to ﬁnd frequent n-grams3 in consumer
product reviews and use these n-grams as candidate features.
Hybrid methods are also developed by combining both ap-
proaches, where a POS-tagger is used as a preprocessing step
before applying association mining algorithm to discover fre-
quent nouns and noun phrases [19, 23]. An alternative tech-
nique for discovering product features that are not explicitly
mentioned in the review is to use a classiﬁer [9] that deter-
mines whether a particular feature is discussed (implicitly)
in the review or not.

2.3 Mining Consumer Opinions

Of course, identifying product features per se is not the
end goal. The important goal is to understand what the
customer’s opinion is about each of the identiﬁed product
features. An increasingly popular trend in opinion mining
is in combining feature mining and sentiment identiﬁcation
techniques to extract consumer opinions in form of feature-
based summaries [3, 8, 15, 23]. Though technical details
may diﬀer, the proposed algorithms usually consist of three
In the ﬁrst step, a feature mining technique
basic steps.
is used to identify product features.
In the second step,
the algorithms extract sentences that give (positive or neg-
ative) opinions for a product feature. Finally, a summary is
produced using the discovered information. Unfortunately,
the existing approaches could not provide reasonable quan-
titative evaluations of product features. In most cases, the
evaluation of a product feature was done in a binary scale
(positive or negative). It is also possible to have a count-
ing scale that computes the number of positive and negative
opinion sentences for a particular feature; such counts can
be used for feature-based comparison of two products (see,
for example [19]). Such a comparison tool is undoubtedly
useful for consumers using an online shopping environment.
Unfortunately, such techniques fail to identify the strength
of the underlying evaluations, and do not show the impor-
tance of the underlying feature in the consumer’s purchasing
process. In this paper we show how to address these issues
by taking into consideration the economic context into which
the opinions are being evaluated.

Var Dim Description
F
feature space
E
evaluation space
R
review space
V
basis of review space
R
demand for the product k at time t
Dkt
R
α
constant term
R
β
price elasticity of demand
R
price for the product k at time t
pkt
Wkt Rmn
consumer review component, see Eq. 1
Rm
γ
vector of evaluation weights
Rn
vector of feature weights, ||δ||
δ

2 = 1

Table 1: Notation and symbol descriptions

product features mentioned in the reviews and the respec-
tive consumer evaluations. Recall that in the hedonic model
each product can be characterized by a vector of its features
X = (ef 1, . . . , ef n), where each vector element ef i repre-
sents the quality level of the corresponding feature. In our
current work, we rely on existing approaches to identify the
product features in the text. Speciﬁcally, we assume that
each of the n features can be expressed by a noun, chosen
from the set of all nouns that appear in the reviews. For
example, for a digital camera dimension 1 might be “lens”,
dimension 2 might be “size”, dimension 3 might be “shut-
ter ”.4 Furthermore, to avoid overﬁtting, we only considered
as features the nouns that appeared frequently in our data
set. (We provide more details in Section 4.1.)

After identifying the product features, we need to identify
the consumer evaluation of product feature quality. We rely
on the observation [15, 29] that consumers typically use ad-
jectives, such as “bad,” “good,” and “amazing” to evaluate
the quality of a product characteristic. Therefore, we use a
syntactic dependency parser to identify the adjectives that
modify a noun that we have identiﬁed as product feature.

The result of this technique is a set of noun-adjective pairs
that correspond to pairs of product features and their respec-
tive evaluations. We refer to these pairs as opinion phrases.
It should be noted that such opinion phrases cannot capture
all opinion information contained in consumer reviews. We
would like to emphasize though that the goal of this paper
is not to develop new techniques for identifying product fea-
tures or phrases that evaluate such features.5 Rather, we are
interested in measuring the weight that customers place in
each product feature and the implicit evaluation score (po-
larity and strength) associated with each feature evaluation.
The core contributions of this paper are described next.

3. ECONOMETRIC OPINION ANALYSIS

3.2 Structuring the Opinion Phrase Space

In this section, we describe our econometric approach for
modeling and analyzing consumer reviews. In Section 3.1,
we present our approach for identifying the opinions of con-
sumers about product features. Then, in Section 3.2, we
show how to represent consumer reviews as elements of a
tensor product space and in Section 3.3, we describe our
econometric approach for measuring the weight of the in-
dividual product features, and the implicit evaluation score
that a consumer review assigns to each feature.

3.1

Identifying Customer Opinions

In the ﬁrst step of our approach, we need to identify the

3

An n-gram is a sequence of n consecutive words.

Existing consumer review mining approaches tend to con-
sider extracted product features and opinions as simple sets

4

Some researchers have noted that many technical terms are com-
pound nouns [20, 26]. In particular, compound terms like “battery
life”, “image quality” and “memory card” are rated by end users as
more helpful for choosing products than single noun features (“bat-
tery”, “image(s)”, “memory”) [20]. Nevertheless, we observed that
many compound terms without loss of information can be represented
by a single noun only. For example, if the mining tool ﬁnds word “bat-
tery” in a digital camera review, we observed sure that “battery life”
is the feature being evaluated. For this reason we didn’t consider com-
pound nouns as candidate product features and restricted ourselves
to simple nouns only.
5

Of course, our approach can clearly beneﬁt from orthogonal advances
in the topics of product feature identiﬁcation, and in the extraction
of the respective evaluation phrases.

Research Track Paper58and no algebraic structure is imposed on these sets. In order
to use the concepts similar to hedonic regressions, we need to
represent the product demand as a function from the space
of consumer reviews. Such representation assumes a vector
space structure on the set of feature opinions. To construct
such structure, we build two vector spaces: one for product
features and one for feature evaluations.

We model multiple sets of n product features as elements
of a vector space over R with basis f1, . . . , fn. We denote
this feature space as F , (dim F = n).
In the same way,
we deﬁne a space of evaluations as a vector space over R
with basis e1, e2, . . . , em. We denote this evaluation space
as E (dim E = m). Intuitively, when we represent a review
r in the feature space F , the representation contains the
weights that customers assign to each product feature. Sim-
ilarly, when we represent a review r in the evaluation space
E , the representation contains the implicit evaluation scores
that the review assigns to a product feature (notice that the
evaluations in the space E are not bound, yet, to any speciﬁc
feature).

Now, based on the algebraic structures in the feature and
the evaluation space, we can represent the opinion phrases
and whole consumer reviews as elements of the review space
R that we deﬁne as the tensor product of the evaluation and
feature spaces:

R = F ⊗ E

Note that the set of opinion phrases fi ⊗ ej form a basis of
the space R and we denote this basis as V .

Now, each review can be represented as a vector in the re-
view space R: we only need to determine the weight that we
assign to each dimension of R to represent the review. There
are several diﬀerent ways to determine the weight of an opin-
ion phrase in a text corpus (e.g., tf.idf weights). In our work,
we use a standard term frequency measure that discounts
inﬂuence of longer reviews and calculates the weight of the
opinion phrase phrase in review rev for product prod as:

w(phrase, rev , prod ) =

(cid:2)

N (phrase, rev , prod ) + s
y∈V (N (y, rev , prod ) + s)

(1)

where N (y, r, p) is the number of occurrences of the opinion
phrase y in the consumer review r for product p, and s is
a “smoothing” constant.6 Notice that using our convention,
the sum of the weights of the opinion phrases within each
review is equal to one, discounting the inﬂuence of longer
reviews.

Example 3.1. Consider the following review for a digital
camera: “ The camera is of high quality and relatively easy
to use. The lens are fantastic! I have been able to use the
LCD viewﬁnder for some fantastic shots... To summarize,
this is a very high quality product.” This review can be
represented by the following element of the tensor product,
assuming s = 0:

0.4 ·
0.2 ·
0.2 ·
0.2 ·

(quality ⊗ high) +
(use ⊗ easy) +
(lens ⊗ fantastic) +
(shots ⊗ fantastic)

review, the weight of this dimension is 0.4, in contrast to
all the other opinion phrases that appear only once and have
weight equal to 0.2. (cid:2)

So far, we have discussed how to represent reviews in an
algebraic form. While we could achieve a similar result by
simply deﬁning directly a space of opinion phrases and then
represent each review as a vector in this space, we will see
next that our tensor space approach has signiﬁcant analytic
advantages over this simpler approach. Speciﬁcally, we will
see that the tensor space approach will allow us to estimate
naturally the weight of each product feature and the implicit
score of each evaluation, using relatively small training sets
and avoiding the problems of data sparsity and of overﬁtting.
Next, we describe our approach in detail.

3.3 Econometric model of product reviews

A simple econometric technique for modeling product de-
mand as a function of product characteristics and its price,
is the following simple linear model:

ln(Dkt) = ak + β ln(pkt) + εkt.

(2)

where Dkt is the demand for the product k at time t, pkt is
its price at time t, β is the price elasticity, and ak is a prod-
uct speciﬁc constant term which captures the unobserved
product heterogeneity, such as diﬀerences in product char-
acteristics and brand equity. The variable εkt represents a
random disturbance factor which is usually assumed to be
normally distributed, i.e., εkt ∼ N (0, σ2). This is a clas-
sical ordinary-least-squares (OLS) regression with product
level ﬁxed eﬀects and the parameters can be estimated us-
ing standard panel data methods [31].

A potential drawback of such a model is that it can not be
used to evaluate separately diﬀerent product characteristics
because it mixes all product features into the single term ak.
Another limitation is time invariant nature of the product
speciﬁc eﬀect. Though the technical characteristics of the
product typically stay the same during the product’s life
cycle, its popularity may change as a result of consumer
evaluations of the product.

We extend the model using our original assumption that
qualitative consumer reviews correspond to some quantita-
tive evaluations of product characteristics. Such evaluations
cannot be measured directly but can be learned from prod-
uct demand ﬂuctuations, if a suﬃciently large data set is
available. We replace the product speciﬁc eﬀect ak by a
sum of two components:

ak = α + Ψ(Wkt).

(3)

where we have

• a consumer review component Wkt ∈ R that cap-
tures opinions contained in consumer product reviews
for product k available at time t, including all reviews
before time t, and

• a time and product invariant constant term α.

Notice that each opinion phrase dimension has a weight co-
eﬃcient determining its relative importance in the review.
Since the opinion phrase quality-high appears twice in the

6

We set s = 0.01 in our paper

The vector Wkt (for ﬁxed k and t) contains the weights of
all opinion phrases that appeared in the consumer reviews
for product k available at time t. (Essentially, we take the
vectors that represent the consumer reviews posted by time
t and “collapse” them into a single vector.) For simplicity,

Research Track Paper59(cid:3)

phrase∈V

n(cid:3)

m(cid:3)

i=1

j=1

we compute these weights by averaging7 the weights for each
opinion phrase across all reviews posted until time t.

In Equation 3, we represented the impact of a set of con-
sumer reviews on the product demand as some generic func-
tional Ψ : R → R. Similar to hedonic regressions, we assume
that the functional form is linear and formally this can be
written as Ψ ∈ R∗ where R∗ is the dual space of R (space of
linear functionals). A linear functional from a tensor product
of two vector spaces is just a bilinear form of two parameters,
so Ψ is just a bilinear form of features and evaluations. Any
linear functional can be written in the basis representation:

Ψ(Wkt) =

ψ(x) · w(phrase, reviews t, product k) =

ψ(fi ⊗ ej) · w((fi ⊗ ej), reviews t, product k).

where ψ(x) = ψ(fi ⊗ ej) is the value of the functional on
the basis vector fi ⊗ ej. Intuitively, the value of ψ(x) is the
inﬂuence of the opinion phrase (cid:6)fi, ej(cid:7), which in turn is a
function of the weight of feature fi (when evaluated by ej)
and of the implicit score that ej assigns to fi. Continuing
the example from Section 3.2, we can write the value of the
functional on the sample consumer review as:

0.4 · ψ(quality ⊗ high) + 0.2 · ψ(use ⊗ easy)+
0.2 · ψ(lens ⊗ fantastic) + 0.2 · ψ(shots ⊗ fantastic)

Using Equations 2 and 3, we have our extended linear model:

ln(Dkt) = α + β ln(pkt) + Ψ(Wkt) + εkt

Unfortunately, this model has a very large number of param-
eters and would require a very large training set of product
reviews to estimate. In the case where we have n product
features and m evaluation words for N products with similar
features, the number of model parameters will be n · m + N .
Since, we rarely have more than 30 reviews for a product,
model overﬁtting is deﬁnitely a problem.

To alleviate this problem, we reduce the model dimension
by placing a rank constraint on the matrix Ψ.
In other
words, we are not going to search for any linear function but
only for those with low matrix ranks. The approach is based
on the following observation.

Theorem 3.1. (Singular Value Decomposition) Any
linear functional Ψ ∈ R∗ such that rank Ψ = rank(ψij) ≤ p
i=1 Δi ⊗ Γi where Δi ∈ F ∗ and
can be represented as
Γi ∈ E ∗ and ||Δi||

(cid:2)

p

2 = 1.

Corollary 3.1. Any linear functional Ψ ∈ R∗ such that
rank(Ψ) = rank(ψij) = 1 can be represented as Δ ⊗ Γ where
Δ ∈ F ∗ and Γ ∈ E ∗ and ||Δ||

2 = 1.

Corollary 3.1 shows how to model features and evaluations
as independent multiplicative components. We can replace
a complex functional from R∗ by a product Δ ⊗ Γ of two
simple functionals Δ ∈ F ∗ and Γ ∈ E ∗.
In other words,
we assume that each coeﬃcient ψ(x) can be decomposed as
a product of the feature component (deﬁning importance

7

Instead of giving equal weight to each review, we also experimented
with weighting schemes involving a time-discount factor (older reviews
have smaller weights) and a “usefulness” factor. In the latter case,
opinion weights were multiplied by a factor (h + 1)/(t + 1) where h
and t are the number of helpful and total votes for the parent review.
In both cases, the results were qualitatively similar to those of the
simpler model.

of the feature) and the evaluation component (determining
relative weight of the evaluation). For example:

ψ(shots ⊗ fantastic) = γ(shots) · δ(fantastic)

The resulting approach is similar to ANOVA decomposi-
tion, which is frequently used to reduce model complexity
for multidimensional splines and generalized additive mod-
els [14]. Our model, though, operates in diﬀerent context
because features and evaluations do not represent indepen-
dent dimensions of consumer reviews: each evaluation word
occurrence describes some feature and each feature word oc-
currence relates to some evaluation.

One limitation of this rank-1 approximation is the restric-
tion that each adjective has one meaning, independently of
the feature that it evaluates. While this restriction might
seem too strict, we observed that it worked well for our set-
ting. We should note though that our approach allows ﬂex-
ibility in the approximation approach. If we would like to
assign two potential meanings for each adjective, we can use
a rank-2 approximation, allowing two meanings per adjec-
tive and two potential weights for each feature (e.g., negative
evaluations may have high inﬂuence when evaluating a fea-
ture, but positive evaluations may have low weight). In this
case, the functional ψ would simulate a mixture model and
have the form ψ = γ1δ1 +γ2δ2. (Of course, estimating such a
model would require a larger number of training examples.)
Similarly, we can use even higher rank approximations, al-
lowing more meanings per adjective, but we would need more
training data to avoid overﬁtting.

Using the rank-1 approximation of the tensor product

functional, we rewrite the model of Equation 3.3 as:
ln(Dkt) = α + β · pkt + γT · Wkt · δ + εkt.

(4)

where γ is a vector that contains n elements corresponding
to the weight of each product feature, and δ is a vector that
contains the implicit score that each adjective assigns to a
product feature. The new model has only m + n + 1 + N
parameters instead of original n · m + 1 + N , but this is
achieved by sacriﬁcing the linearity of the original model.
Despite the loss of linearity, we can still search for the max-
imum likelihood estimate (MLE) of the model parameters.
Assuming that εkt are independent and identically normally
distributed residuals, the ML estimate is the same as the
minimum of the least-squares ﬁt function:

∗

(α

, β

∗

∗

, δ

) =

∗
, γ
⎛

⎝

(cid:3)

(cid:6)

k,t

argmin

ln(Dkt) − α − β · pkt − γT · Wkt · δ

(cid:7)

⎞

2

⎠

One of possible approaches to parameter estimation is to
use the Newton-Rhapson method, or its variations, to search
for the minimum. Unfortunately the Newton-Rhapson algo-
rithm convergence suﬀers from numerical diﬃculties, in par-
ticular, ill-conditioning of the Hessian in the neighborhood
of the solution. To solve the problem, we propose a diﬀerent
iterative algorithm. Our algorithm is based on the observa-
tion that if one of the vectors γ or δ is ﬁxed, the Equation 4
represents a linear model. The steps of the algorithm are
described below:

1. Set δ to a vector of initial feature weights.

2. Minimize the ﬁt function by choosing the optimal eval-
uation weights (γ) assuming that the feature weights

Research Track Paper60(δ) are ﬁxed. If δ is ﬁxed, the equation is just a usual
linear model and γ can be estimated by ordinary-least-
squares (OLS) or generalized-least-squares (GLS) esti-
mators [12].

3. Minimize the ﬁt function by choosing the optimal fea-
ture weights (δ) assuming that the evaluation weights
(γ) are ﬁxed. Again this can be done by using OLS or
GLS estimator.

4. Repeat Step 2 and 3, until the algorithm converges.

Note that the algorithm described above (and the Newton-
Rhapson algorithm as well) may converge to some local min-
imum of the ﬁt function. To compensate for such potential
errors, we repeat the execution of the algorithm with multi-
ple, randomly generated, initial starting points.

Summary: In this section, we have presented our ap-
proach for estimating the weights of the diﬀerent product
features and the implicit scores that the adjectives assign to
the product features. We have presented how to use a low-
rank approximation of the review space to estimate these
values, and presented an eﬃcient algorithm for estimating
the parameters of our model. Next, we present the experi-
mental evaluation of our approach.

4. EXPERIMENTAL EVALUATION

In this section, we validate our techniques on a data set
covering 242 products drawn from the product categories
“Audio & Video” and “Camera & Photo” sold on Amazon.
We ﬁrst describe our data set (Section 4.1). Then, in Sec-
tion 4.2, we describe how we run our text mining algorithm
to identify the product features and the evaluations. In Sec-
tion 4.3, we present the exact setup of our econometric-based
technique, and, in Section 4.4 we discuss the experimental
ﬁndings that show that our techniques can provide action-
able business intelligence and can give useful insights on how
customers behave when shopping online.

4.1 Data

We gathered data on a set of products using publicly avail-
able information at Amazon.com. The data set covered two
diﬀerent product categories: “Camera & Photo” (115 prod-
ucts) and “Audio & Video” (127 products). During a 15-
month period (from March 2005 to May 2006), we have been
collecting daily price and sales rank information for the prod-
ucts in our data set, using the API provided by Amazon Web
Services. In the “Camera & Photo” category we had 31,233
observations and in the “Audio & Video” category we had
35,143 observations. Each observation contains the collec-
tion date, the product ID, the price on Amazon.com (which
includes a possible Amazon discount), the suggested retail
price, the sales rank of the product, and the average product
rating according to the posted consumer reviews. Addition-
ally, we used Amazon Web Services to collect the full set of
reviews for each product. Each product review has a numer-
ical rating on a scale of one to ﬁve stars, the date the review
was posted and the actual text posted by the reviewer. We
collected 1,955 reviews in the “Camera & Photo” category
and 2,580 reviews in the “Audio & Video” category, overlap-
ping with our sales rank observations. Thus, each product
had about 20 reviews on average. Figures 1 and 2 show dis-
tributions of the number of consumer reviews per product in
the “Audio & Video” and “Camera & Photo” categories. A

60

50

40

30

20

10

s
t
c
u
d
o
r
p

 
f

o
 
r
e
b
m
u
N

s
t
c
u
d
o
r
p

 
f

o
 
r
e
b
m
u
N

45

40

35

30

25

20

15

10

5

0

0

0

0

10

20
30
Number of reviews

40

50

Figure 1: Distribution of the number of consumer
reviews per product (Audio & Video)

5

10

15

20

25

30

35

40

45

Number of reviews

Figure 2: Distribution of the number of consumer
reviews per product (Camera & Photo)

few outlier products, with more than 50 reviews, are not dis-
played on the ﬁgures. For example, in the “Audio & Video”
category Apple 1GB iPod Shuﬄe had 271 consumer reviews.

4.2 Selecting Feature and Evaluation Words

In order to determine the set of product features and eval-
uation words to use, we applied a simple approach consisting
of three steps. First, we used the part-of-speech tagger de-
veloped by the Stanford NLP Group, to analyze all reviews
and assign a part of speech tag to each word. Second, a
set of frequent nouns was extracted from the tagged review
corpus. The second step tends to produce a signiﬁcant num-
ber of infrequent, non-relevant items. Fortunately, the set
of frequent nouns was relatively small (about 800 items per
category). Since, our work is not focused on product feature
identiﬁcation from product review, we decided to quickly
process the list of frequent items, and manually select a sub-
set of approximately 30 nouns to use as product features.
For example, in the “Camera & Photo” category the set of
features included “battery/batteries,” “screen/lcd/display,”
“software,” “viewﬁnder,” “lens/lenses,” and so on. To iden-
tify the set of evaluations, we used the syntactic dependency
parser from the Stanford NLP toolkit, and we extracted the
adjectives that evaluated the selected product features. The

Research Track Paper61set of evaluations contained popular adjectives describing
the level of satisfaction with each particular feature. Words
like “amazing,” “bad,” “great,” “exceptional,” and “out-
standing” appeared frequently in our data set. We kept the
list of 30 most frequent adjectives to create our evaluation
space. We used the same set of evaluation words for both
product categories, but, of course, the set of features was
diﬀerent in each category.

4.3 Experimental Setup

In order to evaluate our techniques using data from Ama-
zon, we had to modify slightly the model of Section 3.3.
Speciﬁcally, Amazon.com doesn’t report the demand for the
products available on the web site.
Instead, Amazon.com
reports a sales rank ﬁgure for each product, which ranks the
demand for a product relative to other products in its cat-
egory. Prior research in economics and in marketing (for
instance, [5, 11]) has associated these sales ranks with de-
mand levels for products such as software and electronics.
The association is based on the experimentally observed fact
that the distribution of demand in terms of sales rank has
a Pareto distribution (i.e., a power law) [5]. Based on this
observation, it is possible to convert sales ranks into demand
levels using the following Pareto relationship:

ln(D) = a + b · ln(S)

(5)

where D is the unobserved product demand, S is its observed
sales rank, and a > 0, b < 0 are industry-speciﬁc parameters.
Therefore, we can use the log of product sales rank on Ama-
zon.com as a proxy of the log of product demand. We also
modiﬁed the model of Section 3.3 to include both the sug-
gested retail price (P1) and the price on Amazon.com (P2)
since its natural to expect the prices will inﬂuence product
demand, besides word-of-mouth. Furthermore, we included
the review rating variable (R), which represented the aver-
age numeric rating of the product as given by the reviews.
Our model predicts the product sales rank based on its
price, average review rating, and a set of consumer reviews.
Note that as deﬁned before, the review-level variables are
the ones published before a given observation date.8 Us-
ing our model, we analyze how diﬀerent feature-evaluation
combinations aﬀect sales, after controlling for product price.
The transformed equation is given below:

ln(Skt) = α + β1 · Rkt + β2 · ln(P1kt) + β3 · ln(P2kt)+

m(cid:3)

n(cid:3)

Wktij · γi · δj + εkt

i=1

j=1
= α + ykt · β + γT · Wkt · δ + εkt

(6)

In the above equation, Wkt is the “review matrix” (see
Section 3.3) and Wktij was calculated using Equation 1.
We found that due to sparsity of the review data if we
use a large number of features and evaluations, our model
tends to overﬁt the noise in the training data set. To al-
leviate this concern, we added the regularization constraint
8

We should clarify that ours is not a hedonic demand estimation
model. In hedonic demand estimations, the ﬁrst step involves comput-
ing individual equilibrium trait prices based on estimates of a hedonic
price function to ﬁnd the market price of a trait in the bundle. The
second step is to estimate an inverse demand or marginal bid function
using the trait prices as the dependent variable. Typically two-stage
least squares (2SLS) regressions are employed with the supplier traits
being appropriate instruments for the endogenous variables in the
marginal bid function. Our approach is nested in a framework that
is similar in notion to a hedonic demand model but very diﬀerent in
implementation.

(cid:10)(cid:2)

(cid:11) (cid:6)(cid:2)

(cid:7)

i

j

n

m

j=1 δ2

i=1 γ2

≤ λ, which transformed this linear
model to a “ridge regression” [14]. Note that due to negli-
gible correlation9 between the list and retail prices, multi-
collinearity is not a concern in our model. Our results are
also robust (and similar to the reported ones) if we were to
only use the retail price in Equation 6.

4.4 Experimental Results

Predicting Future Sales: After obtaining the review
matrix, we used 10-fold cross-validation to test the model’s
performance and obtain reliable coeﬃcient estimates. The
original sample was partitioned into 10 sub-samples of prod-
ucts.10 Of the 10 sub-samples, a single sub-sample was
retained as validation data for testing the model, and the
remaining 9 sub-samples were used as training data. The
cross-validation process was repeated 10 times and each of
the 10 sub-samples was used exactly once as validation data.
For our experiments, we run our regression on the train-
ing data and derived the coeﬃcients for each of the regres-
sors. After deriving the coeﬃcients from the training set,
we tested how well the derived regressions predicts the sales
rank for the products in the test set. We compared per-
formance for predicting sales rank, using the Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE)
metrics, averaged over all the observations in the test set.
We compared our model with the same model that has no
consumer review text available (but including all other vari-
ables). We observed a 5% improvement in RMSE and 3%
improvement in MAE. To test for statistical signiﬁcance we
used the Wilcoxon11 signed rank test (p < 0.001). We should
note that the 5% improvement is a signiﬁcant achievement,
given the high volatility of Amazon sales rank information,
the fact that the numeric rating information is already taken
into account (both models contained average rating of con-
sumer reviews as a variable) and the fact that we are mea-
suring errors in log-scale. This result indicates that the text
of the reviews contains information that inﬂuences the be-
havior of the consumers, and that the numeric ratings alone
cannot capture the information in the text.

Estimating Product Feature Weights and Evalua-
tion Scores: The other signiﬁcant contribution of our work
is the ability to identify the product feature weights and the
evaluation scores associated with the adjectives, within the
context of an electronic market.

Tables 2 and 3 present the average feature and evaluation
coeﬃcients that were obtained for the 49 digital cameras12
from the “Camera & Photo” category. The coeﬃcients were
averaged across cross-validation runs to produce reliable es-
timates and empirical standard error values. We should also
note that we excluded the rating variable from the regres-
sion, in order to obtain feature and evaluation coeﬃcients
that are not detrended with respect to numeric review rat-

9

This happens because in the two product categories that we analyze,
the retail price on Amazon is not a ﬁxed discount oﬀ the list price,
unlike in the case of other products such as books where publishers
typically give retailers a ﬁxed discount oﬀ the list price for a wide
variety of books.
10

We did not split observations for the same product due to time-series

We used a non-parametric test to avoid problems with non-normality

eﬀects within a product over time.
11

of the underlying distributions.
12

We separated the results for point-and-shoot from those for SLR
cameras and camcorders to avoid possible heterogeneity issues. Due
to space constraints we do not list the results for these products and
for the “Audio & Video” category. The results were qualitatively
similar.

Research Track Paper62Table 2: Feature weights for the Camera & Photo
category. Higher weight values signify higher im-
portance of each attribute. (The ∗ symbol indicates
statistical signiﬁcance at the 5% conﬁdence level.)

Feature Weight Std.Err.
camera∗
0.091
quality∗
0.106
battery∗
0.048
resolution∗
0.018
0.063
size
0.052
color
0.040
photos
lens
0.033
0.037
screen

0.810
0.484
0.192
0.129
0.096
0.086
0.074
0.046
0.037

Evaluation Score Std.Err.
great∗
0.353
good∗
0.211
best∗
0.154
excellent∗
0.180
perfect∗
0.146
0.051
nice
decent
0.056
0.050
fantastic
bad∗
0.038
amazing∗
0.094
ﬁne∗
0.101
poor∗
0.066

-2.460
-1.693
-0.914
-0.442
-0.433
-0.006
0.001
0.085
0.206
0.220
0.258
0.345

Table 3: Some evaluation scores for the Camera &
Photo category. Higher scores mean increase in sales
rank and are therefore negative. Lower values are
(The ∗ symbol indicates statistical signiﬁ-
better.
cance at the 5% conﬁdence level.)

ings. Note that higher values of evaluation coeﬃcients sig-
nify increase of the sales rank and, therefore, have negative
impact on product sales.

We should note that making conclusions based on the in-
dividual model coeﬃcients may be incorrect, due to model
complexity and interaction eﬀects between coeﬃcients. So,
in addition to the raw coeﬃcients, we also calculated the par-
tial eﬀects for frequent opinion phrases. The partial eﬀect of
a opinion phrase x = e⊗f is deﬁned as γT · ¯Wx
·δ−γT · ¯Wkt·δ
kt
where ¯Wkt is the “average review” obtained by averaging
all consumer reviews in this product category with proper
normalization and ¯Wx
kt is the “average review” where all
evaluations of the feature f were replaced by the evaluation
e. For example, to calculate a partial eﬀect of the “solid
lens” phrase (f = lens, e = solid ) we take the “average dig-
ital camera review” and replace all evaluations of the “lens”
feature to “solid”. This enables us to simply calculate the
diﬀerence between the modiﬁed review score and the average
review score. The calculated partial eﬀects for the “Camera
& Photo” product category are presented in Table 4. Re-
member, that a negative sign on an opinion phrase denotes
the fact that there is an increase in sales (since sales rank
on Amazon is inversely proportional to demand) when that
”opinion feature” is present in the content of the product
review.

We observed that seemingly positive evaluations like “de-
cent quality” or “nice/ﬁne camera” end up hurting sales.
Even though this may seem counterintuitive, it actually re-
ﬂects the nature of an online marketplace: most of the posi-
tive evaluations contain superlatives, and a mere “decent” or
“ﬁne” is actually interpreted by the buyers as a lukewarm,

Phrase
great camera
good camera
great quality
good quality
great battery
great size
great photos
great resolution
good battery
great lens
good size
great color
good photos
good resolution
good lens
great screen
good color
good screen
nice screen
excellent lens
excellent color
perfect size
nice lens
decent lens
fantastic lens
amazing lens
ﬁne lens

Eﬀect Phrase
-0.4235
-0.1128
-0.0931
-0.0385
-0.0138
-0.0060
-0.0060
-0.0052
-0.0051
-0.0037
-0.0027
-0.0023
-0.0022
-0.0017
-0.0016
-0.0012
-0.0004
-0.0004
0.0014
0.0020
0.0027
0.0027
0.0032
0.0032
0.0035
0.0038
0.0039

excellent photos
nice size
decent photos
fantastic photos
amazing resolution
amazing photos
ﬁne photos
excellent battery
decent battery
amazing battery
ﬁne battery
best quality
excellent quality
nice quality
decent quality
fantastic quality
amazing quality
poor quality
best camera
excellent camera
perfect camera
nice camera
decent camera
fantastic camera
bad camera
amazing camera
ﬁne camera

Eﬀect
0.0040
0.0045
0.0062
0.0066
0.0069
0.0073
0.0075
0.0089
0.0139
0.0164
0.0168
0.0170
0.0507
0.0817
0.0822
0.0882
0.0979
0.1067
0.2026
0.3936
0.3973
0.5703
0.5731
0.6071
0.6547
0.6619
0.6770

Table 4: Partial Eﬀects for the Camera & Photo
product category: A negative sign signiﬁes decrease
in sales rank and means higher sales.

slightly negative evaluation. Furthermore, we observed only
a small number of unambiguously negative evaluations, such
as “bad” and “horrible”: products that get bad reviews,
tend to disappear from the market quickly, and do not get
many further negative evaluations. In general, the reviews
that appear on Amazon are positive, especially for products
with large number of posted reviews. Finally, a strange ob-
servations is that the evaluations “best camera,” “excellent
camera,” “amazing camera,” “perfect camera,” and so on,
have a negative eﬀect on demand. This puzzling result may
be caused by the fact that most of the reviews praising the
camera in general do not usually have many details about
the product features of the camera. Customers discount such
reviews, and potentially treat them as bogus: a review that
simply says that a camera is the “best camera” in the mar-
ket, without going into other details does not provide useful
information to the customer and has negative eﬀect on sales.
Evaluation Conclusions: We have presented our exper-
imental evaluation of our technique by presenting results on
a real data set from Amazon.com. Our results show that we
can identify the features that are important to consumers
and that we can derive the implicit evaluation scores for
each adjective, in an objective and context-aware manner.
Deriving the polarity and strength of an evaluation was gen-
erally considered a hard problem, but by evaluating an opin-
ion within an economic framework, we showed that we can
solve the problem in a natural manner. Furthermore, our
technique takes into consideration the peculiarities of the
environment in which the opinion is evaluated. Weak posi-
tive opinions like nice and decent are actually evaluated in a
negative manner in electronic markets, since customers are
used to see only strong positive opinions, and a mere nice or
decent is a bad signal to the buyers.

Research Track Paper635. RELATED WORK

Our paper adds to a growing literature on sentiment analy-
sis. Similar to almost any other sentiment mining technique,
the ﬁrst step involves selecting the set of features to use (see
Section 2.2). Our approach to feature selection is very close
to the one presented by Hu and Liu [15]. Hu and Liu used
a POS-tagger and association miner to ﬁnd frequent item-
sets, which are then treated as candidate features. For each
instance of a candidate feature in a sentence, the nearby
adjective (if there is such) was treated as the eﬀective opin-
ion. Note that eﬀective opinions used by Hu and Liu are
direct counterparts of evaluation words in our study. A ma-
jor diﬀerence of our approach is that whereas Hu and Liu
were interested in the eﬀectiveness of feature extraction and
high recall values, we are concerned about gathering a small
set of major features and evaluation words. In order to en-
sure that gathered features reﬂect hedonic characteristics of
the products, we performed manual post-processing of fre-
quent itemsets. Contrary to Hu and Liu, who performed
additional research to identify infrequent features, we inten-
tionally discarded such features to obtain robust estimates
of model coeﬃcients. It should also be noted that while Hu
and Liu used WordNet to identify polarity of opinion words,
our model evaluates polarity and strength of each evaluation
directly from the regression on product demand.

Our research was inspired by previous studies about opin-
ion strength analysis. Popescu and Etzioni [23] presented
OPINE, an unsupervised information extraction system ca-
pable of identifying product features, identifying user opin-
ions regarding product features, determining polarity of the
opinions and ranking the opinions based on their strength.
Unfortunately, so far, no paper was published explaining
how OPINE solves the last task (opinion ranking). Eval-
uating strength of a sentiment quantitatively is even more
challenging task than simple ranking and there were just a
few papers on the topic published thus far. Wilson, Wiebe
and Hwa [30] presented a supervised learning approach able
to distinguish between weak, medium and strong subjectiv-
ity of the opinion. Unfortunately, this technique requires
a manually annotated corpus of opinions. Human annota-
tors might not able to distinguish strength of opinions on
a ﬁner-grained scale or estimate economic impact of each
particular opinion. In a close stream of research, Pang and
Lee [21] studied the rating-inference problem. They aug-
mented SVM classiﬁer with a metric labeling concept and
applied the altered classiﬁer to infer the author’s numerical
rating for Rotten Tomatoes movie reviews.

We also add to an emerging stream of literature that com-
bines economic methods with text mining [7, 10, 18]. For
example, Das and Chen [7] examined bulletin boards on Ya-
hoo! Finance to extract the sentiment of individual investors
about technology companies. They have shown that the ag-
gregate tech sector sentiment predicts well the stock index
movement, even though the sentiment cannot predict well
the individual stock movements. There has also been re-
lated work on studying connections between online content
such as blogs, bulletin boards and consumer reviews, and
consumer behavior, in particular purchase decisions. Gruhl
et al. [13] analyzed the correlation between online mentions
of a product and sales of that product. Using sales rank
information for more than 2,000 books from Amazon.com,
Gruhl et al. demonstrated that, even though sales rank mo-
tion might be diﬃcult to predict in general, online chatter
can be used to successfully predict spikes in the sales rank.

To the best of our knowledge, our study is the ﬁrst to
use econometric approaches for analyzing the strength and
polarity of consumer review opinions. Contrary to Gruhl et
al. who used blogs as the indicator of spikes in the sales
rank, our research is based on the premise that changes in
sales rank, can be partially explained by the impact of con-
sumer reviews. We draw on the results of Chevalier and
Mayzlin [6] who have shown that online book ratings aﬀect
product sales by examining the relationship between rela-
tive market shares (sales rank) and consumer reviews across
the two leading online booksellers, Amazon.com and Bar-
nesandNoble.com. Comparing the sales and reviews of a
given book across the two sites, allows to control for exter-
nal factors that can aﬀect the sales and word-of-mouth of
both retailers (for example, release of a new Harry Potter
movie may result in a temporary increase of the correspond-
ing book sales). While our research is similar to the study
by Chevalier and Mayzlin, it does diﬀer in several signiﬁ-
cant ways. While the model in [6] included only numerical
rating information (such as average star rating and fraction
of 1 star and 5 star reviews), our approach employs text
mining to extract consumer opinions about diﬀerent prod-
uct features. Contrary to the work in [6], we were not able to
use multiple retailers in our experimental study. In order to
alleviate possible concerns from the inﬂuence of external fac-
tors or measurement errors on our coeﬃcient estimates, we
used 10-fold cross validation of the model to precisely infer
product-speciﬁc characteristics. We found that our results
are robust across products.

6. CONCLUSIONS AND FUTURE WORK

We have presented a novel method for mining consumer
reviews that combines existing text mining approaches with
econometric techniques. The major novelty of our tech-
nique is that it allows an economic-aware analysis of the con-
sumer reviews, identifying the weight that customers place
on individual product features and the polarity and strength
of the underlying evaluations. By using product demand
as the objective function, we derive a context-aware inter-
pretation of opinions and we show how customers inter-
pret the posted comments and how they aﬀect their choices.
We have presented examples, where opinions that would
be interpreted as positive by existing opinion mining sys-
tems, are actually negative within the context of electronic
markets. The source code with our implementation, to-
gether with the data set used in this paper are available
from http://economining.stern.nyu.edu.

Using a unique data set from a leading online retailer,
Amazon, we have demonstrated the value of using economic
data and econometric modeling for a quantitative interpre-
tation of consumer reviews on the Internet. Our results can
be used by manufacturers to determine which features con-
tribute most to the demand for their product. Such informa-
tion can also help manufacturers facilitate changes in prod-
uct design over the course of a product’s life cycle as well
as help retailers decide on which features to promote and
highlight in advertisements and in-store displays.

We believe that there is rich potential for future research.
From the econometric point of view, future work can focus
on pure price-hedonic regressions that highlight which fea-
ture of the product, both implicit and explicit, constitutes
what proportion of the product price. Such an analysis can
enable consumers to ﬁgure out exactly how much they are
paying for each product attribute within a class of products.

Research Track Paper64It would also be interesting to examine how traditional he-
donic studies can be enhanced when they incorporate quali-
tative features, and not just directly measurable parameters.
From the text mining point of view, advances in algorithms
for product feature identiﬁcation, and for extraction of the
associated evaluation phrases, can deﬁnitely improve the re-
sults of our technique. We plan to examine the limits of
these improvements by analyzing manually product reviews
and extracting the features that are discussed together with
their evaluations. Another interesting direction that we plan
to explore is the results of our technique when using higher
rank approximations of the tensor space. Right now, our
rank-1 approximation allows a single score for each evalua-
tion and a single weight for a product feature. A natural
extension is to examine how many diﬀerent meanings we
can allow for each phrase, without running into overﬁtting
problems.

Overall, we believe that the interaction of economics re-
search with data mining research can beneﬁt tremendously
both ﬁelds. Economic approaches can oﬀer natural solutions
to problems that seemed too hard to solve in a vacuum (e.g.,
determining the strength of an opinion). Similarly, data min-
ing approaches can improve the current state of the art in
empirical economics, where the focus has traditionally been
on relatively smaller data sets.

Acknowledgments
We thank Rhong Zheng for assistance in data collection.
This work was partially supported by a Microsoft Live Labs
Search Award, a Microsoft Virtual Earth Award, and by
NSF grants IIS-0643847 and IIS-0643846. Any opinions,
ﬁndings, and conclusions expressed in this material are those
of the authors and do not necessarily reﬂect the views of the
Microsoft Corporation or of the National Science Founda-
tion.

References
[1] Berndt, E. R. The Practice of Econometrics: Classic and Con-

temporary. Addison-Wesley, 1996.

[2] Bickart, B., and Schindler, R. M. Internet forums as inﬂuential
sources of consumer information. Journal of Interactive Mar-
keting 15, 3 (2001), 31–40.

[3] Carenini, G., Ng, R. T., and Zwart, E. Extracting knowledge
from evaluative text. In K-CAP’05: Proceedings of the 3rd In-
ternational Conference on Knowledge Capture (2005), pp. 11–
18.

[4] Chen, Y., and Xie, J. Online consumer review: A strategic analy-
sis of an emerging type of word-of-mouth. University of Arizona,
Working Paper, 2004.

[5] Chevalier, J. A., and Goolsbee, A. Measuring prices and price
competition online: Amazon.com and BarnesandNoble.com.
Quantitative Marketing and Economics 1, 2 (2003), 203–222.

[6] Chevalier, J. A., and Mayzlin, D. The eﬀect of word of mouth
on sales: Online book reviews. Journal of Marketing Research
43, 3 (Aug. 2006), 345–354.

[7] Das, S. R., and Chen, M. Yahoo! for Amazon: Sentiment extrac-
tion from small talk on the web. Working Paper, Santa Clara
University. Available at http://scumis.scu.edu/~srdas/chat.pdf,
2006.

[8] Dave, K., Lawrence, S., and Pennock, D. M. Mining the peanut
gallery: Opinion extraction and semantic classiﬁcation of prod-
In Proceedings of the 12th International World
uct reviews.
Wide Web Conference (WWW12) (2003), pp. 519–528.

[9] Ghani, R., Probst, K., Liu, Y., Krema, M., and Fano, A. Text
mining for product attribute extraction. SIGKDD Explorations
1, 8 (June 2006), 41–48.

[10] Ghose, A., Ipeirotis, P. G., and Sundararajan, A. Opinion min-
ing using econometrics: A case study on reputation systems,. In

Proceedings of the 44th Annual Meeting of the Association for
Computational Linguistics (ACL 2007) (2007).

[11] Ghose, A., and Sundararajan, A. Evaluating pricing strategy
using ecommerce data: Evidence and estimation challenges. Sta-
tistical Science 21, 2 (2006), 131–142.

[12] Greene, W. H. Econometric Analysis, 5th ed. Prentice Hall,

2002.

[13] Gruhl, D., Guha, R., Kumar, R., Novak, J., and Tomkins, A.
In Proceedings of the
The predictive power of online chatter.
Eleventh ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining (KDD-2005) (2005), pp. 78–
87.

[14] Hastie, T., Tibshirani, R., and Friedman, J. H. The Elements

of Statistical Learning. Springer Verlag, Aug. 2001.

[15] Hu, M., and Liu, B. Mining and summarizing customer reviews.
In Proceedings of the Tenth ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining (KDD-2004)
(2004), pp. 168–177.

[16] Hu, M., and Liu, B. Mining opinion features in customer reviews.
In Proceeding of the 2004 AAAI Spring Symposium Series: Se-
mantic Web Services (2004), pp. 755–760.

[17] Lee, T. Use-centric mining of customer reviews. In Workshop

on Information Technology and Systems (2004).

[18] Lewitt, S., and Syverson, C. Market distortions when agents are
better informed: The value of information in real estate transac-
tions. Working Paper, University of Chicago, 2005.

[19] Liu, B., Hu, M., and Cheng, J. Opinion observer: Analyzing and
comparing opinions on the Web. In Proceedings of the 14th In-
ternational World Wide Web Conference (WWW 2005) (2005),
pp. 342–351.

[20] Nakagawa, H., and Mori, T. A simple but powerful automatic
term extraction method. In COMPUTERM 2002: Second In-
ternational Workshop on Computational Terminology (2002),
pp. 1–7.

[21] Pang, B., and Lee, L. Seeing stars: Exploiting class relationships
In
for sentiment categorization with respect to rating scales.
Proceedings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL 2005) (2005).

[22] Pang, B., Lee, L., and Vaithyanathan, S. Thumbs up? Sentiment
classiﬁcation using machine learning techniques. In Proceedings
of the Conference on Empirical Methods in Natural Language
Processing (EMNLP 2002) (2002).

[23] Popescu, A.-M., and Etzioni, O. Extracting product features
and opinions from reviews. In Proceedings of Human Language
Technology Conference and Conference on Empirical Methods
in Natural Language Processing (HLT/EMNLP 2005) (2005),
pp. 339–346.

[24] Rosen, S. Hedonic prices and implicit markets: Product diﬀeren-
tiation in pure competition. The Journal of Political Economy
82, 1 (Jan.-Feb. 1974), 34–55.

[25] Samuelson, P. A., and Nordhaus, W. D. Economics, 18th ed.

McGraw-Hill/Irwin, 2004.

[26] Scaffidi, C. Application of a probability-based algorithm to ex-
traction of product features from online reviews. Tech. Rep.
CMU-ISRI-06-111, Institute for Software Research, School of
Computer Science, Carnegie Mellon University, June 2006.

[27] Snyder, B., and Barzilay, R. Multiple aspect ranking using the
good grief algorithm. In Proceedings of the Human Language
Technology Conference of the North American Chapter of the
Association of Computational Linguistics (HLT-NAACL 2007)
(2007).

[28] Turney, P. D. Thumbs up or thumbs down? Semantic orienta-
tion applied to unsupervised classiﬁcation of reviews. In Proceed-
ings of the 40th Annual Meeting of the Association for Com-
putational Linguistics (ACL 2002) (2002), pp. 417–424.

[29] Turney, P. D., and Littman, M. L. Measuring praise and criti-
cism: Inference of semantic orientation from association. ACM
Transactions on Information Systems 21, 4 (Dec. 2003), 315–
346.

[30] Wilson, T., Wiebe, J., and Hwa, R. Recognizing strong and weak
opinion clauses. Computational Intelligence 22, 2 (May 2006),
73–99.

[31] Wooldridge, J. M. Econometric Analysis of Cross Section and

Panel Data. The MIT Press, 2001.

Research Track Paper65