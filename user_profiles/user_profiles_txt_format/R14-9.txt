Ranking by Dependence—A Fair Criteria

Harald Steck

Computer-Aided Diagnosis and Therapy

Siemens Medical Solutions, 51 Valley Stream Parkway E51

Malvern, PA 19355, USA
harald.steck@siemens.com

Abstract

Estimating the dependences between random
variables, and ranking them accordingly, is a
prevalent problem in machine learning. Pur-
suing frequentist and information-theoretic
approaches, we ﬁrst show that the p-value
and the mutual information can fail even in
simplistic situations. We then propose two
conditions for regularizing an estimator of de-
pendence, which leads to a simple yet eﬀec-
tive new measure. We discuss its advantages
and compare it to well-established model-
selection criteria. Apart from that, we derive
a simple constraint for regularizing parame-
ter estimates in a graphical model. This re-
sults in an analytical approximation for the
optimal value of the equivalent sample size,
which agrees very well with the more involved
Bayesian approach in our experiments.

1

Introduction

Quantifying the degree of dependence between two
random variables is pivotal to many machine-learning
approaches,
including discriminative and generative
learning. When given the empirical distribution as
implied by the given data, a properly regularized
dependence-measure is essential.
In the context of
model-selection, various scoring functions have proven
useful, including the p-value, Akaike Information Cri-
teria (AIC) [1], Bayesian Information Criteria (BIC)
[16], Minimum Description Length (MDL) [15] and
(Bayesian) posterior probability. Typically, the ob-
jective is to estimate the predictive accuracy of the
learned models. For instance, −AIC approximates the
test error Ep[− log ˆp] in a frequentist way,
i.e., the
model parameters are based on the empirical distri-
bution ˆp, while the expectation E is with respect to
the (unknown) true distribution p [1].

As to obtain a fair ranking according to the depen-
dences between pairs of random variables, our objec-
tive is to assess dependence with respect to the (un-
known) true distribution p, rather than using the em-
pirical probabilities as model parameters. Like most
of the model-selection criteria above, our approach is
also based on the log maximum likelihood. As our
objective is diﬀerent, however, we need a new kind of
regularization: the two limiting conditions are outlined
in Section 3. We present the resulting new measure,
which we call standardized information, in Section 4.
Section 5 discusses its interesting properties, includ-
ing its particularly simple form, and its relationship
to common model-selection criteria. Our experiments
in Section 7 show that commonly-used measures can
already fail in simplistic situations, while our new mea-
sure yields the expected results.

Apart from that, our frequentist approach also yields
the optimal regularization of the parameter estimates
of a graphical model: we derive an analytical approxi-
mation for the optimal value of the equivalent sample
size in Section 6. It agrees very well with the (involved)
Bayesian approach in our experiments (Section 7.2).

2 Notation

This section introduces relevant notation and reviews
bias-correction of mutual information. For simplicity
and without loss of generality, we focus on two random
variables following a multinomial distribution, say A
and B; for the generalization to many variables, see
Section 5.5; concerning continuous variables, and the
estimation of entropy thereof, paper [3] discusses the
relevant issues, which diﬀer from the objective of this
paper. Let a denote a state of A, and |A| its number of
states; p(A, B) is the true (yet unknown) distribution,
and ˆp(A, B) is the empirical one, as implied by data
D: ˆp(A = a, B = b) = Nab/N , where Nab serve as
suﬃcient statistics (frequencies of (A = a, B = b)),
and N is the sample size.

is

information I(A, B)

the information-
Mutual
theoretic measure of dependence (cf.
for an
overview).1 As the true distribution p(A, B) is typ-
ically not available in machine-learning applications,
the true I(A, B) unfortunately cannot be computed.
Instead, it has to be estimated from the empirical dis-
tribution ˆp. The frequentist plug-in estimator reads

[5]

ˆI(A, B) =

ˆp(a, b) log

X

a,b

ˆp(a, b)
ˆp(a)ˆp(b)

.

(1)

It is well known that this plug-in estimator is biased
(e.g., [11, 18, 12]). The bias-corrected estimator reads

ˆI BC(A, B) = ˆI(A, B) − dAB/(2N )

(2)

in leading order in N , where dAB are the degrees of
freedom;
if all joint conﬁgurations (A = a, B = b)
occur in data D, dAB = (|A|−1)(|B|−1). If some joint
conﬁgurations are missing in the (small) data set, the
eﬀective degrees of freedom are used instead, cf. [4].

3 Two Conditions for Regularization

In this section we propose two basic conditions that a
well-regularized—and thus fair—estimator of depen-
dence has to fulﬁll. These conditions apply to the ex-
treme cases of vanishing and maximum dependence.

3.1 First Limiting Condition

Before we present the ﬁrst condition, namely for the
case of a vanishing degree of dependence, let us ﬁrst
consider a simple example for illustration purposes.

Consider the task of ranking two pairs of variables,
(A, B) and (X, Y ), according to their degree of de-
pendence (cf. Figure 1). Assume that the given data
implies ˆI(A, B) < ˆI(X, Y ). This suggests from a naive
point of view that X and Y are more strongly depen-
dent than A and B.

As the various discrete variables may have diﬀerent
numbers of states, consider the case where dAB <
dXY . As implied by Fig. 1, assume the bias-corrected
estimator (cf. Eq. 2) yields ˆI BC(A, B) < ˆI BC(X, Y ),
which also suggests that the dependence between X
and Y is stronger than the one between A and B.

Adopting a frequentist point of view, the estimator
for mutual information follows a distribution. While
the bias-correction accounted for its mean, let us now
also account for its standard deviation: as implied by
Fig. 1, assume that ˆI BC(A, B) > std( ˆI(A, B)), while
ˆI BC(X, Y ) < std( ˆI(X, Y )). Obviously, when the de-
viation of ˆI from mean d/(2N ) is measured in terms

1As we focus on two variables, we use log (maximum)

likelihood ratio and mutual information interchangeably.

Figure 1: Example: expected distribution of the plug-
in estimator ˆI for variables (A, B) versus (X, Y ).

of the standard deviation, then ˆI(X, Y ) is closer to the
mean dXY /(2N ) than is ˆI(A, B) to dAB/(2N ). This
implies that (A, B) are more strongly dependent than
are (X, Y ), which is contrary to the previous results.

In summary, this example illustrates that a fair as-
sessment of dependence requires that the same scale
is used for both pairs (A, B) and (X, Y ). The stan-
dard deviation is such a natural length scale.

As to formalize this insight, let us focus on the limit-
ing case of a vanishing dependence in this section (cf.
next section for strong dependence): I → 0, i.e., the
variables are independent w.r.t. the (unknown) true
distribution p.
In this case, like in basic frequentist
independence testing, the standard deviation of the
estimator ˆI is given by
(cid:17)
(cid:16) ˆI(A, B)

+ O(

std

(3)

=

).

1

√
dAB√
2N

N 3/2

Note that we do not need to calculate the standard
deviation for the general case of possibly strong de-
pendence here (cf.
[12, 11] for elaborations on that),
rendering our approach much simpler and computa-
tionally much more eﬃcient. Now we can formulate
Condition 1:
In the limiting case of vanishing dependence, a well-
regularized estimator for dependence, ˆJ, has to fulﬁll

ˆJ(A, B) ≈ ˆR(A, B) ≡

ˆI(A, B) − dAB
2N
pdAB/2/N

(4)

when ˆI(A, B) ≈ dAB/(2N ); more formally ˆJ → ˆR
d ˆJ/d ˆI → d ˆR/d ˆI as ˆI(A, B) → dAB/(2N ) for
and
ﬁxed dAB > 0, ignoring higher order derivatives.

This condition can be interpreted in various ways:
ﬁrst, Eq. 4 mimics the behavior of the p-value, which
also accounts for the variance of the distribution under
the independence-assumption, cf. Section 5.3; second,
the ratio in Eq. 4 can be viewed as the one-dimensional
version of the well-known Mahalanobis distance, which
is typically used in the context of Gaussian distributed
variables; third, the ratio in Eq. 4 may be interpreted
as the well-known standardized score or z-score, which
is usually used to assess the deviation of individual
data points with respect to a given distribution.

dAB2N1I(A,B)I(X,Y)std(I(A,B))std(I(X,Y))Id2N1XY3.2 Second Limiting Condition

As to ensure consistency with information theory, we
also require Condition 2: If the random variables A
and B are dependent based on the (unknown) true dis-
tribution p (i.e., I(A, B) > 0), then a well-regularized
estimator for dependence, ˆJ, has to fulﬁll

ˆJ(A, B) → f ( ˆI(A, B)) as N → ∞,

(5)

where f is a strictly monotonically growing function
that is independent of dAB.

This condition essentially applies to the cases where
the estimated mutual information is large, i.e., where
ˆI(A, B) (cid:29) dAB/(2N ). Obviously, the ratio in Eq. 4
of condition 1 does not fulﬁll condition 2 due to dAB
in the denominator. Note that we require for f only
independence from dAB, but not from N .

√

√

irrelevant constant
N → ∞ and I(A, B) > 0, then cSI(A, B)/
q

2). Also Condition 2 holds: when
2N →
ˆI(A, B) → pI(A, B) > 0, which is strictly mono-
tonically growing in ˆI(A, B) and independent of dAB.
This proof also shows that the length-scale of the tran-
sition of cSI between conditions 1 and 2 is of the order
of the standard deviation, as desired. We call cSI the
standardized information, as it measures weak depen-
dences in (fractional) multiples of the standard devia-
tion, which accounts for its regularization.

5 Discussion of Estimator

This section discusses interesting properties of the pre-
sented standardized information (cf. Eq. 6), as well
as the diﬀerences to popular model-selection criteria.

4 New Regularized Estimator

5.1 Ranking by Dependence

This section outlines the estimators that comply with
the two conditions proposed above. While such an
estimator ˆJ can take a multitude of functional forms,
the most important distinction is as to how ’quickly’
they transition from following the behavior required
for small values ˆI (condition 1) to the behavior for
large values ˆI (condition 2). It is easy to construct a
family of functions where the rate of this transition is
controlled by a free parameter.

In the following we focus on this transition being of the
same order as the standard deviation of the distribu-
tion of ˆI under the independence-assumption, which is
a natural length-scale for the transition (cf. also Sec-
tion 5.4). The following estimator takes a particularly
elegant form:

cSI(A, B) =

q

2N ˆI(A, B) −

p

dAB,

(6)

as it diﬀers from the commonly-used bias-corrected
estimator for mutual information only in the square-
roots of each individual term. The proof that cSI in-
deed obeys both the conditions proposed in Section 3
is obvious: condition 1 holds because
ˆI(A, B) − dAB/(2N )

ˆR(A, B) =

=

(cid:26)q

2N ˆI(A, B) −

= cSI(A, B) ·

2 ·

1 +

2N ˆI(A, B) +

(cid:27)

√

dAB

pdAB/2/N
(cid:26)q

(cid:27)

p

dAB

(

√

√

2dAB
)

cSI(A, B)
dAB
2

√

shows that, as ˆI(A, B) → dAB/(2N ), ˆR(A, B) and
cSI(A, B) are identical up to linear order (ignoring the

The two conditions proposed in Section 3 ensure that
dependence is assessed on a scale that is invariant
under diﬀerent cardinalities of the variables involved.
This leads to a fair comparison—and thus ranking—
of variables with diﬀerent numbers of states. With-
out condition 1, weak dependences would be over-
estimated for variables with large cardinalities; with
condition 1 but without 2, strong dependences would
be overestimated for variables with small cardinalities.

This invariance of the scale is the main diﬀerence to
other popular model-selection criteria. For instance,
AIC, BIC or MDL contain only an additive correc-
tion (the penalty term for complexity) to the log like-
lihood ratio term. This has two consequences. First,
as their penalty terms are typically larger than the
bias-correction in Eq. 2, the zero-point of the result-
ing ’scale of dependence’ gets shifted by more, result-
ing in an increased penalty for variables with large
cardinalities compared to our measure. Second, these
scores lack a re-scaling factor that would render the
scale of dependence invariant under varying cardinal-
ities of the variables. Therefore, these scores are ap-
propriate for determining whether a dependence (or an
edge in a graphical model) is signiﬁcant/notable due
to thresholding (additive correction), but they do not
necessarily yield a fair quantitative ranking.

When the (unknown) true I is small, then cSI can
also be expected to take a small positive value (cf.
bias correction). Only if cSI > c for some thresh-
old value c > 0, then the dependence appears to
be notable/signiﬁcant. Using Fisher’s asymptotic re-
sult [7], c is related to the p-value α according to
Φ(
2c) ≈ 1 − α, where Φ is the cumulative function of
the standard normal distribution (cf. also Sect. 5.4).

√

5.2 Estimating the Conditional Entropy

In contrast to generative learning (of a joint distribu-
tion over variables), discriminative approaches often
aim to learn the optimal conditional probability dis-
tribution p(Y |X), where Y is the class variable and X
is a (vector of) input variables/features. While mini-
mizing the unknown true conditional entropy H(Y |X)
is a valid goal, the maximum likelihood (ML) estimate
of the conditional entropy ˆH(Y |X) is typically mini-
mized in practice. While this criteria seems diﬀerent
from maximizing the ML estimate of the mutual in-
formation ˆI(Y, X) at ﬁrst glance, both criteria are in
fact equivalent. This is obvious from the fact that

ˆI(Y, X) = ˆH(Y ) − ˆH(Y |X),

(7)

where ˆH(Y ) is a constant, as it is the entropy of the
class variable Y based on the empirical distribution
ˆp(Y ), which is solely determined by the given data,
and it is thus independent of the input variables X.

From a slightly diﬀerent view point, one can interpret
both ˆH(Y ) and ˆH(Y |X) to be estimated conditional
entropies, where Y and X are assumed independent in
the former case, while dependent in the latter. Hence,
the mutual information ˆI(Y, X) can be interpreted as
the diﬀerence in the discriminative scores (conditional
entropies) of the two models where Y and X are in-
dependent vs. dependent (cf.
[5] for other/standard
interpretations of I).

This is a particular example of the general concept
of absolute and relative scores: absolute scores (e.g.,
ˆH(Y |X) here) refer to values assigned to individual
models, while a relative score (e.g., ˆI(Y, X) here) is the
diﬀerence in the (absolute) scores between two models.
Even though it is irrelevant for the optimization task
whether the absolute or relative score is used, the esti-
mator of the relative score often has a major advantage
(at least in the frequentist approach): it can more eas-
ily be regularized because its distribution (e.g., mean
and variance, ignoring higher-order moments) can be
determined more easily. For this reason, we prefer to
use the well-regularized (relative) score cSI in Eq. 6
instead of the unregularized (absolute) score ˆH(Y |X).

5.3 Numerical Instability of P-Value

The p-value originates from frequentist hypothesis
testing. The p-value of ˆI(A, B) is the probability
p(K ≥ ˆI(A, B)), where the random variable K follows
the distribution of the mutual-information statistic un-
der the assumption that A and B are independent. It
is well-known that, in the asymptotic limit, 2N K fol-
lows a χ2-distribution with dAB degrees of freedom,
which has mean dAB and variance 2dAB, consistent
with the results above. Note that the p-value—as

it is based on a distribution—in particular accounts
for both the mean and the variance (not to mention
higher-order moments), like cSI. Despite this desirable
regularization-property of the p-value, the numerical
computation of the p-value often becomes instable.
The reason is that 2N ˆI takes values in the inﬁnite
range [0, ∞), which then gets mapped to the unit in-
large values of 2N ˆI map
terval [0,1] for the p-value:
to values close to 1 of the cumulative density function,
and thus suﬀer from rounding errors due to limited
numerical accuracy, which is also apparent in our ex-
periments in Section 7.

5.4 Gaussian Approximation

√

√

L −

As mentioned by Fisher [7], a random variable L ∼ χ2
d
following a χ2-distribution with d degrees of freedom
can be transformed into one following a normal distri-
bution approximately:
d ∼ N (0, 1/2) in the
limit d → ∞. Note that the approximately normal dis-
tribution of the transformed variable is independent of
the degrees of freedom d, thus providing a standard-
ized scale for assessing dependence. This shows that
Fisher’s transformation can be understood as a deriva-
tion alternative to ours in Section 4. Apart from that,
this agreement also conﬁrms that in our approach in
Section 4, the transition between the two proposed
conditions indeed takes place at the correct length-
scale. Moreover, Fisher noted that replacing
d by
pd − 1/2 yields an improved approximation accuracy
for ﬁnite values of d [7].

√

5.5 Generalization to Many Variables

While we have focused on the joint distribution of only
two variables so far, now we brieﬂy sketch the various
ways of generalizing our standardized information.

First, the standardized information cSI (Eq. 6) can be
easily generalized to a (conditional) distribution over
a vector of random variables: this generalization is
analogous to the one of the log likelihood ratio, or the
one of mutual/multi information, e.g., see [5, 4].

Second, when learning graphical models containing
many random variables/nodes (see e.g.
[6] for an
overview), many scoring functions comprise the log
maximum likelihood term and a penalty for model
complexity; they are optimized by means of a (heuris-
tic) search strategy. Given complete data, these scores
decompose into a sum of ’local’ scores pertaining to a
small number of variables only (according to the graph
structure). Each of these ’local’ scores reﬂects a con-
ditional (in-)dependence. Our results also carry over
to each of these local scores, and hence allow one to
rank the various (conditional) dependencies between
the diﬀerent variables in the graph in a fair way.

5.6 Normalized Mutual Information

In practical applications, like in medical image pro-
cessing or bioinformatics (e.g., [14, 21]), the normalized
mutual information is a widely used score, even though
it is theoretically not well understood. There are two
insights due to our approach, which help shed light
onto why the normalized mutual information works
ﬁne in some applications, while it fails in others.
It
takes values in [0, 1] and reads

cN I(A, B) =

ˆI(A, B)
(cid:17)
(cid:16) ˆH(A) + ˆH(B)

.

/2

(8)

Similar to condition 1 in our approach, cN I in the de-
nominator of Eq. 8 uses the ’width’ of the distribu-
tion under the independence-assumption, under which
the joint entropy decomposes like ˆH(A, B) = ˆH(A) +
ˆH(B). Thus, cN I(A, B) obviously measures ˆI(A, B)
in (fractional) multiples of the empirical marginal en-
tropies ˆH; ˆH may be viewed as the information-
theoretic measure for the ’width’ of a distribution, in
place of standard deviation in frequentist statistics.

√

Besides these analogies, there are also three major dif-
ference to our approach. First, ˆH(A) + ˆH(B) yields
the widths of the marginal distributions of A and B
instead of the distribution of the mutual-information
statistic itself. Note, however, that ˆH typically also
increases with the number of states of A and B, al-
though at a diﬀerent rate than
dAB in the denom-
inator in Eq. 4. Second, unlike in Eq. 4, there is
no bias-correction term in cN I. Compared to the (un-
regularized) plug-in estimator for mutual information,
however, the partial regularization of cN I due to the
denominator may yield more robust results for small
data sets than the plug-in estimator ˆI. This is in-
deed observed in practical applications (e.g., [14, 21]),
which may explain its popularity among practitioners.
Third, in cN I the regularization does not decrease as
the sample size increases, i.e., it does not obey the sec-
ond condition given in Section 3.2. As a consequence,
the dependence between variables with a large num-
ber of states tends to be underestimated when given
large data sets, and cN I is not a suitable measure of
dependence in this regime.

6 Regularization of Parameters

In the context of (graphical) model selection, the
Bayesian approach allows one to regularize the model
structure (sparseness of the graph) as well as the model
parameters (smoothing of the probabilities), based on
the researcher’s choice of the prior distribution.
In
contrast, frequentist approaches typically focus on re-

stricting model complexity while using the (unregular-
ized) ML estimates of the parameters. In the following,
we outline a simple frequentist approach for determin-
ing the optimal regularization of parameter estimates.

First, we have to assume a reasonable functional form
of the regularized parameter estimates, say ˜p. A com-
mon choice is2

˜pab =

Nab + N 0 · qab

,

N + N 0

where N 0 · qab represents additional virtual counts in
the various joint states: N 0 is the overall number and
qab denotes a probability distribution; in the absence
of background knowledge, the (prior) distribution q is
typically chosen to be uniform. While this is a plau-
sible assumption from a frequentist perspective, it is
also obtained in the Bayesian approach when assum-
ing a Dirichlet prior over the model parameters and
averaging them out [10].
In the Bayesian approach,
N 0 is the scale parameter of the Dirichlet prior, and
is also called the equivalent sample size. As it has
more or less counter-intuitive eﬀects on the structure-
learning results [19], choosing a ’good’ value for N 0
is crucial. Cross-validation or maximized (Bayesian)
marginal likelihood are two standard ways for deter-
mining the value of N 0, e.g., [19].

In the following, we propose an alternative ap-
proach, namely a simple frequentist constraint de-
termining the value of N 0. As to simplify subse-
quent calculations, we consider a quantity that is
linear in the (unknown) true distribution p, namely
P
a,b p(a, b) log[ˆp(a, b)/(ˆp(a)ˆp(b))].3 We estimate its
value by using the empirical mutual information ˆI. As
before, one can easily obtain the approximate leading-
order bias-correction [1], and obtain the constraint

˜pab log

ˆp(a, b)
ˆp(a)ˆp(b)

X

a,b

= ˆI(A, B) −

dAB
N

+ O(

1
N 2 ), (9)

where we have plugged in the regularized parameter
estimates ˜pab in place of the (unknown) true probabil-
ities p(a, b). As the terms on the right hand side are
determined by the given data, obviously the regular-
ized estimates ˜pab—and thus N 0—are determined by
this equality-constraint. Note that the left hand side
in Eq. 9 is monotonically decreasing with growing N 0
if the distribution q is uniform.

Moreover, as Eq. 9 is linear in the regularized prob-
abilities ˜pab, this immediately yields an approximate

2As before, we consider only a pair of variables here for

simplicity but without loss of generality.

3We assume ˆp(a, b) > 0 for all a, b; otherwise we replace
ˆp(a, b) by ˆp+(a, b) ≡ max{Nab, 1}/N , as to avoid numerical
instabilities.

7 Experiments

The ﬁrst section illustrates the advantages of our new
standardized-information cSI in two application areas:
discretization and feature selection. The second sec-
tion illustrates regularization of parameter-estimates.

7.1 Standardized Information Measure

In this section, we show that established measures, like
the bias-corrected mutual information ˆI BC, the p-value
(based on the χ2-distribution) and the normalized mu-
tual information cN I, fail already in simplistic exper-
iments, whereas our measure cSI (cf. Eq. 6) proves
robust. We use data sampled from a known distribu-
tion so that the ground-truth is available for evaluation
of the various dependence-measures.

In our ﬁrst experiment, we consider two discrete ran-
dom variables with four states each, following the dis-
tribution shown in the table in Fig. 2. The free param-
eter z ∈ [0, .1] can be varied as to change the degree of
dependence between the two variables A and B. The
objective is to ’discretize’ the variables A and B, i.e.,
to determine whether the eﬀective number of states is
2 or 4.4 The desired behavior obviously is a follows:
when z = 0, then the (true) I(A, B) = 0, and hence
the estimation from ﬁnite data should favour 2 states,
cf. also Occam’s razor. However, when z = .1, then
4 states should be preferred. The transition between
these two extremes should take place at smaller values
z as the sample size N increases, cf. again Occam’s
razor. Figure 2 summarizes our results: the p-value
as well as our new standardized information cSI show
exactly the desired behavior. The only diﬀerence is
that the transition tends to occur at slightly higher
z−values for cSI than for the p-value. At sample sizes
N ≥ 200, the p-value approaches zero and fails due
to the limited numerical accuracy available (in MAT-
LAB); no results concerning the p-value were thus ob-
tained for N = 500 in Figure 2.

Figure 2 also shows that the bias-corrected mutual-
information does not provide suﬃcient regularization:
when z = 0, ˆI BC is essentially undecided between the
two hypotheses (2 states vs. 4 states), although the
simpler hypothesis should be favoured in this case (cf.
Occam’s razor). ˆI BC hence tends to favour too large
a number of states.
The results regarding cN I lie between the ones for ˆI BC
and the p-value given a small sample size N = 25. This
suggests that regularization by means of the standard
deviation may be more eﬀective than the one relying
on the bias in this regime. As the sample size N in-

4(A, B) are chosen to be already discrete for clarity here;

see [20] for discretization of continuous variables.

Figure 2: Discretization:
from the true distribution
(cf. table), samples of sizes N = 25, 100 and 500 are
sampled. Based on 100 re-samples for each N , the frac-
tion where the dependence-measure favours 2 states
over 4 states is shown along the y-axis of the graphs;
the dependence between A and B increases along the
x-axis, parameterized by z ∈ [0, .1]. The four mea-
sures are ˆI BC (dashed line), cSI (solid), cN I (dotted)
and p-value (dash-dotted).

solution for N 0: assuming that N 02 (cid:28) N , which is typ-
ically the case in real-world applications, we take the
ﬁrst-order Taylor expansion of ˜pab with respect to N 0
at N 0 = 0, namely ˜pab = ˆp(a, b)+N 0(qab−Nab/N )/N +
O(N 02/N 2), and insert it into Eq. 9, which can then
easily be solved for N 0:

N 0 =

dAB

ˆI(A, B) − hlog ˆp(a,b)

ˆp(a) ˆp(b) iq

+ O(

N 02
N

)

(10)

where h·iq denotes the expectation with respect to the
(prior) distribution q; it yields a non-positive number
if the (prior) distribution q is chosen to be uniform (a
direct consequence of the ML principle); hence, N 0 is
indeed a positive number, as expected.

A few comments on Eq. 10 are in order. The ﬁrst
interesting insight is that N 0
is independent of the
i.e., once N 0 has been determined
sample size N ,
for a given data set, it does not need to be adapted
when additional data (from the same distribution) be-
comes available. This also suggests that our assump-
tion N 02 (cid:28) N can indeed be expected to hold for a
suﬃciently large sample size N . Second, the gener-
alization to more than two variables is analogous to
Section 5.5. Third, in our experiments the results of
this simple constraint are consistent with the ones ob-
tained using the two established, but computationally
more expensive methods (Section 7.2).

.025.025412A34.1+z.1−z.1+z.1−z.1+z.1+z.1−z.1−z123B.025.025.025.025.025.02500.010.020.030.040.050.060.070.080.090.100.10.20.30.40.50.60.70.80.91percentage where Score(2 states)>Score(4 states)z010.50S(2 states)>S(4 States)0.050.1zN=2500.010.020.030.040.050.060.070.080.090.100.10.20.30.40.50.60.70.80.91percentage where Score(2 states)>Score(4 states)z0.5S(2 states)>S(4 States)z1000.050.1N=10000.010.020.030.040.050.060.070.080.090.100.10.20.30.40.50.60.70.80.91zpercentage where Score(2 states)>Score(4 states)0.5S(2 states)>S(4 States)1N=500000.10.05zFrom this model, we sampled data sets of various sizes
and for diﬀerent values of z. When z ≈ .0882, we have
for the true mutual information: I(Y, Xi) = I(Y, Xj)
for all i, j = 1, ..., 20. Fig. 3a depicts the case where
z = .10 > .0882, i.e., the variables with four states
provide more true mutual information about Y than
the binary ones do. Fig. 3b shows the results for the
opposite case, where z = .08 < .0882.

In Figure 3a, our new measure cSI and the bias-
corrected mutual information clearly favour a variable
with four states when N is large, as expected. The
bias-corrected information does so even for small sam-
ple sizes (erroneously). In contrast, our standardized
information cSI as well as the p-value favour the sim-
pler hypothesis, namely 2 states, at small sample sizes,
as desirable (e.g., Occam’s razor). Note that the com-
putation of the p-value again suﬀered from limited nu-
merical accuracy at large N , as before.6

At small sample sizes N , the normalized mutual infor-
mation cN I gives reasonable results again, as its values
are between the ones of the p-value and ˆI BC (in Fig-
ures 3a and b). The fact that the regularization of
cN I does not decrease with growing N (cf. Section 5)
favours the variables with 2 states over the ones with
four states at large N . This explains the (erroneous)
increase of the curve pertaining to cN I in Fig. 3a, as
well as the steep increase in Fig. 3b.

In Fig. 3b, all the measures (except for the numerically
instable p-value) agree on a variable with 2 states for
large N , as expected. Even though the sampling noise
at small N can induce a higher score for a variable with
4 states by chance, our new standardized information
cN I as well as the p-value appear quite robust.
In
contrast, the bias-corrected information seems to be
quite sensitive to this noise, favouring variables with a
larger number of states at small N , which contradicts
the idea of regularization (e.g., Occam’s razor).

7.2 Equivalent Sample Size

We determined the optimal value of the equivalent
sample size N 0 based on our Eqs. 9 and 10 for the
data by Sewell and Sha [17] and the alarm-network
data [2]. Figure 4 shows that our linear approxima-
tion of Eq. 9 indeed is valid for the data by Sewell et
[17]. It also yields that N 0 ≈ 67. This is close to
al.
N 0 ≈ 66.1 obtained from our analytical approximation
(Eq. 10). These results agree with the more involved
alternatives: empirical Bayes results in N 0 ≈ 69, and
cross validation yields N 0 ≈ 100, ..., 300 [19].

Figure 3: Variable selection: the y-axis shows the frac-
tion where the dependence-measure favours a variable
with 2 states over one with 4 states, based on 100 re-
samples for each N ; N = 32, ..., 16384 along the x-axis.
The four measures are ˆI BC (dashed line), cSI (solid),
cN I (dotted) and p-value (dash-dotted).

creases (cf. N = 100, 500 in Figure 2), however, the
degree of regularization does not diminish in cN I, as
discussed in Section 5. This explains why the transi-
tion from favouring 2 states over 4 states stays put at
rather large z-values when the sample size increases
(cf. N = 500 in Fig. 2), which is not desirable.

Concerning variable/feature selection (cf.
[8, 13] for
an overview), our second experiment illustrates the
beneﬁts of cSI. Our simplistic aim is to ﬁnd a sin-
gle variable that predicts the class label best, rather
than determining the optimal set of variables.

We chose a simple gold-standard model: the class vari-
able Y is the root of a naive Bayes net with 20 leaf
nodes X1, ..., X20. Y takes each of its four states with
equal probability. The ten variables X1, ..., X10 are
binary, each of which being in state 1 with probabili-
ties .6, .8, .3 and .1 conditioned on Y being in states
1, 2, 3 and 4, respectively.5 The other ten variables
X11, ..., X20 have four states; each of these variables is
in the same state as Y with probability (1/4 + 3z)/4
and in any other state with probability (1/4 − z)/4;
parameter z ∈ [0, 1/4] determines the degree of depen-
dence between Y and the variables with four states.

5We found that the qualitative behavior of our results
does not depend on the particular choice of these proba-
bilities, as expected.

6When it happens, we on purpose choose the ’wrong’
result as to display clearly the ample size N at which the
numerical instability of the p-value occurs in the ﬁgure.

10100100010000−0.100.10.20.30.40.50.60.70.80.911.110,00010100N10000.5S(2 states)>S(4 states)10z=.10(a)10100100010000−0.100.10.20.30.40.50.60.70.80.911.1z=.0810,00010100N10000.5(b)S(2 states)>S(4 states)10[2] Beinlich et al. The alarm monitoring system. 2nd

Europ. Conf. on AI in Med., pp. 247–56. 1989.

[3] Beirlant et al. Nonparametric entropy estimation:
overview. Int. J. Math. Stat. Sci., 6:17–39, 1997.

[4] Y. Bishop, S. Fienberg, and P. Holland. Discrete

Multivariate Analysis. MIT Press, 1975.

[5] T. Cover and J. Thomas. Elements of Information

Theory. Wiley, 1991.

[6] Cowell, Dawid, Lauritzen, and Spiegelhalter.
Probabilistic Networks and Expert Systems. 1999.

[7] R. A. Fisher. Statistical Methods for Research

Workers. Wiley, 1970.

[8] Guyon and Elisseeﬀ. An introduction to variable

and feature selection. JMLR, 3:1157–82, 2003.

[9] Heckerman et al. Learning Bayesian networks:
The combination of knowledge and statistical
data. Machine Learning, 20:197–243, 1995.

[10] Heckerman et al. A Bayesian approach to causal

discovery. MSR-TR-97-05, Microsoft, 1997.

[11] M. Hutter. Distribution of mutual information.

In NIPS, 2001.

[12] L. Paninski. Estimation of entropy and mutual

information. Neural Comp., 15:1191–253, 2003.

[13] H. Peng et al. Feature selection based on mutual

information. PAMI, 27:1226–38, 2005.

[14] Pluim, Maintz, Viergever. Mutual-information-
based registration of medical images: a survey.
IEEE Trans. Med. Imaging, 22:986–1004, 2003.

[15] J. Rissanen. Modeling by shortest data descrip-

tion. Automatica, 14:465–71, 1978.

[16] G. Schwarz. Estimating the dimension of a model.

The Annals of Statistics, 6(2):461–64, 1978.

[17] W. Sewell and V. Shah. Social class, parental en-
couragement, and educational aspirations. Amer-
ican Journal of Sociology, 73:559–572, 1968.

[18] H. Steck and T. S. Jaakkola. Bias-corrected boot-

strap and model uncertainty. NIPS, 2003.

[19] H. Steck and T. S. Jaakkola. On the Dirichlet

prior and Bayesian regularization. NIPS, 2002.

[20] H. Steck and T. S. Jaakkola. Predictive discretiza-
tion during model selection. In Pattern Recogni-
tion, Springer LNCS 3175, pp. 1–8, 2004.

[21] X. Zhou et al. Gene clustering based on cluster-
wide mutual information. Journal of Computa-
tional Biology, 11:147–61, 2004.

Figure 4: The value of the right (dotted line) and left
(solid) hand side of Eq. 9 for various values of N 0;
data by Sewell et al. [17], N = 10318.

Given data of size N = 10000 sampled from the alarm
network [2], our constraint in Eq. 9 yields N 0 ≈ 12,
while our analytical approximation in Eq. 10 results in
N 0 ≈ 14.7. The increased value of our approximation
is due to zero cell counts in the data. These results
agree with N 0 ≈ 16 found in [9] using cross-validation
and structural diﬀerence.

[17], N 0 is
Compared to the data by Sewell et al.
smaller for the alarm network, as expected: the pa-
rameters in the alarm-network take quite extreme val-
ues, resulting in a large value of ˆI (strong dependence),
which appears in the denominator of Eq. 10.

8 Conclusions

We have proposed two conditions for regularization
of dependence-measures, which apply to the extreme
cases of vanishing and strong dependence. This led
us to a simple yet eﬀective new estimator with inter-
esting properties. While established measures failed
already in simplistic experiments, our measure ap-
peared quite robust. Moreover, our approach also shed
light on the applicability of the normalized mutual-
information, which is commonly used in applications
but theoretically not well understood. Along these
lines, we also obtained a simple constraint for regu-
larizing parameter estimates in graphical models. We
showed that, for the equivalent sample size, our linear
approximation is valid and computationally eﬃcient.

Acknowledgements

I am grateful to R. Bharat Rao for encouragement and
support of this work, and to the anonymous reviewers
for useful comments.

References

[1] H. Akaike. Information theory and an extension of
the maximum likelihood principle. 2nd Int. Symp.
on Information Theory, pp. 267–81, 1973.

0100200300N’0.3650.370.3750.380.3850.390.395regularized score