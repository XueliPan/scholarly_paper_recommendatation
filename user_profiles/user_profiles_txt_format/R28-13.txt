Discovering a Term Taxonomy

from Term Similarities

Using Principal Component Analysis

Holger Bast1, Georges Dupret2, Debapriyo Majumdar1,

and Benjamin Piwowarski2

1 Max-Planck-Institut f¨ur Informatik, Saarbr¨ucken

{bast, deb}@mpi-inf.mpg.de

2 Yahoo! Research Latin America

{gdupret, bpiwowar}@yahoo-inc.com

Abstract. We show that eigenvector decomposition can be used to ex-
tract a term taxonomy from a given collection of text documents. So far,
methods based on eigenvector decomposition, such as latent semantic in-
dexing (LSI) or principal component analysis (PCA), were only known
to be useful for extracting symmetric relations between terms. We give
a precise mathematical criterion for distinguishing between four kinds of
relations of a given pair of terms of a given collection: unrelated (car -
fruit), symmetrically related (car - automobile), asymmetrically related
with the ﬁrst term being more speciﬁc than the second (banana - fruit),
and asymmetrically related in the other direction (fruit - banana). We give
theoretical evidence for the soundness of our criterion, by showing that in
a simpliﬁed mathematical model the criterion does the apparently right
thing. We applied our scheme to the reconstruction of a selected part of
the open directory project (ODP) hierarchy, with promising results.

Keywords: Taxonomy Extraction, Ontology Extraction, Semantic Tag-
ging, Latent Semantic Indexing, Principal Component Analysis, Eigen-
vector Decomposition.

1 Introduction

Eigenvector decomposition has proven to be a powerful tool for a variety of
machine learning and information retrieval tasks. Its use comes under a variety
of names: principal component analysis (PCA), latent semantic indexing (LSI)
or latent semantic analysis (LSA), multidimensional scaling, spectral analysis
or spectral learning, and many more. In this introduction, we ﬁrst explain the
common principle behind all these names. We then show how we make novel
use of this principle to derive a term taxonomy, given only a collection of text
documents with no external knowledge base whatsoever.

For eigenvector decomposition to be applicable, the data must be suitably
cast into matrix form. For collections of text documents, the following document-
term matrix representation is standard. Each row corresponds to a document,
and each column corresponds to one of the words occurring in the collection (the

M. Ackermann et al. (Eds.): EWMF/KDO 2005, LNAI 4289, pp. 103–120, 2006.
c(cid:2) Springer-Verlag Berlin Heidelberg 2006

104

H. Bast et al.

so-called vocabulary). An entry in the matrix is, in the simplest case, a count
of how often the respective word occurs in the respective document. This can
be normalized in a number of ways, for example, by having diﬀerent weights for
diﬀerent terms, or by normalizing the norm of each column of the matrix to be
1. In any case, for each document only a small fraction of the words will have a
non-zero entry, so that the matrix is very sparse. This has practical importance
because sparse matrices can be decomposed much more eﬃciently than dense
ones: the computational complexity is essentially proportional to the number of
non-zero entries. A keyword query can be represented just like a document, with
a non-zero entry for each query word.

Given the matrix representation, the similarity between two documents, or
between a document and a query, can be measured by the similarity between
the corresponding (high-dimensional, yet sparse) row vectors. A typical measure
of similarity between two such vectors is the so-called cosine similarity, which
is just the dot-product between the two vectors, divided by the product of their
Euclidean lengths.

With an appropriately normalized document-term matrix, this vector similar-
ity approximates the true similarity of the documents (as perceived by a human
with regard to their contents) surprisingly well, except for one principal draw-
back. If two documents, or a document and a query, have no words in common,
their similarity is zero, even if they are about the same topic but just happen
to use diﬀerent words to describe it. For example, there might be two texts on
automatic taxonomy extraction, one of them indeed using the word taxonomy,
but the other consistently using the word hierarchy. The similarity of the two
vectors will then be relatively low, thus not accurately reﬂecting the strong sim-
ilarity in topic.

Eigenvector decomposition of the document-term matrix is a way to overcome
this problem. The basic idea is to project the documents as well as the query
from their high-dimensional space to a space of a given much lower dimension
k. This space is spanned by a set of eigenvectors derived from the document-
term matrix. In the simplest case, these are just the eigenvectors pertaining to
the k largest eigenvalues of the product of the document-term matrix with its
transpose (the so-called term-term correlation matrix). The idea is that while
the dimensions in the original space correspond to words — which are diﬀerent
even if they mean similar things — the dimensions in the lower-dimensional
space correspond to a set of semantic concepts underlying the collection.

Many variants of this approach have been proposed and shown useful for a
wide variety of machine learning and information retrieval tasks. In [8] and [3] it
has been shown that for collections of text documents, eigenvector decomposition
methods essentially work by identifying pairs of related terms.

1.1 Our Contribution

All previous applications of eigenvector decomposition in information retrieval
tasks were symmetric in the sense that the implicitly identiﬁed term relations,
in the sense of [3], were symmetric.

Discovering a Term Taxonomy from Term Similarities Using PCA

105

In this paper we extend the results of [10, 11] which showed that eigenvector
techniques indeed have the power to discover asymmetric relationships between
terms, in particular hyponym/hypernym relationships as in banana - fruit,
which together form a taxonomy of terms. This is the ﬁrst time eigenvector
techniques have been used — and shown to be useful — for such a purpose. In
particular, we give a mathematical criterion for determining the relationship of
a given word pair: unrelated, symmetrically related, or asymmetrically related.
In the case of an asymmetric relation, the criterion identiﬁes a direction, for
example, it ﬁnds that banana is more speciﬁc than fruit and not vice versa.
We show that in a simpliﬁed mathematical model our criterion classiﬁes all term
pairs correctly.

The criterion does not (and cannot possibly) distinguish between whether the
more speciﬁc term is a kind of the more general term like in banana - fruit
(hyponym/hypernym relation), or a part of it like in ﬁnger - hand (meronym/
holonym relation), or just some unspeciﬁc aspect of it like in disease - outbreak.
This restriction holds for all automatic taxonomy extraction schemes that do
away completely with an external knowledge base; see the discussion of related
work in the following section.

We tested our schemes on two hierarchies derived from the open directory
project (ODP) and manually checked the quality of the relations that were found.
The results are promising. There is no standardized benchmark for assessing a
given taxonomy with respect to a given corpus. In previous works, two sources of
quality assessment were provided. The ﬁrst were extensive examples. The second
where small user studies, asking users to assess whether a set of given relations
makes sense. The examples were usually more expressive in terms of how the
method works than the user studies. In this paper, we give only examples.

1.2 Related Work

The work closest in spirit to ours is by Sanderson and Croft [25]. They say that
term A subsumes term B if and only if the set of documents containing term A
is (approximately) a superset of the set of documents containing term B. This
condition is checked for each pair of terms from a pre-selected set. Like in our
approach, no knowledge whatsoever on what the terms mean is used, that is,
each term could be replaced by a unique number, with no change in result. As
is common in vector-space based approaches, even the positions of the terms
in the text are ignored, that is, if each document were sorted alphabetically
(which would eﬀectively make it unreadable for a human) exactly the same term
taxonomy would be extracted.

According to [3], our eigenvector decomposition approach in this paper can
be seen as way to assess the relations of all term pairs without the need for
actually looking at each term pair explicitly. In particular, we have no need for
an explicit pre-selection of terms as in [25].

The work by Sanderson and Croft has been extended in a number of ways.
For example, Nanas et al [22] ﬁrst identiﬁed symmetric relations between term
pairs (via occurrence counts in a ﬁxed-size sliding window) and then made those

106

H. Bast et al.

relations with a large diﬀerence in (a sort of) document frequency between the
two terms asymmetric. Glover et al [14] have explored the use of anchor texts
in a hyperlinked environment to determine the level of hierarchy of a term; they
do not explicitly compute individual relations though. Joho et al [17] showed
the usefulness of the subsumption hierarchies from [25] for interactive query
expansion.

Much work in information retrieval is concerned with building so-called topic
hierarchies, that is, ﬁnding a hierarchy of (relatively few) topics that describe
the collection well, and for each topic providing a succinct summary. The ﬁrst
task is usually achieved by some form of hierarchical clustering. Summaries are
provided by giving few descriptive terms. Lawrie and Croft have shown good
results with this approach using language modelling techniques, for the topic
generation as well as for the summarization [20] [19] [18]. Chuang and Chien
have shown web search snippets to be useful [4]. A survey of the large body of
work along these lines is beyond the scope of this paper. Note that eigenvector
decomposition methods perform a kind of soft clustering on the collection, in
the sense that each document is assigned not to one but to a number of topics
(implied by the few selected eigenvectors).

It is surprising and interesting that fully automatic methods, oblivious of
any meaning of the words and sometimes, like ours, even of their position in
the text, can contribute anything at all to taxonomy extraction. The price to
pay is that for all these methods, including ours, the extracted relations are of
somewhat mixed quality. While a signiﬁcant fraction of the extracted relations
are of the kind hyponym/hypernym (banana - fruit), many relations reﬂect that
one term is somehow an aspect of the other term, e.g., disease - outbreak. In
many applications these latter relations are of limited use.

The bulk of the existing very large body of work on taxonomy extraction
therefore makes use of some external knowledge base or the other. Given the
abundance of material, and the scope of this paper, we give only a brief overview
here. For a more comprehensive treatment, see the recent survey by Uren et al
[27] or the recent book by Buitelaar et al [6].

One of the simplest approaches, yet a very eﬀective one, is the use of so-
called Hearst-patterns, that is, patterns in the text that are likely to point to a
hyponym/hypernym relationship [15] [16]. Examples are “such as”, as in “fruits
such as banana”, or “and other”, as in “banana and other fruits”. Following this
idea, numerous schemes with a more sophisticated linguistic parsing have been
presented. For example, Woods [29] used a large morphological knowledge base
to extract asymmetric term relations from compound phrases, such as “oak tree”
or “tree root”. In a similar vein, Anick and Tipirneni [2] measured the dispersion
of terms, that is, the number of compound phrases a particular term appears
in; terms with a large dispersion would be in the upper layer of their two-level
hierarchy. Maedche and Staab [21] combine established tools for shallow text
processing and association rule mining.

A simple and elegant way to boost approaches based on linguistic patterns
is to search for the patterns not on the collection, for which a taxonomy is

Discovering a Term Taxonomy from Term Similarities Using PCA

107

to be constructed, but on the Web (or a similarly large and diverse external
collection). The basic idea is then to formulate a number of hypothetical relations
as keyword (phrase) queries, for example, "banana is a fruit" or "banana is
an animal", and then assess their validity by the number of hits obtained. Two
recent systems built on this idea are Pankow [5] and KnowItAll [13].

More sophisticated systems enhance the set of relations obtained by one or
more of these techniques, and/or relations input by a human, by various kinds
of bootstrapping techniques. The Snowball system, for example, tries to learn
new extraction patterns from the relations it already knows, then applies these
patterns to obtain new relations, from these tries to learn more patterns, and so
on [1].

Finally, there are many systems whose primary goal is not the extraction of
a term taxonomy but to assist the user in identifying meaningful relations by
oﬀering few promising options. Examples are OntoMat [28] and SemTag [7].

2 Our Algorithm for Computing a Term Taxonomy

In this section, we give a mathematical criterion for determining the relation of
each term pair. The criterion is based on a sequence of low-rank approximations
of the term-term similarity matrix.

2.1 The Term-Term Similarity Matrix

Our approach requires a matrix that speciﬁes for each term pair a similarity.
A simple way to obtain similarities between each pair of terms is to multiply
the document-term matrix A by its transpose, that is, compute S = AT A, and
take the entry Sij as a measure for the similarity between term i and term j. If
we normalize the columns (terms) of A prior to computing S, then all diagonal
entries (standing for the similarities of terms with themselves) will be exactly 1.
Two terms which never co-occur in any document, have a similarity of zero.

Other common measures for term-term similarity are as follows. For the so-
called Pearson correlation, the mean row (document) is subtracted from every
row (document) of A, and columns (terms) are normalized by dividing by their
standard deviation from the mean norm (after subtracting the mean document
from every document, the columns have mean zero, so this is equivalent to di-
viding the columns by their norms) of a column (term). Nanas et al. [22] count
the number of term co-occurrence in sliding windows of ﬁxed length, giving
more weight to pairs of terms appearing close each other. Park et al. [24] use a
Bayesian network.

We remark that computing term-term similarities from term co-occurrence
information makes sense when each document of the given collection is on a
single topic: Two terms that co-occur frequently with each other must then refer
to a common topic and are thus related. If the documents are not believed to be
single-topic, we can always break them up into smaller single-topic chunks, and
call these our documents.

108

H. Bast et al.

The method we present here does not rely on a particular measure of similarity
or distance. The only requirement is an estimate of the similarity between any
two index terms, represented by a symmetric matrix S.

To determine the kind of relations of term pairs, we will look at all the low-
rank approximations of the term-similarity matrix S. Let S = VΣVT be the
eigenvector (Schur) decomposition of S. Then Sk = V(k)Σ(k)V(k)T is the best
rank-k approximation of S in terms of both Frobenius and L2-norm, where S(k)
is the diagonal matrix holding the k largest eigenvalues, and V(k) is the matrix
consisting of those k columns from V pertaining to these eigenvalues.

2.2 Term Validity Rank

We deﬁne the similarity simk(i, j) between the i-th and j-th terms at dimension
k by the entry S(k)ij . To investigate how the similarity of a term changes with
the dimension k, we deﬁne the notion of similarity curve, which is deﬁned as
relatedness curve in [3].

Deﬁnition 1 (Similarity Curve). The similarity curve of two terms ti and
tj is deﬁned as the plot of the function

k (cid:2)→ simk(i, j) = S(k)ij

We seek a representation that is suﬃciently detailed to encompass enough in-
formation for a term to be correctly represented, without being so detailed as
to distinguish between terms with essentially the same meaning. The following
deﬁnition uses the notion of a term being more similar to itself than to any other
term:

Deﬁnition 2 (Validity). A term t is correctly represented in the k-order ap-
proximation of the similarity matrix only if it is more similar to itself than to
any other term, that is, simk(t, t) ≥ simk(t, t’) for any other term t’ (cid:5)= t. The
term t is then said to be valid at rank k.

Note that for a term t, for a rank k < N , simk(t, t) is usually less than
simN (t, t), but still more than simk(t, t’) for any other term t’ when t is
valid.

It is useful to deﬁne the rank below which a term ceases to be valid:

Deﬁnition 3 (Validity Rank). A term t is optimally represented in the k-
order approximation of the similarity matrix if k − 1 is the largest value for
which it is not valid. Note that it implies that the term is valid at rank k, which
is the validity rank of term t and is denoted rank(t).

In practice it might happen for some terms that validity is achieved and lost
successively for a short range of ranks. It is not clear whether this is due to a
lack of precision in the numerically sensitive eigenvalue decomposition process
or to theoretical reasons.

The deﬁnition of validity was experimentally illustrated in [8] where all the
documents containing a speciﬁc term a were replicated in the database with a

Discovering a Term Taxonomy from Term Similarities Using PCA

109

replaced by some new term a’. The query composed of the term a was shown to
return in alternation a and a’ versions of the documents as long as the rank k of
the approximation was below the validity rank of a. Beyond the validity rank,
version of the documents containing the term a were returned ﬁrst, suggesting
that the representation of that term was ambiguous below rank(a), and unam-
biguous beyond it. This shows that if the rank of the similarity approximation
matrix and the validity rank of a term used as a single word query coincide,
then retrieval precision1 is optimal. This justiﬁes Deﬁnition 2 a posteriori. An
extension to more than one term queries showed mixed results in [9]. A the-
oretical justiﬁcation of the experimental result obtained in [8] was presented
in [3].

2.3 Term Taxonomy

In the experiment described above, we observed that terms a and a’ were not
correctly distinguished in the k-dimensional latent concept space if k is inferior
to the validity rank of a2. This shows that 1) the two terms bear a common
meaning to a certain extent, 2) the common meaning is more general than the
meaning of any of the two terms. For these two reasons, we call the common
meaning the concept 3 shared by the two terms.

Moreover, we know by Deﬁnition 3 that below their validity rank, a and a’
are more similar to some other terms than to themselves. If they are both more
similar to a common term c valid at rank k, the representation of this term
better covers the concept common to a and a’: We say that a and a’ share
the common concept c∗ where the notation c∗ is used to recall the diﬀerence
between the representation of the single term document at full rank and at its
validity rank.

Deﬁnition 4 (Concept of a Term). A concept c∗ associated to term c is
a concept of term a if rank(c) < rank(a) and if for some rank k such that
rank(c) ≤ k < rank(a), a∗ is more similar to c∗ than to itself.

The requirement that rank(c) < rank(a) ensures that a∗ is never a concept of
c∗ if c∗ is a concept of a∗. If we associate terms to nodes and add directed links
from the terms to their concepts, we obtain a directed acyclic graph (DAG).
In practice, there is a whole range of ranks between rank(c) and rank(a) where
concept a∗ points to its concept c∗, and we keep only the largest one to con-
struct the graph. By identifying the concepts associated to all the terms, we can
construct a taxonomy. This is illustrated in Section 4.

There is a typically a range of ranks between rank(c) and rank(a) where

concept a∗ points to its concept c∗. This motivates the following deﬁnition:

1 We refer to the traditional deﬁnition of precision and recall.
2 Terms a and a’ being perfectly related, they have the same validity rank, as we will

3 This concept diﬀers from the notion of latent concept popularized by Latent Semantic

show in Section 3.

Analysis.

110

H. Bast et al.

Deﬁnition 5 (Coverage of a Link). Deﬁne kmin and kmax as the mini-
mum and maximum k for which c∗ is a concept of term a. Since they verify
rank(c) ≤ kmin ≤ kmax < rank(a), we can deﬁne the normalized coverage of the
link between the two concepts as the ratio

coverage =

kmax − kmin + 1
rank(a) − rank(c)

The coverage has values in ]0, 1].

The coverage reﬂects “how long”, with respect to the possible range deﬁned by
rank(c) and rank(a), the valid term was a concept for the other term. We will
see when we illustrate the hierarchy building procedure in Section 4 that the
coverage is a good predictor of interesting links.

3 Theoretical Underpinning of our Algorithm

We next justify the notion of validity rank via a simple model. Intuitively, if
a concept c∗ associated to a term c is a concept for a set of terms T then we
expect c to occur in the documents in which any of the terms a ∈ T is present.
We deﬁne a notion of a concept c∗ being a perfect concept for two other terms,
which have symmetrical co-occurrence patterns and are called perfectly related
terms in [3].
Deﬁnition 6 (Perfect Concept). Let A be a D × N document-term matrix
with D documents and N terms. Without loss of generality, let us assume that
the terms c, a and a’ correspond to the last three columns of A. Then, a and
a’ are said to be perfectly related to each other and the concept c∗ associated
to c is said to be a perfect concept for a and a’ if, for some permutation of the
rows,

⎡

⎣

A =

⎤

⎦

A1 a1 a1 0
A1 a1 0 a1
B 0 0 0

where A1 is a sub-matrix of dimension d × (N − 3), a1 is column vector of size
d and B is a sub-matrix of dimension (D − 2d) × (N − 3), for some d with
0 ≤ d < D/2.
The following two lemmas say that a perfect concept c∗ of a pair of perfectly
related terms a and a’ induce a particular substructure in the eigenvectors,
which in turn implies that c is always more similar to itself than to a or a’
while for a large range of dimension k a and a’ are more similar to c than to
themselves. Hence c∗ is a concept for a and a’.
Lemma 1. Let S be an N × N symmetric matrix such that

⎡

⎢
⎢
⎣

S =

⎤

⎥
⎥
⎦

C 2β
α c 2β2
2β
α
c
β
c
β

α cT cT cT
β β
α 0
0 α

Discovering a Term Taxonomy from Term Similarities Using PCA

111

where C is a symmetric sub-matrix of dimension (N − 3) × (N − 3), c is a row
vector of size N , α and β are scalers. Then,

1. The vector v = (0, . . . , 0, 0, − 1√
2

, 1√
2

) is an eigenvector of S with eigenvalue

2. The vector v(cid:5) = (0, . . . , 0, − α

β , 1, 1) is an unnormalized eigenvector of S with

3. All other eigenvectors u of S are of the form u = (u1, . . . , uN −3, 2 β

α x, x, x)

α.

eigenvalue 0.

for some x.

Proof. The proofs of parts 1 and 2 are straightforward, because Sv = αv and
Sv(cid:5) = 0. If u is any other eigenvector of S and if the last three entries of u are
uN −2, uN −1 and uN , then uN −1 = uN because u is orthogonal to v. Also, since
u is orthogonal to v(cid:5), we have α
β uN −2 = uN −1 + uN , hence part 3 of lemma 1
follows.

Lemma 2. For a document-term matrix A as in Deﬁnition 6, the correlation
matrix S = AT A has the form as described in lemma 1. This property is invari-
ant of whether the columns (terms) of A are normalized before computing S or
not.

T A1 + BT B, c = A1

Proof. The correlation matrix S = AT A has the form as in 1 with C =
T a1. If the columns of A are
2A1
normalized ﬁrst, then the normalized matrix becomes
⎤

T a1, and α = β = a1

⎡

A(cid:5) =

⎢
⎣

A(cid:5)
1
A(cid:5)
1
B(cid:5)

a1
a1√
|a1| 0
2|a1|
2|a1| 0 a1
a1√
|a1|
0
0

0

⎥
⎦

for some sub-matrices A(cid:5)
1 with C = 2A(cid:5)
1
lemma.

T A(cid:5)

1 and B(cid:5). Then, S = A(cid:5)T A(cid:5) is of the form as in Lemma
, hence the

T a1, α = 1 and β = 1√
2

1 + B(cid:5)T B(cid:5), c = 1√

A(cid:5)
1

2

Suppose A is a document-term matrix as in Deﬁnition 6, terms a and a’ are
perfectly related to each other and c∗ is a perfect concept for a and a’. Using the
similarity curves of the terms c and a we show that c∗ is a concept for a as deﬁned
in Deﬁnition 4. If the correlation matrix S = AT A is computed after normalizing
the columns of A, by Lemma 2, S has the form as shown in Lemma 1 with α = 1
. From Lemma 1, we also know that v = (0, · · · , 0, − 1√
and β = 1√
, 1√
) is an
2
2
2
eigenvector of S with eigenvalue α = 1. Also, v(cid:5) = (0, · · · , 0, − 1√
, 1
2 , 1
2 ) is the
2
normalized form of another eigenvector of S with eigenvalue 0. Let 1 be the k-th
eigenvalue of S. From Lemma 1 the three rows of V corresponding to terms c,
a and a’ are of the form

√

√

√

√

c :
a :
a’ :

2x1 . . .
x1 . . .
x1 . . .

2xk−1
0
xk−1 − 1√
2
1√
xk−1
2

2xk+1 . . .
xk+1 . . .
xk+1 . . .

2xN −1 − 1√
2
1
xN −1
2
1
xN −1
2

112

H. Bast et al.

 

 

y
t
i
r
a

l
i

m
s

i

0.5

1

0

 
0

y
t
i
r
a

l
i

m
s

i

0.5

1

0

 
0

sim(c,c)
sim(c,a)
sim(c,a,)

N

k

rank

k

rank

sim(a,a)
sim(a,c)
sim(a,a,)

N

Fig. 1. Similarity curves of c with a, a’
and itself. The curves for (c,a) and (c,a’)
actually overlap, but for clarity we have
shown them separately.

Fig. 2. Similarity curves of a with c, a’
and itself. Until rank k, the curves of
(a,a) and (a,a’) overlap, but for clarity
we have drawn the lines separately.

From this particular substructure in the eigenvectors, we obtain similarity curves
of c with a, a’ and itself as in Figure 1, and similarity curves of a with itself and
two other terms as in Figure 2. To draw these similarity curves, we do not take
the eigenvalues of S into account because, for a general matrix like S, all the
eigenvalues cannot be determined, and as discussed in [3], the use of eigenvalues
does not change the overall behavior of the similarity curves. Also, to illustrate
the relative behavior of the curves clearly, we draw straight lines between the
main breakpoints of the curves.

Let us assume that the terms c, a and a’ are not related to any other term,
so that their validity ranks depend only on their mutual similarities. Since the
similarity curves of (c,c) is above the curves for (c,a) and (c,a’) for all ranks,
the term c is valid at all ranks greater than or equal to 1 and hence the validity
rank of c is 1. On the other hand, we observe from 2 that until dimension k,
sim(c, a) is larger than sim(a, a), so term a is not valid until rank k. However,
for ranks k or greater, the similarity curve of (a,a) rises above the curves of (a,c)
and (a,a’) (Figure 2) and so a is valid for all ranks k(cid:5) ≥ k. Hence the validity
rank of a is k. Here, c∗ is a concept for a∗ for all ranks k(cid:5) for 0 ≤ k(cid:5) < k.

4 Numerical Experiments

There are no standard procedures to evaluate hierarchies although some at-
tempts have been made [18]. Beyond the fact that evaluation is diﬃcult even
when a group of volunteers is willing to participate, it also depends on the task
the hierarchy is designed for. For example, the measure used in [18] could not be
applied here as the scoring is based on an estimate of the time it takes to ﬁnd
all relevant documents by calculating the total number of menus –this would be
term nodes in this work– that must be traversed and the number of documents
that must be read, which bears no analogy to this work.

As mentioned in the Introduction, we expect PCA to uncover symmetric and
asymmetric relations between terms. We can divide further asymmetric relations

Discovering a Term Taxonomy from Term Similarities Using PCA

113

in two types: The ﬁrst one is semantic and can be found in dictionaries like
WordNet4. These are relations that derives from the deﬁnition of the terms like
“cat” and “animal” for example. The other kind of relation we expect to uncover
is more circumstantial but equally interesting like, for example, “Rio de Janeiro”
and “Carnival”. These two words share no semantic relation, but associating
them makes sense. To evaluate the PCA hierarchy, we chose to compare the links
it extracts from the document collection associated with the Open Directory
Project5 to the original, edited hierarchy. To identify the ability of PCA to
extract “semantic” relations, we compare it with WordNet.

The Open Directory Project (ODP) is the most comprehensive human edited
directory of the Web. We extracted the hierarchies below the entries Shopping
and Science. Out of the 104,276 and 118,584 documents referred by these cate-
gories, we managed to download 185,083 documents to form the database we use.
Documents were processed with a language independent part-of-speech tag-
ger6 and terms replaced by their lemmata. We extracted only adjectives and
substantives to form the bag-of-word representations. Low and high frequency
terms as well as stopwords were discarded unless they appeared in the ODP
hierarchy. Documents were divided in blocks of 25 terms to reduce the confusion
of topics inside a same document (Section 2).

A path in the ODP hierarchy is composed as a series of topics, from the most
generic to the most speciﬁc. An example of such a path is “Health/Beauty/-
Bath and Body/Soap”. We discard concepts described as a sequence of terms.
For example, the previous sequence is transformed into “Health/Beauty/Soap”.
The hierarchy is then decomposed into direct links – i.e. relations that exist
between adjacent terms – and indirect links where relations between terms belong
to the same path. The direct links in our example are Health ← Beauty and
Beauty ← Soap and the set of transitive links is composed of the former links
more Health ← Beauty.

In order to test the stability of the discovered links, we bootstrapped [12] the
document database. The method consists in picking randomly with replacement
185,083 documents from the original database to form a new correlation matrix
before deducing a new set of links. This process is repeated ten times. The
number of replications where a particular link appears reﬂects its stability with
respect to variations in the database. We say that a link is stable when the
relationship between the two terms held the ten times, and in the opposite case
it is said to be unstable. For the science and shopping topics, half of the links
are stable.

This stability analysis permits us to discover terms that share an asymmetric
relation which direction changes from one re-sampling to the other (unstable
links). This points out terms with a symmetric relation like alluded in the Intro-
duction. Table 1 shows an unedited list of such relations as extracted from the
Shopping ODP database.

4 http://wordnet.princeton.edu
5 http://www.dmoz.org
6 TreeTagger: http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger

114

H. Bast et al.

Table 1. Symmetric relations in the Shopping ODP database

clarinet
aikido
woodwind
libertarianism mazda
anarchism
shrimp
crab
wednesday
thursday
impressionism surrealism
classiﬁcation
conﬁrmed
expressionism surrealism
crab
clarinet

beef
judo
new
nissan
woodwind bassoon bassoon woodwind
result
eﬀect
july
shrimp
lobster
september mg
june
oct
nov
jujitsu
judo
ﬂour
grain
ingredient soap

june
new
dart
scarves nissan
june
word

jujitsu
ﬂowers
oct
toyota
ﬂour
snowboard

billiard
necktie
august
english

lobster
woodwind

aikido
ﬂorist
dec

karate
jan

grain
skiing

meat
used

judo
feb

By analogy with the Information Retrieval measures, we deﬁne recall as the
proportion of links in the original hierarchy that the PCA method manages to
retrieve automatically. The precision is deﬁned as the proportion of ODP links
present in the set of PCA links. If we denote by H the set of links in the ODP
human edited hierarchy and by A the set in the PCA automatic hierarchy, recall
and precision become

recall =

precision =

|H ∩ A|

|H|

|H ∩ A|

|A|

Recall answers the question “How many ODP link do I retrieve automatically?”,
while precision answers “What is the concentration of ODP links among all the
PCA links?”

To ﬁx ideas, we intended to compare our method with the most popular one,
from Sanderson and Croft [25], but the results were so poor that we abandoned
the idea. Their method use the co-occurrence information to identify a term that
subsumes other terms. More speciﬁcally, a term u is said to subsume another
term v if the documents in which v occurs belong to a subset of the documents in
which u occurs. Given that a more frequent term tends to be more general [26],
subsumption hierarchies organize terms in a ’general to speciﬁc’ manner. For two
terms x and y, x subsumes y whenever P (x|y) ≥ Θ and P (y|x) < P (x|y) where
P (x|y) is the probability that term x occurs in a document where y occurs. We
ﬁrst tried to use the same division of documents in sequences of 25 terms that
we applied on ODP documents to avoid topic heterogeneity, but such a small
window of terms proved detrimental for the algorithm and we ﬁnally decided to
use the full documents. Sanderson and Croft set the parameter Θ to 0.8 in the
original paper, but we varied it to study its impact on precision and recall. The
results were quite poor. Over all possible settings with respect to the stability, the
minimum Θ and the hierarchies we compared with, the recall we achieved topped
around 5% for a precision of approximately 1%. The best precision amount to
12.5% but the corresponding recall is only 0.03%!

In the remaining of this section, we compute the proportion of direct and
indirect links present in ODP that we retrieve automatically with our Principal
Component Analysis method. We also study the impact of link stability and
coverage (Deﬁnition 5). In the last part, the same set of discovered links is
compared with the WordNet database. Note that a large intersection between
human and automatically generated links increases the conﬁdence on the validity

Discovering a Term Taxonomy from Term Similarities Using PCA

115

Table 2. The ﬁrst 30 direct links in Shopping and Science databases, ordered by
decreasing coverage and limited to the stable links. Links in bold are in the ODP
database.

Shopping

Science

→ chocolate
→ candle
→ golf
→ canada
→ racket
→ australia
→ mattress
→ soap
→ billiard

→ canada
→ lighting
→ sociology
→ archaeology
→ slovenian
→ relativity
→ forensic
→ maya
→ ﬁnnish
→ asia

→ cigar
alberta
humidor
→ cigar
cuban
monorail
→ canada
alberta
criminology
→ clock
prehistory
cuckoo
grandfather → clock
romanian
gravitation
fudge
soy
forensics
putter
aztec
quebec
karelian
oceania
racquetball
transpersonal → psychology
tasmania
→ greek
etruscan
airbed
→ wheat
glycerin
barley
→ eastern
snooker
papuan
→ canada
housebreaking→ dog
quebec
→ cryonics
cryobiology
waterbed
→ solar
soho
oceania
→ chemistry
catalysis
tincture
geotechnical → engineering
gunsmithing → gun
iguana
chrysler
sociologist
equestrian
olmec
ﬂamenco
oceanographer→ oceanography pistachio
condiment
canine
appraiser
neptunium
salsa
lapidary
ontario
raptor
ogham
volkswagen
governmental → organization arthropod
forestry

→ chevrolet
→ horse
→ guitar
→ nut
→ sauce
→ estate
→ sauce
→ canada
→ volvo
→ insect
→ terrier

→ dog
→ plutonium
→ mineral
→ bird
→ irish

→ lizard
→ sociology
→ maya

→ mattress
→ asia
→ herbal

→ forest

bulldog

of the automatic method, but it does not invalidate the automatic links absent
from edited hierarchy because documents and topics can be organized in a variety
of equally good ways. This is corroborated in Table 2 where links absent from
ODP are in normal font.

4.1 Coverage and Stability of Direct Links

Coverage is perceived as a relevant indicator of link quality because it reﬂects the
strength that unite the two terms linked by a hierarchical relation. In Table 3,
the number of links discovered from the Science documents are reported as a
function of the minimum coverage in both the stable and unstable cases. We see
that 70% and 80% of the links have a coverage lower than 20%. Discarding all
the links below this level of coverage results in the loss of only 30% and 33% of
ODP links.

The stability is also an important selection criterion. We observe that if we
consider all the PCA links, stable or not, we retrieve 551 of the original 2,151
ODP links present in Science. If we select only the stable links, we retrieve 436
ODP links, but the total number of PCA links is divided by two from 28,859 to
14,266. Some of the links present in the ODP hierarchy are lost, but more than
half of the PCA links are discarded. A similar conclusion holds when varying the

116

H. Bast et al.

Table 3. Number of links discovered by PCA in Science documents as a function of
the coverage and, in parenthesis, the size of the intersection with the 2,151 Science
ODP links

stable

unstable

0% 14,266 (436)
20% 3,832 (308)
40% 1,867 (251)
60% 1,095 (166)
80% 644 (115)
99% 218 (59)

28,859 (551)
5,850 (368)
2,831 (261)
1,676 (198)
998 (138)
294 (65)

coverage minimum threshold. This justiﬁes stability as an important criterion
for selecting a link.

o

i
t
a
R

(2)

 0.15

(1)

 0.4

 0.35

 0.3

 0.25

 0.2

 0.1

 0.05

 0

(1) Recall, science (s)
(2) Recall, science (u)
(3) Precision, science (s)
(4) Precision, science (u)

(1) Recall, shopping (s)
(2) Recall, shopping (u)
(3) Precision, shopping (s)
(4) Precision, shopping (u)

o

i
t
a
R

(3)

(4)

(2)

(1)

(3)

(4)

 0.4

 0.35

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

 0

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Minimum coverage

Minimum coverage

Fig. 3. Comparison of the PCA stable (s) and unstable (u) links with the ODP hierar-
chy on the Science and Shopping topics. Recall is the proportion of links in the original
ODP hierarchy rediscovered by PCA. Precision is the proportion of ODP links among
those retrieved by PCA. The x-axis is the coverage ratio: For a given value c, the PCA
links we consider are those whose coverage is superior to c.

Fig. 3 oﬀers a global view of the impacts of stability and coverage on recall and
precision for topics Science on the left and Shopping on the right. The portion of
common links is signiﬁcantly larger when the coverage is closer to its maximum.
On both graphs, if we select only links with a coverage superior to 0.8, one tenth
of the links in A are present in ODP. When varying the coverage threshold from
0 to 1, precision increases and recall decreases almost always. This means that
coverage is a good predictor of the link “relevance”. This was veriﬁed empirically
as well by inspecting some part of the discovered links ordered by coverage.

Summarizing, stability and coverage are both important predictors of link

quality.

4.2 Transitive Links

Some links present in ODP might appear as combination of links in PCA and
vice-versa. We already explained how ODP was processed to obtain these links.

Discovering a Term Taxonomy from Term Similarities Using PCA

117

For PCA, we create a link between two terms if there is a path from one term
to another. A link is said to be direct if it appears in the original hierarchy,
and indirect if it was discovered by transitivity. A set of links is transitive if it
includes both direct and indirect links.

The coverage being a good indicator of the link quality, we try to extend this
notion to transitive links. We found experimentally that the minimum coverage
of all the traversed links led to the best results: An indirect link is penalized if
all the paths between the two terms traverse a link with a low coverage.

A study of the eﬀect of coverage and stability on precision and recall is re-
ported in Fig. 4 (left) where we aggregated the results over the science and
shopping topics, and compared the direct and transitive ODP and PCA links.
The results being similar for both topics, there is no need to treat them sep-
arately. Precision and recall when both links set are either transitive or direct
(PCA, ODP and PCA+, ODP+ curves on Fig. 4, left) are very similar: This
shows that precision is not much aﬀected by the new PCA indirect links (around
38% more links, from 31,611 to 43,632) while recall is not much aﬀected by the
new ODP links (around 126% more links, from 4,153 to 9391). It is interest-
ing also to observe that among the 2,297 links common to the transitive PCA
and ODP sets, 1,998 are present in the direct PCA set. This is reﬂected on
Fig. 4 (ODP+, PCA plot) where the corresponding precision curve is signiﬁ-
cantly superior while recall is less aﬀected. This suggests that the indirect links
of PCA did not contribute much.

o

i
t
a
R

 0.4

 0.35

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

 0

(1) Recall (ODP+,PCA)
(2) Recall (ODP+,PCA+)
(3) Recall (ODP,PCA)
(4) Precision (ODP+,PCA)
(5) Precision (ODP+,PCA+)
(6) Precision (ODP,PCA)

(4)

(5)

(6)

o

i
t
a
R

(2)

(3)

(1)

 0.4

 0.35

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

 0

(1) Recall (WN)
(2) Recall (ODP)
(3) Recall (Both)
(4) Precision (WN)
(5) Precision (ODP)
(6) Precision (Both)

(1)

(6)

(5)

(3)

(2)

(4)

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Minimum coverage

Minimum coverage

Fig. 4. Left: Comparison of the PCA direct links (PCA) and transitive links (PCA+)
with the ODP direct links (ODP) and transitive links (ODP+). Right: Comparison
with diﬀerent hierarchies. Only stable and transitive links are considered.

In conclusion, the new deﬁnition of coverage as the minimum on the path of
traversed links proves a good selection indicator, as the precision increases with
the coverage threshold. The manually derived and the PCA hierarchies share
a signiﬁcant amount of links and it seems that PCA is successful in discovering
relations between terms. This is a specially good result given that the ODP
directory is only one among numerous possible ways of organizing the documents
in the database.

118

H. Bast et al.

4.3 Comparison with WordNet

WordNet is a lexical database for the English language while the PCA hierarchy
method necessarily reﬂects the document collection it is extracted from. It is
nevertheless interesting to compare these hierarchies and investigate to what
point PCA is able to detect lexical relations.

To obtain the links from WordNet, we followed three diﬀerent relationships:
the hypernyms (generalization), the holonyms (an object is a part of) and the
synonyms. For each term, we ﬁrst computed the sets of its synonyms. We com-
puted the transitive closure of this set with respect to each relationship sepa-
rately. We then selected all the links from the original term to one of the terms in
the three computed sets. We restricted the set of links to those only containing
terms belonging to the ODP topic: This created two sets of links, one for science
and one for shopping.

There are few links common to ODP and WordNet. For the Science topic,
only 464 links were common, representing 10% and 24% of the links present
in WordNet and ODP respectively. For shopping, we found 354 common links
representing 8% and 11% of WordNet and ODP respectively.

In Fig. 4 (right), we compare the PCA hierarchy with ODP, WordNet and
with the union of WordNet and ODP. We use the transitive links for the three of
them. We observe that the PCA hierarchy is closer to ODP than to WordNet in
terms of precision: the precision for WordNet varies between 1% and 5% while it
varies between 2% and 28% for ODP. This reﬂects the fact that PCA and ODP
are based on the same set of documents. When ODP and WordNet hierarchies
are merged, we observe a small overall increase of precision, lower than the simple
aggregation of the ODP and WordNet precision curves because some links are
common.

Recall values are similar for the three hierarchies. This is a good result since,
as stated above, the intersection between WordNet and ODP is relatively small.

5 Conclusions

We have shown a way to use eigenvector decomposition for the automatic ex-
traction of a term taxonomy. We have shown some mathematical soundness
properties of our approach, and our experiment gave promising results.

The mathematic model could be extended by analysing the eﬀect of pertur-
bation on the special matrix considered in Section 3. We would expect matrix
perturbation theory, as pioneered in [23] and used in a number of subsequent
works, to be helpful for this task.

Our primary goal in this work was the automatic extraction of a term tax-
onomy. It would be interesting to use this taxonomy for information retrieval
tasks such as ad-hoc retrieval. We would expect asymmetric relations to give
potentially better results than symmetric ones.

Finally, it would be interesting to investigate the possibility of combining the
fully automatic eigenvector approach, explored in this paper, with some kind of
external knowledge base.

Discovering a Term Taxonomy from Term Similarities Using PCA

119

References

[1] E. Agichtein and L. Gravano. Snowball: Extracting relations from large plain-text

collections. In 5th Conference on Digital Libraries (DL’00), 2000.

[2] P. G. Anick and S. Tipirneni. The paraphrase search assistant: terminological
feedback for iterative information seeking. In SIGIR ’99: Proceedings of the 22nd
annual international ACM SIGIR conference on Research and development in
information retrieval, pages 153–159, New York, NY, USA, 1999. ACM Press.

[3] H. Bast and D. Majumdar. Why spectral retrieval works. In Proceedings of the
28th annual international ACM SIGIR conference on Research and development
in information retrieval, pages 11–18. ACM, 2005.

[4] S.-L. Chuang and L.-F. Chien. A practical web-based approach to generating topic
hierarchy for text segments. In CIKM ’04: Proceedings of the Thirteenth ACM
conference on Information and knowledge management, pages 127–136, New York,
NY, USA, 2004. ACM Press.

[5] P. Cimiano, G. Ladwig, and S. Staab. Gimme’ the context: context-driven auto-
matic semantic annotation with c-pankow. In 14th International Conference on
the World Wide Web (WWW’05), pages 332–341, 2005.

[6] P. B. P. Cimiano and B. Magnini. Ontology Learning from Text: Methods, Evalu-
ation and Applications (Volume 123: Frontiers in Artiﬁcial Intelligence and Ap-
plications). IOS Press, 2005.

[7] S. Dill, N. Eiron, D. Gibson, D. Gruhl, R. Guha, A. Jhingran, T. Kanungo, K. Mc-
Curley, S. Rajagopalan, A. Tomkins, J. Tomlin, and J. Zienberer. A case for
automated large scale semantic annotation. J. Web Semantics, 1(1), 2003.

[8] G. Dupret. Latent concepts and the number orthogonal factors in latent semantic
analysis. In Proceedings of the 26th annual international ACM SIGIR conference
on Research and development in information retrieval, pages 221–226. ACM Press,
2003.

[9] G. Dupret. Latent semantic indexing with a variable number of orthogonal fac-
tors. In Proceedings of the RIAO 2004, Coupling approaches, coupling media and
coupling languages for information retrieval, pages 673–685. Centre de Hautes
Etudes Internationales d’informatique documentaire, C.I.D., April 26-28 2004.

[10] G. Dupret and B. Piwowarski. Deducing a Term Taxonomy from Term Similari-
ties. In ECML/PKDD 2005 Workshop on Knowledge Discovery and Ontologies,
2005.

[11] G. Dupret and B. Piwowarski. Principal components for automatic term hierarchy
building. In Proceedings of the 13th International Symposium on String Processing
and Information Retrieval (SPIRE 2006), LNCS 4209, pages 37–48. Springer,
2006.

[12] B. Efron and R. J. Tibshirani. An Introduction to the Bootstrap. Chapman &

Hall/CRC, May, 15 1994.

[13] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu, T. Shaked, S. Soderland,
D. Weld, and A. Yates. Unsupervised named-entity extraction from the web: an
experimental study. Artiﬁcial Intelligence, 165(1):91–134, 2005.

[14] E. Glover, D. M. Pennock, S. Lawrence, and R. Krovetz. Inferring hierarchical
descriptions. In CIKM ’02: Proceedings of the eleventh international conference
on Information and knowledge management, pages 507–514, New York, NY, USA,
2002. ACM Press.

[15] M. A. Hearst. Automatic acquisition of hyponyms from large text corpora. In
Proceedings of the 14th conference on Computational linguistics, pages 539–545,
Morristown, NJ, USA, 1992. Association for Computational Linguistics.

120

H. Bast et al.

[16] M. A. Hearst. Automated discovery of wordnet relations. In e. Fellbaum, Chris-

tiane, editor, WordNet: An Electronic Lexical Database, MIT Press, May 1998.

[17] H. Joho, C. Coverson, M. Sanderson, and M. Beaulieu. Hierarchical presentation
In SAC ’02: Proceedings of the 2002 ACM symposium on

of expansion terms.
Applied computing, pages 645–649, New York, NY, USA, 2002. ACM Press.

[18] D. Lawrie and W. Croft. Discovering and comparing topic hierarchies. In Pro-

ceedings of RIAO 2000, 2000.

[19] D. Lawrie, W. B. Croft, and A. Rosenberg. Finding topic words for hierarchical
summarization. In SIGIR ’01: Proceedings of the 24th annual international ACM
SIGIR conference on Research and development in information retrieval, pages
349–357, New York, NY, USA, 2001. ACM Press.

[20] D. J. Lawrie and W. B. Croft. Generating hierarchical summaries for web searches.
In SIGIR ’03: Proceedings of the 26th annual international ACM SIGIR confer-
ence on Research and development in informaion retrieval, pages 457–458, New
York, NY, USA, 2003. ACM Press.

[21] A. Maedche and S. Staab. Discovering conceptual relations from text. In 14th

European Conference on Artiﬁal Intelligence (ECAI’00), pages 321–325, 2000.

[22] N. Nanas, V. Uren, and A. D. Roeck. Building and applying a concept hierarchy
In SIGIR ’03: Proceedings of the 26th annual
representation of a user proﬁle.
international ACM SIGIR conference on Research and development in informaion
retrieval, pages 198–204, New York, NY, USA, 2003. ACM Press.

[23] C. H. Papadimitriou, H. Tamaki, P. Raghavan, and S. Vempala. Latent semantic
indexing: a probabilistic analysis. In Proceedings PODS’98, pages 159–168, 1998.
[24] Y. C. Park, Y. S. Han, and K.-S. Choi. Automatic thesaurus construction using
bayesian networks. In CIKM ’95: Proceedings of the fourth international confer-
ence on Information and knowledge management, pages 212–217, New York, NY,
USA, 1995. ACM Press.

[25] M. Sanderson and B. Croft. Deriving concept hierarchies from text. In SIGIR ’99:
Proceedings of the 22nd annual international ACM SIGIR conference on Research
and development in information retrieval, pages 206–213, New York, NY, USA,
1999. ACM Press.

[26] K. Sparck Jones. A statistical interpretation of term speciﬁcity and its application
in retrieval. Journal of Documentation, 28:11–21, 1972. (Reprinted in Griﬃth,
B. C. (Ed.) Key Papers in Information Science, 1980, and in Willett, P. (Ed.)
Document Retrieval Systems, 1988).

[27] V. Uren, P. Cimiano, J. Iria, S. Handschuh, M. Vargas-Vera, E. Motta, and
F. Ciravegna. Semantic annotation for knowledge management: Requirements
and a survey of the state of the art. Journal of Web Semantics, 4(1):14–28, 2006.
[28] R. Volz, S. Handschuh, S. Staab, L. Stojanovic, and N. Stojanovic. Unveiling
the hidden bride: deep annotation for mapping and migrating legacy data to the
semantic web. Journal of Web Semantics, 1(2):187–206, 2004.

[29] W. A. Woods. Conceptual indexing: A better way to organize knowledge. Tech-

nical report, 1997. Sun Labs Technical Report: TR-97-61.

