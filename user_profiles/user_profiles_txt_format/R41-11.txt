The Price of Uncertainty in Security Games

(Technical Report)

Jens Grossklagsa

Benjamin Johnsonb

Nicolas Christinb

aSchool of Information

University of California, Berkeley

Berkeley, CA 94720

jensg@ischool.berkeley.edu

bInformation Networking Institute & CyLab

Carnegie Mellon University

5000 Forbes Avenue
Pittsburgh, PA 15213

{johnsonb,nicolasc}@andrew.cmu.edu

May 23, 2009

Abstract

In the realm of information security, lack of information about other users’ incentives in a network
can lead to inefﬁcient security choices and reductions in individuals’ payoffs. We propose, contrast
and compare three metrics for measuring the price of uncertainty due to the departure from the payoff-
optimal security outcomes under complete information. Per the analogy with other efﬁciency metrics,
such as the price of anarchy, we deﬁne the price of uncertainty as the maximum discrepancy in expected
payoff in a complete information environment versus the payoff in an incomplete information environ-
ment. We consider difference, payoff-ratio, and cost-ratio metrics as canonical nontrivial measurements
of the price of uncertainty.

We conduct an algebraic, numerical, and graphical analysis of these metrics applied to different
well-studied security scenarios proposed in prior work (i.e., best shot, weakest-link, and total effort). In
these scenarios, we study how a fully rational expert agent could utilize the metrics to decide whether
to gather information about the economic incentives of multiple nearsighted and na¨ıve agents. We ﬁnd
substantial differences between the various metrics and evaluate the appropriateness for security choices
in networked systems.

1

Introduction

The importance of (the lack of) information about security threats, response mechanisms, and associated
expected losses and cost has long been identiﬁed in the computer science, risk management and economics
communities. Granick, for example, argues that weaknesses in our understanding of the measurability of
losses serve as an impediment in sentencing cybercrime offenders [13]. Swire adds that deterring fraudsters
and criminals online is hampered if we cannot correctly aggregate their offenses across different jurisdictions
[33].

The question arises how much defenders can gain by investing in techniques or other efforts to improve
information availability for decision-making? Swire’s analysis foreshadows signiﬁcant costs to create an
information exchange for law enforcement that could support evidence gathering. Similarly, private organi-
zations struggle with how to accumulate data about security risks and incidents in their respective industries.
Past work has, for example, considered the role of intermediaries such as Information Sharing & Analysis
Centers to create incentives for exchanging and disclosing data between companies. Researchers investi-
gated under which conditions organizations are willing to contribute to an information pool about security
breaches and investments when (negative) competitive effects may result from this cooperation [9, 12]. In
different contexts disclosure is not always voluntary and companies may question how much proﬁt they
squander when undesirable information is released. For example, other economics research explores the
impact of (mandated) breach disclosures [4] or publication of software vulnerabilities [34] on the ﬁnancial
market value of corporations. Some work shows that the information gathering or disclosure effect is not
always unambigiously positive or negative, respectively. Choi et al. [6], for example, present another model
on mandatory disclosure of security vulnerabilities. They present scenarios in which disclosure is and is not
welfare-improving.

This trade-off between cost and beneﬁts of information gathering, sharing or disclosure reappears in
many contexts. From a viewpoint of individual rationality it is decided based on the difference of how much
the individual can learn in comparison to the advantage gained by attackers or competitors [32].

Our contribution is to propose and evaluate a set of generic metrics that are applicable to different se-
curity decision-making situations to help with this trade-off calculation. In particular, we are interested in
quantifying the payoff differential that results from the changes in security choices given different informa-
tion available. In economic terms we thereby refer to the differences in payoff that results from changes in
the underlying information structure of the scenario that makes explicit the nature of the utility of informa-
tion to agents [23].

Speciﬁcally, we introduce the “price of uncertainty” metric that quantiﬁes the maximum discrepancy in
the total expected payoff between exactly two information conditions. Our terminology is made per analogy
with Koutsoupias and Papadimitriou’s “price of anarchy” [20]. We consider difference, payoff-ratio, and
cost-ratio sub-metrics as canonical nontrivial measurements of the price of uncertainty.

Since the possibilities for the economic formalization of information are vast we illustate our approach
on a speciﬁc example. In our model for security choices, we assume that each agent faces a randomly drawn

2

probability of being subject to a direct attack. We study how the decisions and payoffs of an individual agent
differ if all draws are common knowledge, compared to a scenario where this information is only privately
known [15].

We conduct this analysis within the framework of security games [14]. This allows us to understand
the important of the price of uncertainty across different canonical cases of interdependency: best shot,
weakest-link and total effort [35]. In a recent extention of this work we distinguish between the roles of
a fully rational expert agent and na¨ıve end users. The latter conduct a simple self-centered cost-beneﬁt
analysis, and neglect interdependencies.
In the current paper, we analyze the price of uncertainty from
the perspective of the expert agent that fully comprehends the beneﬁts of information in the context of the
interrelationship with other na¨ıve users [15]. This allows us to make a general observation. The value of
information for the expert agent is always weakly positive [23] since na¨ıve users do not strategize based on
additional information.

In this model, the price of uncertainty can depend on several different parameters: the cost of security
measures, the magnitude of potential losses, the initial security budget or endowment, and the number of
other na¨ıve agents. We study the impact of these parameters algebraically, numerically and graphically.

We show that a simple difference metric of the price of uncertainty increases linearly in losses, L, and
decreases superlinearly in the number of agents, N . That is, only in the presence of extremely large losses
would a decision-maker strictly prefer to explore the threat probabilities of other agents at a reasonable
cost. We additionally present a ratio metric that is strictly decreasing in N . Interestingly, we demonstrate
that this metric is independent of the magnitude of potential losses, L. Finally, our third purely cost-based
metric suggests that it might lead to misleading conclusions about the necessity of information gathering by
overemphasizing the need for action in the presence of relatively small costs.

By evaluating the price of uncertainty for a range of parameters in different security scenarios, we can
determine which conﬁgurations can accomodate limited information environments (i.e., when being less
informed does not signiﬁcantly jeopardize an expert user’s payoff). We also provide a framework for future
work in the area of analysis of the value of security-relevant information. For example, we believe that the
game-theoretic analysis in specialized scenarios, e.g., intrusion detection games [24], and security patrol
versus robber avoidance scenarios [28] can beneﬁt from a substantiation of the signiﬁcance of informational
assumptions by studying the price of uncertainty.

In Section 2, we summarize the security games framework we developed in prior work, and detail our
assumptions about agent behaviors and information conditions. We present the different metrics for the price
of uncertainty and describe our analysis methodology in Section 3. We conduct our analysis and discuss the
results in Section 4. Finally, we close with a discussion and concluding remarks in Section 5.

2 Decision Theoretic Model

Our study of the price of uncertainty is conducted within the context of a decision-theoretic security analysis
that we have completed in prior work [15]. We studied the decision-making of a sophisticated (expert) agent

3

who interacts with a group of users that follow a simple but reasonable rule-of-thumb strategy.

The analysis in [15] signiﬁcantly differs from prior decision-theoretic approaches that we summarize
brieﬂy in the following. Gordon and Loeb present a model that highlights the trade-off between perfect
and cost-effective security [11]. They consider the protection of an information set that has an associated
loss if compromised, probability of attack, and probability that attack is successful. They show that an
optimizing ﬁrm will not always defend highly vulnerable data, and only invest a fraction of the expected
loss. Cavusoglu et al. [5] consider the decision-making problem of a ﬁrm when attack probabilities are
externally given compared to a scenario when the attacker is explicitly modeled as a strategic player in
a game-theoretic framework. Their model shows that if the ﬁrm assumes that the attacker strategically
responds then in most considered cases its proﬁt will increase.

We next summarize the security games we analyze that are an extension of models we previously pro-

posed [14] to the case of an economy consisting of an expert user and several unsophisticated users.

2.1 Basic model

Self-protection and self-insurance.
In practice, the action portfolio of a defender may include different
options to prevent successful compromises and to limit losses that result from a breach. In Grossklags et al.
[14] we provide a model that allows a decoupling of investments in the context of computer security. On the
one hand, the perimeter can be strengthened with a higher self-protection investment (e.g., implementing or
updating a ﬁrewall). On the other hand, the amount of losses can be reduced by introducing self-insurance
technologies and practices (e.g., backup provisions). Formally, player i decides whether to invest in protec-
tion (ei = 1) or not (ei = 0). Similarly, each player can adopt a self-insurance technology (si = 1) or not
(si = 0). In other words, ei and si are two discrete decision variables.

Discrete choice decision-making captures many practical security problems. Examples include purchase
and adoption investments as well as updating and patching of protection and self-insurance technologies
[2, 21, 25, 26].

We have further conducted a sensitivity analysis with respect to the discrete choice assumption and
ﬁnd that, for the study in the present paper, the only differences between the discrete and continuous cases
(where ei and si are continuous variables over the interval (0, 1) as opposed to be mere binary variables)
arise when there is strict equality between some of the terms in our case-specifying inequality conditions
(see derivations in [15] and in the Appendix). We believe that focusing on these boundary cases is of limited
practical applicability, and could even be misleading. For comparison, we refer to our prior work where we
considered the continuous case in a full information environment [14].

We further denote by b ≥ 0 and c ≥ 0 the cost of protection and self-insurance, respectively, which are

homogeneous for the agent population. So, player i pays bei for protection and csi for self-insurance.

4

Interdependency. We focus in this work on tightly coupled networks [35].1 In a tightly coupled network
all defenders will face a loss if the condition of a security breach is fulﬁlled whereas in a loosely coupled
network consequences may differ for network participants. We denote H as a “contribution” function that
characterizes the effect of ei on agent’s utility Ui, subject to the protection levels chosen (contributed) by
all other players. We require that H be deﬁned for all values over (0, 1)N . We distinguish three canonical
cases that we discussed in-depth in prior work [14]:

• Best shot: H = max(ei, e−i).

• Weakest-link: H = min(ei, e−i).

• Total effort: H = 1
N

P

k ek.

where, following common notation, e−i denotes the set of protection levels chosen by players other than i.

Attack probabilities, network size and endowment. Each of N ∈ N agents receives an endowment
M .
If she is attacked and compromised successfully she faces a loss L. We assume that each agent i
draws an individual attack probability pi (0 ≤ pi ≤ 1) from a uniform random distribution. This models
the heterogeneous preferences that attackers have for different targets, due to their economic, political, or
reputational agenda. The choice of a uniform distribution ensures the analysis remains tractable, while
already providing numerous insights. We conjecture that different distributions (e.g., power law) may also
be appropriate in practice.

2.2 Player behavior

At the core of our analysis is the observation that expert and non-expert users differ in their understanding of
the complexity of networked systems. Indeed, consumers’ knowledge about risks and means of protection
with respect to privacy and security can be quite varied [1], and ﬁeld surveys separate between high and low
expertise users [30].

Sophisticated (expert) user. Advanced users can rely on their superior technical and structural under-
standing of computer security threats and defense mechanisms, to analyze and respond to changes in the
environment [7]. In the present context, expert users, for example, have less difﬁculty to conclude that
the goal to avoid censorship points is a best shot scenario, whereas the protection of a corporate network
frequently suggests a weakest-link optimization problem [14]. Accordingly, a sophisticated user correctly
understands her utility to be dependent on the interdependencies that exist in the network:

Ui = M − piL(1 − si)(1 − H(ei, e−i)) − bei − csi .

1There is an ongoing debate whether researchers should assume full connectivity of a network graph given modern computer

security threats such as worms and viruses. (Personal communication with Nicholas Weaver, ICSI.)

5

Na¨ıve (non-expert) user. Average users underappreciate the interdependency of network security goals
and threats [1, 30]. We model the perceived utility of each na¨ıve agent to only depend on the direct security
threat and the individual investment in self-protection and self-insurance. The investment levels of other
players are not considered in the na¨ıve user’s decision making, despite the existence of interdependencies.
We deﬁne the perceived utility for a speciﬁc na¨ıve agent j as:

P Uj = M − pjL(1 − sj)(1 − ej) − bej − csj .

Clearly, perceived and realized utility actually differ: by failing to incorporate the interdependencies
of all agents’ investment levels in their analysis, na¨ıve users may achieve sub-optimal expected payoffs far
below their anticipated expected payoffs. This paper does not aim to resolve this conﬂict, and, in fact, there
is little evidence that users will learn the complexity of network security over time [30]. We argue that non-
expert users would repeatedly act in an inconsistent fashion. This hypothesis is supported by ﬁndings in
behavioral economics that consumers repeatedly deviate from rationality, however, in the same predictable
ways [19].

2.3 Information conditions

Our analysis is focused on the decision making of the expert user subject to the bounded rational behaviors
of the na¨ıve network participants. That is, more precisely, the expert agent maximizes their expected utility
subject to the available information about other agents’ drawn threat probabilities and their resulting actions.
Two different information conditions may be available to the expert agent:

Complete information: Actual draws of attack probabilities pj for all j 6= i, and her own drawn proba-
bility of being attacked pi.

Incomplete information: Known probability distribution of the unsophisticated users’ attack threat, and
her own drawn probability of being attacked pi.

Therefore, the expert agent can accurately infer what each agent’s investment levels are in the complete
information scenario. Under incomplete information the sophisticated user has to develop an expectation
about the actions of the na¨ıve users.

2.4 Remarks on basic results

We have conducted the basic analysis of this scenario in [15]. Below we are making several general obser-
vations to guide the reader through the results summarized in the appendix.

Every security scenario (i.e., best-shot, weakest-link and total effort) involves simple cost-beneﬁt anal-
yses for both sophisticated and na¨ıve agents [10]. Agents remain passive when the cost of self-protection
and self-insurance exceeds the expected loss. Further, they differentiate between the two types of secu-
rity actions based on their relative cost. This behavior describes what we would usually consider as basic
risk-taking that is part of everyday life: It is not always worth protecting against known risks.

6

One important feature of our model is the availability of self-insurance. If c < b the decision scenario
signiﬁcantly simpliﬁes for all games and both information conditions. This is because once insurance is
applied, the risk and interdependency among the players is removed. The interesting cases for all three
games arise when b ≤ c and protection is a potentially cost-effective option. Within this realm insurance
has a more subtle effect on the payoffs.

There are several key differences between the games, and between the information conditions. In par-
ticular, we encourage the reader to browse the results for the probabilities of self-protection, self-insurance
and passivity (within each case) that are viewable in Tables 3, 8, and 13 in the companion Appendix.

For example, in the weakest-link game only cases 3 and 4 allow for investments in self-protection. We
ﬁnd that increasing the number of agents, N , results in a shrinkage of both cases 3 and 4 to the beneﬁt of case
2. In contrast, the determination of case boundaries in the best shot game is independent of the size of the
network. Finally, in the total effort game only cases 3 and 4 allow for rational self-protection investments.
Again an increase in the network size reduces the prevalence of these cases (since bN ≤ L is a necessary
condition).

Tables 5, 10, and 15 contain the total expected payoff for decisions made by the sophisticated agent,
but also for the na¨ıve agents. We have already highlighted that for c < b all agents follow the same simple
decision rule to decide between passivity and self-insurance. Therefore, payoffs in this region are identical
for all agent types in the case of homogeneous security costs. But, there are payoff differences among all
three information conditions for some parts of the parameter range when b ≤ c.

It is intuitive that the na¨ıve agents suffer in the weakest-link game since they do not appreciate the
difﬁculty to achieve system-wide protection. Similarly, in the best shot game too many unsophisticated
agents will invest in protection lowering the average payoff. In the total effort game, sophisticated agents
realize that their contribution is only valued in relation to the network size. In comparison, na¨ıve agents
invest more often. Further, the payoff proﬁle of the unsophisticated agents remains ﬂat for b < c. This
reﬂects the fact that the na¨ıve agent ignores the insurance option whenever protection is cheaper.

We can observe that the sophisticated agents will suffer from their misallocation of resources in the
weakest-link game when information is incomplete. In the best shot game this impact is limited, but there is
a residual risk that no na¨ıve agent willingly protects due to an unlikely set of draws. In such cases the fully
informed expert could have chosen to take it upon herself to secure the network. In the total effort game we
observe a limited payoff discrepancy for expert users as a result of limited information.

2.5 Outlook on further analyses

Above we have conducted a short summary of the key results that help to distinguish the three canonical
scenarios and the decision-making of the expert and na¨ıve agents detailed in [15]. From this point on we
venture into new territory.

Our starting point are the total payoff results in Tables 5, 10, and 15. We will derive metrics to compare
the impact of the important decision making parameters on the payoffs achievable in the two different

7

information conditions. Thereby, we focus on the choices and payoffs garnered by the expert agent.

3 Price of uncertainty metrics

3.1 The price of uncertainty

In previous work we discussed two information conditions (complete information and incomplete informa-
tion) for an expert player in three canonical security games. In this context, the price of uncertainty measures
the disadvantage of the expert player when she has incomplete information, compared to when she has com-
plete information. Depending on the form this measure takes, the price of uncertainty potentially depends
on ﬁve different parameters:

1. the cost of protection b,

2. the cost of insurance c,

3. the magnitude of potential losses L,

4. the initial endowment M , and

5. the number of other players N .

Because the analysis of ﬁve-variable functions is somewhat cumbersome, a central objective in our metric-
creation exercise is to reduce the number of parameters in a manner such that something both relevant and
interesting can be said. In this work we focus on how the price of uncertainty depends on the magnitude of
potential losses L and the number of other players N . To eliminate M we choose a canonical value of either
0 or L, and to eliminate b and c we chose the values that cause the price of uncertainty to have the greatest
signiﬁcance. This choice depends on the metric.

3.2 Three metrics for the price of uncertainty

For each of our three security games, best shot, weakest link, and total effort, we deﬁne metrics for the price
of uncertainty having the following three forms:

1. The difference metric P oU1(L, N ), deﬁned by

max

[Expected Payoff Complete(b, c, L, L, N ) − Expected Payoff Incomplete(b, c, L, L, N )]

b,c∈[0,L]

2. The payoff-ratio metric P oU2(L, N ) deﬁned by

max

b,c∈[0,L]

(cid:20) Expected Payoff Complete(b, c, L, L, N )
Expected Payoff Incomplete(b, c, L, L, N )

(cid:21)

3. The cost-ratio metric P oU3(L, N ) deﬁned by

min

b,c∈[0,L]

(cid:20) Expected Payoff Complete(b, c, L, 0, N )
Expected Payoff Incomplete(b, c, L, 0, N )

(cid:21)

8

3.3 Discussion of the deﬁnitions

3.3.1 The difference metric

The difference metric is our most straightforward metric. It says the price of uncertainty is the worst case
difference in payoff between complete and incomplete information, where the maximum is taken over all
possible prices for protection and insurance. In this metric, a completely insigniﬁcant price of uncertainty
yields an output of zero, and the metric’s output increases directly as the price of uncertainty becomes more
signiﬁcant.

3.3.2 The payoff-ratio metric

The payoff-ratio metric is motivated by the game-theoretic notion of the ”price of anarchy”, which is deﬁned
as a payoff-ratio of a game’s socially optimal equilibrium to its worst case Nash equilibrium [20]. By
analogy, we deﬁned the price of uncertainty as the worst case payoff-ratio of the expert with complete
information to the expert with incomplete information, with the worst case taken over all possible prices
of protection and insurance. One advantage of using a ratio-style metric of this type is that its output is
currency-independent. In other words, while our difference metric might depend on say dollars or euros, this
ratio metric is just a pure number. In the payoff-ratio metric, a completely insigniﬁcant price of uncertainty
yields an output of 1, and the metric’s output increases as the price of uncertainty becomes more signiﬁcant.

3.3.3 The cost-ratio metric

The cost-ratio metric is similar to the payoff-ratio metric, but with a different canonical choice of 0 for
the initial endowment M . This metric directly measures the ratio of costs induced by the expert’s choices.
These costs are reﬂected in formulas involving b, c, L, and N . Mathematically, the cost ratio allows for a
simpler algebraic analysis due to an abundance of term cancellations. A minor disadvantage of this metric’s
formulation is that it has a somewhat nonstandard orientation, in the sense that it decreases as the price of
uncertainty becomes more signiﬁcant. There are two justiﬁcations for this choice. First we wanted to cast
this metric as being a simpler analogue to the payoff-ratio metric; and second we wanted to avoid values at
inﬁnity, which would have resulted had we used this metric’s multiplicative inverse. In our cost-ratio metric,
a completely insigniﬁcant price of uncertainty yields an output of 1, and the metric’s output decreases toward
zero as the price of uncertainty becomes more signiﬁcant.

4 Analysis

In this section, we analyze the price of uncertainty as deﬁned by each of our three metrics in each of our
three security games. In each case the analysis proceeds as follows. First, considering the magnitude of
potential loss L and the number of other players N as ﬁxed parameters, we determine the protection cost
b and insurance cost c which cause the metric under consideration to yield its most signiﬁcant value. This

9

process deﬁnes a function of two parameters L and N , which we then analyze as a measure of the price
of uncertainty.
In some scenarios we are able to produce clean algebraic results with tight asymptotic
bounds. For others we must rely almost completely on computer-aided numerical analysis and graphs. Each
subsection contains graphs of all relevant metrics and maximizing parameters, and concludes with some
important observations.

4.1 Best shot game

4.1.1 The best shot difference metric: BP oU1(L, N )

In this section we analyze the price of uncertainty metric BP oU1(L, N ) deﬁned as:

max

[Best Shot Exp. Payoff Complete(b, c, L, M, N )−Best Shot Exp. Payoff Incomplete(b, c, L, M, N )]

b,c∈[0,L]

(1)
In the best shot game, the complete and incomplete payoffs are the same when c < b; hence to compute
the maximum payoff difference we may assume that b ≤ c. Observe that in this case, the payoffs do not
depend on c at all. This will help to simplify our analysis.

Best Shot Exp Payoff Complete(b, c, L, M, N ) − Best Shot Exp. Payoff Incomplete(b, c, L, M, N )

(cid:19)N −1#

"

−

M −

(cid:19)N −1#

(cid:18) b
L

L
2

"

(cid:18)

=

M − b

1 −

=

=

=

− b +

(cid:18) L
2

b2
2L
L2 − 2bL + b2

2L
(L − b)2

2L

(cid:18) b
L

(cid:19)N −1

(cid:19) (cid:18) b
L

b
2L
(cid:19) (cid:18) b
L
(cid:19)N −1
(cid:18) b
L
(cid:19)N −1

This expression is maximized as a function of b when its partial derivative with respect to b is zero. So

we compute:

10

Figure 1: Best shot – difference metric: the maximizing b for BP oU1(L, N ).

(cid:18)

0 =

−1 +

0 = −

(cid:18) b
L

b
L

(cid:19) (cid:18) b
L
(cid:18) b
L

+

(cid:19)N −1

(cid:19)N −1

(L − b)2

(N − 1)

2L

(cid:19)N

L2(N − 1)

(cid:19)N −2

·

1
L

(cid:18) b
L
(cid:19)N −2

+

+

(cid:18) b
L

2L(N − 1)

−

(cid:19)N −1

(cid:18) b
L

(N − 1)

+

2

(cid:19)N

(cid:18) b
L

2L2
(cid:19)N −1

N − 1

+

2

(cid:18) b
L

·

(cid:19)N −2

(cid:19)2

−

2N

N + 1

(cid:19)

(cid:18) b
L

+

N − 1
N + 1

2L

!

(cid:18) b
− N ·
L
(cid:19)N −2  (cid:18) b
L

0 =

0 =

0 =

N + 1

2

(cid:19)N

(cid:18) b
L

·

(cid:18) N + 1

(cid:18) N + 1

2

2

(cid:19) (cid:18) b
L
(cid:19) (cid:18) b
L

The expression is zero if and only if

(cid:19)N −2 (cid:18) b
L

− 1

(cid:19) (cid:18) b
L

−

N − 1
N + 1

(cid:19)

b = 0 or b = L or b = L ·

(cid:18) N − 1
N + 1

(cid:19)

.

From the second derivative test we ﬁnd that b = 0 and b = L give local minima, hence the maximizing
N +1 . Figure 1 plots this maximizing b as a

value of this expression for b ∈ [0, L] occurs when b = L · N −1
function of N . For the price of uncertainty, we have

11

 25 5 10 15 20 25L 5 10 15 20 25 30 35 40 45 50N 0 5 10 15 20 25 0 5 10 15 20Best shot − Maximizing bFigure 2: Best shot – difference metric: BP oU1(L, N ). The metric grows linearly in the potential loss L
for a ﬁxed network size N , and decreases inverse-quadratically in the network size N for a ﬁxed loss L.

= max

[Best Shot Exp. Payoff Complete(b, c, L, M, N ) − Best Shot Exp. Payoff Incomplete(b, c, L, M, N )]

BP oU1(L, N )

(cid:19)N −1#

b,c∈[0,L]
"

= max
b∈[0,L]

(cid:16)

L − L ·

(cid:18) b
L

(cid:17)(cid:17)2

(L − b)2

2L
(cid:16) N −1
N +1

2L

=

=

=

L2 (cid:16)

1 −

(cid:16)

(cid:17)(cid:17)2

1 − 2

N +1

2L
(cid:18) N − 1
N + 1

(cid:19)N −1

2L

(N + 1)2

= 2L ·

(N − 1)N −1
(N + 1)N +1

(cid:17)



N −1

L ·





(cid:16) N −1
N +1
L



(cid:19)N −1

(cid:18) N − 1
N + 1

To give an asymptotic analysis, we begin by noting that limn→∞

(cid:17)N −1

(cid:16) N −1
N +1

= 1

e2 . Rewriting the

expression above as 2L
that the second part decreases to zero quadratically in 1

(N +1)2 , we see that the ﬁrst part approaches 2L

e2 as N gets large, and
N . Hence this metric for the price of uncertainty

1

·

(cid:17)N −1

(cid:16) N −1
N +1

12

 2 5 10 15 20 25L 5 10 15 20 25N 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8Best shot − BPoU1(L,N)increases linearly in L for ﬁxed N and decreases quadratically to zero in 1
graph of the metric BP oU1 as a function of N and L.

N for ﬁxed L. Figure 2 shows a

Observations. The interpretation of our numerical results for this metric is that the price of uncertainty
increases with the potential losses, but as the number of players increases, the price of uncertainty diminishes
(unless the losses are quite high – approaching the square of the number of players).

4.1.2 The best shot payoff-ratio metric BP oU2(L, N )

In this section we analyze the price of uncertainty metric BP oU2(L, N ), deﬁned as

max

b,c∈[0,L]

(cid:20) Best Shot Exp. Payoff Complete(b, c, L, L, N )
Best Shot Exp. Payoff Incomplete(b, c, L, L, N )

(cid:21)

(2)

BP oU2(L, N )

= max

b,c∈[0,L]

(cid:20) Best Shot Exp. Payoff Complete(b, c, L, L, N )
Best Shot Exp. Payoff Incomplete(b, c, L, L, N )

(cid:21)

(cid:1)N −1(cid:17)

= max
b∈[0,L]

= max
b∈[0,L]

= max
B∈[0,1]

= max
B∈[0,1]

(cid:1)N −1

(cid:1) (cid:0) b
L
(cid:1)N −1

L − b (cid:0)1 − b
2L
(cid:0) b
L

L

(cid:16)

1 − b
L
(cid:16)

L − L
2
(cid:0)1 − b
2L
(cid:0) b
L
(cid:1) BN −1(cid:1)

1 − 1
2
(cid:0)1 − B (cid:0)1 − B
2

(cid:1)N −1(cid:17)

(cid:1) (cid:0) b
L

L

(cid:0)1 − 1
1 − BN + 1

2 BN −1(cid:1)
2 BN +1

1 − 1
2 BN −1
−BN + 1

= max
B∈[0,1]

1 +

= max
B∈[0,1]

1 +

1

2 BN −1 (1 − B)2

1 − 1

2 BN −1

2 BN +1 + 1
1 − 1
2 BN −1

2 BN −1

13

To compute the maximum, we take the derivative with respect to B and set it equal to zero. We get:

Figure 3: Best shot – payoff-ratio metric: the maximizing b for BP oU2(L, N ).

(cid:0) N −1

2 BN −2(1 − B)2 + 1

2 BN −1 · 2(1 − B) · (−1)(cid:1) · (cid:0)1 − 1
(cid:0)1 − 1
2 BN −1(cid:1)2
(cid:19)
(cid:18)
1
BN −1
2

1 −

(cid:19)

·

BN −2(1 − B)2 − BN −1(1 − B)

2 BN −1(cid:1) −

2 BN −1 (1 − B)2(cid:17)
(cid:16) 1

· (cid:0)− N −1

2 BN −2(cid:1)

BN −2(1 − B)2 − BN −1(1 − B) −

B2N −3(1 − B)2 +

B2N −2(1 − B) +

B2N −3 (1 − B)2

N − 1

+

4

B2N −3 (1 − B)2

1
2

N − 1

4

N − 1

4
B2N −2(1 − B)
(cid:19)

0 =

0 =

0 =

0 =

(cid:18) N − 1

2
N − 1

N − 1

2

2

0 = (1 − B)BN −2

0 = (1 − B)BN −2

(cid:18) (N − 1)(1 − B)

BN −2(1 − B)2 − BN −1(1 − B) +

1
2
BN
2
BN
2
BN −2 (cid:0)BN − B(N + 1) + N − 1(cid:1)

(cid:18) N − 1

B(N + 1)

− B +

+

−

2

2

2

(cid:19)

0 =

1 − B

2

Both B = 1 and B = 0 are roots of this equation, but when put back into the maximizing formula, they
each give the global minimum value of 1. It remains to ﬁnd a solution to this derivative equation for B in
(0, 1). We know there is such a root because the value of BN − B(N + 1) + N − 1 is positive at B = 0
and negative at B = 1. Unfortunately, this root, which must maximize the BP oU2 metric, is not generally
expressible in closed form for N ≥ 5. Figure 3 plots a graph of the maximizing b = LB as a function of N
and L.

14

 25 5 10 15 20 25L 5 10 15 20 25 30 35 40 45 50N 0 5 10 15 20 25 0 5 10 15 20Best shot − Maximizing bFigure 4: Best shot – payoff-ratio metric: BP oU2(L, N ). The metric is independent of L.

It follows from our derivations that this measure of the price of uncertainty does not depend on L. Figure
4 plots BP oU2 as a function of N . As can be seen from the graph, this metric approaches 1 as N increases.

Observations. Since 1 represents the smallest price possible in this metric, the interpretation would be
that the price of uncertainty becomes insigniﬁcant as the number of players increases, independent of the
magnitude of potential losses.

4.1.3 The best shot cost-ratio metric P oU3(B, L, N )

In this section we analyze the price of uncertainty metric BP oU3(L, N ), deﬁned as

min

b,c∈[0,L]

(cid:20) Best Shot Exp. Payoff Complete(b, c, L, 0, N )
Best Shot Exp. Payoff Incomplete(b, c, L, 0, N )

(cid:21)

(3)

This metric is expressed in terms of our payoff functions, but by starting with an initial endowment of
zero, it really is a ratio of costs. If the cost of limited information is great compared to the cost of complete
information, this ratio will tend toward zero. On the other hand, if the costs are similar, then the ratio will
tend toward one. We select the minimizing b and c for this ratio so as to obtain the most signiﬁcant price of
uncertainty under the metric. We have

15

 1.1 5 10 15 20 25L 5 10 15 20 25N 1 1.01 1.02 1.03 1.04 1.05 1.06 1.07 1.08 1.09 1.1 1 1.01 1.02 1.03 1.04 1.05 1.06 1.07 1.08 1.09Best shot − BPoU2 (L,N)Figure 5: Best shot – cost-ratio metric: the maximizing b for BP oU3(L, N ). Here b is constantly equal
to zero.

BP oU3(L, N )

= min

b,c∈[0,L]

(cid:20) Best Shot Exp. Payoff Complete(b, c, L, 0, N )
Best Shot Exp. Payoff Incomplete(b, c, L, 0, N )

(cid:21)

(cid:1)N −1

(cid:1) (cid:0) b
L
(cid:1)N −1

= min
b∈[0,L]

= min
b∈[0,L]

0 − b (cid:0)1 − b
2L
(cid:0) b
L
(cid:19)

0 − L
2
b
2L

2b
L

1 −

(cid:18)

Clearly the minimum value (of zero) for this expression (assuming 0 ≤ b ≤ L) is achieved by taking
b = 0. Or if the value b = 0 is to be avoided, the minimum is achieved by taking b arbitrarily close to zero.
We observe that for the best shot game, this cost-ratio metric always measures the price of uncertainty at its
greatest possible value, independent of N or L. The graphs for the maximizing b and the cost-ratio metric
are both trivial but are included for consistency in Figures 5 and 6 respectively.

Observations. The most direct interpretation for this result would be that the price of uncertainty is very
signiﬁcant, regardless of the number of players or the potential losses. An alternative, and arguably better
explanation is that this particular metric is not a very useful provider of information for the best shot game.

16

 1 5 10 15 20 25L 5 10 15 20 25 30 35 40 45 50N−1−0.5 0 0.5 1−1−0.5 0 0.5Best shot − Maximizing bFigure 6: Best shot – cost-ratio metric: BP oU3(L, N ). As can be seen here, this metric is constant and
equal to zero throughout the parameter space.

4.2 Weakest link game

In the weakest link game, the complete and incomplete payoffs are the same when c < b, but for b ≤ c there
are a wide variety of cases to consider, and without some direction it is not clear which equations we should
use. Unlike the best shot game in which most of our equational analysis involved a single variable b in a
relatively-simple expression, a soft algebraic analysis of the weakest link game is much more difﬁcult to
conduct. Our strategy is to use numerical approximations and graphs to determine which cases to consider,
and consequently which equations to work with. Thus most of our algebraic work for this game takes the
form of supporting, verifying, and clarifying the numerical analysis.

4.2.1 The weakest link difference metric: W P oU1(L, N )

In this section we analyze the price of uncertainty metric W P oU1(L, N ) deﬁned as:

max

[Weakest Link Exp. Payoff Complete(b, c, L, L, N )−Weakest Link Exp. Payoff Incomplete(b, c, L, L, N )]

b,c∈[0,L]

(4)
Our numerical analysis of this difference metric indicates that all the highest values lie in the weakest
. Assuming that the

link game’s case WI3, in which we have

(cid:1)N −1(cid:17)

(cid:16)

1 − (cid:0)1 − b
L

b
(1− b

L )N −1 < c < b + L

minimizing values of b and c do lie in this case, we can analyze the payoff equations for this case to get

17

0 5 10 15 20 25L 5 10 15 20 25NBest shot − BPoU3 (L,N)more speciﬁc information.

Weakest Link Exp Payoff Complete(b, c, L, L, N ) − Weakest Link Exp. Payoff Incomplete(b, c, L, L, N )

=

L − c +

+ (c − b)

1 −

(cid:18)

c + b
2L

(cid:19) (cid:18)

1 −

b
L

(cid:19)N −1#



−

L − c +

b2
2L (cid:0)1 − b
L

(cid:1)N −1 +

(cid:16)

(c − b)2
1 − (cid:0)1 − b
L

2L

(cid:1)N −1(cid:17)





=

+ (c − b)

1 −

(cid:19) (cid:18)

(cid:19)N −1

c + b
2L

1 −

b
L

−

b2
2L (cid:0)1 − b
L

(cid:1)N −1 −

(cid:16)

(c − b)2
1 − (cid:0)1 − b
L

2L

(cid:1)N −1(cid:17)

=

+ (c − b)

1 −

(cid:19)N −1

c2 − b2

(cid:18)

(cid:19)N −1

−

2L

1 −

b
L

b
L

 

(cid:18)

(cid:19)N −1!

(cid:18)

(cid:19)N −1

=

1 −

1 −

+ (c − b)

1 −

b
L

b
L

−

b2
2L (cid:0)1 − b
L

(cid:1)N −1 −

(cid:16)

(c − b)2
1 − (cid:0)1 − b
L

2L

(cid:1)N −1(cid:17)

b2 (cid:16)

(cid:1)N −1(cid:17)

1 − (cid:0)1 − b
L
(cid:1)N −1
2L (cid:0)1 − b
L

−

−

2L

(cid:16)

(c − b)2
1 − (cid:0)1 − b
L

(cid:1)N −1(cid:17)

c2
2L

(cid:18)

(cid:18)

"

c2
2L

c2
2L

c2
2L

To ﬁnd conditions on a minimum c for this expression we take the partial derivative with respect to c

and set it equal to zero. We get:

(cid:18)

(cid:19)N −1

0 =

+

1 −

b
L

−

c
L

(cid:18)

1 −

b
L

(cid:19)N −1

−

2L

0 =

1 −

1 −

(cid:18)

(cid:19)N −1

b
L

1

−

(cid:16)

1 − (cid:0)1 − b
L

(cid:1)N −1(cid:17)

c
L

c
L



(cid:16)

2(c − b)
1 − (cid:0)1 − b
L


(cid:18)

 +

1 −

b
L

(cid:1)N −1(cid:17)

(cid:19)N −1

+

b

(cid:16)

L ·

1 − (cid:0)1 − b
L

(cid:1)N −1(cid:17)

b

L )N −1(cid:17)

(cid:16)
1−(1− b

L·
(cid:16)
1 − (cid:0)1 − b
L

(cid:1)N −1(cid:17)

c = L ·

L(1− b

L )N −1(cid:17)

+b

(cid:0)1 − b
L

(cid:1)N −1

+

·

1
L )N −1(cid:17) −
(cid:16)
1−(1− b
(cid:16)
L )N −1
1−(1− b
L )N −1(cid:17)
L )N −1(cid:17)2
L )N −1(cid:17)

(cid:16)
1−(1− b
(cid:16)
1−(1− b
1−
(cid:16)
1−(1− b

L (cid:0)1 − b
L

(cid:1)N −1

(cid:16)

·

1 − (cid:0)1 − b
L

(cid:1)N −1(cid:17)

+ b

(cid:16)

1 −
h(cid:0)1 − b
L
(cid:1)N −1

(cid:1)N −1(cid:17)2

1 − (cid:0)1 − b
L
1 − (cid:0)1 − b
L
(cid:1)N −1(cid:17)

(cid:1)N −1

1 − (cid:0)1 − b
L

(cid:16)

(cid:16)

·

·

L

(cid:0)1 − b
L

i

(cid:1)N −1(cid:17)

+ b
L
+ (cid:0)1 − b
(cid:1)N −1
L

c =

c =

c =

18

Figure 7: Weakest Link - difference metric: the maximizing b and c for W P oU1(L, N ).

So this formula gives us the maximizing c as a function of b, L, and N . The dependence on L is quite
L . By making the assumption L = 1 and solving for c,

weak in the sense that that c
we immediately get cL as the maximizing solution for the same equation if L were not equal to 1.

L is a function of N and b

(cid:16)

(cid:1)N −1(cid:17)

(c−b)2
(cid:16)
1−(1− b

1 − (cid:0)1 − b
L

above into the payoff difference formula: c2
2L

Now to algebraically compute the maximizing b, we would just need to substitute the value of c from
L )N −1(cid:17)
L )N −1 −
L )N −1(cid:17) ; then take the derivative with respect to b and ﬁnd a root of this derivative in the interval
2L
[0, L]. We will spare the reader the computation of this derivative, as there is no closed form expression
for the root of the degree 5N polynomial we would eventually need to ﬁnd. Instead we refer to the graphs
relevant to this metric. Figure 7 gives the maximizing b and c (respectively) as functions of L and N . Then
Figure 8 gives the weakest link difference metric W P oU1 as a function of L and N .

+(c − b) (cid:0)1 − b
L

1−(1− b
2L(1− b

(cid:1)N −1

b2(cid:16)

−

Observe that the maximizing b decreases to 0 as a function of N but increases linearly in L. The
maximizing c also decreases in N and increases linearly in L. The difference metric itself increases linearly
in L, but remains relatively-constant as N grows. This phenomenon can be explained by the following
(cid:1), whence the expression
observation. The maximizing b for this metric satisﬁes the relation b
(cid:0)1 − b
approaches a constant as N increases. All terms in W P oU1(L, N ) involving N have this form;
L
thus as N grows the function value does not change. The graph shows additionally that the convergence to
constant is quite fast in N .

L ∈ O (cid:0) 1

(cid:1)N −1

N

Observations. The interpretation for these numerical results is that the price of uncertainty in the weakest
link game is highest when protection is cheap and insurance is competitively-priced. This price of uncer-
tainty increases directly with the potential loss, and it is not affected by the number of other players.

19

 9 5 10 15 20 25L 5 10 15 20 25N 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8Weakest link − Maximizing b for WPoU1(L,N) 18 5 10 15 20 25L 5 10 15 20 25N 0 2 4 6 8 10 12 14 16 18 0 2 4 6 8 10 12 14 16Weakest link − Maximizing c for WPoU1(L,N)Figure 8: Weakest Link – difference metric: W P oU1(L, N ). The metric grows linearly in the losses L
and remains relatively constant for ﬁxed L regardless of the network size N .

4.2.2 The weakest link payoff-ratio metric P oU2(W, L, N )

In this section we analyze the price of uncertainty metric W P oU2(L, N ), deﬁned as

max

b,c∈[0,L]

(cid:20) Weakest Link Exp. Payoff Complete(b, c, L, L, N )
Weakest Link Exp. Payoff Incomplete(b, c, L, L, N )

(cid:21)

(5)

We begin by considering the graphs in Figure 9,which give as functions of L and N the b and c (respec-
tively) which maximize the price of uncertainty under this metric. We see that the maximizing b increases
linearly with L, but decreases to zero super-linearly in 1
N . The maximizing c also increases linearly with L,
and decreases with N . For the weakest link payoff-ratio metric, we observe that the metric has no depen-
dence on L, and that there is a local maximum very close to N = 4, and that after N = 4 the ratio decreases
toward zero as N increases.

The graph for the payoff ratio metric is given in Figure 10. We see from the ﬁgure that it does not
depend on L. We can also derive this observation by considering the equations as we did in the best shot
case, speciﬁcally noting that it is without loss of generality to consider a maximum over b
L in place
of b and c respectively. Because the metric only depends on b
L with the conditions 0 ≤ b, c ≤ L, it
follows that L = 1 without loss of generality, and hence the metric does not depend on L.

L and c

L and c

Observations. We observe that in the weakest link payoff-ratio metric, the price of uncertainty is highest
when there are exactly 4 players, and it decreases toward its minimum possible value as the number of
players increases.

20

 2.5 5 10 15 20 25L 5 10 15 20 25N 0 0.5 1 1.5 2 2.5 0 0.5 1 1.5 2Weakest−link − WPoU1(L,N)Figure 9: Weakest Link – payoff-ratio metric: the maximizing b and c for W P oU2(L, N ). Note that the
functions are actually expected to be continuous; the different “steps” that can be seen are due to sampling
errors in our numerical evaluations.

Figure 10: Weakest Link – payoff-ratio metric: W P oU2(L, N ). Numeric simulations conﬁrm the metric
is independent of L.

21

 12 5 10 15 20 25L 5 10 15 20 25N 0 2 4 6 8 10 12 0 2 4 6 8 10Weakest link − Maximizing b for WPoU2(L,N) 20 5 10 15 20 25L 5 10 15 20 25N 0 2 4 6 8 10 12 14 16 18 20 0 2 4 6 8 10 12 14 16 18Weakest link − Maximizing c for WPoU2(L,N) 1.18 5 10 15 20 25L 5 10 15 20 25N 1.11 1.12 1.13 1.14 1.15 1.16 1.17 1.18 1.11 1.12 1.13 1.14 1.15 1.16 1.17Weakest−link − WPoU2(L,N)Figure 11: Weakest Link – cost-ratio metric: the maximizing b and c for W P oU3(L, N ). ε is an ex-
tremely small positive quantity (limited by machine precision, in this case), and ε0 > ε is another extremely
small positive quantity, barely greater than ε.

4.2.3 The weakest link cost-ratio metric P oU3(W, L, N )

In this section we analyze the price of uncertainty metric W P oU3(L, N ), deﬁned as

min

b,c∈[0,L]

(cid:20) Weakest Link Exp. Payoff Complete(b, c, L, 0, N )
Weakest Link Exp. Payoff Incomplete(b, c, L, 0, N )

(cid:21)

(6)

Consider the graphs in Figure 11, which give as functions of L and N the b and c (respectively) which
maximize the price of uncertainty under this metric. We see that the maximum value for b is achieved when
b (and consequently b
L appropriately.
The graph for the payoff ratio metric is given in Figure 12. As with the payoff-ratio metric considered
above, this ratio-based metric does not depend on L. The plot gives nonzero values for all N but decreases
to zero as N increases. Recall that zero in this metric represents the most signiﬁcant price of uncertainty.

L ) is close to zero. The maximizing c is attained when c

L is scaled with b

Observations. The results for this metric can be interpreted as saying that the price of uncertainty becomes
more signiﬁcant as the number of players increases. This interpretation contradicts our observations in the
difference and payoff-ratio metrics for this game, and serves as a prime example to illustrate that the choice
of metric makes a signiﬁcant difference in the interpretation. Our explanation of the discrepancy is that
this cost-ratio metric focuses on comparing costs which are insigniﬁcantly small in both the complete and
incomplete information environments, but whose limiting ratio indicates a signiﬁcant discrepancy. Based on
this observation, a blunt assessment is that the cost-ratio metric for the weakest link game does not measure
what we most generally think of as important.

22

ε 5 10 15 20 25L 5 10 15 20 25NWeakest link − Maximizing b for WPoU3(L,N)’Weakest link − Maximizing c for WPoU3(L,N) 10 15 20 25L 5 10 15 20 25Nε 5Figure 12: Weakest Link - cost-ratio metric: W P oU3(L, N ). Numeric simulations conﬁrm the metric is
independent of L.

4.3 Total effort game

4.3.1 The total effort difference metric: T P oU1(L, N )

In this section we analyze the price of uncertainty metric T P oU1(L, N ) deﬁned as:

max

[Total Effort Exp. Payoff Complete(b, c, L, M, N )−Total Effort Exp. Payoff Incomplete(b, c, L, M, N )]

b,c∈[0,L]

(7)
As with the weakest link game, there are a number of cases to consider when beginning to analyze the
price of uncertainty metrics. Numerical evidence suggests that the maximizing b and c for this game are in
the total effort game’s case TI3, in which we have bN ≤ L and b + b2
N . Using the
payoff equations from this case, we have:

L (N − 1) < c < 2b − b

23

 0.7 5 10 15 20 25L 5 10 15 20 25N 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0 0.1 0.2 0.3 0.4 0.5 0.6Weakest−link − WPoU3(L,N)Expected Payoff Complete(T, b, c, L, M, N ) − Expected Payoff Incomplete(T, b, c, L, M, N )

b2N
2L

(cid:18)

L
2

!

(c − b)2
2L (cid:0)1 − k+1
N

(cid:1)

k + 1

(cid:19)

N

(cid:19)

+

b2N
2L

bN − c
b c
X

k=0

 

P r[k] ·

M − c +

!

c2

2L (cid:0)1 − k
N

(cid:1)

P r[k] ·

M − c +

+

bN −1− N
X

L (c−b)c

k=bN − c

b +1c

N −1
X

P r[k] ·

M − b −

1 −

k=bN − N
"

L (c−b)c

−

M − c +

#

b2N
2L

+

(c − b)2
2 (cid:0)b − b
N

(cid:1)

 

P r[k] ·

bN − c
b c
X

k=0

bN −1− N
X

L (c−b)c

!

(cid:1) −

b2N
2L

2L (cid:0)1 − k
N

P r[k] ·

!

(c − b)2
2L (cid:0)1 − k+1
N

(cid:1)

 

(cid:18)

c2

 

(cid:18)

k=bN − c

b +1c

N −1
X

L (c−b)c

k=bN − N
(c − b)2
2 (cid:0)b − b
N

(cid:1)

=

+

+

=

+

+

−

P r[k] ·

c − b −

1 −

(cid:18)

L
2

k + 1

(cid:19)(cid:19)

N

Now because c occurs in the terms of this expression only quadratically, we could compute an expression
for the partial derivative with respect to c that is almost-everywhere valid, then set the derivative equal to
zero and solve for c. In fact, we did compute this, obtaining

c =

(cid:18)

(cid:19)

PbN −1− N
k=bN − c

L (c−b)c
b +1c
(cid:18)

PbN − c
b c

k=0

− PN −1

Apr[k]
L(1− k+1
N )
+ PbN −1− N
k=bN − c

(cid:19)

L (c−b)c
b +1c

k=bN − N
L (c−b)c
(cid:18)

P r[k] − b
(b− b

N )

.

(cid:19)

P r[k]
L(1− k+1
N )

− 1
b− b
N

P r[k]
L(1− k

N )

The problem with this formulation in terms of an algebraic analysis is that the variable c also occurs in the
terms of the summands, and it is not clear how to use algebra to get it out of there.

Proceeding with our numerical analysis, Figure 13 plots the price of uncertainty as a function of N and
L. We observe that the price of uncertainty in this metric increases linearly in L and decreases to zero with
N signiﬁcantly more quickly than 1
N .

24

Figure 13: Total effort – difference metric: T P oU1(L, N ).

Observations. The interpretation of our numerical results for this metric is that the price of uncertainty
increases with the potential losses, but as the number of players increases, the price of uncertainty diminishes
quickly.

4.3.2 The total effort payoff-ratio metric: T P oU2(L, N )

In this section we analyze the price of uncertainty metric T P oU2(L, N ) deﬁned as:
(cid:20) Total Effort Exp. Payoff Complete(b, c, L, L, N )
Total Effort Exp. Payoff Incomplete(b, c, L, L, N )

b,c∈[0,L]

max

(cid:21)

For the remaining total effort metrics, our analysis relies exclusively on numerical approximations.
Figure 14 plots the total effort game’s payoff-ratio price of uncertainty as a function of N . The ﬁgure shows
that the price of uncertainty does not depend on L and that it decreases toward 1 as N increases.

Observations.
it diminishes to its least signiﬁcant possible value as the number of players increases.

In the total effort game, the payoff-ratio metric depends only on the number of players, and

4.3.3 The total effort cost-ratio metric: T P oU3(L, N )

In this section we analyze the price of uncertainty metric T P oU3(L, N ) deﬁned as:

max

b,c∈[0,L]

(cid:20) Total Effort Exp. Payoff Complete(b, c, L, 0, N )
Total Effort Exp. Payoff Incomplete(b, c, L, 0, N )

(cid:21)

25

(8)

(9)

 1.4 5 10 15 20 25L 5 10 15 20 25N 0 0.2 0.4 0.6 0.8 1 1.2 1.4 0 0.2 0.4 0.6 0.8 1 1.2Total effort − PoU1(L,N)Figure 14: Total effort – payoff-ratio metric: T P oU2(L, N ).

Figure 15: Total effort – cost-ratio metric: T P oU3(L, N ).

26

 1.08 5 10 15 20 25L 5 10 15 20 25N 1 1.01 1.02 1.03 1.04 1.05 1.06 1.07 1.08 1 1.01 1.02 1.03 1.04 1.05 1.06 1.07Total effort − TPoU2(L,N) 0.82 5 10 15 20 25L 5 10 15 20 25N 0.66 0.68 0.7 0.72 0.74 0.76 0.78 0.8 0.82 0.66 0.68 0.7 0.72 0.74 0.76 0.78 0.8Total Effort −− TPou3(L,N)Figure 15 plots the total effort game’s cost-ratio price of uncertainty as a function of N . As can be seen

from the graph, the price of uncertainty does not depend on L, and decreases as N increases.

Observations. Using the cost-ratio metric for the total effort game, the price of uncertainty becomes more
signiﬁcant with an increase in the number of players. Once again this goes against the analogous conclusions
for the other two metrics. Again we surmise that this happens because the cost-ratio metric focuses on the
cases where the cost for both complete and incomplete information scenarios are quite small, but the ratio
shows a signiﬁcant distinction.

5 Conclusions

Users frequently fail to deploy, or upgrade security technologies, or to carefully preserve and backup their
valuable data [18, 27], which leads to considerable monetary losses to both individuals and corporations
every year. This state of affairs can be partly attributed to economic considerations.

Signiﬁcant challenges for average users arise when they have to determine optimal security strategies in
the presence of interdependencies between security choices of other agents [14, 21]. Struggling with this
task we anticipate the vast majority of users to be na¨ıve, and to apply approximate decision-rules that fail to
accurately appreciate the impact of their decisions on others [1].

In this paper we continue our investigation into the incentives of an individual expert user that rationally
responds to the security choices of unsophisticated end-users under different informational assumptions
[15]. In particular, we study how the expert evaluates the importance of improving the information available
for her decision-making. We propose three variations of the price of uncertainty metric that may serve as
a decision help for the expert user. We distinguish between a difference, a payoff-ratio, and a cost-ratio
metric.

Our work complements the rich area of security metrics that are commonly technical, ﬁnancial [17] or
market-based [3]. However, the price of uncertainty is motivated by game-theory and, more speciﬁcally, by
Koutsoupias and Papadimitriou’s metric to evaluate worst-case equilibria [20], and adds to the rich literature
on information sharing, (mandatory) disclosure, and notice and consent that we reviewed in the introductory
section.

Our research yields a number of somewhat counter-intuitive results:

• Using cost-ratio metrics can be misleading, as two negligible costs in front of a large endowment may
still produce a large ratio when divided by each other. While mathematically trivial, such a pitfall is
relatively easy to get into. We showed that, unfortunately, for all games we studied, cost-ratios are
never an appropriate metric. The cynic in ourselves could actually point out that their main use would
be for marketing purposes. Beware of snake oil!

• Aside from the cost-ratio metric, the other metrics show a relatively low price of uncertainty across all
the scenarios we considered, and this is especially true with a large number of players. The difference

27

metric shows some signs of a penalty for lack of information, but if we consider the absolute payoff
values (reported in Tables 5, 10, and 15) we ﬁnd the price of uncertainty in the difference metric is
at most 20% of the magnitude of the potential loss. Accordingly, we can summarize that in scenarios
with many players the lack of information does not penalize an expert too much. On the other hand,
the lack of knowledge (about interdependencies) that makes a user na¨ıve, as opposed to expert, results
in signiﬁcant payoff degradation regardless of the number of players [15].

• Assuming ﬁxed possible losses, the more players are in a network, the less information matters. This
is actually good news, as full information typically gets increasingly difﬁcult to gather as the number
of players grows large.

• In contrast to our arguments in favor of difference-based metrics behavioral research has shown that
individuals are frequently inﬂuenced by ratio-difference evaluations [29]. However, this makes con-
sumers more vulnerable to (numerical) framing differences that change perceptions about the beneﬁts
of additional information. For example, experimental research has reported robust evidence for con-
sumers’ preferences for beneﬁts that are presented as large ratios in comparison to small ratios [22]. In
the security context, marketers could easily switch the framing from a security to a reliability measure
and thereby vary the size of the beneﬁt ratio (e.g., from 3% vs. 5% failure to 97% vs. 95% reliability).
As a result, individuals may exaggerage the importance of changes when risks or beneﬁts are small
[16, 31].

• We have also shown that the payoff-ratio and the cost-ratio metrics are independent of the size of
the losses, L. Human-subject experiments suggest, however, that decision-makers may falsely utilize
ratio considerations in the presence of (apparently) irrelevant information. For example, psychologists
have found that investments in measures leading to savings of a ﬁxed number of lives were prefered
if the total number of individuals at risk was decreased [8]. Unfortunately, such a bias would lead to
even less optimal decisions when considering the difference metric since the loss, L, is shown to be
positively and linearly related to the price of uncertainty.

Of course, we should not forget that we consider a rather specialized environment, where only one single
expert is alone in a population of na¨ıve users. However stringent this assumption may sound, one should
note that in reality, the number of expert users is dwarfed by the number of “lambda” users, that may not
have the expertise, or inclination, to act very strategically.

Regardless of these limitations, we hope that our work will be a useful starting point for a serious
discussion of information metrics applied to interdependent security scenarios. As we have shown here,
picking the right metric is not an straightforward choice, and several pitfalls exist.

References

[1] A. Acquisti and J. Grossklags. Privacy and rationality in individual decision making. IEEE Security & Privacy,

3(1):26–33, January–February 2005.

28

[2] T. August and T. Tunca. Network software security and user incentives. Management Science, 52(11):1703–

1720, November 2006.

[3] R. B¨ohme and T. Nowey. Economic security metrics.

In I. Eusgeld, F. Freiling, and R. Reussner, editors,
Dependability Metrics (Lecture Notes in Computer Science, No. 4909), pages 176–187. Springer-Verlag, 2008.

[4] K. Campbell, L. Gordon, M. Loeb, and L. Zhou. The economic cost of publicly announced information security

breaches: Empirical evidence from the stock market. Journal of Computer Security, 11(3):431–448, 2003.

[5] H. Cavusoglu, S. Raghunathan, and W. Yue. Decision-theoretic and game-theoretic approaches to IT security

investment. Journal of Management Information Systems, 25(2):281–304, Fall 2008.

[6] J. Choi, C. Fershtman, and N. Gandal. Network security: Vulnerabilities and disclosure policy, December 2008.

[7] D. D¨orner. The Logic Of Failure: Recognizing And Avoiding Error In Complex Situations. Metropolitan Books,

Working paper.

1996.

[8] D. Fetherstonhaugh, P. Slovic, S. Johnson, and J. Friedrich. Insensitivity to the value of human life: A study of

psychophysical numbing. Journal of Risk and Uncertainty, 14(3):283–300, May 1997.

[9] E. Gal-Or and A. Ghose. The economic incentives for sharing security information. Information Systems Re-

[10] L. Gordon and M. Loeb. Managing Cyber-Security Resources: A Cost-Beneﬁt Analysis. McGraw-Hill, New

search, 16(2):186–208, June 2005.

York, NY, 2006.

[11] L.A. Gordon and M. Loeb. The economics of information security investment. ACM Transactions on Information

and System Security, 5(4):438–457, November 2002.

[12] L.A. Gordon, M. Loeb, and W. Lucyshyn. Sharing information on computer systems security: An economic

analysis. Journal of Accounting and Public Policy, 22(6):461–485, November 2003.

[13] J. Granick. Faking it: Calculating loss in computer crime sentencing. I/S: A Journal of Law and Policy for the

Information Society, 2(2):207–228, Spring/Summer 2006.

[14] J. Grossklags, N. Christin, and J. Chuang. Secure or insure? A game-theoretic analysis of information security
games. In Proceedings of the 2008 World Wide Web Conference (WWW’08), pages 209–218, Beijing, China,
April 2008.

[15] J. Grossklags, B. Johnson, and N. Christin. When information improves information security. Technical Report
CMU-CyLab-09-004, UC Berkeley & Carnegie Mellon University, CyLab, February 2009. Available at http:
//www.cylab.cmu.edu/research/techreports/tr_cylab09004.html.

[16] J. Hershey and J. Baron. Clinical reasoning and cognitive processes. Medical Decision Making, 7(4):203–211,

[17] A. Jaquith. Security Metrics: Replacing Fear, Uncertainty, and Doubt. Pearson Education, Upper Saddle River,

December 1987.

NJ, 2007.

[18] Kabooza. Global backup survey: About backup habits, risk factors, worries and data loss of home PCs, January

2009. Available at: http://www.kabooza.com/globalsurvey.html.

29

[19] D. Kahneman and A. Tversky. Choices, values and frames. Cambridge University Press, Cambridge, UK, 2000.

[20] E. Koutsoupias and C. Papadimitriou. Worst-case equilibria. In Proceedings of the 16th Annual Symposium on

Theoretical Aspects of Computer Science, pages 404–413, 1999.

[21] H. Kunreuther and G. Heal. Interdependent security. Journal of Risk and Uncertainty, 26(2–3):231–249, March

2003.

[22] J. Kwong and K. Wong. The role of ratio differences in the framing of numerical information. International

Journal of Research in Marketing, 23(4):385–394, December 2006.

[23] J. Laffont. The economics of uncertainty and information. MIT Press, Cambridge, MA, 1989.

[24] Y. Liu, C. Comaniciu, and H. Man. A bayesian game approach for intrusion detection in wireless ad hoc net-
works. In Proceedings of the Workshop on Game Theory for Communications and Networks, page Article No.
4, 2006.

[25] D. Meier, Y. Oswald, S. Schmid, and R. Wattenhofer. On the windfall of friendship: Inoculation strategies on
social networks. In Proceedings of the 9th ACM Conference on Electronic Commerce (EC’08), pages 294–301,
Chicago, IL, July 2008.

[26] T. Moscibroda, S. Schmid, and R. Wattenhofer. When selﬁsh meets evil: Byzantine players in a virus inoculation
game. In Proceedings of the 25th Annual ACM Symposium on Principles of Distributed Computing (PODC’06),
pages 35–44, Denver, CO, July 2006.

[27] NCSA/Symantec. Home user study, October 2008. Available at: http://staysafeonline.org/.

[28] P. Paruchuri, J. Pearce, J. Marecki, M. Tambe, F. Ordonez, and S. Kraus. Playing games for security: An efﬁcient
exact algorithm for solving bayesian stackelberg games. In Proceedings of the 7th Int. Conf. on Autonomous
Agents and Multiagent Systems (AAMAS 2008), pages 895–902, Estoril, Portugal, May 2008.

[29] G. Quattrone and A. Tversky. Contrasting rational and psychological analyses of political choice. The American

Political Science Review, 82(3):719–736, September 1988.

[30] J. Stanton, K. Stam, P. Mastrangelo, and J. Jolton. Analysis of end user security behaviors. Computers &

Security, 2(24):124–133, March 2005.

[31] E. Stone, F. Yates, and A. Parker. Risk Communication: Absolute versus Relative Expressions of Low-

Probability Risks. Organizational Behavior and Human Decision Processes, 3(60):387–408, December 1994.

[32] P. Swire. A Model for When Disclosure Helps Security: What is Different About Computer and Network

Security? Journal on Telecommunications and High Technology Law, 1(3):163–208, 2004.

[33] P. Swire. No Cop on the Beat: Underenforcement in E-Commerce and Cybercrime. Journal on Telecommunica-

tions and High Technology Law, forthcoming 2008.

[34] R. Telang and S. Wattal. An empirical analysis of the impact of software vulnerability announcements on ﬁrm

stock price. IEEE Transactions on Software Engineering, 33(8):544–557, 2007.

[35] H.R. Varian. System reliability and free riding. In L.J. Camp and S. Lewis, editors, Economics of Information
Security (Advances in Information Security, Volume 12), pages 1–15. Kluwer Academic Publishers, Dordrecht,
The Netherlands, 2004.

30

A Technical appendix

This appendix replicates the tabulated results from [15].

A.1 Tabulated results for decision-theoretic analysis

Table 1: Weakest link security game: Payoffs for different strategies under different information conditions

b ≤ c and minj6=i pj < b/L
b ≤ c and b
L ≤ minj6=i pj
c < b

Information

Type

Payoff
Passivity
Complete M − piL
Complete M − piL
Complete M − piL

Incomplete M − piL
Incomplete M − piL

Self-Insurance

Payoff

M − c
M − c
M − c

M − c

M − c

Payoff

Protection

M − b − piL
M − b − piL

M − b

M − b − piL

M − b − piL

(cid:16)

1 − (cid:0)1 − b

L

(cid:1)N −1(cid:17)

Table 2: Weakest link security game: Conditions to select protection, self-insurance or passivity strategies

Information

Type

Complete
Complete
Complete

Incomplete
Incomplete

Conditions
Passivity
pi < c
L
pi < c
L
pi < b
L
pi < c
L
pi < c
L

Conditions

Self-Insurance

pi ≥ c
L
pi ≥ c
L
NEVER!
pi > c
L
pi ≥ c
L

Conditions
Protection
NEVER!
NEVER!
pi ≥ b
L
NEVER!
NEVER!

Incomplete

pi <

b
L )N −1
L(1− b

pi >

c−b
1−(1− b

(cid:16)

L

L )N −1(cid:17)

b
L(1− b

L )N −1 ≤ pi ≤

c−b
L(1−(1− b

L )N −1)

b ≤ c and minj6=i pj < b
L
b ≤ c and b
L ≤ minj6=i pj
c < b

b ≤ c ≤

b
L )N −1
(1− b
L )N −1 < c

b
(1− b

Case

c < b

b ≤ c

Case

c < b

31

Table 3: Weakest link security game: Probabilities to select protection, self-insurance or passivity strategies

Information

Type

Complete
Complete
Complete

Incomplete
Incomplete

Incomplete

c
L
c
L
b
L
c
L
c
L

Case

c < b

b ≤ c and minj6=i pj < b
L
b ≤ c and b
L ≤ minj6=i pj
c < b

b ≤ c ≤

b
L )N −1
(1− b
b
L )N −1 < c and
(1− b
(cid:16)
1 − (cid:0)1 − b
L )N −1 < c and
(cid:1)N −1(cid:17)

b
(1− b
(cid:16)
1 − (cid:0)1 − b

L

L

(cid:1)N −1(cid:17)

b + L

≤ c

c < b + L

Probability
Passivity

Probability

Self-Insurance

Probability
Protection

1 − c
L
1 − c
L

0

1 − c
L
1 − c
L

1 − b
L

0
0

0
0

b
L )N −1
L(1− b

1 −

c−b
(cid:16)
1−(1− b

L

L )N −1(cid:17)

c−b
L(1−(1− b

L )N −1)

−

b
L )N −1
L(1− b

Incomplete

b
L )N −1
L(1− b

0

1 −

b
L )N −1
L(1− b

Table 4: Weakest link security game: Total expected game payoffs, conditioned on other players

Information

Total Expected Payoff for player i

(conditioned on other players)

Type

Complete
Complete
Complete

Incomplete
Incomplete

Case

c < b

b ≤ c and minj6=i pj < b
L
b ≤ c and b
L ≤ minj6=i pj
c < b

c < b + L

(cid:1)N −1(cid:17)

b ≤ c ≤

b
(1− b

(cid:16)

b
L )N −1
(1− b
L )N −1 <
1 − (cid:0)1 − b
L )N −1 <

L

b
(1− b
1 − (cid:0)1 − b

L

(cid:16)

b + L

(cid:1)N −1(cid:17)

≤ c

M − c + c2
2L
M − c + c2
2L
M − b + b2
2L
M − c + c2
2L
M − c + c2
2L

Incomplete

M − c +

b2
2L(1− b

L )N −1 +

(cid:16)

(c−b)2
1−(1− b

L )N −1(cid:17)

2L

Incomplete M − b − L
2

(cid:16)

1 − (cid:0)1 − b

L

(cid:1)N −1(cid:17)

+

b2
L )N −1
2L(1− b

32

Case

c < b

b ≤ c

c < b

c < b

b ≤ c

Case

c < b

b ≤ c

Table 5: Weakest link security game: Total expected game payoffs, not conditioned on other players

b ≤ c ≤

b
(1− b
b
(1− b

L )N −1 < c < b + L
L )N −1 < b + L

(cid:16)

b
L )N −1
(1− b
(cid:16)
1 − (cid:0)1 − b

L

1 − (cid:0)1 − b

L

(cid:1)N −1(cid:17)

(cid:1)N −1(cid:17)

Incomplete

M − c +

≤ c

Incomplete M − b − L
2

Information

Type

Complete

Complete

Incomplete
Incomplete

Total Expected Payoff for player i
(not conditioned on other players)

M − c + c2

2L + (c − b) (cid:0)1 − c+b

2L

(cid:1) (cid:0)1 − b

L

(cid:1)N −1

M − c + c2
2L

M − c + c2
2L
M − c + c2
2L

L )N −1 +

b2
2L(1− b
(cid:16)
1 − (cid:0)1 − b

(cid:16)
2L
(cid:1)N −1(cid:17)

L

(c−b)2
1−(1− b

L )N −1(cid:17)

+

b2
L )N −1
2L(1− b

M − c + c2
2
(cid:16)
(cid:17) (cid:16)
1 − b2
L2

1 − (cid:0)1 − b

L

(cid:1)N −1(cid:17)

Naive

Naive

M − b + b2

2L − L

2

Table 6: Best shot security game: Payoffs for different strategies under different information conditions

b ≤ c and maxj6=i pj < b
L
b ≤ c and b
L ≤ maxj6=i pj
c < b

Information

Type

Complete
Complete
Complete

Payoff
Passivity
M − piL
M − piL

M

M − piL
Incomplete
Incomplete M − piL (cid:0) b

L

(cid:1)N −1

Payoff

Payoff

Self-Insurance

Protection

M − c
M − c
M − c

M − c

M − c

M − b
M − b
M − b

M − b

M − b

Table 7: Best shot security game: Conditions to select protection, self-insurance or passivity strategies

b ≤ c and maxj6=i pj < b/L
b ≤ c and b/L ≤ maxj6=i pj

Case

c < b

c < b
b ≤ c

Type

Information Conditions
Passivity
pi < c/L
pi < b/L
ALWAYS!

Complete
Complete
Complete

pi < c/L
Incomplete
Incomplete ALWAYS!

Conditions

Self-Insurance

pi ≥ c/L
NEVER!
NEVER!

pi ≥ c/L
NEVER!

Conditions
Protection
NEVER!
pi ≥ b/L
NEVER!

NEVER!
NEVER!

33

Table 8: Best shot security game: Probabilities to select protection, self-insurance or passivity strategies

Case

c < b

b ≤ c and maxj6=i pj < b
L
b ≤ c and b
L ≤ maxj6=i pj
c < b
b ≤ c

Information

Type

Complete
Complete
Complete

Incomplete
Incomplete

c
L
b
L
1

c
L
1

Probability
Passivity

Probability

Self-Insurance

Probability
Protection

1 − c
L

0
0

0

1 − c
L

1 − b
L

0

0

0
0

Table 9: Best shot security game: Total expected game payoffs, conditioned on other players

Case

c < b

b ≤ c

b ≤ c and maxj6=i pj < b
L
b ≤ c and b
L ≤ maxj6=i pj
c < b

Information

Total Expected Payoff

Type

Complete
Complete
Complete

Incomplete

Incomplete

M − c + c2
2L
M − b + b2
2L

M

M − c + c2
2L
(cid:1)N −1

M − L
2

(cid:0) b
L

Table 10: Best shot security game: Total expected game payoffs, not conditioned on other players

Case

Information

Total Expected Payoff

Complete
Complete M − b (cid:0)1 − b

(cid:1)N −1

Type

Incomplete

Incomplete

Naive
Naive

c < b

b ≤ c

c < b

b ≤ c

c < b
b ≤ c

M − c + c2
2L
(cid:1) (cid:0) b
L
M − c + c2
2L
(cid:1)N −1

2L

M − L
2

(cid:0) b
L

M − c + c2
2
M − b + b2
2L

34

Table 11: Total effort security game: Payoffs for different strategies under different information conditions

Payoff
Passivity
M − piL

Case

Information

Type

Complete
Complete

c < b
b ≤ c

c < b
b ≤ c

M − piL (1 − K/N )

Incomplete
Incomplete M − pi (b + (L − b)/N )

M − piL

Self-Insurance

Payoff

M − c
M − c

M − c
M − c

Payoff

Protection

M − b − piL (1 − 1/N )

M − b − piL (1 − (K + 1)/N )

M − b − piL (1 − 1/N )
M − b − pi (b − b/N )

Table 12: Total effort security game: Conditions to select protection, self-insurance or passivity strategies

Case

c < b

b ≤ c ≤ b(N − K)

b(N − K) < c

c < b
b ≤ c ≤ b + b2

L (N − 1)

b + b2

L (N − 1) < c

Information

Type

Complete
Complete

Complete

Incomplete
Incomplete

Incomplete

Conditions
Passivity
pi < c
L
c

pi <

N )

L(1− K
pi < bN
L

pi < c
L
pi < c
pi < bN
L

b+ L−b

N

Conditions

Self-Insurance

pi ≥ c
L
c

pi ≥

pi >

N )

L(1− K
c−b

L(1− K+1
N )
pi ≥ c
L
pi ≥ c
b+ L−b
pi > c−b
b− b
N

N

Conditions
Protection
NEVER!
NEVER!

bN
L ≤ pi ≤

c−b

L(1− K+1
N )

NEVER!
NEVER!

bN

L ≤ pi ≤ c−b
b− b
N

35

Table 13: Total effort security game: Probabilities to select protection, self-insurance or passivity strategies

b(N − K) < c < b + L (cid:0)1 − K+1

(cid:1)

N

TC1
TC2

TC3

TC4

TC5

TC6

TI1
TI2

TI3

TI4

TI5

TI6

Case

c < b

bN ≤ L and

b ≤ c ≤ b(N − K)

bN ≤ L and

bN ≤ L and
b + L (cid:0)1 − K+1
L < bN and

N

(cid:1) ≤ c

b ≤ c < L (cid:0)1 − K

(cid:1)

N

L < bN
and L (cid:0)1 − K+1

(cid:1) < c

N
c < b

bN ≤ L and

b ≤ c ≤ b + b2

L (N − 1)

bN ≤ L and
2b − b
N ≤ c
L < bN and

b ≤ c < b + L−b
N
L < bN and
b + L−b
N ≤ c

Probability
Passivity

Probability

Self-Insurance

Probability
Protection

1 − c
L
c

1 −

L(1− K

N )

L(1− K

N )

1 −

c−b

L(1− K+1
N )

L(1− K+1
N )

c−b

− bN
L

1 − bN
L

Information

Type

Complete
Complete

Complete

Complete

Complete

Incomplete
Incomplete

Complete

L(1− K

N )

1 −

c

L(1− K

N )

1 − c
L
1 − c

b+ L−b

N

b+ L−b

N

c
L
c

bN
L

bN
L

c

1

c
L
c

bN
L

bN
L

c

1

0

0

0

0

0
0

0

0

0
0

0

0

bN ≤ L and

Incomplete

b + b2

L (N − 1) < c < 2b − b

N

Incomplete

1 − c−b
b− b
N

c−b
b− b
N

− bN
L

1 − bN
L

Incomplete

b+ L−b

N

1 − c

b+ L−b

N

Incomplete

36

Table 14: Total Effort security game: Total expected game payoffs, conditioned on other players

Case

Information

Total Expected Payoff

TC1
TC2

bN ≤ L and

TC3

bN ≤ L and

c < b
b ≤ c ≤ b(N − K)
b(N − K) < c < b + L (cid:0)1 − K+1
b + L (cid:0)1 − K+1
b ≤ c ≤ L (cid:0)1 − K

(cid:1) ≤ c

(cid:1)

N

N

N

(cid:1)

bN ≤ L and
TC4
TC5 L < bN and
TC6 L < bN and L (cid:0)1 − K

(cid:1) < c

N

TI1
TI2

TI3

TI4
TI5

TI6

bN ≤ L and

bN ≤ L and

b + b2

bN ≤ L and
L < bN and

c < b
b ≤ c ≤ b + b2

L (N − 1)

L (N − 1) < c < 2b − b
N ≤ c

N

2b − b
b ≤ c < b + L−b
N

L < bN and

b + L−b

N ≤ c

Complete M − b − L
2
Complete

M − c +

Type

Complete
Complete

Complete

Complete

Incomplete
Incomplete

Incomplete

Incomplete
Incomplete

Incomplete

M − c + c2
2L
c2

M − c +

M − c + b2N

2L(1− K

N )
2L + (c−b)2
2L(1− k+1
N )
(cid:1) + b2N
(cid:0)1 − K+1
N
c2

2L

M − L
2

2L(1− K
N )
(cid:1)
(cid:0)1 − K
N
M − c + c2
L
c2

M − c +

M − c + b2N

M − b − 1
2

N )
2(b+ L−b
2L + (c−b)2
2(b− b
N )
(cid:0)b − b
(cid:1) + b2N
N
c2

2L

M − c +

M − 1
2

2(b+ L−b
N )
(cid:0)b + L−b
(cid:1)

N

37

Table 15: Total effort security game: Total expected game payoffs, not conditioned on other players

Case

c < b

bN ≤ L and b ≤ c

Information

Type

Complete

Complete

L < bN and b ≤ c

Complete

c < b

bN ≤ L and b ≤ c ≤ b + b2

L (N − 1)

bN ≤ L and b + b2

L (N − 1) < c < 2b − b

N

bN ≤ L and 2b − b

N ≤ c

L < bN and b ≤ c < b + L−b
N
N ≤ c

L < bN and b + L−b

c < b
b ≤ c

Incomplete
Incomplete

Incomplete

Incomplete
Incomplete

Incomplete

Naive
Naive

Total Expected Payoff

PbN − c
b c

k=0

P r[k] ·

M − c + c2
2L

(cid:18)

M − c +
(cid:18)

+ PbN −1− N
k=bN − c

+ PN −1

k=bN − N

(cid:16)

P r[k] ·

M − c + b2N

L (c−b)c
b +1c
L (c−b)c P r[k] ·
P r[k] ·
L +1c P r[k] · (cid:0)M − L

M − b − L
2
(cid:18)

M − c +

k=bN − cN

PbN − cN
L c

k=0
+ PN −1

(cid:19)

c2

N )

2L(1− k
2L + (c−b)2
N )
2L(1− k+1
(cid:0)1 − k+1
(cid:1) + b2N
(cid:19)

2L

N

(cid:19)

(cid:17)

c2

N )

2L(1− k
2N (N − k)(cid:1)

M − c + c2
L
c2

M − c +

M − c + b2N

M − b − 1
2

N )
2(b+ L−b
2L + (c−b)2
2(b− b
N )
(cid:0)b − b
(cid:1) + b2N
N
c2

2L

M − c +

M − 1
2

N )
2(b+ L−b
(cid:0)b + L−b
(cid:1)

N
M − c + c2
2
(cid:0)b − b
(cid:1) + b2

N

L

M − b − 1
2

(cid:0)1 − 1

2N

(cid:1)

38

