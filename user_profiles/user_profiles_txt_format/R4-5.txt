RankingBiomedicalPassagesforRelevanceandDiversity:UniversityofWisconsin,MadisonatTRECGenomics2006AndrewB.Goldberggoldberg@cs.wisc.eduDavidAndrzejewskidmandrzejews@wisc.eduJurgenVanGaeljvangael@cs.wisc.eduBurrSettlesbsettles@cs.wisc.eduXiaojinZhujerryzhu@cs.wisc.eduDepartmentofComputerSciences,UniversityofWisconsin,Madison,WI53705MarkCravencraven@biostat.wisc.eduDepartmentofBiostatistics&MedicalInformatics,UniversityofWisconsin,Madison,WI53705AbstractWereportontheUniversityofWisconsin,Madison’sexperienceintheTRECGenomics2006track,whichasksparticipantstore-trievepassagesfromscientiﬁcarticlesthatsatisfybiologists’informationneeds.Anem-phasisisplacedonreturningrelevantpas-sagesthatdiscussdiﬀerentaspectsofthetopic.Usinganoﬀ-the-shelfinformationre-trieval(IR)engine,wefocusedonquerygen-erationandrerankingqueryresultstoen-couragerelevanceanddiversity.Forquerygeneration,weautomaticallyidentifynounphrasesfromthetopicdescriptions,anduseonlineresourcestogathersynonymsasex-pansionterms.OurﬁrstsubmissionusesthebaselineIRengineresults.Wererankthepassagesusingana¨ıveclustering-basedapproachinoursecondrun,andwetestGRASSHOPPER,anovelgraph-theoretical-gorithmbasedonabsorbingrandomwalks,inourthirdrun.Whileouraspect-levelresultsappeartocomparefavorablywithotherpar-ticipants’onaverage,ourquerygenerationtechniquesfailedtoproduceadequatequeryresultsforseveraltopics,causingourpassageanddocument-levelevaluationscorestosuf-fer.Furthermore,wesurprisinglyachievedhigheraspect-levelscoresusingtheinitialrankingthanourmethodsaimedspeciﬁcallyatpromotingdiversity.Whilethissoundsdiscouraging,wehaveseveralideasastowhythishappenedandhopetoproducenewmethodsthatcorrecttheseshortcomings.1.IntroductionTheUniversityofWisconsin,Madisonparticipatedinthe2006TRECGenomicstrack.TheGenomicstrackinvestigateshowwecandesigninformationretrieval(IR)systemsthatreturnadiversesetofresultsbasedonauser’sinformationneed.Theparticipantsaregivenanumberofquestionssuchas“WhatistheroleofPrnPinmadcowdisease?”andareaskedtore-trievepassagesthathighlightasmanyspeciﬁcaspectsofthequestionaspossible,e.g.,thepsychologicalim-pactofPrnP,theneurologicalimpactofPrnP,etc.Theparticipants’submissionsarescoredinthreedif-ferentways.First,thepassage-levelretrievalperfor-manceisfound:thisismeasuredbytheamountofoverlapbetweenreturnedpassagesandpassagesthejudgesdeemrelevant.Next,theaspect-levelretrievalperformanceisscoredbycomputinghowdiversethesetofpassagesreturnedis.Finally,document-levelre-trievalperformanceiscomputedbyessentiallycount-ingthenumberofrelevantdocumentsforwhichapas-sagewasreturned.Ourteamdecidedtostartoutwithoﬀ-the-shelfcom-ponentssuchastheLemurToolkit(Ogilvie&Callan,2001)forourinformationretrievalneedsandfocusoureﬀortsontwootheraspects:querygenerationandrerankingofqueryresults.Thequerygenerationmethodweimplementedusesanin-domainsyntacticparsertoautomaticallyidentifynounphrasesinthetopicdescriptions.Sinceitisnotuncommoninabiomedicalsettingtohavemanyentityphrasesthatrefertothesameconcept,weuseonlineresourcestoexpandourquerieswithsynonyms.Sincethegoalwastocoverasmanydiﬀerentaspectsofthequerytopic,ourthreesubmissionsdiﬀeredinhowwereranktheIndexIndexBuilderPerformedonly onceSplitting documentsinto paragraph filesIndexing (Phase I)Figure1.Thesystem’sindexingcomponent.informationretrievalresultstomaximizethediversityofaspects.OurﬁrstbaselinejustusestheorderinwhichLemurreturnsthepassages.Thesecondbase-linena¨ıvelyclustersthereturnedpassagesandrerankstheresultsbypickingoutoneresultfromeachclus-terinturn.OurﬁnalexperimentusesGRASSHOP-PER(Zhuetal.,2007),anovelgraph-theoreticap-proachtorerankinginformationretrievalresults.Thisalgorithmusesanabsorbingrandomwalktorerankanysetofitemstomaximizebothdiversityandrele-vanceinaprincipledway.TheTRECGenomics2006submissionsarecatego-rizedasbeinggeneratedbyautomatic,interactive,ormanualsystems.Groupsareresponsibleforassign-ingtheirrunstooneofthesecategoriesbasedontheamountofhumaninterventioninvolvedinproducingtheresults.Ourthreerunsfallintotheautomaticgroup,aswedonotprovidefeedbackorﬁne-tuneanypartofthesysteminresponsetothequalityoftheresultsobtained.Oursystemforretrievingbiomedicalpassagesfromacorpusofdocumentsconsistsoffourprimaryphases(Table1).PhaseI,depictedgraphicallyinFigure1,occursonetimeonly(whenthecorpusisﬁrstob-tained),whereasPhasesII–IV,showninFigure2,pro-ceedautomaticallyforeachtopicdescribingauser’sinformationneed.Sections2–5explorethesephasesindepth.Section6presentstheoﬃcialresultsofourthreeruns.Finally,inSection7,wediscussthestrengthsandweaknessesofthecurrentsystem,anddescribeareasforfuturework.2.Indexing(PhaseI)WedecidedtouseanexistingIRtoolkittohan-dleourindexingandqueryexecutionneeds.Specif-ically,weusedanIndriindexbuiltusingtheLemurToolkit(Metzleretal.,2004;Ogilvie&Callan,2001).Indricombineslanguagemodelingandinferencenet-Table1.Fourphasesofoursystem.IIndexingPhase•Splitalldocumentsintoparagraphs•IndexparagraphsusingIRengineIIQueryGenerationPhase•Obtainatopicdescription•Identifynounphrases(NPs)•Findsynonymsusingonlineresources•BuildstructuredqueryIIIRetrievalPhase•ExecutequeryusingIRengine•Retrieverankedparagraphs•NarrowparagraphsintopassagesIVRerankingPhrase•Rerankpassagesforrelevance/diversityworksapproachestoinformationretrievalandprovidesapowerfulstructuredquerylanguage.1Lemurpro-videsaframeworkinwhichtobuildanindexandusetheIndrisearchengine.Beforebuildingtheindex,theentirecorpusofroughly160,000full-textarticlesfrom59journalswasbro-kenupintoseparateparagraphﬁlesusingthemax-imumlegalboundariesdeﬁnedbytheTREC-provided“legalspans”ﬁle.Thatis,eachindividualﬁlecorre-spondstoexactlyonemaximumlegalpassage.TheseseparateparagraphﬁleswerethenindexedbyLemurtoformanIndrirepository.Notethatwedidnotper-formstemmingorstoppingduringindexing.Thepre-processingstepofseparatingparagraphsintoseparateﬁleshassomenoteworthyconsequences.First,weignoreanydocument-levelinformation.Sep-arateparagraphﬁlesfromthesamedocumentarehan-dledcompletelyindependently.Second,thecollectionofseparateparagraphﬁlescontainsmanyﬁleswhichcorrespondtonon-passagesectionsofthearticle,suchasreferences,keywords,andacknowledgments.Emptyorotherwisespuriouspassageswillbeignoredbytheinformationretrievalsystem,butsomenon-passageﬁlesmayberankedhighlybyourinformationretrievalsystem.Inparticular,ﬁlescorrespondingtothekey-wordssectionofanarticlecanberankedveryhighlyduetotheirhighdensityofrelevantkeywords,but1AdetaileddescriptionoftheIndriretrievalmodelcanbefoundathttp://ciir.cs.umass.edu/∼metzler/indriretmodel.html.AARankingFinalBB1)A2)BCCCRerankSystemExpansionParsingQueryStructuredQuery Generation (Phase II)Reranking (Phase IV)Retrieval (Phase III)3)BCAIndexEngineIRQPerformed once for each query QPassage NarrowingFigure2.Thesystem’squeryingcomponents.thesepassageswouldprobablynotbejudgedasrele-vant.3.QueryGeneration(PhaseII)3.1.TopicParsingOneofthegoalsinoursystemdesignistobeabletotaketopicsentencesasinputandautomaticallygen-eratestructuredIRqueriesfromEnglishnaturallan-guagetext.Todothis,weemployanin-domainsyn-tacticparsertoidentifynounphrases(NPs),andusethesephrasesastermsinthequery.Considerasanexampletopic160:WhatistheroleofPrnPinmadcowdisease?Thehighlightedwordsareparsedasnounphrases.First,topicsentencesaretokenizedandtaggedforpart-of-speech(POS)usingamodiﬁedBrillTagger(Brill,1995)trainedontheGENIAcorpus(Kimetal.,2003).Second,POSoutputisfedthroughashallowphrasechunkerimplementedwithaconditionalran-domﬁeld(Laﬀertyetal.,2001)usingtheMALLETtoolkit2trainedontheCoNLL-2000corpus(Sang&Buchholz,2000)usingwords,POS,andsomeortho-graphicpropertiessuchascapitalizationasfeatures.Wequalitativelycomparedtheresultsofthissimpletwo-phasechunkeronthe28querytopicstothere-sultsofare-trainedCharniakParser(Charniak,1997)providedbyMattLeaseatBrownUniversityforuseinthisyear’sTRECtask,aswellastheStanfordParser(Klein&Manning,2003).OursimplechunkerappearstoproducemoresoundNPsandrunsmuchfasteraswell.2http://mallet.cs.umass.edu3.2.QueryExpansionAfterobtainingalistofnounphrasesinatopicde-scription,thenextstepinoursystemistoexpandthephrasesintolistsofsynonymsandrelatedterms.Beforedoingso,weapplyasmallsetofautomatedheuristicsinanattempttocorrectanyparsingerrorsandﬁlteroutextraneousphrasesandstopwords.WeusethestoplistfromtheCornellSMARTproject,3butdonotﬁlteroutsingleletterstopwords,asthesemayhavebiologicalsigniﬁcance.Wealsoincludeasstopwordsasmallnumberofcommonbiomedicaltermsthatappearedinpastyears’topicdescriptions(e.g.,role,method,gene,etc).NotethatifastopwordisdetectedinthemiddleofanNPchunk,weremovethewordandformtwoNPsfromtheremainingwords(e.g.,aconjunctiveNPlike“HNF4andCOUP-TF1”issplitinto“HNF4”and“COUP-TF1”).Returningtotheexampleoftopic160,theﬁrsttwoNPs“What”and“therole”areignoredbecausetheycontaincom-monwordslikelytoappearinanyscientiﬁcquery.Nowthatwehaveasetofpresumablysigniﬁcantnounphrases(“PrnP”and“madcowdisease”),weexpandthemintosynonymlistsbysearchingtheMeSH(Med-icalSubjectHeading)database.4WeissueeachNPasaquerytotheMeSHWebserviceandgatherthetermsassociatedwiththetoptwoMeSHheadingsreturned.WecombinethesetermswiththeoriginalNPtoformapreliminarysynonymlist.Foreachiteminthislist,wethenapplyadditionallexicographicheuristicstotrans-formthetermsintophraseswhicharemorelikelytoappearasexactphrasematchesinadocument.Specif-ically,weremoveanythingaftertheﬁrstcomma(sincethisisusuallysomemodiﬁerwhichwouldnotappearinthismannerinanactualarticle).Forexample,oneoftheexpansiontermsfor“PrnP”is“prionprotein,3ftp://ftp.cs.cornell.edu/pub/smart/english.stop4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=meshhuman,”whichweshortento“prionprotein.”Wealsoremoveparentheticalstrings,sincethesearetypicallyothertermsalsoreturnedfromtheMeSHsearchandwillappearinourlistseparately.Finally,weremoveallpunctuation,sinceIndri/Lemurignorespunctua-tionduringindexing.BasedonatechniqueusedinMetzleretal.(2004),wealsoincludeinoursynonymlistsallrareunigramandbigramswithintheoriginalNP.Wedeﬁnerareunigramsasthosenotappearinginalistofthetop2000mostfrequentwordsintheBrowncorpus.Inthefuture,wemightconsiderusingamorebiologically-relevantcorpusforsuchstatistics.Applyingthisex-pansiontechniqueto“madcowdisease”addsthebi-grams“madcow”and“cowdisease,”butnotthecom-monunigrams“mad,”“cow,”or“disease.”However,foraspecializedphraselike“hypocretinreceptor2,”weobtain“hypocretin,”“hypocretinreceptor,”and“receptor2.”Asaﬁnalexpansion,wealsoaddcopiesofwordswithanytrailing‘s’removed,inanattempttoconvertpluralstosingulars.Thisisacrudeheuristic,butitcannothurt—havinganextrasynonymwhichisneverfoundinthecorpuswillnotaﬀectourretrievalresults.Fortopic160,theaforementionedexpansiontech-niquesproducethefollowingsynonymlists:•PrnP:infectiousamyloidprecursorprotein,prnpprotein,chromosome20amyloidprecursorpro-tein,prionproteinp2730,gssprotein,prnppro-tein,sincprotein•madcowdisease:encephalopathy,bovinespongiformencephalopathy,bse,bses,encephali-tis,encephaliti,bovinespongiformencephalitis,madcowdiseases,spongiformencephalopathy,madcow,cowdisease3.3.BuildinganIndriStructuredQueryWeutilizeseveraloftheIndristructuredquerylan-guageoperatorsinbuildingqueriesforLemurtoex-ecute.WereferinterestedreaderstotheURLlistedearlierforadetailedexplanationofalltheoperatorsandhowtheyareevaluatedtocomputequerylikeli-hoodscores.Wedescribeourqueryconstructionthrougharun-ningexampleusingtopic160.Webeginatthelevelofformingaquerytermbasedonasinglesynonymlist.Speciﬁcally,weforma#syntermthattreatseachoftheexpressionsitcontainsassynonyms.The#syntermcontainseachiteminthesynonymlistasanexactphraseviathe#1operator.Thismeanswelookfordocumentsthatcontainatleastoneofthesynonymsasanexactmatch.Forexample,werep-resentoneofthetopic-160synonymlistsasfollows:#syn(#1(madcowdisease)#1(BSE)#1(BovineSpongiformEncephalopathy)#1(BovineSpongiformEncephalitis)...)Afterformingtermscorrespondingtoeachsynonymlist,wecombinethesynonymlistsusingthe#bandop-erator,whichrequiresallofitsoperandstobepresent.Forexample,wejointhetopic-160synonymlistsasfollows:#band(#syn(#1(madcowdisease)#1(BSE)...)#syn(#1(PrnP)#1(prionprotein)...))Sofar,ourquerysaysthatweneedtoﬁndatleastonesynonymforeachimportantnounphraseinthetopic.The#bandrequireseach#synto“returntrue,”butthissimplymeansoneofthecontainedphrasesmustbefound.Finally,weemployIndri’s#combineand#filreqop-erators.UnlikeasimplebooleanAND,whichgivesaresultoftrueorfalse,the#combineoperatorgivesahigherscoretoresultsthatcontainmoreofitsoperands.The#filreqoperatorselects(ﬁlters)docu-mentsbasedononesetofcriteria(requirements),andthenranksthemaccordingtoanothersetofcriteria.Weassemblethesepiecesasfollows:weuse#filreqtoﬁrstselectdocumentssatisfyingthe#bandcriteriadescribedabove,andthenranktheresultsaccordingtoaquerytermusing#combine.The#combinetermresemblesthe#bandterm,butlacksthe#synoper-ators,thusﬂatteningthesynonymlists.WeendupwithaqueryofthegeneralformshowninFigure3.#filreq(#band(#syn(#1(a)#1(b))#syn(#1(c)#1(d)))#combine(#1(a)#1(b)#1(c)#1(d)))Figure3.GeneralformoftheIndristructuredqueriesex-ecutedbyLemurtolocaterelevantparagraphs.TheendresultisthatLemur/Indrifetchesallthedoc-umentsmeetingthestricter#bandcriteria,butthenranksthemaccordingtohowmanymatchingtermsarefound.Ifweusedonlythe#bandquery,Lemur/Indriwouldessentiallyrankthedocumentsinincreasinglengthorder(duetoshorterdocumentshavinghigherlikelihoodscoresthanlongerones).4.Retrieval(PhaseIII)Afterconstructingqueriesasdescribedabove,weex-ecutethemagainsttheIndriindexbuiltinPhaseI.Thisproducesarankedlistofparagraphﬁlessatisfy-ingourquery,whichwemapbacktobyteoﬀsetsandlengthswithintheoriginaldocuments.Wethenad-justpassageboundariestoincludeonlysentencesbe-tweentheﬁrstandlastoccurrencesofkeytermsfromthequery.Speciﬁcally,welocatethesetofconsecu-tivesentencesmaximallyspanningallofthematchedqueryterms.Forexample,ifaparagraphcontainssentencesA,B,C,D,andE,andsentenceBandDcontaintermsinourquery,thenweformapassagecomprisedofsentencesB,C,andD.Considertheconcreteexampleoftopic160.TheﬁrstresultreturnedbyLemuristhefollowingparagraph,inwhichwehaveomittedHTMLmarkupandhighlightedthenarrowedpassageinboldface:InDecember1984aUKfarmercalledaveterinarysur-geontolookatacowthatwasbehavingunusually.Sevenweekslaterthecowdied.Earlyin1985morecowsfromthesameherddevelopedsimilarclinicalsigns.InNovember1986bovinespongiformencephalitis(BSE)wasﬁrstidentiﬁedasanewdisease,laterreportedintheveterinarypressasanovelpro-gressivespongiformencephalopathy.LaterstillthecausalagentofBSEwasrecognizedasanab-normalprionprotein.SincetheoutsetthestoryofBSEhasbeenbesetbyproblems.TheﬁrstthreesentenceslackanyexactphrasesfromourIndristructuredquery.5Thenextthreesentences,however,eachcontaintermsandphrasesfromourquery(e.g.,“BSE”and“prionprotein”).Thus,wereturntheboldfacedpassage,whichisthelongestspanofcompletesentencescoveringallofthematchedterms.5.Reranking(PhaseIV)Giventhenarrowedpassagesobtainedinthepreced-ingphase,wenextoptionallyrerankthemtopromotediversityamongtherelevantpassagesandtargetthe5Ourquerycontainedtheword“cow,”butonlyaspartoflargerphrases.aspect-levelevaluationmetrics.5.1.BaselineRankingOurﬁrstsubmittedrunsimplyliststhenarrowedpas-sagesintheorderinwhichtheircontainingparagraphswerereturnedbyLemur.5.2.ClusteringOursecondrunna¨ıvelyattemptstoensuresomeamountofaspectdiversitythroughaprocedurethatbeginsbyperforminghierarchicalclusteringonpas-sagebag-of-wordsvectors,usingacosine-baseddis-tancemetricandreturning,somewhatarbitrarily,10clusters.Undertheassumptionthatclustersgrouptogetherpassagesaddressingthesametopic,weinter-leaveresultsfromeachclustertoformthererankedre-sults.Weconsidertheclustersinturn,basedontheiraverageinitialLemurranking.Webeginbychoos-ingtheclusterwhosepassageswererankedhighestbyLemur.Wethenremovethehighestrankedamongthemastheﬁrstresult.Next,weselectthesecondbestclusterandremoveitshighestrankedresult.Thisprocessrepeatsuntilallofthepassagesareremovedfromalloftheclusters.Thehopeisthateachclusterrepresentsadistinctas-pect,andtheinterleavingprocessensuresthatadi-versesetofaspectsisrepresentedhighintherankedlist.Forexample,intopic160,thecluster-basedrerankingrearrangedtheLemurresultstoproducethefollowingtopﬁvepassages(identiﬁedbyLemurrank):1,9,27,3,2.Thismeanstheﬁrstresultisthesame,thesecondresultwasninthaccordingtoLemur,thethirdresultwas27thaccordingtoLemur,etc.Spotchecksaftersubmittingtheresultsrevealthatthissometimesproducesmorediversehighly-rankedresults,butoftendoesnot.Theoutcomestronglyde-pendsonhowreliablethedistancemetricis,andthequalityoftheresultsfromLemur.Ifsomeresultsareirrelevant,theymaygetrankedhighlybecausetheyareaboutacompletelydiﬀerenttopicthanthetrulyrelevantresults.Thismethodmighthaveperformedbetterifwecouldhavetunedthenumberofclustersandselectedadistancemetricbasedontrainingdata.5.3.RankingforAspectDiversityOurthirdandﬁnalrunusestheGRASSHOPPER(GraphRandom-walkwithAbsorbingStateSthatHOPsamongPEaksforRanking)algorithmtoreranktheretrievedpassagesastopromotediver-sity.Existingmethodstoimprovediversityinrankingincludemaximummarginalrelevance(MMR)(Car-bonell&Goldstein,1998),cross-sentenceinforma-tionalsubsumption(Radev,2000),mixturemod-els(Zhangetal.,2002),subtopicdiversity(Zhaietal.,2003),diversitypenalty(Zhangetal.,2005),andoth-ers.Thebasicideaistopenalizeredundancybylow-eringanitem’srankifitissimilartoitemsalreadyranked.Thesemethodsoftentreatrelevancerank-inganddiversityrankingseparately,sometimeswithheuristicprocedures.GRASSHOPPERisanalternativetoMMRandvari-ants,withaprincipledmathematicalmodelandstrongempiricalperformanceonartiﬁcialdata.Acompletedescriptionofthealgorithm,andsuccessfulresultsintextsummarizationandsocialnetworkanalysis,ispre-sentedelsewhere(Zhuetal.,2007).Forthecurrenttask,thealgorithmranksasetofpassagessuchthat:1.Ahighlyrankedpassageisrepresentativeofalo-calgroupintheset,i.e.,itissimilartomanyotheritems.Ideally,thesegroupscorrespondtodiﬀerentaspects.2.Thetoprankedpassagescoverasmanydistinctgroupsaspossible.3.TheinitialrankingfromLemurisincorporatedaspriorknowledge.Importantly,thealgorithmachievestheseinauniﬁedframeworkofanabsorbingMarkovchainrandomwalk.Thekeyideaisthefollowing:Wedeﬁnearandomwalkonagraphoverthepassages.Passageswhichhavebeenrankedsofarbecomeabsorbingstates.Theseabsorbingstates“dragdown”theimportanceofsim-ilarunrankedstates,thusencouragingdiversity.Themodelnaturallybalancescentrality,diversityandtheprior.AsinputtoGRASSHOPPER,weuseafullycon-nectedgraphinwhichstatesrepresentpassages.Theedgeweightbetweentwopassagestatesisbasedonthecosinesimilarityofthepassagesusingtheirbag-of-wordsrepresentations.Edgesbetweenstatesrepre-sentingpassageswithhighcosinesimilarityreceivealargeweight.Aftertheweightmatrixisnormalizedtoformastochasticmatrix,thistranslatestoahighprobabilitythattherandomwalkwillmovefromonepassagetoanothersimilarpassage.Ifapassagegetsrankedandbecomesanabsorbingstate,thesimilarpassageswillnotberankedagainforseveralitera-tionsbecauseawalkpassingthroughthemwillgetabsorbed.GRASSHOPPERendsupreorderingthetopic160re-sultsconsiderably,placingthemostcentralpassage(i.e.,similartothemostotherpassages)atthetopofthelist.Thetop5rankedpassagesarenow141,16,11,Table2.Document,passage,andaspectmeanaveragepre-cisionscoresforthethreeUniversityofWisconsin,Madisonsubmissions.RunDocumentPassageAspectLemurranking0.23680.01880.1516Clustering0.20300.01370.1319GRASSHOPPER0.22080.01590.141115,35.ThismeansthemethodplacedLemur’s141strankedpassageastheﬁrstpassageinthererankedlist.Liketheclusteringapproach,thismethodispronetohighlyrankingirrelevantpassagesthatappeardi-verse(i.e.,notsimilartootherhighlyrankedpassages).Withouttrainingdataindicatingtheaspectsassoci-atedwithexamplequeryresults,wedidnothaveagoodwaytoevaluatediﬀerentgraphtopologiesoredgeweightingschemes.Asaresult,itispossiblethatourgraphdoesnotrepresentthetypeofsimilarityrela-tionships(intermsofaspectpresence)thatweassumeexist.6.ResultsWenowpresenttheresultsofourrunsintermsofthemeanaverageprecision(MAP)scoresforthedoc-ument,passage,andaspectlevels(Table2).Meanaverageprecisionvaluesaredeterminedbyﬁrstcalcu-latingprecisionvaluesthatrepresentaveragesacrosssomeunitoftext(passage,aspect,ordocument)foreachtopic,andthencomputingtheaverageofthesevaluesacrosstopics.Whileitappearsthatourdocu-mentandpassagescoresareonlymediocre,theaspectscoresforallthreerunsappearcompetitive(comparedtothemeanofthemedianscoresobtainedbyallauto-maticruns).Whatsurprisesusmostinourresultsisthattheﬁrstrun(Lemurranking),whichdidnotdoanythingspeciﬁctopromoteaspectdiversity,actuallyachievedhigheraspect-levelscores.Wearepleasedtoseethatthemoretheoreticallymotivatedthirdap-proachusingGRASSHOPPERdidbetterthantheadhocclustering-basedmethod.7.DiscussionandConclusionsWesuspectthatthepooroveralldocumentandpas-sageresultsareduetoinadequatequerygenerationforseveraltopics.Insomecases,ourtopicparsingandexpansiontechniquesfailedtoproduceasetofexactphrasesthatcouldrealisticallybefoundinjournalar-ticles.Consequentially,weobtainedfewornoresultsforsometopics.Onesolutionwouldbetorelaxtheexactphraserequirement,usingIndri’sproximityop-erators,whichwouldonlyrequirethetermstoappearwithinsomewindow.Thisrelaxationcouldbeappliedautomaticallyasafall-backoptionincaseswheretheinitialqueryproducesfewerthanaspeciﬁednumberofresults.Ofcourse,thecorpusmayonlycontainahandfulofrelevantpassages,inwhichcasewemayintroducefalsepositiveresults.Abetteroptionwouldbetoreﬁnetheparsingtech-niqueandconsultadditionalresourcesinsearchofvalidsynonymsandrelatedtermslikelytoco-occurwiththetermsinthetopicdescription.Somere-sourcesweconsideredusingaretheGeneOntology,theUniﬁedMedicalLanguageSystem(UMLS)Metathe-saurus,andtheStanfordBiomedicalAbbreviationServer.6Amoretraditionalapproachtoqueryexpan-sionusingrelevancefeedbackmightalsobebeneﬁcial.Inanycase,wecouldusequerytermweightstorep-resentourconﬁdenceinthevariousexpansiontermsdependingontheirsource.Forthetopicsforwhichwedidobtainnumerousre-sults,poorprecisionscoressimplyindicatesmanyofthereturnedpassagesweredeemedirrelevant.Incaseswherewegeneratedmanyplausibleexpansionterms,weoftenreturnedkeywordsorreferencessectionsaspassages.Thesearevalidspansandloadedwithmean-ingfulterms,butitisunlikelythatjudgeswouldhavemarkedthemasrelevant.Wearestillsearchingforanexplanationastowhyourrerankingmethodsactuallyhurtaspectdiversity.Onepossibilityisrelatedtotheaboveproblemsinquerygeneration:wesimplydidnothaveagoodsetofinitialpassagestorerank.Aspreviouslydiscussed,boththeclusteringandGRASSHOPPERapproachesarepronetoplacingirrelevant(andthusdiverse)pas-sageshighintherankedlist.Assumingwedidhavemanyrelevantpassages,theproblemwiththecluster-ingmethodliesinalackofmeaningfulclustersthatgrouppassagesbyaspect.Ofcourse,thenumberofclustersisalsocritical,whichprobablyshoulddependonthespeciﬁcsetofpassagestobereranked.Givenrelevantpassages,GRASSHOPPERstronglydependsonasensiblesimilaritygraphthatactuallycaptureswhetherpassagessharethesameaspects.Withoutaspect-similarityknowledgeencodedinourgraph,thisalgorithmwillalsofailtoproduceausefulreranking.Tocorrecttheseproblems,weplantoexperimentwithalternativepassagerepresentations,speciﬁcallyterm6http://abbreviation.stanford.edufrequency–inversedocumentfrequency(TF–IDF)vec-tors,wheretheIDFiscomputedbasedonlyonthecurrentsetofretrievedpassages.Webelievethismayleadtoacosinesimilaritymeasurewithgreaterpowerindistinguishingpassagesbasedonaspects.Inaddi-tion,wemaytryothersimilaritymeasures,suchastheKullback-Leiblerdivergencebetweenpassagelanguagemodels(Zhaietal.,2003).Wealsobelieveapplyingathresholdtothesimilaritymeasureinordertocreateasparsergraphmayleadtoimprovedresults.Finally,weplantostudythebehaviorofourrerankingalgo-rithmswhenartiﬁciallygivenonlytrulyrelevantpas-sages.Separatingthererankingphasefromthequeryandretrievalphaseswillhelplocalizethestrengthsandweaknessesofthecurrentsystem.Weshouldpointoutthatalloftheaboveproblemscouldpartlyarisefromapoorindexingstrategy.In-dexingcompletedocumentscouldbemoreinformativethanindexingindividualparagraphs.Whileahumanjudgemaybeabletodeterminethataparagraphisrelevantwithoutseeingtheentirearticle,thisdeter-minationmaydependonsubtleanaphoraresolutionthattheIRenginecannotperform.Forexample,ifaparagraphbegins“Thediseaseaﬀectscows’brainsby...”butneverexplicitlysays“madcow”oroneofthephrasesinourquery,thentheparagraphwillnotbereturnedasapossibleresult.Presumably,though,thearticleincludedthecompletephrase“madcowdis-ease”or“BSE”inapreviousparagraphorthetitleofthearticle.Thus,theabilitytosearchatthepara-graphlevel,whilemakinguseofdocument-wideinfor-mation,isatopicwehopetoexploreinthefuture.WehavepresentedthedetailsofoursystemandthreerunsfortheTRECGenomics2006track.Usinganex-istingIRengineandquerylanguage,weconcentratedondevelopingautomatedquerygenerationtechniques,aswellasmethodsforrerankingresultstoboostdi-versityinthehighrankedpassages.Themethodspre-sentedshowpromise,butstillexhibitcertainweak-nessesthatweplantoaddressinfuturework.AcknowledgmentsThisworkwassupportedinpartbyaWisconsinAlumniResearchFoundation(WARF)grant.AGwassupportedbyaUW-MadisonGraduateSchoolFellow-ship.DAwassupportedbyanNLMtraininggranttotheComputationandInformaticsinBiologyandMedicineTrainingProgram(NLM5T15LM007359).BSandMCweresupportedinpartbyNSFgrantIIS-0093016.ReferencesBrill,E.(1995).Transformation-basederror-drivenlearningandnaturallanguageprocessing:Acasestudyinpart-of-speechtagging.ComputationalLin-guistics,21,543–565.Carbonell,J.,&Goldstein,J.(1998).TheuseofMMR,diversity-basedrerankingforreorderingdoc-umentsandproducingsummaries.SIGIR1998:Proceedingsofthe21stAnnualInternationalACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval.Charniak,E.(1997).Statisticalparsingwithacontext-freegrammarandwordstatistics.Pro-ceedingsofthe14thNationalConferenceonArti-ﬁcialIntelligence.MenloPark,CAUSA:AAAIPress/MITPress.Kim,J.,Ohta,T.,Teteisi,Y.,&Tsujii,J.(2003).GENIAcorpus-asemanticallyannotatedcorpusforbio-textmining.Bioinformatics,19,i180–i182.Klein,D.,&Manning,C.(2003).Fastexactinferencewithafactoredmodelfornaturallanguageparsing.AdvancesinNeuralInformationProcessingSystems(NIPS),15.Laﬀerty,J.,McCallum,A.,&Pereira,F.(2001).Con-ditionalrandomﬁelds:Probabilisticmodelsforseg-mentingandlabelingsequencedata.ProceedingsoftheInternationalConferenceonMachineLearning(ICML)(pp.282–289).MorganKaufmann.Metzler,D.,Strohman,T.,Turtle,H.,&Croft,W.(2004).IndriatTREC2004:Terabytetrack.Pro-ceedingsoftheTextREtrievalConference.Ogilvie,P.,&Callan,J.P.(2001).Experimentsusingthelemurtoolkit.ProceedingsoftheTextREtrievalConference.Radev,D.(2000).Acommontheoryofinformationfusionfrommultipletextsources,stepone:Cross-documentstructure.Proceedingsofthe1stACLSIGDIALWorkshoponDiscourseandDialogue.Sang,E.F.T.K.,&Buchholz,S.(2000).IntroductiontotheCoNLL-2000sharedtask:Chunking.Proceed-ingsoftheConferenceonNaturalLanguageLearn-ing(CoNLL)(pp.127–132).Lisbon,Portugal.Zhai,C.,Cohen,W.W.,&Laﬀerty,J.(2003).Be-yondindependentrelevance:Methodsandevalu-ationmetricsforsubtopicretrieval.SIGIR2003:Proceedingsofthe26thAnnualInternationalACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval.Zhang,B.,Li,H.,Liu,Y.,Ji,L.,Xi,W.,Fan,W.,Chen,Z.,&Ma,W.-Y.(2005).Improvingwebsearchresultsusingaﬃnitygraph.SIGIR2005:Proceedingsofthe28thAnnualInternationalACMSIGIRConferenceonResearchandDevelopmentinInformationRetrieval.Zhang,Y.,Callan,J.,&Minka,T.(2002).Noveltyandredundancydetectioninadaptiveﬁltering.SIGIR2002:Proceedingsofthe25thAnnualInternationalACMSIGIRConferenceonResearchandDevelop-mentinInformationRetrieval.Zhu,X.,Goldberg,A.B.,VanGael,J.,&Andrzejew-ski,D.(2007).Improvingdiversityinrankingusingabsorbingrandomwalks.HumanLanguageTech-nologies:ProceedingsoftheAnnualConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics(NAACL-HLT).