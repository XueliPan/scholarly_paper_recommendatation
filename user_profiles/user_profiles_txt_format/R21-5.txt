15th IEEE Real-Time and Embedded Technology and Applications Symposium

Lightweight Modeling of Complex State Dependencies

in Stream Processing Systems

Anne Bouillard1

Linh T.X. Phan2

Samarjit Chakraborty3

1ENS Cachan (Bretagne) / IRISA. Email: Anne.Bouillard@bretagne.ens-cachan.fr

2Department of Computer Science, NUS. Email: phanthix@comp.nus.edu.sg

3Institute for Real-Time Computer Systems, TU Munich. Email: samarjit@rcs.ei.tum.de

Abstract

Over the last few years, Real-Time Calculus has been
used extensively to model and analyze embedded systems
processing continuous data/event streams. Towards this,
bounds on the arrival process of streams and bounds on
the processing capacity of resources serve as inputs to
the model, which are used to calculate end-to-end delays
suffered by streams, maximum backlog, utilization of re-
sources, etc. This “functional” model, although amenable
to computationally inexpensive analysis methods, has lim-
ited modeling capability. In particular, “state-based” pro-
cessing, e.g. blocking write – where the processing depends
on the “state” or ﬁll-level of the buffer – cannot be mod-
eled in a straightforward manner. This has led to a num-
ber of recent proposals on using automata-theoretic models
for stream processing systems (e.g. Event Count Automata
[RTSS 2005]). Although such models offer better modeling
ﬂexibility, they suffer from the usual state-space explosion
problem. In this paper we show that a number of complex
state-dependencies can be modeled in a lightweight man-
ner, using a feedback control technique. This avoids explicit
state modeling, and hence the state-space explosion prob-
lem. Our proposed modeling and analysis therefore extend
the original Real-Time Calculus-based functional modeling
in a very useful way, and cover much larger problem domain
compared to what was previously possible without explicit
state-modeling. We illustrate its utility through two case
studies and also compare our analysis results with those
obtained from detailed system simulations (which are sig-
niﬁcantly more time consuming).

1 Introduction

The escalating complexity of stream processing systems
has prompted the need for modeling and analysis techniques
that go beyond those traditionally studied in the literature.
Many of these systems process irregular data/event streams
and rely on highly dynamic resource management policies

α′

B

β
2

 β′
2

α″

input stream 
α

PE1

α′

PE2

α″

PEn

output stream 
α

out

Figure 1. An example system model.

that cannot be modeled using standard periodic/sporadic
event models and ﬁxed-priority or deadline-based schedul-
ing policies.

In this context, the Network Calculus framework [4, 7]
– which was originally proposed for modeling communi-
cation networks – has been extensively adapted in recent
years for the modeling and analysis of embedded systems
processing continuous data and event streams (e.g., see
[5, 22, 24, 26]). The resulting framework (often referred
as Real-Time Calculus or RTC in the literature) is designed
to model and analyze heterogeneous real-time systems in a
compositional manner. The key feature of this framework
is its use of count-based abstraction to model the timing
properties of the input streams, as well as the availability of
the resources. In particular, the timing properties of a data
stream are speciﬁed as a constraint on the maximum and
minimum number of data items that may arrive over every
time interval of length Δ. A collection of such constraints
for different values of Δ are captured as functions αl(Δ) and
αu(Δ) that denote the lower- and upper-bound on the data
arrival process. In other words, αl(Δ) and αu(Δ) specify the
minimum and maximum number of items that may arrive
within any time interval of length Δ. Clearly, these func-
tions will admit a rich collection of arrival sequences. Stan-
dard event models such as periodic, sporadic and periodic
with jitter turn out to be special cases of such a speciﬁca-
tion. Resource availability can also be speciﬁed in a similar
fashion. Here, βl(Δ) and βu(Δ) shall specify the minimum
and maximum number of items that can be processed by
a resource within any time interval of length Δ. Given the

1080-1812/09 $25.00 © 2009 IEEE
DOI 10.1109/RTAS.2009.27

195

functions α, denoting (αl, αu), and β denoting (βl, βu),
it is possible to compute using purely algebraic techniques,
the bounds on system properties such as the maximum de-
lay suffered by the stream and the maximum backlog of data
items in front of the resource. Further, it is also possible to
, αu(cid:2)) which denotes bounds on the tim-
compute α(cid:2) = (αl
ing properties of the processed stream. α(cid:2) may now serve as
the input to the next resource which further processes this
stream, and the output from which may be denoted as α(cid:2)(cid:2).
This is repeated for all resources until the timing properties
of the output stream αout are computed (see Figure 1).

(cid:2)

Figure 1 shows an architecture consisting of n resources
PE1, . . . , PEn, which process an input stream sequentially.
Each PEi has an input buffer to store incoming data items
waiting to be processed. The service rendered by each PEi
(cid:2)
is constrained by βi. Similar to α(cid:2), the service function βi
that bounds the remaining resource which can be used to
process other data streams. Besides buffer requirements and
the delay incurred by the input stream at each resource PEi,
various other performance characteristics such as the uti-
lization of each resource, output jitter, the maximum end-
to-end delay and the total buffer requirement in the system
can also be obtained from the bounds α and αout.

1.1 Our contributions

Owing to the functional nature of RTC, analysis in this
framework involves algebraic manipulations which allows
for highly efﬁcient computation of system properties in a
fully compositional manner. However, modeling of com-
plex state dependencies is awkward; common scenarios
such as the one where the service offered by a resource de-
pends on the ﬁll-level of a buffer cannot be modeled easily.
In constrast, ﬁne-grained modeling of state information, e.g.
using timed automata [1, 9] or event count automata [6] of-
ten leads to state space explosion when applied to realistic
problems.

In this paper, we present a technique to model a variety
of complex state dependencies in the existing RTC frame-
work with a feedback control mechanism without resorting
to explicit state-space modeling. Firstly, this technique sig-
niﬁcantly enhances the modeling power of the framework
while sidestepping the problems associated with state-space
modeling. Secondly, our model of a system is a composition
of multiple abstract components with each component cap-
turing all the relevant state-dependencies as well as process-
ing semantics. The properties of these components can be
computed functionally using our results and thereby attain a
high efﬁciency. Thirdly, our technique enables state-based
scheduling policies to be modeled and efﬁciently analyzed
in a modular manner.

Through case studies, we illustrate how our method can
be seamlessly integrated into the current RTC framework,
and at the same time we show the effects of capturing state-

dependencies on the accuracy of the analysis. We also pro-
vide experimental validation of our analysis method against
simulation. The analysis results obtained from both meth-
ods match well with each other, however our analysis is sig-
niﬁcantly faster than simulation.

1.2 Related work

The ﬁrst line of related work is concerned with develop-
ing task and event models that generalize classical periodic
or sporadic event models, which assume ﬁxed execution
times for tasks. Towards this, timed automata and related
automata-theoretic formalisms have been recently used in
various setups to model and analyze task scheduling prob-
lems (e.g., see [1, 8, 9]). To overcome the lack of state-
based modeling in the RTC framework, we had proposed
event count automata (ECAs) [6] that retain the count-based
abstraction used in RTC. Although automata-based mod-
els are much more expressive and capable of representing
a wide variety of state-dependencies, they suffer from the
state explosion problem and can become inefﬁcient when
analyzing large system architectures.

RTC has also been extended lately to model complex
event patterns and task activation schemes. For example,
[10] presented a method to model conditional blocking-
read on an input buffer.
In particular, it modeled tasks
that are triggered by events on multiple input streams using
AND/OR-activation, where an OR-task is triggered when-
ever an event is available on either of the input streams
and an AND-task is only activated when there is at least
one event from each stream. [13] proposed a way to com-
pute delay and output arrival functions of data streams that
are split and joined during the system execution following
the OR-activation and in-order activation semantics, while
taking into account correlations in data streams and data
distribution based on different types of delay. Correlation
between jitter and response time of individual events were
also considered in [12]. Analysis methods of more complex
scheduling policies such as non-preemptive and scenario-
aware scheduling of tasks were studied in [10] and [11] re-
spectively. Timing properties of hierarchical event streams
that are generated by the communication stack are modeled
in [19]. These proposed techniques do not handle state-
modeling and control-feedback dependencies though.

The back-pressure effect with ﬁnite buffer capacities has
been studied in the context of data ﬂow graphs [15]. For
instance, in [27], an algorithm for computing the buffer ca-
pacities that satisfy throughput constraints was presented.
Analysis of self-time scheduling for multirate data ﬂow
with ﬁnite buffer capacities was considered in [16]. Also,
back-pressure was used in [23] as a mechanism to allow a
semantics preserving implementation of synchronous mod-
els on Loosely Time Triggered Architectures. These meth-
ods however are not applicable into our setting.

196

There have also been hybrid frameworks that combine
various analysis methodologies. For example, [21] uniﬁed
the SDF [15] and SymTA/S[2] into a single framework that
is able to model data-dependencies using SDF and to ab-
stract event streams using SymTA/S. SymTA/S and RTC
have been merged in [14] to capture more complex inter-
actions with high accuracy. RTC and ECA can also be in-
tegrated using the interfacing technique provided in [18] to
achieve higher accuracy than using RTC alone while be-
ing more efﬁcient than using ECA alone. The method we
propose here can be plugged into the integrated RTC-ECA
framework to further increase the efﬁciency of the analysis,
since we can now use RTC to analyze a number of state-
dependent components in the system instead of using ECAs,
which will in turn reduce the total analysis time.

1.3 Organization of the paper

In the next section we describe the basic concepts of
the RTC framework.
In Section 3 we present our analy-
sis method. We begin with an example that will be used to
illustrate our method, followed by an overview of our anal-
ysis technique in Section 3.2. Sections 3.3 and 3.4 estab-
lish the theoretical results that enable the analysis of a state-
dependent component, which will be applied to model state-
based scheduling in Section 3.5. In Section 4 we present
experimental results using two case studies derived from
an MPEG-2 decoder to illustrate the beneﬁts of our anal-
ysis methods. Finally, we conclude with a discussion on the
prospects for extending our study initiated in this paper.

2 The Real-Time Calculus background

RTC is based on the (min,+) algebra [4, 7] and models
data streams and services in a network with non-decreasing
non-negative functions taking their values in the (min,+)
semiring. More formally, (Rmin +, min, +), with Rmin + =
R+ ∪ {∞}, is a commutative semi-ring, its zero element is
∞ and its unitary element is 0.

Consider the set F = { f : R+ → Rmin + | ∀s < t, 0 ≤
f (s) ≤ f (t)}. One can deﬁne as follows two operators on
F : the minimum, denoted by ⊕ and the (min,+) convolu-
tion, denoted by ⊗:

for all f , g in F , ∀t ∈ R+,
• f ⊕ g(t) = min( f (t), g(t)) and
• f ⊗ g(t) = inf0≤s≤t( f (s) + g(t − s)).
The triple (F , ⊕, ⊗) is also a commutative semiring and
the convolution can be seen as an analogue to the classi-
cal (+,×) convolution of ﬁltering theory, transposed in the
(min,+) algebra. Its zero element is the function ε : t (cid:10)→ ∞
and its unitary element is e : 0 (cid:10)→ 0;t (cid:10)→ ∞.

Two other important operators for RTC are the sub-
additive colsure and the (min,+) deconvolution, denoted by
(cid:11): let f , g ∈ F ,

(cid:2)∞

• f ∗ =

n=0 f n, where f 0 = e and f n+1 = f n ⊗ f .

• f (cid:11) g(t) = supu≥0

( f (t + u) − g(t)).

The following lemma holds for the sub-additive closure op-
erator.

Lemma 1. ([7, theorem 2.1.6]) Let f , g, h ∈ F , and con-
sider the inequation f ≤ f ⊗ g ⊕ h. Then we have

f ≤ h ⊗ g∗.

2.1 Arrival and service curves

Given a data stream traversing a system that contains a
single processing element (PE), let A be its cumulative ar-
rival function (i.e. A(t) is the number of data items that have
arrived until time t). Here a data item can be a network
packet or a video/audio macroblock. We say that α is an
(upper) arrival curve for A (or that A is upper-constrained
by α) if ∀s,t ∈ R+, A(t + s) − A(s) ≤ α(t). This means
that the number of items arriving between time s and t + s
is never larger than α(t). An important particular case of
arrival curve is the afﬁne functions: α(t) = σ+ ρt. Then σ
represents the maximal number of items that can arrive si-
multaneously (the maximal burst) and ρ the maximal long-
term rate of arrivals.

Consider D the cumulative departure function of the
stream, deﬁned similarly by the number D(t) of items that
have left the system until time t. The system provides a
(minimum) service curve β , D(t) ≥ A ⊗ β. Particular
cases of service curves are the peak rate functions with
rate r (the system can process r items per unit of time and
β(t) = rt) and the pure delay service curves with delay d:
β(t) = 0 if t < d and β(t) = +∞ otherwise. The combina-
tion of those two service curves gives a rate-latency func-
tion β : t (cid:10)→ R(t − T )+ where a+ denotes max(a, 0).

A strict service curve β is a service curve such that for
all t ∈ R+, let u be the last instant before t when there is no
packet in the system, then D(t) ≥ A(u) + β(t − u).

2.2 Performance characteristics and bounds

The worst-case backlog and the delay can be easily char-

acterized in the RTC framework as below.

Deﬁnition 1. Let A be the arrival function of a data stream
through a system and D be its corresponding departure
function. Then the backlog of the stream at time t is

b(t) = A(t) − D(t)

and the delay (assuming FIFO order for processing items
of the stream) at time t is

d(t) = inf{s ≥ 0 | A(t) ≤ D(t + s)}.

197

Given an arrival curve and a service curve, it is possible
to compute with the RTC operations the maximal backlog
and delay.

Theorem 1 ([4, 7]). Let A be the arrival function with an
arrival curve α for a stream entering a system with service
curve β. Let D be the departure function. Then,

1. b(t) ≤ Bmax = sup{α(t) − β(t) | t ≥ 0},
2. d(t) ≤ Dmax = inf{d ≥ 0 | ∀t ≥ 0, α(t) ≤ β(t + d)}.

The maximal backlog is the maximal vertical distance
between α and β while the maximal delay is given by the
maximal horizontal distance between those two functions.
Figure 2 illustrates this fact.

α

Bmax

Dmax

β

Figure 2. Guarantee bounds on backlog and
delay.

Further, bounds on the output stream and the remaining
resource of the system can be determined using Theorem 2.

Theorem 2 ([4]). Assume a stream constrained by an ar-
rival curve α entering a system with service curve β.

3 Modeling complex state-dependencies

Modern stream-processing systems are usually hetero-
geneous networks of resources processing multiple data
streams using complex scheduling policies. Often, the pro-
cessing of a stream depends not only on the available ser-
vice but also the internal state of the system. One typical
example is when the amount of on-chip memory is limited
and hence the internal buffers that hold the processed items
can only accommodate up to a certain capacity. To avoid
loss of data, the processor may implement blocking-write
for its output buffers, i.e it stalls whenever the buffers are
full. Otherwise, to save resource, it may proceed to process
the next data streams based on some sharing policy, in case
the output buffer that stores the currently processed stream
is ﬁlled up.

Modeling and analysis of systems described above re-
quire us to take into consideration the state-dependencies
that are imposed among the different elements of a sys-
tem. The original RTC framework presented in Section 2
(i) does not express state-information and furthermore (ii)
assumes that all buffers have inﬁnite capacities. As a result,
it is not able to represent and correctly analyze such sys-
tems. Automata-based approaches developed recently for
stream processing systems[6, 17] can encapsulate state in-
formation; however, their analyses become inefﬁcient for
large systems due to the state-space explosion. In this sec-
tion, we present a functional analysis technique, developed
on top of the original RTC framework, which is capable of
capturing the complex state-dependencies while achieving
high efﬁciency. We shall illustrate our method with an ex-
ample of stream-processing systems that is described below.
More general systems can be easily modeled and analyzed
using the same approach.

1. The output stream is upper-constrained by an arrival

3.1 An illustrative example

curve

α(cid:2) = α(cid:11) β.

2. If β is a strict service curve, the remaining resource af-
ter processing the stream is bounded by a service curve

β(cid:2) = (β − α)+.

Figure 3 sketches the system architecture of a picture-in-
picture (PiP) application where two video streams are de-
coded. The ﬁrst stream represents a set of regular video
clips with high motion contents and the latter represents a
set of still images. After fully decoded by the PEs, they will
be displayed at the output device.

In this paper, we assume that service curves are strict to
ensure for the positiveness of remaining service; however,
our method is not restricted to this assumption.

From the results concerning systems with a single PE,
one can obtain more general results for systems with mul-
tiple PEs, using the composition of the RTC operators. For
example, if there are two PEs in sequence, for respective
service curves β1 and β2, the overall service curve is β1 ⊗ β2
(see [4, 7] for details). Such results have been based on the
properties of the (min,plus) algebra.

input 

stream 1

input 

stream 2

PE
3

b1

b2

IDCT
 MC

IDCT
 MC

PE

1

PE

2

s‘
1

s‘
2

VLD
 IQ

VLD
 IQ

B1

B2

Output
Device

Figure 3. A PiP application.

198

The system consists of three PEs on which the tasks of an
MPEG-2 decoder application are partitioned and mapped.
As shown in the ﬁgure,
the Variable Length Decoding
(VLD) and Inverse Quantization (IQ) tasks run on each of
PE1 and PE2 while the Inverse Discrete Cosine Transform
(IDCT) and Motion Compensation (MC) tasks run on PE3.
PE1 processes the ﬁrst input video stream and PE2 pro-
cesses the second input video stream. The partially decoded
streams from PE1 and PE2 (denoted by s(cid:2)
2) are stored
in the buffers b1 and b2 respectively, where they will further
be processed by PE3. The two fully decoded streams from
PE3 are then written to the playout buffers B1 and B2 before
being read by the output device.

1 and s(cid:2)

1 and s(cid:2)
PE3 schedules the two streams s(cid:2)
2 using a ﬁxed-
priority scheduling policy, with s(cid:2)
1 having higher priority
than s(cid:2)
2. Further, PE3 implements blocking-write on the
playout buffer B1; when B1 is full, the processor will pro-
cess s(cid:2)
2 if there are some items in b2. This is done regardless
of whether there are items in b1.

Given the above system architecture, we are interested
in answering questions concerning the behavior of the sys-
tem such as (1) what is the maximum backlog of a buffer?
(2) what is the maximum delay experienced by a stream?
(3) is the system schedulable while guaranteeing none the
buffers overﬂows? A correct evaluation of such properties
are essential for designers to optimize the design of the sys-
tem. As mentioned earlier, we cannot use the standard RTC
framework to analyze the system since PE3 implements
state-based scheduling scheme.

3.2 A functional analysis approach

In constructing the model for the system, we describe
each input stream to the system as an arrival curve and each
processing resource of the system as a service curve. The
processing of a stream by a resource is represented by an
abstract component whose inputs are the arrival curve of
the input stream and the service curve of the resource. The
outputs of an abstract component are an arrival curve that
bounds the output stream and a service curve that bounds
the resource left after processing the input stream. By con-
necting the abstract components following the ﬂow of the
stream (from left to right) and the order at which the dif-
ferent streams are processed by a shared resource (from top
to bottom), we obtain the complete abstract model of the
system. Figure 4 depicts the abstract model of the system
architecture in Figure 3.

In this ﬁgure, α1 and α2 denote the arrival curves of the
two input video streams; β1, β2 and β3 denote the service
curves of PE1, PE2 and PE3 respectively. Similarly, β4 and
β5 are the service curves that bound the consumptions of the
two fully processed streams. The processing of the streams
by PE1 and PE2 are represented by the abstract components
C1 and C2, whose output arrival curves are denoted by α(cid:2)
1

α
1

α
2

PE
1
β
1

C1

β

2

C2

PE

2

α′
1

α′
2

PE
3
β
3

C3

β′
3

C′3

α″
1

α″
2

OD1
β
4

C4

β
5

C5

OD2

Figure 4. The abstract model of the system in
Figure 3.

2. The processing of PE3 on the output streams s(cid:2)

and α(cid:2)
1 and
s(cid:2)
2 comprises two abstract components C3 and C(cid:2)
3. Since PE3
processes s(cid:2)
1 before s(cid:2)
2, the remaining service of C3 is con-
nected as input to C(cid:2)
3. Finally, the consumption of the items
from B1 and B2 are modeled by C4 and C5. The connection
of the arrival curves to the abstract components follows the
sequence at which the corresponding streams are processed.
Our analysis proceeds component-wise where we eval-
uate each abstract component and thereafter combine the
evaluated results. To analyze a component, we ﬁrst deter-
mine the input arrival curve and effective service curve of
the component if they are not yet known. An effective ser-
vice curve is a service curve that bounds the actual resource
used to process a stream taking into account the state depen-
dencies in the system. Based on the obtained input arrival
curve and effective service curve, we can compute the dif-
ferent performance characteristics and bounds of the com-
ponent using Theorem 1 and 2.

In Figure 4, since C1 and C2 have no state dependency
with the succeeding components, their effective curves are
equal to β1 and β2, respectively. By the same reason, the
output arrival curve α(cid:2)
1 from C1 can be computed from α1
and β1 using Theorem 2. Similarly, the arrival curve α(cid:2)
2 can
be derived from α2 and β2.

On the other hand, since the processing at PE3 is contin-
gent on the state of the playout buffer B1, the actual resource
that is used to process s(cid:2)
1 depends not only on the total avail-
able resource of PE3 but also the readout rate of the output
device and the capacity of B1. Hence the effective service
curve βeff
3 of C3 is dependent on β3, β4 and the capacity of
B1. This effective service curve will in turn affect the re-
maining service curve β(cid:2)
and β(cid:2)
3
will be described in the coming sections. With the obtained
3 and β(cid:2)
βeff
3, we can apply Theorem 2 to compute the output
arrival curves α(cid:2)(cid:2)
2 that are inputs to C4 and C5. The
effective service curves of C4 and C5 are exactly β4 and β5
since there is no state-dependency in these two components.
In the next three sections, we present our technique for
computing the effective service curve of a component taking

3. The computation of βeff

1 and α(cid:2)(cid:2)

3

199

into account the state-dependency of the subsequent compo-
nents in the system. Section 3.3 looks into the case where
the processing of the stream in the component is depen-
dent on only one buffer of the next component. Section 3.4
moves one step further to solve for the general case when
the processing within the component is dependent on the
buffer state of many components in tandem. The computa-
tion of the effective service curves of components that are
scheduled using ﬁxed-priority policy while being subjected
to the state of the buffers in the system is described in Sec-
tion 3.5. Before going into the details, we ﬁrst prove the
following lemma, which will be used in our formulation.

Lemma 2. Let f and g be two functions and c be a constant.
Then,

1. ( f ⊗ g) + c = ( f + c) ⊗ g = f ⊗ (g + c)

2. ( f ⊗ g∗)∗ = e + f + ⊗ g∗ and ( f ⊗ g∗)+ = f + ⊗ g∗,

where f + =

(cid:2)

n>0 f n.

Proof.

1. Let hc ∈ F , such that hc(0) = c and hc(t) = ∞,
∀t > 0. Then, for every function f ∈ F , f ⊗ hc = f +
c. The formula follows from the associativity and the
commutativity of the ⊗ operator.

(cid:2)

2. ( f ⊗ g∗)∗ =

( f ⊗ g∗)n = e ⊕

n≥0

(g∗)n = g∗, then ( f ⊗ g∗)∗ = e ⊕ g∗ (cid:2)
result.

(cid:2)

( f ⊗ g∗)n. As
n>0
n>0 f n, hence the

3.3 Simple blocking-write at a single buffer

In this section, we model a setup where the processing
of a stream is interrupted when an output buffer is full (i.e.
blocking-write). This is done by extending the existing RTC
framework using a feedback control mechanism. The sys-
tem, shown in Figure 5 consists in two PEs in sequence,
where the second one has a ﬁnite capacity B2. The PEs have
respective service curves β1 and β2, and when the backlog
in PE2 exceeds B2, then the service at PE1 is interrupted.
The functions A1, A2 and A3 are the respective arrival pro-
cesses at the entrance of the system, after serviced by the
ﬁrst PE and at the output of the system.

A1

A2

β1

A3

β2

B2

Figure 5. System with two PEs in sequence,
the second PE has a ﬁnite capacity buffer B2.

As the backlog on the second PE cannot exceed B2, one
must have A2 − A3 ≤ B2 and then A2 ≤ A3 + B2. A simple
solution to ensure this is to put a feedback control before

PE1, admitting only the amount of data that ensures that the
backlog constraint in PE2 is satisﬁed. In entrance of PE1,
the arrival process then becomes A(cid:2)
1

= min(A1, A3 + B2).

A3 + B2

A1

A2

β1

A3

β2

Figure 6. Feedback control to ensure non-
overﬂow for the second buffer.

Figure 6 represents the system that can be translated into

the following equations:

(cid:3)

A2 ≥ min(A1, A3 + B2) ⊗ β1
A3 ≥ A2 ⊗ β2,

which leads to the following inequation:

A2 ≥ min(A1, A2 ⊗ β2 + B2) ⊗ β1

= min(A1 ⊗ β1, A2 ⊗ (β2 + B2) ⊗ β1).

From Lemma 1, the solution if this inequality is:

A2 ≥ A1 ⊗ β1 ⊗ [(β2 + B2) ⊗ β1]∗,

which proves the following lemma:

Lemma 3. The effective service curve for PE1 taking into
account the interruption of service when B2 is full is:

βeff
1

= β1 ⊗ [(β2 + B2) ⊗ β1]∗.

Suppose α is the arrival curve of the input stream. The
maximal backlog and delay of the PE as well as the arrival
curve of the output stream can be easily deduced from α
and βeff
1

following Theorem 1 and 2.

3.4 Blocking-write at multiple buffers in sequence

Now suppose that there are several PEs in sequence, each
of which has a buffer with ﬁnite capacity. Then, the effec-
tive service curve of the ﬁrst PE (the one which has an inﬁ-
nite capacity) will depend on the capacities of all the buffers
and on the other service curves: the feedback controls in-
duce some cycles in the network, as shown in Figure 7.

A3 + B2

A4 + B3

An+1 + Bn

A1

A3

A4

An

An+1

β2

β3

βn

A2

β1

Figure 7. Line of PEs with ﬁnite buffer capac-
ities.

200

Consider a system with n PEs processing sequen-
tially, where PE2, · · · , PEn have respective buffer capaci-
ties B2, . . . , Bn. Theorem 3 gives the formula for computing
the effective service curve of PE1 considering the blocking-
write at the subsequent PEs.

Similar networks have been studied (see [7]), but the
goal in this reference is to compute the overall service curve.
Here, we are only interested in ﬁndig the real service curve
of the ﬁrst server, in order to dimension the size of the
buffer, taking into account the block-writing phenomenon.

Theorem 3. The effective service curve βeff
1 of PE1, taking
into account the feedback controls from the other PEs, is
given by

βeff
1

= β1 ⊗

[βj−1 ⊗ (B j + βj)]+.

n

min
i=0

i(cid:4)

j=1

Proof. The result is proved by induction. The initialization
step exactly corresponds to Lemma 3. Suppose that the re-
sult holds for n PEs, and let us show it for n + 1 PEs. The
system obeys to the following equations:

⎧
⎨

⎩

Ai

≥ min(Ai−1, Ai+1 + Bi) ⊗ βi−1

∀i ∈ {2, . . . n + 1},

An+2 ≥ An+1 ⊗ βn+1.

In particular, the equations concerning PEn+1 are:

(cid:3)

An+1 ≥ min(An, An+2 + Bn+1) ⊗ βn
An+2 ≥ An+1 ⊗ βn+1,

which is equivalent to An+1 ≥ An ⊗ βn ⊗ [(βn+1 + Bn+1) ⊗
βn]∗. Now, one can replace the system with n + 1 PEs in se-
quence with an equivalent system with n PEs, the n − 1 ﬁrst
PEs having the same service curve, and the last PE having
service curve β(cid:2)
= βn ⊗ [(βn+1 + Bn+1) ⊗ βn]∗. The capaci-
n
ties of buffers 2 to n remain the same. Consequently, on can
apply the induction hypothesis to that system and obtain a
service curve for the ﬁrst PE (denoting βi ⊗ (Bi+1 + βi+1)
by fi and βn−1 ⊗ (Bn + β(cid:2)
n

) by f (cid:2)

n−1):

βeff
1

= β1 ⊗[e⊕ f +
1
Consider only the last factor f (cid:2)+

⊕ f +
1

⊗ f +
2

⊕· · ·⊕ f +
1

⊗· · ·⊗ f +
n−2
n−1 and replace β(cid:2)

⊗ f (cid:2)+
n−1

].

n by its

expression:

f (cid:2)+
n−1

= [βn−1 ⊗ (Bn + βn ⊗ [(βn+1 + Bn+1) ⊗ βn]∗)]+
= [βn−1 ⊗ (βn + Bn) ⊗ [(βn+1 + Bn+1) ⊗ βn]∗)]+
= [ fn−1 ⊗ f ∗
n

]+ = f +
n−1

(e ⊕ f +
n

),

which leads the desired formula and ﬁnishes the proof.

Remark that this formula takes into account the fact that
if PEi on the line has no backlog constraint (the buffer has
an inﬁnite capacity and Bi = ∞), then the service curve does
not depend on the service curves βj, j ≥ i. Indeed, in that
case fi = ∞ and f +
= ∞. Analysis bounds on
i
the system can be easily computed in the same fashion as
done in the simple case when blocking-write is imposed at
a single buffer.

⊗ · · · ⊗ f +
j

3.5 State-based scheduling policies

Recall that in the illustrative example in Figure 3 (Sec-
tion 3.1), the resource of PE3 is shared between two streams
s(cid:2)
1 and s(cid:2)
2. The processing policy used by PE3 is dependent
on the state of the playout buffer B1 as well as the priorities
of the streams. Speciﬁcally, PE3 will ﬁrst process s(cid:2)
1 and
only process s(cid:2)

2 when b1 is empty or B1 is full.

The analysis for such a state-based scheduling policy is
divided into two phases. First, we determine the effective
service curve that is used to process each stream taking into
consideration the state dependency. With the obtained ef-
fective service curves, we compute the various performance
characteristics using the results presented in Section 2.

The effective service curve βeff
3

that is used to process s(cid:2)
1
taking into account the state dependency is computed using
Lemma 3 and Theorem 3 described above. The effective
service curve that is used to process s(cid:2)
2 is also the one that
bounds the remaining resource after processing s(cid:2)
1, which
can be computed using Corollary 1 below.

Corollary 1. Given a PE with service curve β processing a
higher priority stream s with arrival curve α. Assume βeff is
the effective service curve used to process the stream taking
into account the state-dependency. The remaining resource
of the PE given to the lower priority streams is bounded by
the service curve

β(cid:2) = β−

(cid:8)
α(cid:11) βeff

(cid:9)
.

Proof. For any given Δ > 0,
the maximum number of
items that are processed in any interval of length Δ is
(α(cid:11) βeff )(Δ) (Theorem 2.1). Since the PE starts processing
the lower priority streams as soon as there is no more items
from s to be processed or when the output buffer is full, the
amount of service given to the lower priority streams in any
interval of length Δ is at least β(Δ) − (α(cid:11) βeff )(Δ). This
proves the corollary.

Using the computed effective service curve, the maxi-
mum backlog, maximum delay the output arrival curve can
be easily computed using Theorem 1 and 2.1.

4 Experimental case studies

We employed two case studies to evaluate our theoreti-
cal results and to illustrate the effect of state-dependency on
the behavior of a system. The ﬁrst case study aims to show
the immediate ramiﬁcation of processor stalling on the ﬁll-
levels of the buffers in a system. The second case study

201

illustrates the intermediate effect of blocking of one stream
on another, at the same time demonstrates how our tech-
nique can be used to evaluate systems with multiple input
streams that are scheduled using ﬁxed-priority scheduling
policy with state-dependency.

4.1 Case study 1: blocking-write of a stream

Figure 8 shows the architecture of an MPEG-2 decoder
which consists of two PEs decoding an input video stream
in sequence. The MPEG-2 application is partitioned and
mapped onto these PEs where the VLD and IQ tasks run on
PE1 while the IDCT and MC tasks run on PE2. The coded
input stream arrives at the system at a constant rate and it
is initially processed by PE1. The partially decoded mac-
roblocks of the stream are subsequently stored in the buffer
b before being processed by PE2. The resulting fully de-
coded macroblocks are written to the playout buffer B and
ﬁnally transmitted to the output video device. We are partic-
ularly interested in the behavior of the components shown
in the rectangle box.

input video

stream

b

B

VLD
 IQ
PE1

IDCT
 MC
PE2

output
device

Figure 8. An MPEG-2 decoder application.

Although the input bit stream enters the system at a con-
stant bit-rate, the execution times of the VLD + IQ tasks
may vary. The number of bits constituting each partially
decoded macroblock is also not constant. Consequently, the
stream that is written to b is highly bursty. We assume that
(a) the bursty behavior of this stream is speciﬁed by an ar-
rival curve α(Δ); (b) the variability in the execution require-
ments of the IDCT + MC tasks running on the PE2 is cap-
tured by a service curve βf (Δ) where f represents the clock
frequency of PE2; (c) PE2 implements blocking-write for B
where it stalls when B is full; (d) the output device reads the
macroblocks from B at a constant rate r.

In order to understand the effect of blocking-write on
the behavior of the system, we permuted different capac-
ities of B and frequencies f of PE2 to observe the result-
ing changes on the maximum backlog of b. The maximum
backlog of b is computed following Lemma 3 and compared
with our simulated results. The theoretical technique is im-
plemented using the Java API provided by the Real-Time
Calculus Toolbox [25].

4.1.1 Obtaining arrival and service curves

To obtain the arrival curve that characterizes the partially
decoded stream, we collected execution traces of the differ-
ent tasks by simulating their executions on a customized

version of the SimpleScalar instruction set simulator [3].
From these traces, we measured the execution demands of
the VLD and IQ tasks for each macroblock and derived
a function x(t), where x(t) denotes the number of mac-
roblocks arriving at b during the time interval [0,t]. The
function x(t) was used to compute the arrival curve α(Δ) of
the partially processed stream.

Similarly, based on the execution demands of the IDCT
and MC tasks, we computed the workload function γ(k)
which gives the maximum number of cycles required by any
k consecutive macroblocks at PE2. By combining γ and the
frequency f of PE2, we derive the service curve βf (Δ). The
service curve that represents the consumption at the output
device is given by C(Δ) = rΔ.

4.1.2 Analysis results

Figure 9 reports the estimated values of the maximum back-
log of b against the different frequencies f of PE2 for the
varying capacities of buffer B.

Capacity of the playout buffer, B = 1500

B = 1900

2600

2000

1400

 

 

 

b
 
r
e
f
f
u
b
e
h
t
 
f
o
g
o
l
k
c
a
b
m
u
m
i
x
a
M

 

l

]
s
k
c
o
b
o
r
c
a
m

 
f
o
 
r
e
b
m
u
n
[

800

1.3

1.4

1.6

1.5
Frequency of PE2 [GHz]

1.7

Figure 9. Maximum backlog analysis of b.

B = 2900

1.8

1.9

As f

increases, more macroblocks are processed thus
leading to declining backlog for all the different capacities
of B. However, beyond a certain threshold frequency, the
value of the maximum backlog of b stabilizes for a ﬁxed
capacity of B. This happens at the point where B is full and
no other macroblocks in b can be processed until there is
available space in B. Therefore, as we increase the capacity
of B, the maximum backlog of b decreases, which is also
illustrated in the ﬁgure.

Thus, running a processor beyond a threshold frequency
reduces its utilization rate. With a ﬁxed memory size, a
designer can therefore determine the processor frequency
and the corresponding capacities of the buffers in the system
which maximize the utilization rate of the processor.

To compare our method against simulation-based ap-
proaches, we implemented a SystemC simulator and used

202

it in conjunction with the SimpleScalar instruction set sim-
ulator in [3] to run a detailed SimpleScalar+SystemC sim-
ulation. Our simulated results match well with the ones
computed using our analytical method described above. In
particular, the analytical bounds are always less than 5%
more than those obtained from simulation. On the other
hand, performing the analysis using the RTC toolbox incor-
porated with our method is signiﬁcantly faster than pursuing
the pure simulation approach (less than a minute vs. several
hours). Note also that results from simulation are unable to
provide a formal guarantee on the maximum backlog that
may incur in the system.

4.2 Case study 2: state-based scheduling of mul-

tiple input streams

In this case study, we analyze the example system de-
scribed in Section 3.1. We assume the two input video
streams arrive at a constant bitrate of 8 Mbps and their fully
decoded macroblocks are read by the output device at a rate
of 40,000 macroblocks per second. The frequencies of PE1
and PE2 are set to be f1 = 1.3GHz and f2 = 1.25GHz, re-
spectively. Given these values ﬁxed, we are interested in
the backlog of b2 with respect to different values of the fre-
quency of PE3 and capacity of B1.

and α(cid:2)

3 using Theorem 1.

First, we obtain the arrival curves α1 and α2 of the two
input streams and the service curves β1, β2 and β3 of the
three PEs (see Section 4.1.1). From α1 and β1, we com-
pute the arrival curve α(cid:2)
1 that characterizes the output stream
from PE1. Similarly, the arrival curve α(cid:2)
2 that represents the
output stream from PE2 is derived from α2 and β2. Based
on α(cid:2)
1, β3 and the capacity of B1, we follow Lemma 3 to
compute the effective service curve βeff
that processes the
3
output stream from PE1 considering blocking-write at B1.
The remaining service curve β(cid:2)
3 that is used to process the
second stream is deducted from βeff
1 using Corol-
3
lary 1. The maximum backlog of b2 is then calculated from
α(cid:2)
2 and β(cid:2)
Figure 10 plots the maximum backlog of b2 in relation
to the capacity of B1 and the frequency of PE3. Observe
from the ﬁgure that the maximum backlog of b2 is small-
est around the region with highest frequencies of PE3 and
largest capacities of B2. Reversely, b2 has smallest back-
logs in the area where PE3 has lowest frequencies and B2
has smallest capacities. In fact, the result shown in the ﬁg-
ure demonstrates that the maximum backlog of b2 is always
proportional to the frequency of PE3 and the capacity of B1.
Thus the maximum backlog of the input buffer correspond-
ing to the lower priority stream exhibits the same pattern as
that the higher priority stream (as seen in case study 1). This
demonstrates the effect of feedback control at one stream on
the other streams that share the same resource.

Table 1 reports the total maximum backlogs of the two
buffers b1 and b2 in reference to the capacity of B1 and the

4
x 10

l

]
s
k
c
o
b
o
r
c
a
m

 
f
o
 
r
e
b
m
u
n
[

 

 
 
 

2
b
 
r
e
f
f
u
b
e
h
t
 
f
o
g
o
l
k
c
a
B

 

1.6

1.5

1.4

1.3

1.2

1.1

1

0.9
2.8

2.9

3.0

Frequency of PE   [G

3.2

3.1

3

3.3
Hz]

3.4

0 

500

3500

3000

4000

2500

2000

1000

1500

C a p a c i t y   o f   t h e   p l a y o u t   b u f f e r   B
[ n u m b e r   o f   m a c r o b l o c k s ]

1

 

Figure 10. Case study 2: maximum backlog
of the lower priority stream.

Table 1. Total buffer space required for PE3.

Total backlog of b1 and b2 (macroblocks)

PE3 Freq. B1 = 1000 B1 = 2000 B1 = 3000 No feedback
2.8 GHz
2.9 GHz
3.0 GHz
3.1 GHz
3.2 GHz

28043
27169
26347
25825
25439

29498
28624
28332
27478
26885

14382
12430
10868
9104
7396

31170
30490
29619
29359
28603

frequency of PE3. The last column of the table gives the val-
ues for the case when there is no state dependency. It is ob-
served consistently for all frequencies that when the capac-
ity of B1 is ﬁnite and blocking-write is imposed on the sys-
tem, the total backlog at PE3 is much larger than the com-
puted backlog in the case of no state-dependency. Thus, as-
suming the buffers having inﬁnite capacity may potentially
lead to inaccurate results, as shown in this case study. It is
therefore important for us to capture the state-dependency
in the model and analysis of such systems.

For simplicity, we assume in both case studies that
blocking-write is implemented only at a single buffer in the
system. The analysis for the case when blocking-write is
imposed on multiple buffers can be done similarly, except
that one may additionally need to use Theorem 3 to com-
pute the effective service curve offered by a processor to
a stream. The same technique presented here can also be
employed to analyze systems with more than two streams.
Additionally, we have also modeled the given case stud-
ies using the ECA and carried out the analysis using the
SAL (Symbolic Analysis Laboratory) model checker [20].

203

It is observed from our experiments that the analysis time
when using ECA is much slower than when using RTC. For
example, in case study 1, using ECA takes in average more
than 10 times as compared to using RTC. As the system be-
comes more complex, the speed up is near exponential on
the number of PEs in the system. This shows that analyz-
ing blocking-write using our method is considerably more
efﬁcient than using an explicit state-based model.

5 Concluding remarks

We have formulated a method that enhances the origi-
nal RTC framework by modeling and analyzing a variety of
state-dependencies using a feedback control technique. Our
analysis is purely functional and thereby avoids the state-
space explosion problem faced by explicit state-modeling in
automata-based approaches. Since a number of state-based
components that were originally modeled by ECA can now
be analyzed functionally, it will be meaningful to integrate
our proposed method into the hybrid framework of RTC and
ECA [18]. It will also be interesting to extend our technique
to capture more complex state-dependencies, for instance
synchronization between streams.

References

[1] Y. Abdeddaïm, E. Asarin, and O. Maler. Scheduling with
timed automata. Theoretical Computer Science, 354(2):272–
300, 2006.

[2] R. Henia A. Hamann M. Jersak R. Racu K. Richter R. Ernst.
System level performance analysis - the symta/s approach.
In Computers and Digital Techniques, 2005.

[3] T. Austin, E. Larson, and D. Ernst. SimpleScalar: An in-
frastructure for computer system modeling. IEEE Computer,
35(2):59–67, 2002.

[4] J.-Y. Le Boudec and P. Thiran. Network Calculus: A Theory
of Deterministic Queuing Systems for the Internet, volume
LNCS 2050. Springer, 2001.

[5] S. Chakraborty, S. Künzli, and L. Thiele. A general frame-
work for analysing system properties in platform-based em-
bedded system designs. In DATE, 2003.

[6] S. Chakraborty, L. T. X. Phan, and P. S. Thiagarajan. Event
count automata: A state-based model for stream processing
systems. In RTSS, 2005.

[7] C.-S Chang. Performance Guarantees in Communication

Networks. Springer, 2000.

[8] E. Fersman, P. Krcál, P. Pettersson, and W. Yi. Task au-
tomata: Schedulability, decidability and undecidability. In-
formation and Computation, 205(8):1149–1172, 2007.

[9] E. Fersman, L. Mokrushin, P. Pettersson, and W. Yi. Schedu-
lability analysis of ﬁxed-priority systems using timed au-
tomata. Theoretical Computer Science, 354(2):301–317,
2006.

[10] W. Haid and L. Thiele. Complex task activation schemes in
system level performance analysis. In CODES+ISSS, 2007.

[11] R. Henia and R. Ernst. Scenario aware analysis for complex

event models and distributed systems. In RTSS, 2007.

[12] R. Henia, R. Racu, and R. Ernst.

Improved output jitter
calculation for compositional performance analysis of dis-
tributed systems. In IPDPS, 2007.

[13] K. Huang, L. Thiele, T. Stefanov, and E. Deprettere. Perfor-
mance analysis of multimedia applications using correlated
streams. In DATE, 2007.

[14] S. Künzli, A. Hamann, R. Ernst, and L. Thiele. Combined
approach to system level performance analysis of embedded
systems. In CODES+ISSS, 2007.

[15] E. A. Lee and D. G. Messerschmitt. Synchronous data ﬂow.

Proceedings of the IEEE, 75(9):1235–1245, 1987.

[16] O. Moreira and M. Bekooij. Self-timed scheduling analysis
for real-time applications. EURASIP Journal on Advances in
Signal Processing, 2007.

[17] C. Norström, A. Wall, and W. Yi. Timed automata as task

models for event-driven systems. In RTCSA, 1999.

[18] L. T. X. Phan, S. Chakraborty, P. S. Thiagarajan, and
L. Thiele. Composing functional and state-based perfor-
mance models for analyzing heterogeneous real-time sys-
tems. In RTSS, 2007.

[19] J. Rox and R. Ernst. Modeling event stream hierarchies with

hierarchical event models. In DATE, 2008.

[20] Symbolic Analysis Laboratory.

http://sal.csl.sri.com.

[21] S. Schliecker, S. Stein, and R. Ernst. Performance analysis
of complex systems by integration of dataﬂow graphs and
compositional performance analysis. In DATE, 2007.

[22] L. Thiele, S. Chakraborty, M. Gries, and S. Künzli. A frame-
work for evaluating design tradeoffs in packet processing ar-
chitectures. In DAC, 2002.

[23] S. Tripakis, C. Pinello, A. Benveniste, A. Sangiovanni-
Vincentelli, P. Caspi, and M. Di Natale.
Implementing
synchronous models on loosely time triggered architectures.
IEEE Transactions on Computers, 2008.

[24] E. Wandeler, A. Maxiaguine, and L. Thiele. Quantitative
characterization of event streams in analysis of hard real-
time applications. Real-Time Systems, 29(2-3):205–225,
2005.

[25] E. Wandeler and L. Thiele. Real-Time Calculus (RTC) Tool-

box. http://www.mpa.ethz.ch/Rtctoolbox, 2006.

[26] E. Wandeler and L. Thiele. Workload correlations in multi-
processor hard real-time systems. Journal of Computer and
System Sciences (JCSS), 73(2):207–224, 2007.

[27] M. Wiggers, M. Bekooij, P. Jansen, and G. Smit. Efﬁcient
computation of buffer capacities for multi-rate real- time sys-
tems with back-pressure. In CODES+ISSS, 2006.

204

