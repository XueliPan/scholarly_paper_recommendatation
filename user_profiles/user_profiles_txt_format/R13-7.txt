Logical Circuit Filtering

Dafna Shahaf

and Eyal Amir

Computer Science Department

University of Illinois, Urbana-Champaign

Urbana, IL 61801, USA
dshahaf2,eyal

@uiuc.edu

f

g

Abstract

Logical Filtering is the problem of tracking the pos-
sible states of a world (belief state) after a sequence
of actions and observations.
It is fundamental to
applications in partially observable dynamic do-
mains. This paper presents the (cid:2)rst exact logical
(cid:2)ltering algorithm that is tractable for all determin-
istic domains. Our tractability result is interesting
because it contrasts sharply with intractability re-
sults for structured stochastic domains. The key to
this advance lies in using logical circuits to repre-
sent belief states. We prove that both (cid:2)ltering time
and representation size are linear in the sequence
length and the input size. They are independent of
the domain size if the actions have compact repre-
sentations. The number of variables in the result-
ing formula is at most the number of state features.
We also report on a reasoning algorithm (answer-
ing propositional questions) for our circuits, which
can handle questions about past time steps (smooth-
ing). We evaluate our algorithms extensively on AI-
planning domains. Our method outperforms com-
peting methods, sometimes by orders of magnitude.

Introduction

1
Much work in AI applies system models whose state changes
over time. Applications use these dynamic-system models to
diagnose past observations, predict future behavior, and make
decisions. Those applications must consider multiple possi-
ble states when the initial state of the system is not known,
and when the state is not observed fully at every time step.
One fundamental reasoning task in such domains is Logical
Filtering [Amir and Russell, 2003]. It is the task of (cid:2)nding
the set of states possible (belief state) after a sequence of ob-
servations and actions, starting from an initial belief state.

Logical Filtering in large deterministic domains is impor-
tant and dif(cid:2)cult. Planning, monitoring, diagnosis, and others
in partially observable deterministic domains estimate the be-
lief state (e.g., [Biere et al., 1999; Cimatti and Roveri, 2000;
Bertoli et al., 2001; Petrick and Bacchus, 2004]) as part of
performing other computations. This estimation is dif(cid:2)cult
because the number of states in a belief state is exponential in
the number of propositional features de(cid:2)ning the domain.

Several approaches were developed that represent belief
states compactly in logic (e.g., BDDs [Bryant, 1992], Log-
ical Filter, and database progression [Winslett, 1990; Lin and
Reiter, 1997]) and update this representation. However, none
of them guarantees compact representation, even for simple
domains. [Amir and Russell, 2003], for instance, guarantees
compactness and tractability only for sequences of STRIPS
actions whose preconditions are known to hold. Most impor-
tantly, the straightforward approach to Logical Filtering (de-
ciding if a clause should be in the belief state representation
of time t + 1, based on the belief state of time t) was shown
to be coNP-complete [Liberatore, 1997].

In this paper we show that solving the update problem in
its entirety is easier (done in poly-time) than creating the new
belief state piecemeal. We present C-Filter(cid:150) the (cid:2)rst exact,
tractable Logical Filtering algorithm that can handle any de-
terministic domain. Importantly, both time (to compute a be-
lief state) and space (to represent it) do not depend on the do-
main size. Furthermore, the number of variables in the result-
ing formula is at most n, the number of state features (com-
pare this with n
t, the number of variables used in Bounded
Model Checking [Clarke et al., 2001]).

(cid:1)

We extend C-Filter to NNF Circuits (no internal negation
nodes), and show that similar space and time bounds hold for
this more restricted representation. We further show how to
reason with an output circuit, including smoothing (queries
about the past). Our results are also useful from the perspec-
tive of representation-space complexity; they sidestep previ-
ous negative results about belief-state representation (Section
5.4) and intractability results for stochastic domains.

The key to our advance lies in using logical circuits to rep-
resent belief states instead of traditional formulas. We show
that updating a logical circuit formula amounts to adding a
few internal connectives to the original formula. We take ad-
vantage of determinism: a feature is true after an action iff
the action made it true or it was already true and the action
did not change that. Interestingly, our empirical examination
suggests that other graphical representations (e.g., BDDs) do
not maintain compact representation with such updates.

C-Filter applies to many problems that require belief-state
update, such as Bounded Model Checking and planning with
partial observability. The attractive nature of this approach is
that we can apply standard planning techniques without fear
of reaching belief states that are too large to represent.

2 Logical Filtering
We now describe the problem of Logical Filtering (tracking
the state of the world), hereby referred to as Filtering. Imag-
ine an assembly robot that can put items together in order to
construct some machine. The parts are randomly oriented,
and they must be brought to goal orientations for assembly.
At the beginning, the parts are located on a conveyor belt.
Each part drifts until it hits a fence perpendicular to the belt,
and then rotates so one of its edges is aligned against the fence
(see Figure 1). A sensor measures that edge, providing par-
tial information about the part’s orientation (partial, because
the part can have some edges of equal length, and the sensor
might be noisy). The robot can then rotate a part (by a certain,
discrete amount) and place it back on the belt, or pick it up
and try assembling it. We now de(cid:2)ne the problem formally.

De(cid:2)nition 2.1 (Deterministic Transition System) A transi-
. P is a (cid:2)nite set of propo-
tion system is a tuple
i
sitional (cid:3)uents, S
Pow(P ) is the set of world states. A state
(cid:18)
contains exactly the (cid:3)uents that are true in it. A is a (cid:2)nite set
of actions, and R : S

S is the transition function.

P; S; A; R
h

A

Executing action a in state s results in state R(s; a). R may be
partial. In our example, P =
OnBelt(part1), PartOfAssem-
bly(part1), Touch(part1-e1), Touch(part1-e2), ...
PickUp(part1), Assemble(part1), Rotate(part1,90), ...
In the sequel we assume an implicit transition system.

, A =
g

f

g

f

(cid:2)

!

Figure 1: A conveyor belt: the triangle drifts down, hits the fence
and rotates. The edge touching the fence is then measured.

Our robot tries to keep track of the state of the world, but
it cannot observe it completely. One possible solution is to
maintain a belief state(cid:150) a set of possible world states. Every
(cid:26)
S is a belief state. The robot updates its belief state as
the result of performing actions and receiving observations.
We now de(cid:2)ne the semantics of Filtering.

(cid:18)

De(cid:2)nition 2.2 (Filtering Semantics [Amir and Russell, 2003])
(cid:26)
A.
We assume that observations oi are logical sentences over P .

S, the states that the robot considers possible, ai 2

(cid:18)

1. Filter[(cid:15)]((cid:26)) = (cid:26) ((cid:15): an empty sequence)
2. Filter[a]((cid:26)) =
(cid:26)
j
g
3. Filter[o]((cid:26)) =
2
t]((cid:26)) =
aj; ojii
4. Filter[
h
(cid:20)
t] (Filter[oi](Filter[ai]((cid:26))))
Filter[
aj; ojii<j
h

s0 = R(s; a); s
2
o is true in s
(cid:26)
g

s0
f
s
f
j
(cid:20)

(cid:20)

j

We call step 2 progression with a and step 3 (cid:2)ltering with o.

Every state s in (cid:26) becomes s0 = R(s; a) after performing
action a. After receiving an observation, we eliminate every
state that is not consistent with it.

Figure 2 illustrates a belief-state update. Imagine that the
robot has an isosceles right triangle (edges of size 1,1,p2),
and one of the 1-edges is currently touching the fence. There

are two possible orientations ((a) and (b), left part). After
rotating the triangle 90 degrees, each possible state is updated
(middle part). If the world state was (a), we should see a 1-
edge again. Otherwise, we expect to see the p2-edge. After
observing a 1-edge (right part), the robot eliminates (b) from
his belief state, leaving him only with (a). That is, the robot
knows the orientation of the triangle.

(cid:12)(cid:10)(cid:15)(cid:8) (cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)

(cid:12)(cid:10)(cid:15)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)

(cid:12)(cid:10)(cid:15)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)(cid:8)

(cid:12)(cid:17)(cid:15)

(cid:12)(cid:17)(cid:15)

(cid:12)(cid:17)(cid:15)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)

(cid:9)(cid:5)(cid:3)(cid:10)(cid:3)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)

(cid:16)(cid:17)(cid:18)(cid:11)(cid:19)(cid:20)(cid:10)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)

(cid:21)(cid:11)(cid:6)(cid:22)(cid:3)(cid:23)(cid:24)(cid:25)

Figure 2: A belief-state update with a 1,1,p2 triangle. Left: Pos-
sible initial states. Middle: Progressing with Rotate(90)(cid:150) rotating
the triangle by 90(cid:14) and putting it on the belt again. Right: After
observing length=1, state (b) is eliminated.

P

3 Circuit Filtering
Filtering is a hard problem. There are 22j
j belief states, so
na¤(cid:17)ve methods (such as enumeration) are intractable for large
domains. Following [Amir and Russell, 2003], we represent
belief states in logic. Their solution provides the foundations
for our research, but it guarantees an exact and compact rep-
resentation only for a few classes of models (e.g. restricted
action models, belief-states in a canonical form). We use log-
ical circuits (not (cid:3)at formulas) in order to extend their results
to all deterministic domains. In this section we describe our
representation and explain how to update it with an action-
observation sequence, and how to reason with the result.

(cid:19)

P : a state s is in (cid:26) iff it satis(cid:2)es ’ (s

3.1 Representation
A belief-state (cid:26) can be represented as a logical formula ’
over some P 0
’
is satis(cid:2)able). We call ’ a belief-state formula. We represent
our belief state formulas as circuits.
De(cid:2)nition 3.1 (Logical Circuits) Logical Circuits are di-
rected acyclic graphs. The leaves represent variables, and
the internal nodes are assigned a logical connective. Each
node represents a formula(cid:150) the one that we get by applying
the connective to the node’s children.

^

We allow the connectives
;
^

exactly one child, while
5.6 we explain how to avoid internal

_

.

;
_

;
nodes should have
^
can have many. In Corollary

:

:

We use logic to represent R, too: a domain description is
a (cid:2)nite set of effect rules of the form (cid:147)a causes F if G(cid:148), for
a an action, F and G propositional formulas over P . W.l.g.,
F is a conjunction of literals. The semantics of these rules
is as follows: after performing a in state s, iterate through
its rules. If the rule’s precondition G holds in s, its effect F

nodes (for NNF).

:

will hold in R(s; a). If this leads to a contradiction, a is not
possible to execute. The rest of the (cid:3)uents stay the same; if
no preconditions hold, the state does not change (we can also
make action failure lead to a sink state).

Consider the triangle in Figure 2. If the triangle is on the
belt, action a = Rotate(90) will rotate it, so the touching edge
will change: e1 to e2, e2 to e3, e3 to e1. a’s effect rules are:
(cid:147)a causes Touch(e2)
Touch(e1)(cid:148)
(cid:147)a causes Touch(e3)
Touch(e2)(cid:148)
(cid:147)a causes Touch(e1)
Touch(e3)(cid:148)

Touch(e1) if OnBelt()
Touch(e2) if OnBelt()
Touch(e3) if OnBelt()

^ :
^ :
^ :

^
^
^

3.2 C-Filter
We described how domains and belief-states are represented;
we can now present our Circuit-Filtering algorithm, C-Filter.

PROCEDURE C-Filter(
ai; oi
h
ai actions, oi observations, ’ an initial belief state over P ,
f
D domain description

t; ’; D)

0<i

(cid:20)

i

1: ProcessDomain(D;
2: for f
3: cb := Time0(’ )

2

P do explf := a new proposition f0

g Preprocess D, ’

ai
h

i

0<i

t)

(cid:20)

Process sequence

4: for i = 1 to t do
5:
6:
7: return cb

ProgressAction(ai)
FilterObservation(oi)

f

P (f
2

$

^

explf )

PROCEDURE ProgressAction(a)
a an action
f

g

V

Update cb: a executed, thus was possible.

Get f ’s next-value explanation:

a caused f , or f held and a did not cause
Effects(a) do
cb := cb
Time0( Poss(a,f) )
expl0f := Time0( NextVal(a,f) )
Effects(a) do explf := expl0f

^

f
:

1: for f
2:
3:
4: for f

2

2

PROCEDURE FilterObservation(o)
o an observation over P
f
g
Time0(o)
1: cb := cb

^

PROCEDURE Time0( )
  a formula
f

gReturn an equivalent circuit over time 0
P in   do replace f with the node pointed by explf

1: for f
2: return  

2

PROCEDURE ProcessDomain(D;
ai
h
D a domain description, ai actions
g
f

i

0<i

t)

(cid:20)

Extract (cid:148)Next Value(cid:148) and (cid:148)Possible(cid:148) Formulas

1: for f
2:
3:
4:

2

i

ai

do

2 h

P; a
NextVal(a,f) := Cause(a,f)
_
Poss(a,f) :=
(Cause(a,f)
^
(optional: Simplify Formulas)

:

(f
Cause(a,

^ :

Cause(a,

f)) 1

:

f))

:

Figure 3: C-Filter Algorithm

Algorithm Overview
C-Filter is presented in Figure 3 and demonstrated in Section
4. It receives an action-observation sequence, an initial belief

state formula, ’, over P , and a domain description D.
outputs the (cid:2)ltered belief state as a logical circuit.

It

The algorithm maintains a circuit data structure, and point-
ers to some of its nodes. A pointer to a node represents the
formula which is rooted in that node (and they will be used
interchangeably). We maintain pointers to the following for-
mulas: (1) A formula cb (constraint base) (cid:150) the knowledge
obtained so far from the sequence (receiving observations and
knowing that actions were possible to execute constrains our
belief state). (2) For every (cid:3)uent f
P , a formula explf ; this
formula explains why f should be true now (in Figure 4, the
node marked e(Tch1) is the explanation formula of Touch(e1)
at time t, and the root node is the explanation at time t + 1).
We keep the number of variables in our representation
P
) by allowing those formulas to involve only (cid:3)u-
small (
j
j
ents of time 0. In a way, this is similar to regression: explf
expresses the value of (cid:3)uent f as a function of the ini-
tial world state, and cb gives the constraints on the initial
state.

2

f

^

The belief state is always cb

explf ). In other
words, a possible model should satisfy cb, and each (cid:3)uent f
can be replaced with the formula explf .

P (f
2

$

V

In the preprocessing phase, we extract data from the do-
main description (Procedure C-Filter, line 1). We then cre-
ate a node for each (cid:3)uent, and initialize the explf pointers to
them. We also create a circuit for the initial belief-state, ’
(using the explf nodes), and set the cb pointer to it (lines 2-
3). Then we iterate through the sequence, update the circuit
and the pointers with every time step (lines 4-6, see below),
and (cid:2)nally return the updated belief state.

A Closer Look
The circuit is constructed as follows.
In the preprocessing
stage, we extract some useful formulas from the domain de-
scription. Let Effects(a) be the set of (cid:3)uents that action a
might affect. For each f in this set, we need to know how a
can affect f . Let Cause(a,f) be a formula describing when a
causes f to be true. It is simply the precondition of the rule of
a causing f to hold (if there are several, take the disjunction;
= Cause(a,f)
if there are none, set it to FALSE). That is, if s
j
and a is possible to execute, f will hold after it. Cause(a,
f)
is de(cid:2)ned similarly.

:

For example,

take a = Rotate(90)
Effects(a)=
Touch(e1), Touch(e2), Touch(e3)
f

g

(Section 3.1).
, and

^

:

Touch(e1)

Touch(e3)

^
Touch(e1)) = OnBelt()

Cause(a,Touch(e1)) = OnBelt()
Cause(a,
Procedure ProgressDomain then constructs the formula
NextVal(a,f), which evaluates to TRUE iff f holds after a
(given the previous state). Intuitively, either a caused it to
hold, or it already held and a did not affect it. Similarly, the
formula Poss(a,f) states that a was possible to execute regard-
ing f , i.e. did not cause it to be true and false at the same
time.

(*)

After preprocessing, we iterate through the sequence. Pro-
cedure ProgressAction uses those formulas to update the be-
lief state: First, it constructs a circuit asserting the action was

1Cause(a,f) represents the conditions for a to cause f , extracted

from the domain description (See (*))

possible (corresponding to the Poss formula) and adds it to
cb (line 2). Then, it builds a circuit for the NextVal formula.
Procedure Time0 ensures the circuit uses only time-0 (cid:3)uents.
When we construct a new Poss or NextVal circuit, its leafs
represent (cid:3)uents of the previous time step; Time0 replaces
them by their equivalent explanation nodes. Our circuit im-
plementation is crucial for the ef(cid:2)ciency of this replacement.
Instead of copying the whole formula, we only need to up-
date edges in the graph (using the pointers). This way, we
can share formulas recursively, and maintain compactness.

After all the new circuits were built, the explanation point-
ers are updated (line 4); the new explanation is the root of the
corresponding NextVal circuit, built earlier (line 3; see also
Section 5.1). Then we deal with the observation (Procedure
FilterObservation): similarly, we use Time0 to get a time-0
formula, and simply add it to cb.

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:13)(cid:14)(cid:11)(cid:13)(cid:15)(cid:16)(cid:6)

(cid:17)(cid:18)(cid:19)(cid:20)(cid:1)
(cid:1)(cid:3)(cid:4)(cid:5)(cid:6)

(cid:217)

(cid:1)

(cid:218)

(cid:17)(cid:18)(cid:19)(cid:20)(cid:1)
(cid:3)(cid:4)(cid:5)(cid:6)

(cid:217)

(cid:217)
(cid:21)(cid:21)(cid:21)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:8)(cid:7) (cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:9)(cid:7)

(cid:21)(cid:21)(cid:21)

(cid:21)(cid:21)(cid:21)

(cid:1)(cid:2)(cid:10)(cid:11)(cid:12)(cid:7)

(cid:21)(cid:21)(cid:21)

Figure 4: Updating the explanation of Touch(e1) after Rotate(90)

Example:

Figure 4 shows an update of the explanation
of Touch(e1) after the action Rotate(90). Rectangles (on the
bottom nodes) represent the explanation pointers of time t
(before the action). The circuit in the image is the NextVal
formula, after Procedure Time0 replaced its (cid:3)uents by the cor-
responding explanation nodes.

_

The

node is the root of the graph representing state of
Touch(e1) after the action: the right branch describes the case
that the action caused it to hold, and the left branch is the
case that it held, and the action did not falsify it. In the next
iteration, the pointer of Touch(e1) will point at this node.

Note the re-use of some time-t explanation nodes; they are

internal nodes, possibly representing large subformulas.

3.3 Query Answering with the End Formula
C-Filter returns an updated belief state ’t, represented as
a logical circuit. We are interested in satis(cid:2)ability queries
(’t
  satis(cid:2)able) and entailment queries (’t
=  , or
j
’t
  unsatis(cid:2)able). In the following, we construct a circuit
corresponding to the query and run inference on it.

^
^:

Query Circuits
Let   be an arbitrary propositional query formula; we want to
check whether ’t
  is satis(cid:2)able. Very similarly to an obser-
vation, we add   to cb, and replace the (cid:3)uents for their expla-
nations. The new cb is our query circuit. Queries are usually
about time t, but the circuit structure allows more interesting
queries, in particular smoothing(cid:150) queries that refer to the past
(e.g., did f change its value in the last 5 steps? Could the

^

initial value of g be TRUE?). Note that every (cid:3)uent in every
time step has a corresponding node. If we keep track of those
nodes, we can replace (cid:3)uents from any time step by their ex-
planations. If the queries are given in advance, this does not
change the complexity. Otherwise, (cid:2)nding a past-explanation
node might take O(log t) time. Note that the same mecha-
nism (tracking previous explanations) has many interesting
applications, such as (cid:2)ltering in non-Markovian domains.

SAT for Circuits
After building a query circuit, we check satis(cid:2)ability. Tradi-
tional approaches check circuit-SAT by converting the circuit
into a CNF formula. The approaches for doing so either grow
the representation exponentially (duplicating shared subfor-
mulas) or grow the number of variables signi(cid:2)cantly.

Instead, we run inference on the circuit itself. A number of
works show that the structural information lost in a CNF en-
coding can be used to give SAT procedures a signi(cid:2)cant per-
formance improvement. Using circuit SAT solvers, we can
solve the problem more ef(cid:2)ciently and effectively in its origi-
nal non-clausal encoding. Several such algorithms have been
proposed recently, taking advantage of the circuit structure
[Ganai et al., 2002; Thiffault et al., 2004]. We use those, and
a simple algorithm of our own, C-DPLL.

C-DPLL is a generalization of DPLL. Every iteration, an
uninstantiated variable f is chosen, and set to TRUE. The
truth value is then propagated as far as possible, resulting in
a smaller circuit (for example, if f had an OR parent, it will
be set to TRUE as well). Then, C-DPLL is called recursively.
If no satisfying assignment was found, it backtracks and tries
f =FALSE. If no assignment is found again, return UNSAT.
C-DPLL takes O(
) space for a circuit
E
j
with

2l) time and O(
E
j

edges and l leaves.

j (cid:1)

j

E
j

j

4 Extended Example
We now give a detailed example of the whole process. Inter-
estingly, this example demonstrates how logical circuits can
represent compactly a belief state that one cannot represent
compactly using CNF formulas over the same variables.

Our domain includes (cid:3)uents

. The follow-
g
ing sequence of actions makes odd equal to p1 (cid:8)
:::pn,
p2 (cid:8)
the parity of the other (cid:3)uents. Our actions a1; :::; an
1 are
p2, and any other ai
de(cid:2)ned such that a1 sets odd := p1 (cid:8)
sets odd := odd

p1; :::; pn; odd
f

pi+1. Formally:

(cid:0)

:

odd if

p2)(cid:148)
p2)
(
p1 ^
(cid:147)a1 causes odd if (p1 ^ :
:
_
p2)
(cid:147)a1 causes
(
[(p1 ^ :
p1 ^
:
_
:
(
(cid:147)ai causes odd if (odd
pi+1)
odd
_
^
^ :
:
(cid:147)ai causes
(
pi+1)
[(odd
odd
:
_
^ :
1 sets odd = p1 (cid:8)
Applying the sequence a1; :::; an

pi+1)](cid:148)
:::pn.
We now show how our algorithm maintains the belief state
throughout the sequence.

p2)](cid:148)
pi+1)(cid:148)

odd if

:

:

^

(cid:0)

(cid:8)

Preprocessing the Domain:
In this phase we extract the Poss and NextVal formulas. We
examine the action speci(cid:2)cations:
the only (cid:3)uent which is
affected is odd. a1 is executable when it does not cause both
odd;

odd.

:
Cause(a1,odd) = (p1 ^ :

p2)

(

p1 ^
:

_

p2)

:

odd) =

[(p1 ^ :
:

p2)
[Cause(a1,odd)

Cause(a1,
Poss(a1,odd) =
It is easy to see that both cannot hold simultaneously, and
the formula can be simpli(cid:2)ed to TRUE: indeed, a1 is always
executable. Similarly, all of our actions are always possible
to execute, so the Poss formulas are all equal TRUE.

(
p1 ^
:
Cause(a1,

odd)]

p2)]

_
^

:

:

Now, the NextVal formulas. After executing a1, odd will

be set to Cause(a1,odd)

[odd

Cause(a1,

odd)].

This is equivalent to Cause(a1,odd). In other words, odd
p2. Similarly, after action ai odd will
will be set to p1 (cid:8)
be set to pi+1 (cid:8)
odd. Note, simplifying the formulas is not
mandatory; the representation will be compact without it, too.

_

^ :

:

(cid:0)

the

receive

(arbitrary)

that we
1; odd

Executing the Actions:
Imagine
sequence
a1; a2; :::; an
pn (performing n actions and
^ :
receiving an observation).
Figure 5 describes how the
algorithm updates the belief-state with this sequence. At
time 0 (5a) we create a node for every (cid:3)uent, and another for
TRUE. The nodes represent the value of the (cid:3)uent at time 0.
We set a pointer (the rectangles) for each formula that we
want to maintain: the formula for cb (constraints) is set to
TRUE because we do not have any initial knowledge. The
explanation formula of each (cid:3)uent is set to the corresponding
node.

We then execute a1, arriving at time 1 (5b). No constraint
was added to cb, since the action is always executable. No
explanation formula of pi changed, since a1 does not affect
them. The only thing that changed is the state of odd: its new
p2. We construct the graph for this for-
explanation is p1 (cid:8)
mula, and update the explanation pointer to its root node.
NOTE: the image shows xor gates just for the sake of clar-
ity. In fact, each of them should be replaced by (cid:2)ve gates, as
depicted in 5b.

Executing a2 is similar (time 2, 5c). We construct the graph
p3. Note that we substitute the
for odd’s new value, odd
(cid:3)uents in this formula (odd; p3) by their explanations in time
1, i.e. the pointers of the previous time step.

(cid:8)

(cid:0)

We execute a3; :::; an

1, and then observe odd

pn (5d.
This is just an example observation; alternatively, you can
pn
think of it as querying whether it is possible that odd
holds now). First, we process the actions and update the ex-
pn to our constraints,
planation of odd. Then we add odd
creating a new cb circuit and updating the pointer. Finally, we
return the circuit in 5d, along with the pointers. This is our
updated belief state.

^ :

^ :

^ :

Answering Queries:
In 5e we show an example of truth-value propagation: if we
assume that at time 0 p1=TRUE and the rest are set to FALSE,
those values are propagated up and result in cb=TRUE. That
is, this assignment is consistent with our sequence.

5 Analysis and Complexity
5.1 Correctness
Theorem 5.1 C-Filter is correct. For any formula ’ and a
sequence of actions and observations

ai; oii0<i
t,
h
t; ’)
S that satisfy C-Filter(
ai; oii0<i
h
g
S that satisfy ’
).
g

s
2
Filter[
ai; oii0<i
h

t](
s
f

2

(cid:20)

(cid:20)

(cid:20)

=

f

(cid:11)(cid:11)(cid:11)

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:6)(cid:5) (cid:1)(cid:2)(cid:3)(cid:7)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:8)(cid:5)

(cid:18)(cid:19)

(cid:1)(cid:2)(cid:2)(cid:3)

(cid:4)(cid:6)(cid:3)

(cid:4)(cid:5)(cid:3)

(cid:4)(cid:8)(cid:3)

(cid:4)(cid:7)(cid:3)

(cid:9)(cid:10)(cid:11)(cid:12)

(a) At time t=0: initial belief state ’ = TRUE

¯

(cid:15)

(cid:14)

”

(cid:218)

(cid:217)

(cid:1)

(cid:217)

(cid:1)

(cid:14)(cid:15)

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)
(cid:12)(cid:9)(cid:13)(cid:14)(cid:15)(cid:16)(cid:17)

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)
¯

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:6)(cid:5) (cid:1)(cid:2)(cid:3)(cid:7)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:8)(cid:5)

(cid:18)(cid:19)

(cid:1)(cid:2)(cid:2)(cid:3)

(cid:4)(cid:6)(cid:3)

(cid:4)(cid:5)(cid:3)

(cid:4)(cid:8)(cid:3)

(cid:4)(cid:7)(cid:3)

(cid:9)(cid:10)(cid:11)(cid:12)

(b) Time t=1: after performing a1

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)
(cid:12)(cid:9)(cid:13)(cid:14)(cid:15)(cid:16)(cid:4)

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)
¯

¯

(cid:11)(cid:11)(cid:11)

(cid:11)(cid:11)(cid:11)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:6)(cid:5) (cid:1)(cid:2)(cid:3)(cid:7)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:8)(cid:5)

(cid:21)(cid:22)

(cid:1)(cid:2)(cid:2)(cid:3)

(cid:4)(cid:6)(cid:3)

(cid:4)(cid:5)(cid:3)

(cid:4)(cid:8)(cid:3)

(cid:4)(cid:7)(cid:3)

(cid:9)(cid:10)(cid:11)(cid:12)

(c) Time t=2: after performing a1; a2

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)(cid:14)(cid:12)(cid:9)(cid:13)(cid:14)(cid:15)(cid:16)(cid:2)(cid:8)(cid:17)(cid:6)(cid:5)

¯

(cid:11)(cid:11)(cid:11)
¯

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)
(cid:12)(cid:9)(cid:13)(cid:14)(cid:15)(cid:16)(cid:6)

¯

(cid:1)(cid:2)(cid:9)(cid:10)(cid:10)(cid:5)
¯

(cid:21)(cid:22)
(cid:217)

(cid:1)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:6)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:7)(cid:5)

(cid:1)(cid:2)(cid:3)(cid:8)(cid:5)

(cid:11)(cid:11)(cid:11)

(cid:1)(cid:2)(cid:2)(cid:3)

(cid:4)(cid:6)(cid:3)

(cid:4)(cid:5)(cid:3)

(cid:4)(cid:8)(cid:3)

(cid:4)(cid:7)(cid:3)

(cid:9)(cid:10)(cid:11)(cid:12)

(d) Time t=(n-1): after performing a1; ::; an

1 and observing

(odd

pn)

^ :

(cid:0)

(cid:9)

¯(cid:11)(cid:11)(cid:11)
¯

(cid:9)

(cid:9)

¯

(cid:9)

(cid:18)(cid:19)
(cid:217)

(cid:1)(cid:9)

(cid:9)

¯

(cid:11)(cid:11)(cid:11)

(cid:9)
(cid:4)(cid:6)(cid:3)

(cid:13)
(cid:4)(cid:5)(cid:3)

(cid:13)
(cid:4)(cid:8)(cid:3)

(cid:1)(cid:2)(cid:2)(cid:3)

(cid:13)
(cid:4)(cid:7)(cid:3)

(cid:9)(cid:10)(cid:11)(cid:12)

Figure 5: (e) Propagating truth-values

^

Recall that a state s satis(cid:2)es formula ’ if s

’ is satis(cid:2)able

(Section 3.1). s is used as a formula and as a state.

PROOF SKETCH We present an effect model, and show
how to update a belief-state ((cid:3)at) formula with this model.
We show that the Filtering de(cid:2)nition in Section 2 can be re-
duced to consequence (cid:2)nding (in a restricted language) with
this formula. Then, we show that C-Filter computes exactly
those consequences.

De(cid:2)nition 5.2 Effect Model:
For an action a, de(cid:2)ne the effect model of a at time t to be:
Teff(a; t) = at !

NextVal(a; f; t))

f

P Poss(a; f; t)
2

(ft+1 $

^

V

Poss(a; f; t) =
(Cause(a,f)t ^
:
NextVal(a; f; t) = Cause(a,f)t _

Cause(a,
(ft ^ :

f)t)

:
Cause(a,

f)t)

:

at asserts that action a occurred at time t, and ft+1 means
that f after performing a.  t is the result of adding a sub-
script t to every (cid:3)uent in formula   (see Section 3.2 for de(cid:2)-
nition of Cause(a,f)). The effect model corresponds to effect
axioms and explanation closure axioms from Situation Cal-
culus [Reiter, 1991]. If the robot can recognize an impossible
action, we can drop the assumption that actions are possible,
and adopt a slightly different effect model.

Recall that Filter[](
) was de(cid:2)ned over a set of states. We
(cid:1)
now de(cid:2)ne its analogue L-Filter, which handles belief-state
logical formulas.
De(cid:2)nition 5.3 (L-Filter) Let ’ a belief-state formula.

L-Filter[a](’) = CnLt+1 (’t ^
L-Filter[o](’) = ’

o

at ^

Teff(a; t))

Pt+1)

where CnL( ) are the consequences of   in vocabulary L.
Lt+1 = (L(’t)
and
L(’t) the language of ’t; i.e., Lt+1 does not allow (cid:3)uents
with subscript t.
Lemma 5.4 The result of applying L-Filter[a] for a
2
formula representing exactly the set of states Filter[a].

Pt , for Pt =

ft j
f

A is a

[

2

P

n

g

f

More formally, let ’ be a belief state formula.

(cid:15)
(cid:15)

^

Filter[a](
s
f
s satis(cid:2)es L-Filter[a](’)
g

s satis(cid:2)es ’
) =
g

s
f

2

2

S

S

j

j

That is, both de(cid:2)nitions are equivalent (for lack of space,
we do not present the proof here). As a result, we can com-
pute Filter using a consequence (cid:2)nder in a restricted lan-
guage. However, this does not guarantee tractability. Instead
of using a consequence-(cid:2)nder, we show that C-Filter com-
putes exactly those consequences.

Let   := ’t ^

Teff(a; t). According to our de(cid:2)nition,
L-Filter[a](’) = CnLt+1 ( ). We now observe that conse-
quence (cid:2)nding is easy if we keep ’t in the following form:

at ^

’t = cb

P (ft $

f

2

explf )

^

cb and explf do not involve any (cid:3)uent of time t.

V

We now show how to compute the consequences of such
formulas. Furthermore, we show that the resulting formula
maintains this form, so we only need to check the form of the
initial belief-state. Luckily, this is not a problem; every ini-
tial belief-state can be converted to this form (in linear time)
using new proposition symbols.

Let   be a formula in this form.   states that (ft $

explf )
Pt: we construct an equivalent formula,  0, by

for every ft 2
replacing every ft 2
Notation:  0 := ’t ^
)

 0

(cid:17)

 

Pt in Teff(a; t) with the formula explf .
at ^
CnLt+1 ( )

Teff(a; t)[explf =ft].

CnLt+1 ( 0)

(cid:17)

Therefore, we can (cid:2)nd the consequences of  0 instead.
Note that consequence (cid:2)nding in Lt+1 is the same as using
the Resolution algorithm to resolve (cid:3)uents of Pt. We use this
to compute CnLt+1 ( 0):

CnLt+1 ( 0)

2
cb0 := cb

V

Let

(cid:17)
f

f

cb
^
P (ft+1 $

V

P (Poss(a; t; f )[explg=gt])
2

^
NextVal(a; t; f )[explg=gt])

f

P (Poss(a; t; f )[explg=gt])
2

^

expl0f := NextVal(a; t; f )[explg=gt]).

V

The last formula can be re-written as
P (ft+1 $

cb0

^

2

f

expl0f )

V

Now note that C-Filter maintains the belief-state for-

f

mula exactly in that easy-to-compute form, namely cb

^
explf ) , cb and explf involve only special propo-
sitions, representing time-0 (to avoid confusion, you might
V
think of the new propositions in line 2 as finit, not f0).

P (ft $

2

Also, cb0; expl0f are exactly the constraint-base and expla-
nation formulas after C-Filter’s ProgressAction. That is, C-
Filter correctly progresses the belief-state with actions. The
proof for handling observations is similar.

Obs
j

5.2 C-Filter Complexity
Let ’0 be the initial belief state, t the length of the action-
observation sequence, and
the total length of the obser-
vations in the sequence. Let ActDesc be the longest descrip-
tion of an action a
Theorem 5.5 Allowing preprocessing of O(
) time and
j
j
space (or, alternatively, using a hash table), C-Filter takes
’0
time O(
+
ActDesc) . Its output is a circuit of
j
the same size.

A (preconditions + effects).

Obs
j

+ t

2

P

j

j

j

(cid:1)

j

Obs
j

If the observations are always conjunctions of literals, we
can drop
from space complexity. If there are no precon-
ditions, we can maintain a (cid:3)at formula instead. Note that this
does not depend on the domain size,
. ActDesc is usually
j
small(cid:150) especially if the actions in the domain affect a small
number of (cid:3)uents, and have simple preconditions.

P
j

j

j

PROOF SKETCH: Initializing cb takes O(

) time. Han-
dling each action adds at most O(ActDesc) nodes and edges
to the graph, and takes the same time: in the worst case, as-
suming no simpli(cid:2)cations were done, we need to construct a
graph for each of the action’s Causes formulas. Finally, each
time we receive an observation o we add at most O(
o
) nodes
j
j
and edges, resulting in total O(
Obs
j

Corollary 5.6 We can maintain an NNF-Circuit (no negation
nodes) with the same complexity.

).

j

’0

PROOF SKETCH

The circuit’s leaves represent literals
(instead of propositions). We maintain explanation formulas
for them. Since (f
explf ), we can
$
de(cid:2)ne expl
explf . We take the NNF-form of every

explf )

$ :

f
:

)

(

f :=
:

:

(cid:13)(cid:30)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:9)(cid:28)(cid:31) (cid:29)

(cid:13)(cid:30)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:9)(cid:28)(cid:21)! (cid:29)

(cid:13)(cid:30)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:9)(cid:28)(cid:21)"(cid:20)(cid:18)(cid:29)

#$$(cid:9)(cid:28)(cid:31) (cid:29)

#$$(cid:9)(cid:28)(cid:18)(cid:31)(cid:18)(cid:29)

#$$(cid:9)(cid:28)(cid:21)! (cid:29)

%(cid:7)(cid:6)(cid:14)(cid:3)(cid:3)(cid:9)(cid:28)(cid:31) (cid:29)

%(cid:7)(cid:6)(cid:14)(cid:3)(cid:3)(cid:9)(cid:28)(cid:21)! (cid:29)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:9)(cid:28)(cid:31) (cid:29)(cid:9)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:9)(cid:28)(cid:21)! (cid:29)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:6)(cid:13)(cid:5)(cid:10)(cid:11)(cid:4)(cid:14)(cid:7)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:2)(cid:7)(cid:8)(cid:9)(cid:10)(cid:2)(cid:11)(cid:5)(cid:12)(cid:9)(cid:13)(cid:14)(cid:11)(cid:15)(cid:16)(cid:6)(cid:2)(cid:17)(cid:14)(cid:7)

$(cid:8)(cid:4)%(cid:10)& (cid:12)(cid:8)(cid:5)%"(cid:9)(cid:10)
(cid:20)(cid:24)(cid:17)(cid:10)(cid:2)(cid:10)(cid:19)(cid:15)’(cid:17)(cid:20)(cid:10)(cid:3)(cid:5)(cid:27)(cid:7)(cid:28)(cid:6)"

#
(cid:29)
(cid:7)
!"
(cid:7)
(cid:14)
(cid:11)

(cid:4)

(cid:10)

(cid:20)(cid:19)

(cid:19)(cid:22)

(cid:19)(cid:21)

(cid:19)(cid:20)

(cid:18)

(cid:17)

(cid:16)

(cid:15)

(cid:18)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)

(cid:18)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)

(cid:18)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)

(cid:18)(cid:19)(cid:19)(cid:19)(cid:19)

(cid:18)(cid:19)(cid:19)(cid:19)

(cid:18)(cid:19)(cid:19)

(cid:18)(cid:19)

(cid:18)

(cid:29)
(cid:25)
(cid:5)
(cid:17)

(cid:28)(cid:11)

(cid:9)

(cid:5)
(cid:11)
(cid:10)

(cid:2)

(cid:9)
(cid:3)

(cid:16)
(cid:4)
(cid:14)
(cid:10)

(cid:15)

(cid:20)(cid:15)(cid:15)(cid:23)(cid:15)(cid:15)(cid:15)

(cid:24)(cid:15)(cid:15)(cid:23)(cid:15)(cid:15)(cid:15)

(cid:17)(cid:15)(cid:15)(cid:23)(cid:15)(cid:15)(cid:15)

(cid:25)(cid:7)(cid:26)(cid:27)(cid:7)(cid:28)(cid:29)(cid:7)(cid:10)(cid:30)(cid:7)(cid:28)(cid:31)(cid:6) 

((cid:5)(cid:12)(cid:29))(cid:10)& (cid:12)(cid:8)(cid:5)%"(cid:9)(cid:10)
(cid:22)(cid:18)(cid:10)(cid:2)(cid:10)(cid:19)(cid:15)(cid:16)(cid:15)(cid:19)(cid:10)(cid:3)(cid:5)*

(cid:13)(cid:30)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)

(cid:19)

(cid:20)(cid:19)(cid:19)(cid:19) (cid:18)(cid:19)(cid:19)(cid:19)(cid:19) (cid:18)(cid:20)(cid:19)(cid:19)(cid:19) (cid:21)(cid:19)(cid:19)(cid:19)(cid:19) (cid:21)(cid:20)(cid:19)(cid:19)(cid:19)

(cid:22)(cid:5)(cid:23)(cid:24)(cid:5)(cid:7)(cid:25)(cid:5)(cid:9)(cid:26)(cid:5)(cid:7)(cid:8)(cid:4)(cid:27)

Figure 6: Left: Filtering time (sec) for C-Filter, applied to Block-World and Grid domains of different sizes. The time is linear, and does
not depend on the domain size (slight differences in the graph are due to hash-table implementation). Right: Comparison of Filtering time
(msec) for several methods (numbers represent domain size). Note that this is log-scale.

formula we use (observations, explanations, etc.), and replace
every literal by its explanation. Converting to NNF takes time
linear in the formula’s size; therefore, time and space com-
plexities will not change (modulo a small constant).

sibly nondeterministic) domain, an initial belief state, and a
sequence of actions after which our belief state representation
is exponential in the initial belief state size. Our results show
that this does not hold for deterministic systems.

5.3 Projection
Projection is the problem of checking that a property holds
after t action steps of an action system, starting from a belief
state. Generalizations allow additional observations.

Our results from previous sections show that projection is
doable by applying C-Filter (generating the belief state at
time t, ’t, adding the query and running our C-DPLL solver).
Let m be maximal length of a single observation plus
ActDesc. Usually m = O(1). Since ’t includes O(n) vari-
ables, and has overall size O(n + mt), checking if a variable
assignment is a model of ’t takes time O(n+mt). Thus, test-
ing satis(cid:2)ability is NP-Complete in n, instead of n + mt (the
size of the formula) or n
t (the number of propositional vari-
ables that appear in an unrolling of the system over t steps;
used in Bounded Model Checking). We need to guess n vari-
able assignments, and then apply a linear algorithm to check
it. The following result re(cid:2)nes earlier complexity results.
Theorem 5.7 (Projection) Let D be a domain with deter-
ministic actions. The problem of answering whether all the
states in F ilter[(cid:25)](’) satisfy Q, for belief state formula ’,
sequence of actions (cid:25) and query Q, is coNP-complete in the
number of state variables, n. We assume (cid:25), ’, ActDesc and
Q are polynomial in n.

(cid:1)

5.4 Representation Complexity
Our results have implications for the theory of representation-
space complexity. A simple combinatorial argument shows
that there are belief states of n (cid:3)uents that cannot be described
using logical circuit of size o(2n), i.e., strictly smaller than
some linear function of 2n. Nevertheless, our results for C-
Filter show that those belief states that are reachable within a
polynomial number of actions from an initial belief state are
of size linear in t and the input size (initial belief state size,
and longest action description).

Also, [Amir and Russell, 2003] showed that for every
general-purpose representation of belief states there is a (pos-

5.5 A Note on Non-Determinism
C-Filter can handle non-determinism in observations, but not
in transition models. However, many real-life environments
are inherently non-deterministic. One natural solution is to
treat each non-deterministic action as a choice between sev-
eral deterministic ones. For example, coin-(cid:3)ipping:
(cid:3)ipt !
where formula ExactlyOneCase speci(cid:2)es that exactly one of
case1, case2 holds (we can use a binary encoding). Unfortu-
nately, the number of propositions grows linearly with t.

[ExactlyOneCase
(case1 !

(case2 ! :

^
headst+1)

headst+1)]

^

We can handle another (very limited) non-deterministic
class without adding propositions (speci(cid:2)cally, (cid:147)a causes
q if G(cid:148), G deterministic). The idea is to maintain a belief
p
state in a different form, with (l
expll) for every literal l .

_

!

6 Experimental Evaluation
Our Filtering algorithm was implemented in C++. Our im-
plementation could also handle parametrized domain descrip-
tions, such as STRIPS. We tested it on AI-Planning domains
(Figure 7 lists several) of various sizes and observation mod-
els. We generated long action-observation sequences with a
random sequence generator (implemented in Lisp), and ran
inference on the results using our own C-DPLL and NoClause
([Thiffault et al., 2004]). circuit SAT solver.

Blocks: 108/124
Gripper: 110/6
Movie: 47/13

Ferry: 163/17
Hanoi: 259/16 Logistics: 176/16
Tsp: 98/15

Grid: 251/53

Figure 7: Overview of C-Filter experiments: AI-Planning domains
(2000+ (cid:3)uents, 10000 steps). Results presented as Filtering time/
Model (cid:2)nding time (both in msec).

Figures 6, 7, 8 present some of the results. Figure 6 (left)
shows that C-Filter is linear in the sequence length; note that

(cid:11)(cid:12)(cid:13)(cid:14)(cid:12)(cid:13)(cid:15)(cid:16)(cid:17)(cid:16)(cid:18)(cid:19)(cid:14)(cid:20)(cid:21)(cid:16)(cid:22)(cid:23)(cid:24)(cid:25)(cid:26)

(cid:3)(cid:7)(cid:6)(cid:2)(cid:16)(cid:11)(cid:21)(cid:16)(cid:22)(cid:2)(cid:1)(cid:16)(cid:19)(cid:27)(cid:28)(cid:26)
(cid:3)(cid:7)(cid:6)(cid:2)(cid:16)(cid:11)(cid:21)(cid:16)(cid:22)(cid:4)(cid:16)(cid:19)(cid:27)(cid:28)(cid:26)
(cid:3)(cid:4)(cid:10)(cid:16)(cid:11)(cid:21)(cid:16)(cid:22)(cid:2)(cid:1)(cid:16)(cid:19)(cid:27)(cid:28)(cid:26)
(cid:3)(cid:4)(cid:10)(cid:16)(cid:11)(cid:21)(cid:16)(cid:22)(cid:4)(cid:16)(cid:19)(cid:27)(cid:28)(cid:26)
(cid:9)(cid:10)(cid:16)(cid:11)(cid:21)(cid:16)(cid:22)(cid:2)(cid:1)(cid:16)(cid:19)(cid:27)(cid:28)(cid:26)
(cid:9)(cid:10)(cid:16)(cid:11)(cid:21)(cid:16)(cid:22)(cid:4)(cid:16)(cid:19)(cid:27)(cid:28)(cid:26)

(cid:26)
(cid:31)
(cid:20)
(cid:28)
#

(cid:22)
(cid:16)
(cid:20)
#
(cid:25)

(cid:12)

(cid:16)
(cid:21)

(cid:17)
!
(cid:19)
(cid:25)

(cid:10)(cid:1)(cid:1)
(cid:9)(cid:1)(cid:1)
(cid:8)(cid:1)(cid:1)
(cid:7)(cid:1)(cid:1)
(cid:6)(cid:1)(cid:1)
(cid:5)(cid:1)(cid:1)
(cid:4)(cid:1)(cid:1)
(cid:3)(cid:1)(cid:1)
(cid:2)(cid:1)(cid:1)
(cid:1)

(cid:1)

(cid:2)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:6)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:7)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:3)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:4)(cid:1)(cid:1)(cid:1)(cid:1)

(cid:5)(cid:1)(cid:1)(cid:1)(cid:1)
(cid:23)(cid:20)(cid:29)(cid:30)(cid:20)(cid:13)(cid:31)(cid:20)(cid:16) (cid:20)(cid:13)(cid:15)!"

Figure 8: Total time for (cid:2)nding a model (msec), for Block-Worlds
of different size and number of observations per step.

time depends on the domain but not on the domain size. In
both Block-World and Grid-World, (cid:2)ltering time almost does
not change, even when the number of (cid:3)uents grows 100 times
larger (slight difference in the graph is due to hash-table im-
plementation, instead of an array; the circuit size does not
depend on this implementation and was the same).

The right part of Figure 6 shows a comparison to other
(cid:2)ltering methods. We compared our algorithm to (1) Filter
[Amir and Russell, 2003] (in Lisp), (2) Filtering by unrolling
the system over t steps (using
t propositions), (3) BDD-
j
based Filtering, based on the BuDDy package [Lind-Nielsen,
1999]. C-Filter outperformed them all, sometimes by orders
of magnitude; note that the graph is log-scale.

P
j

Comparison Analysis:

BDD sizes depend highly on
variable ordering. Even for some very simple circuits, the
representation can have either linear or exponential size de-
pending on the order ((cid:2)nding an optimal ordering is known
to be NP-complete). The long processing time at the begin-
ning is due to heuristic methods that try to achieve a good
ordering; after a while, a good ordering was reached, mak-
ing processing faster. Even with those heuristics, we could
not process large (> 300) domains. Filter and Unroll were
also slower, and could not process long sequences or large
domains (also, Filter can handle only a limited class of do-
mains). Unroll suffers from the frame problem, i.e. needs to
ft+1),
explicitly state the (cid:3)uents that do not change (ft $
and therefore depends on the domain size. C-Filter, however,
managed to handle large domains (hundreds of thousands of
(cid:3)uents), taking a few milliseconds per step.

Figure 8 shows the time to (cid:2)nd a model for the resulting
circuits using a modi(cid:2)ed version of NoClause. Signi(cid:2)cantly,
reasoning time grows only linearly with t. This allows prac-
tical logical (cid:2)ltering over temporal sequences of unbounded
length. Note that the more observations an agent gets, the
more constrained his belief state is. Therefore, it takes longer
to (cid:2)nd a satisfying model (also, the formula is larger).

7 Conclusions
A straightforward approach to (cid:2)ltering is to create all the
prime implicates (or all consequences) at time t + 1 from the
belief state representation of time t. Previous work (e.g. [Lib-
eratore, 1997]) showed that deciding if a clause belongs to the
new belief state is coNP-complete, even for deterministic do-
mains. This discouraged further research on the problem.

Nevertheless,

in this work we presented an exact and

tractable (cid:2)ltering algorithm for all deterministic domains.
Our result is surprising because it shows that creating a rep-
resentation of all of the consequences at time t + 1 is easier
(poly-time) than creating the new belief state piecemeal.

Several approaches were developed in the past to repre-
sent belief states in logic (e.g., BDDs, [Amir and Russell,
2003]), but none of them guaranteed compactness. The key
to our advance was our logical circuits representation. We
also showed how to maintain NNF-Circuits.

The results obtained here have implications in many impor-
tant AI-related (cid:2)elds. We expect our algorithms to apply to
planning, monitoring and controlling, and perhaps stochastic
(cid:2)ltering. We plan to explore these directions in the future.

Acknowledgements This work was supported by the Na-
tional Science Foundation CAREER award grant IIS 05-
46663. We thank the anonymous reviewers for their helpful
comments.

References
[Amir and Russell, 2003] E. Amir and S. Russell. Logical (cid:2)ltering.

In IJCAI ’03. MK, 2003.

[Bertoli et al., 2001] P. Bertoli, A. Cimatti, and M. Roveri. Heuris-
tic search + symbolic model checking = ef(cid:2)cient conformant
planning. In IJCAI ’01. MK, 2001.

[Biere et al., 1999] A. Biere, A. Cimatti, E.M. Clarke, M. Fujita,
and Y. Zhu. Symbolic model checking using SAT procedures
instead of BDDs. In DAC’99, 1999.

[Bryant, 1992] R. E. Bryant. Symbolic Boolean manipulation with
ordered binary-decision diagrams. ACM Computing Surveys,
1992.

[Cimatti and Roveri, 2000] A. Cimatti and M. Roveri. Conformant

planning via symbolic model checking. JAIR, 2000.

[Clarke et al., 2001] E.M. Clarke, A. Biere, R. Raimi, and Y. Zhu.
Bounded model checking using satis(cid:2)ability solving. Formal
Methods in System Design, 2001.

[Ganai et al., 2002] M. K. Ganai, P. Ashar, A. Gupta, L. Zhang, and
S. Malik. Combining strengths of circuit-based and cnf-based
algorithms for a high-performance sat solver. In DAC, 2002.

[Liberatore, 1997] P. Liberatore. The complexity of the language

[Lin and Reiter, 1997] F. Lin and R. Reiter. How to progress a

A. ETAI, 1997.

database. AIJ, 1997.

[Lind-Nielsen, 1999] J. Lind-Nielsen. Buddy - a binary decision di-
agram package. Technical report, Institute of Information Tech-
nology, Technical University of Denmark, 1999.

[Petrick and Bacchus, 2004] R.P.A. Petrick and F. Bacchus. Ex-
tending the knowledge-based approach to planning with incom-
plete information and sensing. In ICAPS-04. AAAI Press, 2004.
[Reiter, 1991] R. Reiter. The frame problem in the situation cal-
culus: A simple solution (sometimes) and a completeness result
for goal regression. In Arti(cid:2)cial Intelligence and Mathematical
Theory of Computation. Academic Press, 1991.

[Thiffault et al., 2004] C. Thiffault, F. Bacchus, and T. Walsh. Solv-
In Principles and

ing non-clausal formulas with dpll search.
Practice of Constraint Programming, 2004.

[Winslett, 1990] M.A. Winslett. Updating Logical Databases.

Cambridge U. Press, 1990.

