Kernel Nystr¨om Method for Light Transport

Jiaping Wang∗

Yue Dong† ∗

Xin Tong∗

Zhouchen Lin∗

Baining Guo∗ †

∗ Microsoft Research Asia

† Tsinghua Univeristy

Figure 1: Relighting results using the light transport matrix reconstructed by our method. Complex light transport effects, including caustics
(a), complex occlusions (b), and a mixture of caustics, complex occlusions, inter-reﬂections, and subsurface scattering (c) are all faithfully
reproduced.

Abstract

We propose a kernel Nystr¨om method for reconstructing the light
transport matrix from a relatively small number of acquired images.
Our work is based on the generalized Nystr¨om method for low rank
matrices. We introduce the light transport kernel and incorporate it
into the Nystr¨om method to exploit the nonlinear coherence of the
light transport matrix. We also develop an adaptive scheme for efﬁ-
ciently capturing the sparsely sampled images from the scene. Our
experiments indicate that the kernel Nystr¨om method can achieve
good reconstruction of the light transport matrix with a few hun-
dred images and produce high quality relighting results. The ker-
nel Nystr¨om method is effective for modeling scenes with complex
lighting effects and occlusions which have been challenging for ex-
isting techniques.

1 Introduction

The goal of image-based relighting is to directly capture the light
transport of a real-world scene so that it can be rendered with new
illumination [Debevec et al. 2000; Wenger et al. 2005; Peers et al.
2009]. Mathematically, image-based relighting can be formulated
as the following equation [Ng et al. 2003; Peers et al. 2009]:

b = T · l,

(1)

where T is the m × n light transport matrix that describes the light
transport from n light sources to m camera pixels, l is the illumina-
tion condition represented by a vector of incident radiance from n

∗email:{jiapw,xtong,zhoulin,bainguo}@microsoft.com

ACM Reference Format
Wang, J., Dong, Y., Tong, X., Lin, Z., Guo, B. 2009. Kernel Nyström Method for Light Transport. 
ACM Trans. Graph. 28, 3, Article 29 (August 2009), 10 pages. DOI = 10.1145/1531326.1531335 
http://doi.acm.org/10.1145/1531326.1531335.

Copyright Notice
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted 
without fee provided that copies are not made or distributed for proﬁ t or direct commercial advantage 
and that copies show this notice on the ﬁ rst page or initial screen of a display along with the full citation. 
Copyrights for components of this work owned by others than ACM must be honored. Abstracting with 
credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any 
component of this work in other works requires prior speciﬁ c permission and/or a fee. Permissions may be 
requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, 
fax +1 (212) 869-0481, or permissions@acm.org.
© 2009 ACM 0730-0301/2009/03-ART29 $10.00 DOI 10.1145/1531326.1531335 
http://doi.acm.org/10.1145/1531326.1531335

light sources, and b is the outgoing radiance observed in a camera
image with m pixels. Our task is to ﬁnd the matrix T.

Image-based relighting offers an unparalleled advantage of realistic
rendering without scene modeling, which is often an arduous task.
However, to generate high quality results, the existing techniques
often require tens of thousands of images for accurate reconstruc-
tion of the light transport matrix (e.g., see [Debevec et al. 2000;
Wenger et al. 2005]). Several approaches have shown promise in
reducing the number of required images [Zongker et al. 1999; Ma-
tusik et al. 2004; Peers and Dutr´e 2005; Peers et al. 2009; Sen
and Darabi 2009]. However, these techniques are either dedicated
to speciﬁc light transport effects [Zongker et al. 1999] or mainly
effective with scenes of simple geometry conﬁgurations [Matusik
et al. 2004; Peers and Dutr´e 2005]. Applying these techniques to
scenes with complex lighting effects and occlusions still requires a
large number of input images and expensive reconstruction meth-
ods [Peers et al. 2009].

In this paper we propose a kernel Nystr¨om method for reconstruct-
ing the light transport matrix from a small number of images. We
ﬁrst acquire a small number of rows and columns of the light trans-
port matrix of a real world scene and then reconstruct the entire
matrix from these sparse samples. Our work is inspired by the
Nystr¨om method proposed by Williams and Seeger [2000] for re-
constructing a low rank symmetric matrix using a linear combina-
tion of sparsely sampled rows and columns. In this paper, we apply
a generalized form of the Nystr¨om method [Goreinov et al. 1997]
previously developed in the linear algebra community for recon-
structing asymmetrical matrices.

The main contribution of this paper is the introduction of the
light transport kernel so that the nonlinear coherence of the light
transport matrix can be exploited to enhance the effectiveness of
the Nystr¨om method. The kernel Nystr¨om method refers to the
Nystr¨om method with the light transport kernel incorporated. The
power of the Nystr¨om method essentially comes from its ability to
exploit the linear coherence of the light transport matrix. By further
exploiting the nonlinear coherence, the kernel Nystr¨om method be-
comes much more powerful and the number of sampled rows and
columns (and hence acquired images) needed for the matrix re-
construction is greatly reduced. The light transport kernel works

ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.as follows. First, we design a data speciﬁc kernel function that
can be estimated from the sparse row and column samples. Then
by mapping these samples with the kernel function, we reduce the
rank of the light transport matrix so that a high quality matrix can
be reconstructed from the kernel-mapped sparse samples via the
Nystr¨om method. Finally, the light transport matrix is obtained
from elements of the reconstructed matrix by inverse kernel map-
ping.

A novel aspect of the kernel Nystr¨om method is that it exploits the
data coherence during the matrix reconstruction process, before the
whole matrix is known. It has been recognized in the past that the
data coherence in light transport can be used for data compression
after the whole matrix is known [Masselus et al. 2004; Mahajan
et al. 2007]. The kernel Nystr¨om method takes a different approach
and only uses the known row and column samples as an oracle for
analyzing the data coherence and reconstructing the matrix. To this
end, we develop an adaptive scheme for measuring the sparse row
and column images of the light transport matrix and estimating the
light transport kernel.

We have evaluated the kernel Nystr¨om method using a variety of
test scenes, including those with inter-reﬂections, caustics, and
complex occlusions. We also used the method to measure the light
transport between object surface points due to diffuse subsurface
scattering inside the object volume. Our experiments indicate that
the kernel Nystr¨om method can achieve good reconstruction of the
light transport matrix with a few hundred images and produce high
quality relighting results. Moreover, the kernel Nystr¨om method is
effective for modeling scenes with complex lighting effects and oc-
clusions which have remained challenging for existing techniques.

2 Related Work

The light transport matrix represents discrete samples of the re-
ﬂectance ﬁeld [Debevec et al. 2000]. A complete 8D reﬂectance
ﬁeld, which describes the light transport from the incident light ﬁeld
to the outgoing light ﬁeld [Levoy and Hanrahan 1996], is difﬁcult
to capture and process [Garg et al. 2006]. Therefore, most existing
methods only consider simpliﬁed 4D [Debevec et al. 2000; Lin et al.
; Matusik et al. 2004; Peers and Dutr´e 2005] and 6D reﬂectance
ﬁelds [Matusik et al. 2002; Masselus et al. 2003; Sen et al. 2005;
Wenger et al. 2005]. In this paper, we focus on 4D reﬂectance ﬁelds
with a ﬁxed viewpoint and point light sources that lie in a 2D plane.

Light Transport Acquisition. We categorize the existing methods
into three classes: brute force, sparsity based, and coherence based
methods.

The brute force methods directly measure the light transport ma-
trix from the scene, where each column is an image of the scene
lit by a single light source in the incident light domain. Debevec
et. al. [2000] developed a light stage device for capturing 4D re-
ﬂectance ﬁelds for a ﬁxed viewpoint and distant lighting by moving
a point light source around the object. They later improved the de-
vice for fast capturing [Wenger et al. 2005]. Hawkins et. al. [2005]
exploited the Helmholtz reciprocity to capture the reﬂectance ﬁeld
of highly reﬂective objects. To obtain dense samples in the inci-
dent light domain, rows of the light transport matrix are captured
by shooting rays from the viewpoint and capturing the high reso-
lution image of the scene projected over the incident light domain.
Reciprocity is also exploited in [Sen et al. 2005] for acquiring 6D
reﬂectance ﬁelds. All these methods require tens of thousands of
images for modeling a high quality light transport matrix. For sim-
ilar quality, our approach only requires a few hundred images.

The sparsity based methods model the light transport matrix with
a set of basis functions deﬁned over the incident light domain and
assume that each row of the light transport matrix can be approx-
imated by a linear combination of a sparse set of basis functions.
Thus the light transport matrix can be reconstructed by deriving
the sparse basis and their weights for each row from a set of im-
ages captured under special lighting conditions. Environment mat-
ting [Zongker et al. 1999] models the reﬂectance of specular or re-
fractive objects by representing the light transport of each pixel (i.e.,
a row of transport matrix) with a single 2D box function. It was later
extended for modeling glossy objects by replacing the box function
with an oriented Guassian kernel [Chuang et al. 2000]. Matusik et.
al. [2004] modeled the light transport matrix with hierarchical rect-
angular basis functions. An adaptive algorithm is developed for de-
riving the sparse basis and their weights for each pixel from images
of the scene captured under various natural illumination conditions.
Peers et al. [2005] modeled the light transport matrix with wavelets
and inferred the light transport matrix from images of the scene
illuminated by carefully designed wavelet noise patterns. Both ap-
proaches apply a greedy strategy to ﬁnd a suboptimal sparse basis
for each pixel, which only works well for scenes with simple occlu-
sions. Recently a compressive sensing approach [Peers et al. 2009]
was proposed which computes the solution for each pixel from im-
ages captured from a scene illuminated by patterned lighting. How-
ever, the number of images needed for reconstruction depends on
both the row length and the number of basis used for each row,
which becomes quite large for scenes with complex occlusions. The
reconstruction process is also time consuming.

Unlike the above sparsity based approaches, our method exploits
the coherence in the matrix for reconstruction. It can handle well
scenes with complex occlusions and caustics. The number of im-
ages needed for reconstruction is only proportional to the rank of
the light transport matrix and independent on the size of the matrix.
Moreover, our reconstruction algorithm consists of a set of matrix
operations, which is simple and fast.

Coherence based methods acquire the light transport matrix by
exploiting the coherence of reﬂectance ﬁeld data. Masselus et.
al. [2004] explored the interpolation and compression of reﬂectance
ﬁeld. Fuchs et. al. [2007] proposed an adaptive sampling scheme
for sampling the 4D reﬂectance ﬁeld. The spatial coherence of the
reﬂectance ﬁeld in the incident domain is exploited for accelerating
the acquisition process. Starting from a set of images taken with
a sparse set of regularly distributed lighting directions, their algo-
rithm analyzes the observed data and then captures more images in
each iteration with the new lighting directions where the reﬂectance
ﬁeld is not smooth. Note that the smoothness of reﬂectance data
among neighboring pixels is also exploited in [Matusik et al. 2004;
Peers and Dutr´e 2005; Peers et al. 2009] for improving the result
quality.

While these methods only exploit the coherence in either rows or
columns, our method exploits the data coherence in the entire light
transport matrix for reconstruction. Since our approach makes no
assumptions about the smoothness of the sampled reﬂectance ﬁeld,
it can handle well sharp variations of the light transport, such as
shadows, caustics, and surface textures.

Low Rank Matrix Approximation. In addition to the reconstruc-
tion of low rank symmetric matrices, the Nystr¨om method is also
widely used in the machine learning community for approximately
computing the eigenvalues and eigenvectors of a symmetric matrix
from sparse matrix samples [Platt 2005]. For asymmetric matrices,
Goreinov et. al. [1997] presented a pseudoskeleton approximation
for reconstructing a complete matrix from a sparse collection of
its rows and columns.
[2008]

In graphics research, An et. al.

29:2       •       J. Wang et al.ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.applied the Nystr¨om method to accelerate appearance edit propa-
gation by approximating the dense symmetric distance matrix with
sparsely sampled rows and columns. For given illumination, Hasan
et. al.
[2007] applied similar techniques to efﬁciently render syn-
thetic scenes. In their approach, columns of the matrix are clus-
tered in a small number of groups according to their values in the
sparsely sampled rows. A representative column for each group
is then sampled and weighted for approximating other columns in
the same group. This approach only uses the coherence between
the columns for approximating the matrix. Coherence between the
rows is not exploited. Moreover, applying this approach to the light
transport matrix may generate temporal artifacts under animated
light, as noted in [Haˇsan et al. 2008].

3 The Kernel Nystr¨om Method

In this section, we ﬁrst review the generalized Nystr¨om method for
asymmetric matrices [Goreinov et al. 1997] and then introduce our
kernel Nystr¨om method. Here we assume that a sparse set of rows
and columns of the light transport matrix is known. We will discuss
how to capture individual rows and columns from a real world scene
in the next section.

Throughout this paper, we use the following notational convention:
the matrix is denoted by bold uppercase letters, e.g. T, a vector is
denoted by bold lowercase letters, e.g.
l, and a scalar or a scalar
function is denoted by lowercase italic letters, e.g. f . Given a ma-
trix T, its element at row i and column j is denoted as Ti j, while
f (T) denotes a matrix obtained by applying f to each element of
the matrix T.

3.1

Asymmetric Generalization

The Nystr¨om method in [Williams and Seeger 2000] reconstructs
a low rank symmetric matrix from sparsely sampled columns. As
shown in Figure 2(a), an unknown (n + k) × (n + k) symmetric ma-
trix T with k sampled rows [ A CT ] can be approximated as

(cid:183)

T =

A CT
C B

(cid:184)

(cid:183)

≈

CT

A
C CA−1CT

(cid:184)

.

(2)

The reconstruction is accurate when the symmetric matrix T has a
rank d ≤ k, except that the sampled rows [ A CT ] are of a rank
smaller than d.

For asymmetric light transport matrices in which the image pixels
(columns) and light sources (rows) are sampled in different spaces,
the generalized Nystr¨om method [Goreinov et al. 1997] can be
applied for reconstruction. As illustrated in Figure 2(b), we assume
r rows [ A R ] and c columns [ AT CT ]T are known out of an
(r + m) × (c + n) asymmetric matrix T. If the rank of T equals to
that of A: d = rank(T) = rank(A), we can expect the following
relationship:

(cid:163)

(cid:164)

(cid:163)

(cid:164)

C B

= P

A R

and

(cid:183)

(cid:184)

(cid:183)

(cid:184)

R
B

=

Q,

(3)

A
C

where P and Q are matrices of appropriate sizes, which implies that
C = PA, R = AQ and B = PR = CQ. Thus the missing portion B
in the matrix T can be reconstructed as:

B = PAQ = PAA+AQ = CA+R,

where A+ denotes the Moore-Penrose pseudoinverse of A, which
has the property AA+A = A. So the reconstruction is

(cid:183)

T =

R

A
C CA+R

(cid:184)

.

(4)

(5)

Figure 2: Matrix reconstruction from sparsely sampled columns
and rows. (a) Symmetric case. (b) Asymmetric case.

Comparing Equation 2 and 5, the traditional Nystr¨om method is a
special case of the generalized Nystr¨om method when R ≡ CT .

To compute the Moore-Penrose pseudoinverse of A, we apply the
singular value decomposition (SVD) to A and obtain

where UA, ΣA and VT
tively, and the columns of UA and VA are orthonormal: UT
and VT

A are of sizes r × d, d × d and d × c, respec-
AUA = I

AVA = I. The matrix A+ is then computed as

A = UAΣAVT
A,

A+ = VAΣ−1

A UT
A.

(6)

(7)

With A+, we can reconstruct the light transport matrix T using
Equation 5.

3.2 Kernel Extension

Both the traditional and the generalized Nystr¨om methods rely on
the assumption that the ranks of T and A are identical, in order to
achieve an exact reconstruction. In reality, this assumption may be
violated, resulting in some reconstruction error. One possible way
to make the Nystr¨om method more effective is to apply a transfor-
mation to the entries in the matrix so that this low rank assumption
is better satisﬁed, hence the reconstruction error can be expected
to be minimized. As linear transforms do not change the rank of a
matrix, nonlinear transforms are necessary.

In the machine learning literature, the ”kernel trick” [Cristianini and
Shawe-Taylor 2000] is a standard approach for enhancing the per-
formance of algorithms based on nonlinear transformations of the
input data. The kernel trick is to map vectors in the data space to a
(usually) higher dimensional feature space. Then the same proce-
dures of the original algorithm done in the data space are transferred
to the feature space. The key to the success of the kernel trick is
that the mapping function need not be explicitly speciﬁed. Rather,
a kernel function is sufﬁcient for computing the inner products in
the feature space.

Inspired by the success of the kernel trick, we consider using a non-
linear function f to change the values of the entries in light transport
matrix T, such that the rank assumption can be better fulﬁlled, i.e.,
the rank of f (T) is as close to that of f (A) as possible. We name
this nonlinear function f the light transport kernel. After recon-
structing f (T) using the generalized Nystr¨om method, i.e.,

(cid:183)

f (T) ≈ K =

f (A)
f (C)

(cid:161)
f (C)

f (R)
f (A)

(cid:162)+ f (R)

(cid:184)

,

(8)

the original T can be recovered by an inverse mapping with f −1:
T ≈ f −1(K).

To see that the above nonlinear mapping process is a kind of the
kernel method, one may regard T as an inner product matrix:

Ti j = φi · ψj,

(9)

CT(k×n)C(n×k)B(n×n) = ?A(k×k)k + nk + nc +nr+mR(r ×n)C(m×c)A(r×c)B(m×n) = ?(a)(b)Kernel Nyström Method for Light Transport       •       29:3ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.Ki j = f (φi · ψj) = f (Ti j), i.e., K = f (T).

(11)

further minimize

where {φi} and {ψj} are two different point sets in a particular
space1. This is slightly different from the traditional kernel method
which requires that {φi} and {ψj} are identical. We use differ-
ent point sets because here T is asymmetric. The standard kernel
method then uses an implicit mapping Γ to map the point sets to an-
other space. Then the kernel matrix K in the mapped space, a.k.a.
the inner product matrix of the mapped point sets, is:

Ki j = Γ(φi) · Γ(ψj).

(10)

To compute K, one only has to prepare an explicit kernel function g
such that g(φi,ψj) ≡ Γ(φi) · Γ(ψj), rather than explicitly specifying
Γ, which is much more difﬁcult. One of the most frequently used
kernel functions is the polynomial kernel: g(φi,ψj) = (1+φi ·ψj)p.
So one can choose the kernel g in such a form: g(φi,ψj) = f (φi ·
ψj). With this choice of the kernel function, we have that

3.3 Estimating the Light Transport Kernel f

To make the kernel Nystr¨om method work, one has to specify the
light transport kernel f . As the space of all monotonic smooth func-
tions is of inﬁnite dimension, one has to assume its form in order to
narrow down the search space. In this paper, we simply assume that
f is a power function: f (x) = xγ as this family of functions has only
one parameter and hence the optimal function is easy to ﬁnd. More-
over, our experiments show that such a choice of the light transport
kernel can indeed produce a greatly enhanced reconstruction per-
formance. We leave the problem of whether there are even better
light transport kernel functions to future work.

As argued before, to reduce the reconstruction error, one has to
make the rank of f (T) as close to that of f (A) as possible. How-
ever, we do not have the full information on T. So the real rank of
f (T) is actually unknown. To overcome this difﬁculty, we choose
to minimize the rank of f (A) instead. The underlying philosophy
is that if the rank of f (A) is much less than min(r, c), then it is very
likely that the rank of f (T) does not exceed min(r, c). So the gen-
eralized kernel Nystr¨om method can be effective. This leads to the
rank minimization problem [Fazel 2002], which is usually formal-
ized as minimizing the nuclear norm of a matrix. We seek a light
transport kernel f that minimizes the rank factor

er =

(cid:107) f (A)(cid:107)∗
(cid:107) f (A)(cid:107)2

,

(12)

where the nuclear norm is deﬁned as (cid:107)X(cid:107)∗ = ∑
i

σi, the spectral norm

i

{σi} and σi’s are the singular values of
is deﬁned as (cid:107)X(cid:107)2 = max
the matrix X. Note that here we normalize the nuclear norm with
the largest singular value because we don’t want to reduce the rank
by mapping the entries to be close to zeros (which corresponds to
a small (cid:107) f (A)(cid:107)2). Rather, we want to reduce the rank of f (A) by
enhancing the linear coherence of the rows/columns of f (A).

It is easy to imagine that mapping all the entries to a constant can
trivially reduce the rank of f (A) to 1 or even 0. However, such a
trivial mapping causes a problem in inverting from K to T by using
the inverse function f −1. To reduce the reconstruction error, we
have to further make sure that this inversion is numerically robust.
The robustness of inversion can be measured by the slope of f −1:
the steeper f −1 is, the less robust the inversion is. So we have to

1As we will show, it is not necessary to specify what these two point sets

are.

AdaptiveCapture( r(cid:48), c(cid:48), ε )

f inished = f alse
capturing r(cid:48) rows and c(cid:48) columns
r = r(cid:48); c = c(cid:48)
While( f inished == f alse)

estimating f from A
estimating rank factor er of f (A)
If( er/min(r, c) < ε )
f inished = true

Else

capturing r(cid:48) rows and c(cid:48) columns
adding samples in sample set
updating A
r = r + r(cid:48); c = c + c(cid:48)

Figure 3: The pseudo code of adaptive capturing scheme.

es =

( f −1)(cid:48)(x)p(x)dx =

p(x)dx,

(13)

(cid:90) 1

0

(cid:90) 1

1

f (cid:48)(x)

0

where the identity ( f −1)(cid:48)(x) = 1
f (cid:48)(x) is used and p(x) is the dis-
tribution density of the values in A, which is estimated from the
histogram of entry values of A. p(x) is assumed to be identical to
that in T, due to the random sampling of A from T. We weight the
slope of f −1 by p(x) in order to achieve the best overall robustness
for all entry values in T.

Combining the above two criteria, our algorithm selects the light
transport kernel function f whose parameter γ minimizes the ob-
jective function

g(γ) = er · es =

p(x)dx.

(14)

(cid:107) f (A)(cid:107)∗
(cid:107) f (A)(cid:107)2

(cid:90) 1

1

f (cid:48)(x)

0

We use the golden section search [Press et al. 1992] to search for
the optimal γ within [0.001, 1000] in logarithmic space. As A is
of a relatively small size (r × c), this optimization takes only a few
seconds.

In summary, our kernel Nystr¨om method works as follows. Given
the matrices of sampled rows and columns (A, C, and R), we esti-
mate the light transport kernel f from A and map matrices of sparse
samples to their kernel version f (A), f (C), and f (R) respectively.
We then apply the Nystr¨om method to reconstruct the kernel light
transport matrix K = f (T) with the Moore-Penrose pseudoinverse
of f (A) using Equation 5. Finally, we obtain the light transport
matrix T via the inverse kernel mapping T = f −1(K).

4 Adaptive Light Transport Measurement

The kernel Nystr¨om method requires a sparse set of rows and
columns of the light transport matrix as input for reconstruction.
However, without any knowledge about the light transport in the
scene, it is difﬁcult to determine the sample number in advance.
To address this issue, we design an adaptive scheme for capturing
sparse rows and columns from the scene, where the sample number
is determined from the captured data. As shown in Figure 3, after
a batch of rows and columns is sampled from the scene, we esti-
mate the light transport kernel f from the matrix A of the current
sample set and compute the rank factor er of f (A) using Equation
12. For a sample set that has r rows and c columns, if er/min(r, c)
is smaller than a pre-deﬁned threshold ε, the rank of f (A) is much
less than min(r, c). Based on the the same philosophy used in the
kernel estimation, it is very likely the rank of f (T) does not exceed
min(r, c). Thus the sampled data are sufﬁcient for reconstructing

29:4       •       J. Wang et al.ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.Figure 4: Device setup for capturing sparse columns and rows of
the light transport matrix. (a) Illustration. (b) Photograph.

the f (T) and the capturing is ﬁnished. Otherwise, we capture a
new batch of rows and columns and repeat the above steps with the
extended sample set.

A device setup is designed for acquiring a batch of row and column
samples from the scene. As shown in Figure 4, we focus on the light
transport from point light sources on a 2D plane to image pixels
captured from a ﬁxed view point. In our setup, a column of the light
transport matrix is directly obtained from the image of the scene
under the a virtual point light source, while a row of the matrix
is measured via a dual setup by exploiting the reciprocity of light
transport [Hawkins et al. 2005; Sen et al. 2005]. To obtain a batch of
rows and columns, we ﬁrst capture the columns and then acquire the
rows of the light transport matrix. A stratiﬁed sampling scheme is
applied for sampling rows of the matrix based on sparsely sampled
column values.

Device Setup and Calibration As shown in Figure 4(b), our
setup consists of a Optoma HD73 DLP projector, three laser emit-
ters that can generate red, blue and green laser beams, two Canon
20D cameras and a ﬂat vegetable parchment paper (i.e., diffuser)
placed between the projector and the scene. The reﬂection and re-
fraction of the paper are assumed to be diffuse and spatially uni-
form. When the projector shoots a light beam (5 × 5 pixels in our
implementation) onto a point of the diffuser, partial light is refracted
from the other side of the paper and illuminates the scene as a point
light source. With this setup, we model the light transport from
the point light sources that correspond to all projector pixels (i.e.,
all possible shifts of 5 × 5 pixels) to image pixels captured by the
prime camera, which is represented by a very large transport matrix
with nearly a million of columns and rows.

Before capturing, we calibrate the color and intensity of each point
light source. In our implementation, we ﬁrst calibrate the point light
sources sampled on 40 × 40 regular grids by capturing the images
of the diffuser plane lit with each of the 1600 point light sources
from the scene side. We take images of the diffuser plane from the
dual camera simultaneously to build the correspondence between
the point light source positions and pixels of the dual camera image,
in which the images captured by the dual camera are downsampled
to 1024 × 768 to match the projector’s resolution. We then calibrate
the other point light sources within the regular grid by interpolating
the calibration results of the neighbor point light sources on the
grid.

Column Sampling After calibration, we place the scene objects
under the diffuser plane and start to capture the columns of the light

Figure 5: Sampling columns and rows of the light transport ma-
trix. (a) Photograph of the scene in column sampling. (b)(c) Two
column sampling images. (d) Photograph of the scene in row sam-
pling. (e)(f) Two row sampling images. The corresponding pixels
are marked in (c).

transport matrix with the projector and the prime camera. Without
any knowledge on the light transport in the scene, we acquire a set
of columns from the prime camera with r point light sources uni-
formly distributed on the diffuser plane. For each sampled point
light source l j, eight images of different exposures are taken from
the prime camera and then down-sampled and fused into HDR im-
ages as in [Debevec and Malik 1997]. The result is a set of column
vectors T., j of the matrix T.

Row Sampling A dual setup that includes the three laser emitters
and the dual camera is used for row sampling. The laser emitters are
placed close to the prime camera, their orientations being controlled
by a computer; the scene is lit by the laser beams. The reﬂectance
of the scene is then projected onto the diffuser, refracted uniformly
on the other side of the diffuser, and recorded by the dual camera
neighboring the projector.

We utilize the sampled column values to guide the row sampling.
Similar to [Haˇsan et al. 2007], we pack the r sparse elements in
each row to a vector ˆri = (Ti, j1 , Ti, j2 , . . . , Ti, jr ), where j1, . . . , jr are
indices of the sampled columns. We then employ k-means to cluster
the {ˆri} into r clusters. For each cluster, the vector closest to the
cluster center vector is selected as the sampling pixel.

For each row (i.e., pixel location) to be sampled, we adjust the di-
rection of three laser beams so that they focus on the same surface
point whose projection on the prime camera falls in the sampled
pixel position. Since the prime camera and the laser emitters are
relatively far away from the scene, the angle difference between the
camera’s pixel ray and the laser beams is small and ignored in cap-
turing. A HDR image of the diffuse plane is then acquired from
the dual camera. With the correspondence between the dual cam-
era pixels and the point light source positions, we can easily obtain
the sampled row values from the downsampled HDR images. We
repeat this process until all sampled rows are measured. Finally, we
scale the sampled columns so that the matrix element values cap-
tured by both rows and columns become the same. Figure 5 shows
the sampled column and row images.

5 Results and Discussions

We implemented our kernel Nystr¨om method on a PC with Intel
CoreTM2 Duo 3.2GHz CPU and 4GB of memory. In our implemen-
tation, we capture a batch of 10 rows and 10 columns in each adap-
tive capture step and experimentally set the threshold as ε = 0.05.
A typical acquisition session (including image acquisition, HDR
reconstruction, and kernel estimation) takes about 135 minutes for
capturing 150 rows and 150 columns from the scene. The image

Kernel Nyström Method for Light Transport       •       29:5ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.resolution is 1752 × 1168, while the light sampling resolution is
1024 × 768. To reconstruct the light transport matrix for relight-
ing, we store the sampled matrices (C, R, A and A+) in memory
and reconstruct all rows of the matrix during rendering. With 150
rows and 150 columns, our kernel Nystr¨om method takes less than
5 minutes to estimate the kernel and reconstruct all rows of the light
transport matrix of the scene. For samples that do not ﬁt in mem-
ory, we store one matrix (C in our implementation) on disk and the
other matrices in memory. An out-of-core implementation, which
is dominated by the disk I/O, then takes about 30 minutes for re-
construction.

We tested our method on a variety of scenes exhibiting different
light transport effects. As illustrated in Figure 6, the caustics scene
includes a set of transparent objects, where the light transport is
dominated by caustics created by light refraction. In the shadow
scene, the ﬁne geometry of the dragon model results in complex oc-
clusion and produces detailed shadows. The interreﬂection scene is
designed to illustrate the strong inter-reﬂections between different
objects and the color bleeding effects. In the general scene, objects
with different material properties are placed together and present a
mixture of different light transport effects, including reﬂection, re-
fraction, shadows, and inter-reﬂections, subsurface scattering, and
caustics. The light transport kernel coefﬁcient and the sample num-
ber used in reconstruction for each scene are noted in the ﬁgure.

5.1 Method Validation

We validate the kernel Nystr¨om method with the light transport ma-
trices acquired from the general scene and the shadow scene, in
which the light sources are sampled on regular 35 × 35 grids on
the diffuser. We choose these two scenes for validation because the
general scene includes a mixture of different kinds of light trans-
port, while the shadow scene requires a large number of samples
for reconstruction. We simulate the adaptive sampling scheme for
each scene. In each iteration, we randomly pick 10 rows and 10
columns that are not in the sample set from the acquired full ma-
trix and add them in the sparse sample set. After that, we esti-
mate the light transport kernel f and compute the rank of the kernel
mapped matrix f (A) of the sparse samples. The rank of a matrix
is determined by the number of eigenvalues of the matrix that can
preserve 95.0% energy of the original matrix. We also reconstruct
the light transport matrix from the sparse sample set via the kernel

Figure 7: Ranks of the kernel mapped matrices f (A) of the sparse
sample sets with different numbers of samples. The orange line
indicates the sample number determined by the adaptive capturing
scheme, while the blue line indicates the rank of the kernel mapped
matrix f (T).

Nystr¨om method. We repeat this process until the number of sparse
samples achieves 300, which is more than the number of sparse
samples ns determined by the adaptive sampling scheme with the
pre-deﬁned ε.

Figure 7 shows plots of the ranks of kernel mapped matrices f (A)
of sparse sample sets with a different number of samples, where the
number of sparse samples ns determined by the adaptive sampling
scheme is marked by an orange line. The blue line indicates the
rank of the kernel mapped matrix f (T), in which the kernel function
is estimated from the sparse sample set with ns samples. For both
scenes, the ranks of f (A) of sparse samples grow as the number
of samples increases and are close to the f (T) as the number of
samples is close to ns, which leads to a good reconstruction.

Figure 8 shows plots of the relative errors of the light transport ma-
trices reconstructed from a different number of samples, where the
relative reconstruction error is computed as

(cid:115)

ε =

∑i, j |Bi, j − ˜Bi, j|2

∑i, j |Bi, j|2

.

(15)

Here Bi, j is the ground truth submatrix element that is not in the
sparse sample set and ˜Bi, j is the same submatrix element recon-
structed using the kernel Nystr¨om method. To further explore the
impact of different sample sets to the reconstruction quality, we ex-
ecute the above experiment 16 times, each time with different rows
and columns randomly selected from the matrix. As shown in Fig-
ure 8, the relative error decreases quickly as the number of sparse
samples increases. With the same number of sparse samples as we
used in our capturing, the relative error of the reconstructed light
transport matrix is below 5%. Also note that the variance of the
error under the same number of samples reduces quickly with the

Figure 6: Four test scenes from our experiments: (a) caustic scene
(b) shadow scene (c) interreﬂection scene (d) general scene. The
number of rows ns and the light transport kernel coefﬁcient γ for
each scene are noted in the images.

Figure 8: Relative reconstruction errors of the light transport ma-
trix reconstructed from sparse sample sets with different number of
samples. The orange line indicates the sample number determined
by the adaptive capturing scheme.

051015202530354045050100150200250300350ranksample number051015202530354045050100150200250300350sample numberrank29:6       •       J. Wang et al.ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.structed light transport matrix are visually indistinguishable from
the ground truth images.

We used the reconstructed light transport matrix for image-based
relighting. Figure 13 exhibits several results rendered with differ-
ent lighting conditions. Note that complex light transport effects
are faithfully reproduced, providing realistic results. See the com-
panion video for relighting results under dynamic lighting.

5.3 Subsurface Scattering

We also applied the kernel Nystr¨om method for modeling the light
transport due to subsurface scattering. The light transport matrix in
this case is an n × n symmetric matrix, each element of which de-
scribes the diffuse BSSRDF Rd between the two surface points xi
and x j as Ti j = Rd(xi, x j) [Goesele et al. 2004]. Since this matrix
is symmetrical, we only need to sample the columns for reconstruc-
tion.

In our implementation, we use a device setup similar to the one used
in [Goesele et al. 2004] for capturing. The three laser emitters are
close to each other and shoot three color beams to points over the
object surface. We control the laser beams to make sure that they
focus on the same surface point. HDR images of the object surface
are captured from a ﬁxed viewpoint. We repeat this process by
shooting the laser beams to a random set of surface points. With the
calibrated camera position and known geometry of the object, we
map the image pixels onto the object surface. Figure 11(d) shows
an image of the marble used in our experiments.

With 50 sampled images, we reconstruct the light transport ma-
trix of subsurface scattering using the kernel Nystr¨om method. The
coefﬁcient of the light transport kernel used in reconstruction is
γ = 0.0625. The resolution of surface points in the light transport
matrix is the same as the image resolution. Figure 11 compares
the rendering result of the reconstructed light transport matrix, the
ground truth image captured from the object under the same light-
ing condition, and the result rendered by directly interpolating the
nearby sample images. Note that the detailed spatial patterns and
anisotropic subsurface scattering in the real material are well pre-
served with the reconstructed light transport matrix, while the re-
sults generated by interpolation clearly exhibit artifacts. Also note
that to capture the light transport effects with a similar resolution,
brute force methods [Goesele et al. 2004; Peers et al. 2006] need
dense light sampling, which is prohibitively expensive and time
consuming. We show relighting results of the reconstructed light
transport matrix in the companion video.

5.4 Discussions

The light transport matrix of a scene exhibits both data coher-
ence and sparsity. While the sparsity based approaches exploit
the data sparsity for capturing the light transport matrix, the kernel
Nystr¨om method exploits the coherence in both rows and columns
of the light transport matrix for the same task. For scenes with
low frequency light transport effects, such as inter-reﬂections, sub-
surface scattering and glossy shading, their light transport matrices
always exhibit strong coherence in both rows and columns, which
can be efﬁciently reconstructed using the kernel Nystr¨om method
with dozens of images.
In a scene that includes more sharp
light transport variations, such as occlusions, specular reﬂections
and refractions, the coherence in the column vectors may be re-
duced. By exploiting the coherence in the row vectors, the kernel
Nystr¨om method can still achieve good results with hundreds of
image samples. In both cases, the kernel Nystr¨om methods require
much less images than the sparsity based methods. For compari-
son, we project the light transport matrices of the general scene and

Figure 9: Reconstruction results with the kernel Nystr¨om method
and with the Nystr¨om method. The relative reconstruction errors
with respect to the different numbers of samples are compared in
(a). (b) The ground truth image. (c) Image rendered with matrix
reconstructed from 150 samples with the Nystr¨om method. (d) Im-
age rendered with matrix reconstructed from 150 samples with the
kernel Nystr¨om method.

increasing number of samples, which guarantees the quality of the
light transport matrix reconstructed from the random sampled rows
and columns.

Figure 9 compares the performance of the Nystr¨om method and
the kernel Nystr¨om method for the general scene. For each sparse
sample set, we reconstruct the light transport matrices using both
the Nystr¨om method and the kernel Nystr¨om method. Their rela-
tive errors are shown in Figure 9 (a). Without the kernel extension,
the Nystr¨om method requires roughly ﬁve to six times the num-
ber of samples to achieve the same reconstruction quality as the
kernel Nystr¨om method does. Figure 9 (b) shows a visual compar-
ison, where the same number of samples are used in both methods
for reconstruction. The artifacts in the results generated with the
Nystr¨om method are clearly visible.

Figure 10 compares the performance of the kernel Nystr¨om method
with different light transport kernels (i.e., different γ values) for the
shadow scene. For each γ value, we reconstruct the light transport
matrix from the same set of sparse samples (250 samples) with the
kernel Nystr¨om method. Figure 10(a) shows plots of the objective
function g(γ) and the relative error of the reconstructed light trans-
port matrices as a function of γ. Note that the relative reconstruction
error is minimal when the optimal γ value derived by our approach
is used for reconstruction. Also, the light transport matrix is well
reconstructed by the kernel Nystr¨om method using the optimal γ
value. However, the light transport matrices reconstructed with the
kernel Nystr¨om method using other γ values exhibit larger relative
errors and visible artifacts. As shown in Figure 10(e)(g), the large γ
value leads to visible artifacts concentrated in the region with high
frequency features, while the small γ value results in the noise like
artifacts scattered across the entire result image.

5.2 Relighting Results

Figure 12 compares images rendered using the reconstructed light
transport matrix to ground truth images showing illumination un-
der a single point light that was not considered during the recon-
struction process. The rendering results generated from the recon-

Kernel Nyström Method for Light Transport       •       29:7ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.the shadow scene onto the Haar wavelet basis. In each case, for
reconstructing the entire matrix with the similar 5% relative error,
we need to retain thousands of wavelet coefﬁcients, which means
that more than thousands of images are required for reconstructing
the matrix with the sparsity based methods.

In the extreme cases where the light transport matrix exhibits little
coherence in both rows and columns, the kernel Nystr¨om method
would need all rows and columns of the matrix for good reconstruc-
tion. In this case, our approach has no advantage over the brute
force methods and the sparsity based methods. An example is a
scene of a mirror ball, where the light transport matrix exhibits good
sparsity but little coherence. In this scenario, the sparsity based ap-
proaches may provide a good solution.

6 Conclusion

We have presented the kernel Nystr¨om method for reconstructing
the light transport matrix from a relatively small number of acquired

Figure 10: Reconstruction results of the kernel Nystr¨om method
with different light transport kernels.
(a) The objective function
values and the relative reconstruction errors with respect to different
γ values. (b) The ground truth image. (c)(e)(g) Images rendered
with the matrices reconstructed with the kernel Nystr¨om method
using different γ values. The γ value used in (c) is the optimal one.
(d)(f)(h) The difference images between the rendering results of the
reconstructed matrices (c)(e)(g) and the ground truth image (b).

Figure 11: Modeling subsurface light transport with the kernel
Nystr¨om method. (a) The image of marble lit by laser beam at one
point. (b) Image rendered with reconstructed light transport matrix
with light on the same point. (c)The difference between (a) and (b),
intensity of which is scaled by 10. (d) Photograph of the ﬂat mar-
ble sample. (e) Image rendered by interpolating the nearby sample
images. (f) The difference between (a) and (e), intensity of which
is scaled by 10.

images. While existing techniques typically require tens of thou-
sands of images for accurate reconstruction of a light transport ma-
trix, the kernel Nystr¨om method can achieve a good reconstruction
with a few hundred images and produces high quality relighting re-
sults. The kernel Nystr¨om method is able to capture complex light-
ing effects and occlusions which are particularly challenging for
many existing techniques, especially various sparsity-based meth-
ods. The effectiveness of the kernel Nystr¨om method comes from
its ability to exploit both the linear and nonlinear coherence in the
light transport matrix from a relatively small number of rows and
columns of the matrix.

In future work, we are interested in investigating better kernel
estimation methods and designing new kernel functions for light
transport matrix reconstruction. We also plan to apply the kernel
Nystr¨om method to model surface reﬂectance. Finally, we want to
explore ways to extend the kernel Nystr¨om method to handle high-
dimensional tensor data.

7 Acknowledgements

The authors would like to thank Yi Ma and John Wright for helpful
discussions, and Matthew Callcut for proofreading the paper and
dubbing the video. We also thank the anonymous reviewers for
their helpful suggestions and comments.

References

AN, X., AND PELLACINI, F.

appearance-space edit propagation.
Graphics 27, 3 (Aug.), 40:1–40:9.

2008. Appprop: All-pairs
ACM Transactions on

CHUANG, Y.-Y., ZONGKER, D. E., HINDORFF, J., CURLESS, B.,
SALESIN, D. H., AND SZELISKI, R. 2000. Environment mat-
ting extensions: Towards higher accuracy and real-time capture.
In Proceedings of ACM SIGGRAPH 2000, Computer Graphics
Proceedings, Annual Conference Series, 121–130.

CRISTIANINI, N., AND SHAWE-TAYLOR, J. 2000. An introduc-
tion to support vector machines and other kernel-based learning
methods. Cambridge University Press.

29:8       •       J. Wang et al.ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.DEBEVEC, P. E., AND MALIK, J. 1997. Recovering high dynamic
range radiance maps from photographs. In Proceedings of SIG-
GRAPH 97, Computer Graphics Proceedings, Annual Confer-
ence Series, 369–378.

MATUSIK, W., LOPER, M., AND PFISTER, H.

2004.
Progressively-reﬁned reﬂectance functions from natural illumi-
nation. In Rendering Techniques 2004: 15th Eurographics Work-
shop on Rendering, 299–308.

NG, R., RAMAMOORTHI, R., AND HANRAHAN, P. 2003. All-
frequency shadows using non-linear wavelet lighting approxima-
tion. ACM Transactions on Graphics 22, 3 (July), 376–381.

PEERS, P., AND DUTR ´E, P. 2005. Inferring reﬂectance functions
from wavelet noise. In Rendering Techniques 2005: 16th Euro-
graphics Workshop on Rendering, 173–182.

PEERS, P., VOM BERGE, K., MATUSIK, W., RAMAMOORTHI, R.,
LAWRENCE, J., RUSINKIEWICZ, S., AND DUTR ´E, P. 2006.
A compact factored representation of heterogeneous subsurface
scattering. ACM Transactions on Graphics 25, 3 (July), 746–
753.

PEERS, P., MAHAJAN, D. K., LAMOND, B., GHOSH, A., MA-
TUSIK, W., RAMAMOORTHI, R., AND DEBEVEC, P. 2009.
Compressive light transport sensing. ACM Transactions on
Graphics 28, 1 (Jan.), 3:1–3:18.

PLATT, J. C. 2005. Fastmap, metricmap, and landmark mds are all
nystr¨om algorithms. In 10th International Workshop on Artiﬁcial
Intelligence and Statistics, 261–268.

PRESS, W. H., ET AL. 1992. Numerical recipes in C (second

edition). Cambridge University Press.

SEN, P., AND DARABI, S. 2009. Compressive Dual Photography.

Computer Graphics Forum 28, 2, 609 – 618.

SEN, P., CHEN, B., GARG, G., MARSCHNER, S. R., HOROWITZ,
M., LEVOY, M., AND LENSCH, H. P. A. 2005. Dual photogra-
phy. ACM Transactions on Graphics 24, 3, 745–755.

WENGER, A., GARDNER, A., TCHOU, C., UNGER,

J.,
HAWKINS, T., AND DEBEVEC, P. 2005. Performance relight-
ing and reﬂectance transformation with time-multiplexed illumi-
nation. ACM Transactions on Graphics 24, 3 (Aug.), 756–764.

WILLIAMS, C., AND SEEGER, M. 2000. Using the nystr¨om
method to speed up kernel machines. Advances in Neural In-
formation Processing Systems 13, 682–688.

ZONGKER, D. E., WERNER, D. M., CURLESS, B., AND
SALESIN, D. H. 1999. Environment matting and compositing.
In Proceedings of SIGGRAPH 99, Computer Graphics Proceed-
ings, Annual Conference Series, 205–214.

DEBEVEC, P., HAWKINS, T., TCHOU, C., DUIKER, H.-P.,
2000. Acquiring the re-
SAROKIN, W., AND SAGAR, M.
In Proceedings of ACM SIG-
ﬂectance ﬁeld of a human face.
GRAPH 2000, Computer Graphics Proceedings, Annual Confer-
ence Series, 145–156.

FAZEL, M. 2002. Matrix rank minimization with applications.

PhD thesis, Stanford University.

FUCHS, M., BLANZ, V., LENSCH, H. P. A., AND SEIDEL, H.-P.
2007. Adaptive sampling of reﬂectance ﬁelds. ACM Transac-
tions on Graphics 26, 2 (June), 10:1–10:18.

GARG, G., TALVALA, E.-V., LEVOY, M., AND LENSCH, H. P. A.
2006. Symmetric photography: Exploiting data-sparseness in
reﬂectance ﬁelds.
In Rendering Techniques 2006: 17th Euro-
graphics Workshop on Rendering, 251–262.

GOESELE, M., LENSCH, H. P. A., LANG, J., FUCHS, C., AND
SEIDEL, H.-P. 2004. Disco: acquisition of translucent objects.
ACM Transactions on Graphics 23, 3 (Aug.), 835–844.

GOREINOV, S., TYRTYSHNIKOV, E. E., AND ZAMARASHKIN,
N. L. 1997. A theory of pseudo-skeleton approximations. Lin-
ear Algeabra and Applications 261, 1–21.

HA ˇSAN, M., PELLACINI, F., AND BALA, K. 2007. Matrix row-
column sampling for the many-light problem. ACM Transactions
on Graphics 26, 3 (July), 26:1–26:10.

HA ˇSAN, M., VELAZQUEZ-ARMENDARIZ, E., PELLACINI, F.,
AND BALA, K. 2008. Tensor clustering for rendering many-
light animations. Computer Graphics Forum (Proc. Eurograph-
ics Rendering 2008) 27, 4, 1105–1114.

HAWKINS, T., EINARSSON, P., AND DEBEVEC, P. 2005. A dual
light stage. In Rendering Techniques 2005: 16th Eurographics
Workshop on Rendering, 91–98.

LEVOY, M., AND HANRAHAN, P. M. 1996. Light ﬁeld rendering.
In Proceedings of SIGGRAPH 96, Computer Graphics Proceed-
ings, Annual Conference Series, 31–42.

LIN, Z., WONG, T.-T., AND SHUM, H.-Y. Relighting with the
reﬂected irradiance ﬁeld: Representation, sampling and recon-
struction. International Journal of Computer Vision 49, 2.

MAHAJAN, D., SHLIZERMAN, I. K., RAMAMOORTHI, R., AND
BELHUMEUR, P. 2007. A theory of locally low dimensional
light transport. ACM Transactions on Graphics 26, 3 (July),
62:1–62:10.

MASSELUS, V., PEERS, P., DUTR ´E, P., AND WILLEMS, Y. D.
2003. Relighting with 4d incident light ﬁelds. ACM Transactions
on Graphics 22, 3 (July), 613–620.

MASSELUS, V., PEERS, P., DUTR0108, P., AND WILLEMS, Y. D.
2004. Smooth reconstruction and compact representation of re-
ﬂectance functions for image-based relighting.
In Rendering
Techniques 2004: 15th Eurographics Workshop on Rendering,
287–298.

MATUSIK, W., PFISTER, H., NGAN, A., BEARDSLEY, P.,
ZIEGLER, R., AND MCMILLAN, L. 2002.
Image-based 3D
photography using opacity hulls. ACM Transactions on Graph-
ics 21, 3 (July), 427–437.

Kernel Nyström Method for Light Transport       •       29:9ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.Figure 12: Visual comparison of relighting results. Images in the ﬁrst row are captured from each scene as illuminated by a point light
source that is not used when acquiring images for the light transport matrix reconstruction. Images in the second row are rendered from the
reconstructed light transport matrices of the scenes under the same lighting condition. The third row shows the difference images, with their
intensities scaled up by a factor of 10.

Figure 13: Relighting results under complex lighting. (a) The caustic scene. (b) The shadow scene. (c) The interreﬂection scene. (d) The
general scene. The inset images show the three illumination patterns used for rendering.

29:10       •       J. Wang et al.ACM Transactions on Graphics, Vol. 28, No. 3, Article 29, Publication date: August 2009.