Volume 0 (1981), Number 0 pp. 1(cid:150)11

On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

Elmar Eisemann and Xavier DØcoret

ARTIS-GRAVIR/IMAG-INRIA,Francey

Abstract
In this article we present an analytical closed-form expression to ensure exact error bounds for view-dependent
simpli(cid:2)cation which is of importance for several algorithms. The present work contains proofs and solutions for
the general 2D case and particular 3D cases.
Most preceeding works rely on coarse heuristics, that might fail and/or restrict movements or object representa-
tions. We introduce the notion of validity regions as the complete set of possible simpli(cid:2)cations respecting a given
error bound between the object and its simpli(cid:2)cation. The approach handles arbitrary polygonal viewcells which
allow for free movement in the interior. We show how to compute these regions for mesh points and faces. Since
the validity region of a face accounts for all its points, properties like silhouette preservation and textures are
gracefully handled. This is not the case if the error is controlled only at the face’s vertices or edges.

Categories and Subject Descriptors (according to ACM CCS): I.3.5 [Computer Graphics]: Computational Geometry
and Object Modelling

1. Introduction
Simpli(cid:2)cation has become a very important topic in today’s
research. Nowadays, models are made out of thousands of
triangles, and complex scenes like forests can even contain
millions of polygons. Graphics hardware is constantly im-
proving, but not capable of displaying such complex scenes
in real-time, thus simpli(cid:2)cation remains an important issue.

Clark [Cla76] was probably the (cid:2)rst to point out that dis-
tant objects do not need the same precision as closer ones.
Since then, several approaches have been proposed to auto-
matically create simpler representations of an input model. A
key point is to control the error caused by using a coarser re-
placement. This is a dif(cid:2)cult problem for a single viewpoint
but even harder if one considers to keep the same represen-
tation for a certain viewing region (viewcell).

In this article, we are interested in measuring the geomet-
ric error associated with a given simpli(cid:2)cation and viewcell.
Furthermore it is possible to detect for each mesh part the
viewpoints that reveal the maximal error. Reviewing the sim-
pli(cid:2)cation from this very viewpoint gives the user an idea of
the subjective/qualitative error.

y Elmar.Eisemann@inrialpes.fr, Xavier.Decoret@inrialpes.fr, ARTIS is a team of the
GRAVIR/IMAG laboratory, a joint effort of CNRS, INRIA, INPG and UJF

c(cid:13) The Eurographics Association and Blackwell Publishing 2006. Published by Blackwell
Publishing, 9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main Street, Malden,
MA 02148, USA.

A huge amount of literature on simpli(cid:2)cation exists, but
no work on a general error analysis has been published so
far. Interestingly, most previously proposed error bounds,
even for the simpler case of a single viewpoint, are based on
heuristics that are invalid in the general case. Viewcell ap-
proaches (where a simpli(cid:2)cation has been precalculated and
is used while an observer stays inside a certain region, the
viewcell) received a lot of interest because run-time simpli-
(cid:2)cation becomes inef(cid:2)cient for very complex models. The
query-cost exceeds the gain from rendering the simpli(cid:2)ed
version. In this article we de(cid:2)ne and solve the problem of
exact (not only upper) error bounds analytically in two-
dimensional scenes and with arbitrary precision in 3D. In
practice models are often well-behaved, making heuristics
work well, which produce arbitrarily large errors only in
mostly pathological cases. This is probably why the resulting
error has not yet been closely examined. Nevertheless our
analysis can be applied and is of interest in situations where
faithfulness is a must. Also we proof with our work that al-
gorithms with strict error bounds still allow for aggressive
simpli(cid:2)cation. We show this with a simple example applica-
tion. This proof of concept is not the main contribution of
the paper, which is the theoretical foundation and de(cid:2)nition
of the geometric error for viewcell-depedent simpli(cid:2)cation.

In this article we underline the actual complexity of the

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

problem, present how error bounds can be visualized, calcu-
lated and assured. It serves as an invitation to further explore
a (cid:2)eld that existed for more than 30 years. Simpli(cid:2)cation
still contains lots of basic open questions to which our work
gives some answers and provides a deep understanding.

After discussing previous work (section 2), the de(cid:2)nition
of the problem will be presented (section 3). The calculation
of exact validity regions is not trivial and we will derive it in
several steps. Starting with mesh points we show how we can
indirectly obtain the exact solution using special viewpoints.
We describe how to (cid:2)nd them for different types of view-
cells (section 4) and extend the approach from mesh points
to faces (section 5). We then discuss our work, conclude and
give an outlook on future research (sections 6,7).

2. Previous Work
General simpli(cid:2)cation algorithms can be divided into two
classes. The (cid:2)rst selects an appropriate model during
run-time based on the current viewpoint. This often in-
volves hierarchical structures [Hop96,Hop97,XV96,ESV99,
ESSS01]. The second class usually implies the use of al-
ternative representations [SDB97, DSSD99, JWS02, JW02,
WM03] which are created according to a viewcell. Seen
from this region, the corresponding simpli(cid:2)ed representation
should closely match the original model’s appearance.

Run-time based approaches test simple queries to decide
whether more details are needed. Most algorithms use edge
collapses (introduced in [Hop96]) and work with bound-
ing spheres and special silhouette criteria to obtain a bet-
ter quality. Unfortunately, bounding spheres around edges
do not provide a real conservative bound, neither closeness
relations between vertices as used by Luebke et al. [LE97].
In [LE97] some ground rules are speci(cid:2)ed. Polygon soups
should be accepted as valid input, and a (cid:2)ne-grained trade-
off between (cid:2)delity and aggressive simpli(cid:2)cation should be
possible. The analysis in this article ful(cid:2)lls both conditions.

Another run-time approach, that represents a transition
to of(cid:3)ine simpli(cid:2)cation is presented in [COM98]. This al-
gorithm establishes upper bounds on geometry and texture
and is able to limit the actual screen error. Nevertheless the
bound is not tight and only given in accordance to a certain
viewing distance, not for arbitrary viewcells. The method is
best suited for dense objects of high complexity.

Most viewcell-based approaches involve alternative rep-
resentations which can be rendered ef(cid:2)ciently and only one
query (membership of the observer to a viewcell) has to
be evaluated. Typically much information about the scene
can be stored in form of textures on a simpli(cid:2)ed model
[MS95, SDB97]. As pointed out by Wilson et al. [WM03],
invisible parts may cause problems. They perform a recon-
struction based on several viewpoints to maximize visibility.
In some cases this might not be suf(cid:2)cient. Imagine a wall al-
most perpendicular to the observer’s sightline. No geometry
is hidden, but texture information can appear distorted from

a different viewpoint due to the grazing angle. Geometrical
error bounds are not established on such representations.

Jeschke et al. [JWS02, JW02] manage to provide an er-
ror bound for a particular case. Around a cubic viewcell,
they create enclosing cubes on which the scene is projected,
whereas inside the (cid:2)rst one the original geometry is used.
If the user moves on the diagonals of the viewcell, they are
able to deduce the position of the layers for a faithful repre-
sentation. DØcoret et al. [DSSD99] provide an error measure
for parallax effects in two-dimensional scenes for segment
viewcells. We derive a more general error bound which does
not directly depend on the alternative representation being
used. We ensure (cid:2)delity and do not restrict the observer’s
movement to a segment.

Our approach relates to Cohen et al. [CVM(cid:3)96], where a
hull is de(cid:2)ned around the initial model. Simpli(cid:2)cation oper-
ations are only considered valid if the object remains inside
this boundary. Cohen et al.’s approach is not view-dependent
and does not take texture into account, as it uses the Haus-
dorff distance (see section 3). Inspired by their work we are
interested in determining maximum envelopes for a view-
dependent, point-wise measure.

3. Basic De(cid:2)nitions

M

S=s(M)

 

MVS

V

viewcell

Figure 1: Angular distance is evaluated for each viewpoint
V in viewcell V.

The input of the problem is a mesh M and a viewcell V.
The mesh is de(cid:2)ned by vertices Vi and faces F j, and consists
of all the points inside those faces (usually denoted M). The
viewcell V is a set of viewpoints (usually denoted V ).

The goal is to measure the distance between M and a
simpli(cid:2)ed mesh S. A simpli(cid:2)cation is a mapping from the
points of M to the points of S:

s : M 7! S; M ! s(M)

Note that s can be many-to-one, i.e. several points can be

"simpli(cid:2)ed" to the same place.

A classic approach to measure the error is to compare M
and S = s(M) using the Hausdorff distance. This metric
measures the geometric change between the mesh and its
simpli(cid:2)cation. If every point on the mesh has a color (e.g.
through texturing), two meshes can have the same shape (i.e.
a null Hausdorff distance) but look very different. For that
reason, distance measures between M and S should be con-
sidered for each point (not only vertex) on the mesh. Thus,
in a (cid:2)rst step, we will focus on single points on the mesh.

For a single viewpoint V , the distance between M and S :=

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

s(M) is de(cid:2)ned as the angle
MV S under which the segment
[M; S] is seen from V ((cid:2)g. 1). It is important to notice, that
for a (cid:2)xed view frustum, the angle implies a bound on the
projected screen distance and vice versa.

d

For a viewcell V, we de(cid:2)ne the error as the maximum
angle under which a point M and its simpli(cid:2)cation S can be
seen from within the viewcell.

eV (M; S) := max
V 2V

MV S

(1)

We say a simpli(cid:2)cation is valid for a given error Q 2
[0; p=2), if for all mesh points M 2 M the error between
M and its simpli(cid:2)cation s(M) is smaller than Q.

d

4. Validity Regions of Points

M4 

M2 

M3 

M5

view cell

M1

Figure 2: Some examples for validity regions of mesh points
based on a given segment viewcell and a (cid:2)xed error bound.
Notice that the shapes are not symmetric, nor always poly-
hedral and might be unbounded. The image was obtained
via sampled cone intersections.)

The validity region for an error bound Q of a mesh point

M and a viewcell V is de(cid:2)ned as the set:

VRQ

V (M) := fS j eV (M; S) (cid:20) Qg

This de(cid:2)nition is equivalent to:

VRQ

V (M) =

fS j

MV S (cid:20) Qg

V 2V

d

From this we can obtain:

VRQ

V[W (M) = VRQ

V (M) \VRQ

W (M)

(2)

(3)

(4)

Intuitively eq. (4) states that a bigger viewcell leads to
MV S (cid:20) Qg is
smaller validity regions. In eq. (3), the set fSj
(cid:0)!
a cone of apex V in direction
V M and aperture Q. Therefore
the validity region corresponds to the intersection of cones.

d

The remainder of this section describes the determination
of the exact shape of the validity region. Fig. 2 shows some
examples and one sees that the shape is not polyhedral, thus
depending on an in(cid:2)nity of viewpoints.

From eq. (3) we see that validity regions are convex, be-
cause the set is de(cid:2)ned as the intersection of convex cones.
Convexity implies star-shape which means that the validity

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

region of M can be represented radially by its extents with
respect to M and a given direction ~d. This gives a convenient
parametrization of the set we look for.

VRQ

V (~d)(M) := dVRQ

V (M) \ r(M; ~d)

(5)

where r(M; ~d) denotes the ray from M in direction ~d and
V (M) refers to the boundary of the validity region.

dVRQ

For a single viewpoint V it is simple to calculate the ex-
tents. It corresponds to the intersection between the view
cone borders and a ray through M in a direction ~d ((cid:2)g. 3).

M+t d

d

M

Q Q

M

VR extent

d

 
viewpoint

view cell

Figure 3: Validity region extents of points, intersection with
cone (left), hyperplane viewcell (right)

For an error bound Q the validity region extent in direction
~d of M for a viewpoint V is given by M + t ~d, where t is
speci(cid:2)ed by the (smaller) positive result of eq. (6). If there is
none, the validity region is unbounded in this direction.

(cid:0) sin2 Q <

(cid:0)!
V Mj~d > (cid:6) sin Q cos Q

1(cid:0) <

(cid:0)!
V Mj~d >2

(6)

<

(cid:0)!
V M
(cid:0)!
V Mjj
jj

j~d >2 (cid:0) cos2 Q

q

< j > denotes the standard scalar product, jj jj the L2

norm.

For general viewcells, it is dif(cid:2)cult to calculate the valid-
ity region. On the other hand, for a (cid:2)nite set of viewpoints
the solution can be found by evaluating expression (6) sev-
eral times. The key idea is thus to (cid:2)nd a (cid:2)nite set of view-
points in the viewcell that can be used to bound the whole
validity region extent.

Max Viewpoints: It can be shown that for a closed viewcell
there has to be a special viewpoint, the so-called max view-
fVmaxg(~d)(M). Vmax
point, Vmax, such that VRQ
depends on the mesh point, the viewcell, the error bound and
the direction.

V (~d)(M) = VRQ

In other words, the cone associated with the viewpoint
Vmax is actually responsible for the validity region extent in
the direction ~d. Denoting the validity region extent E, it fol-
EVmaxM = Q ((cid:2)g. 4). The max viewpoint thus gives
lows
the validity region extent (expression (6)). This gives us an
an indirect way to (cid:2)nd the exact answer to our problem. The
existence of these points will follow from the discussion in

d

(cid:0)
E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

VRQ

V (M) = VRQ

dV (M)

Figure 6: Parameterizing a simpli(cid:2)cation point leads to a
parameterized bicircle (consisting of two circles). The max
viewpoint is the tangent point on the viewcell.

E

M

d

Q

Q

 

max viewpoint
for direction d

viewcell

Figure 4: For a closed viewcell and a direction ~d, there is
one speci(cid:2)c viewpoint, the max viewpoint, which implies the
validity region extent E of mesh point M.

the special case of polygonal viewcells but it is generally
true for closed viewcells.

The inscribed angle theorem states that in 2D all points
that see a given segment under a (cid:2)xed angle Q lie on a bi-
circle, the outer contour of two intersecting circles. In 3D,
the set is invariant under rotation around axis ~d, thus lead-
ing to a so-called bialy, a torus without hole. This shape also
played an important role in [LKR(cid:3)96], where it was derived
in a different manner for height (cid:2)eld simpli(cid:2)cations during
run-time. All points inside this bialy see the segment under
an angle greater than Q. This shows that the bialy de(cid:2)ned by
the mesh point, the validity region extent and the max view-
point is tangent to the viewcell and leads to the observation:

Hence, it is suf(cid:2)cient to calculate the validity region ex-

tent for the borders of a volumetric viewcell.

Due to eq. (4), each part of a polygonal viewcell can be
treated separately by intersecting the corresponding results.
In 3D we can restrict ourselves to faces, in 2D to simple
line segments. It thus suf(cid:2)ces to suppose one codimensional
viewcells. We start by considering hyperplanes.

Hyperplane Viewcells: The bialy’s tangency is key to (cid:2)nd-
ing the max viewpoint. Due to the bialy’s rotationally invari-
ant shape around direction ~d the tangency point has to lie
on the orthogonal projection of the line S(t) on the plane.
This implies that for hyperplane viewcells the 3D case can
be solved in 2D. Fig. 5 shows a bialy and the possible re-
striction to 2D. The parametrization of a simpli(cid:2)cation point
S(t) = M + t ~d leads to a parameterized bialy of points that
"see" the segment [MS(t)] under the angle Q. The idea is to
(cid:2)nd the parameter t to obtain tangency ((cid:2)g. 6). Instead of
working on the bialy/bicircle itself, we treat the two circular
parts separately.

Without loss of generality, the viewcell corresponds to the
x-axis and the mesh point M = (m1; m2)>, with m2 > 0.
Then the circle is given by the equation for the center C(t)
and the radius r(t).

C(t) = M +

(~d (cid:6) cot Q~d?)

t
2

Figure 5: The 3D shape of the points seeing the segment
[M; S] under the same angle. The max viewpoint has to be
situated in the plane containing the projection of the line
de(cid:2)ned by M, ~d and the viewcell plane’s normal.

S

d

M

Q

V

viewcell

Q

d

S(t2)

S(t1)

M

Q

Q

max viewpoint

viewcell

r(t) =

t

2 sin Q

where (cid:6) indicates the considered part of the bicircle. As
the viewcell corresponds to the x-axis and M is situated in
the upper half-space, the tangent/max viewpoint must have
coordinates (xmax; 0) = C(tmax) (cid:0) (0; r(tmax)). Solving the
implied linear system leads to the coordinates of the max
viewpoint:

Vmax = (m1 + m2 (cid:3)

sin Qd1 (cid:6) cos Qd2

(cid:6) cos Qd1 (cid:0) sin Qd2 + 1

; 0)

(7)

tmax =

2 sin Qm2

(cid:6) cos Qd1 (cid:0) sinQd2 + 1

again, (cid:6) depends on the considered part. More details can

be found in the appendix A.

At this point, we get a (cid:2)rst interesting result. If we pa-
rameterize t, which corresponds to the distance between the
validity region extent and the mesh point M, via the direction
~d = (cos g; sin g)>, given by an angle g, we get:

(8)

(9)

tmax(g) =

sin Qm2

(cid:6) cos(Q (cid:6) g) (cid:0) 1

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

which is an equation describing a hyperbola. The validity
region of a mesh point for a line viewcell is thus formed by
two intersecting hyperbolas ((cid:2)g. 7). In 3D this region is ro-
tated around the normal of the hyperplane viewcell. We have
thus an exact description of the validity region of a point in
three dimensions in the case of a hyperplane viewcell.

M

viewcell

Figure 7: For a line viewcell the validity region of a point is
bounded by two hyperbolas.

One Codimensional Viewcells: In the next step we want to
restrict the hyperplane viewcells to polygonal areas. We will
describe how to solve the problem in the 2D case and explain
how to transfer the idea to the 3D case.

When working with two separated circles instead of the
bicircle, we actually (cid:2)nd two "max viewpoints", one for each
circular part. Although one of these two might not be a max
viewpoint in the strict sense, to avoid confusion and with a
slight abuse of notation, we will refer to both of them as max
viewpoints. It is not problematic to test several points, as
long as their number is (cid:2)nite. In particular it is important to
consider both sides of the bicircle, because the position of a
max viewpoint for a segment viewcell is in no direct relation
to the one for the corresponding line viewcell ((cid:2)g. 8).

d

M

Vl

viewcell

Vs

 

Figure 8: For the line viewcell the max viewpoint in direc-
tion ~d is situated on the left, whereas for the segment viewcell
it is on the right.

Let VS be a segment viewcell and VL its extension to a
line viewcell. Also, let Vs (resp. Vl ) be the max viewpoint for
VS (resp. VL). If Vl 2 VS then Vs = Vl. We now want to show
that if Vl 62 VS then Vs is an extremity of VS ((cid:2)g. 9). Vl has
to be in the interior of the tangent bicircle at VS (inscribed
circle theorem). Therefore the segment [Vs;Vl] lies also in the
interior of the bicircle of Vs. VS \ (Vs;Vl) 6= ; contradicts the
tangency property, thus VS is an extremity.

In the 3D case, we can establish the same distinction. The
proof is essentially the same, the bialy for the hyperplane is

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

d

M

Vl

Vs

viewcell

Figure 9: If the max viewpoint (for one part of the bicircle)
for the line viewcell does not lie on the segment viewcell, its
max viewpoint has to be on an extremity.

contained in the bialy for the viewcell, therefore the space
between the two has to be empty. Unfortunately in 3D, this
border is not a point, but a segment. To solve for the va-
lidity extent it can still be treated as a line and then the
segment’s extremities are taken into account. Still, (cid:2)nding
max viewpoints for the line involves higher order polyno-
mials and we did not yet succeed to obtain an analytic ex-
pression. Nevertheless, it is possible to approach the result
arbitrarily close using numerical methods. It is not a triv-
ial result that numerically stable solutions can be provided.
The proof comes from the geometrical interpretation that we
established. The idea is to embed the line into a plane and
look at iso-values for the sizes of the bialys (which are in
direct relation to the lengths of the validity region extents).
The result are half-moon shaped areas around the actual max
viewpoint of the plane ((cid:2)g 10). Thus, on a line embedded in
this plane at most three extrema can occur. All viewpoints
for which the validity region is unbounded lie inside a cone.
Therefore one can quickly determine which part of the view-
cell is not needed for the determination of the validity extent.
To restrict the search space one can pick an arbitrary view-
point V of the remaining viewcell and de(cid:2)ne a minimum
distance such that all viewpoints exceeding this distance are
less restrictive than V . These properties make it possible to
compute the validity extent in a stable way with arbitrary
precision.

d

Figure 10: For a given direction the sizes of the bialys are
represented on a plane (red low, white high). The halfmoon-
shapes can be explained with our geometrical interpretation.

To resume, so far we have shown that it is possible to cal-
culate the validity region of points given a (cid:2)nite set of (not
necessarily bounded) polygonal viewcells. For a given point
M and a direction ~d, possibly given via an existing simpli-
(cid:2)cation point S, the max viewpoints are classi(cid:2)ed for each

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

face of the viewcell. This is done by considering the hyper-
plane using eq. (7) and discarding viewpoints outside the
viewcell face. Next the borders of the viewcell are exam-
ined. This gives a (cid:2)nite set for which eq. (3) is evaluated,
what leads to the minimal extent.

This result could be applied for e.g. simpli(cid:2)cation of point
clouds or sampled geometry (or texels of a textured mesh).
Such applications lie out of the scope of this article. The
result is general enough to be used with any simpli(cid:2)cation
algorithm. If the creation of the impostor was not performed
using this error bound, the veri(cid:2)cation of validity still re-
mains possible. Concerning level of detail changes, when
the observer approaches the object, our error measure de-
livers the actual distance at which a representation change is
needed. This can be done by determining the bialys for the
desired error and assuring that the minimal distance keeps
the viewer outside of every single one.

5. Validity Regions of Faces
In this section we will extend the notion of validity regions
of points to mesh faces, therefore taking color information of
points (like texture) into account. Mathematically a face con-
tains an in(cid:2)nity of points. Thus to avoid sampling, we want
to establish a way to assure the validity of the modi(cid:2)cation
of a whole face. This part is quite technical and currently our
result is two-dimensional.

The solution is not straightforward because validity re-
gions for points inside the face cannot be simply interpolated
from the validity regions of the vertices. In other words, if
the vertices of a face are moved within their validity region,
mesh points on the face do not necessarily remain in their re-
spective validity region, as illustrated in (cid:2)g. 11. This directly
implies that algorithms basing their error estimate only on
edges or vertex distances cannot succeed in establishing an
upper bound on the error of the actual image (neither in 2D
nor in 3D). A comparison of any algorithm like this with a
method involving our analysis could thus be arbitrarily bi-
ased in our favor. In other words heuristic can and will lead
to arbitrarily large errors (at least in special cases).

s(M)

s(N)

M

C

N

viewcell

Figure 11: When M and N are moved within their valid-
ity region (to s(M) and s(N) respectively) not all points on
[MN] can be simpli(cid:2)ed on [s(M),s(N)]. E.g. C’s validity re-
gion does not intersect [s(M)s(N)]

To de(cid:2)ne a validity region for faces, we must (cid:2)rst (cid:2)x
the way a face is "moved" during the simpli(cid:2)cation process,
thus specifying the "movement" of the corresponding mesh
points. We chose a directional projection onto a simpli(cid:2)-
cation plane. This is actually less restricting than it might
sound and has several bene(cid:2)ts. The order of the mesh points
and a certain injectivity and connectivity is kept during sim-
pli(cid:2)cation. Compared to a perspective projection, no speci(cid:2)c
viewpoint has to be selected and faces could still be cut into
parts to allow different directions per patch. Finally it should
be mentioned that the analysis is independent of the way the
(cid:2)nal representation is stored. If the obtained simpli(cid:2)cation
is texture based, it can still be transformed under perspec-
tive projection to gain memory. Only the resolution changes,
not the position of the samples. The approach of this sec-
tion can also be used to (cid:2)nd optimal texture resolutions for
all viewpoints inside the viewcell (see [Eis04]). The idea is
to choose as the simpli(cid:2)cation direction the surface orien-
tation, thus representing texels on the surface. In this part,
we assume projections along the plane’s normal to ease ex-
planations, although the approach described generalizes to
arbitrary directions.

A simpli(cid:2)cation plane is said to be valid for a face if
each point on the face, when projected onto the simpli(cid:2)ca-
tion plane, remains inside its corresponding validity region
((cid:2)g. 12).

invalid

M

N

valid

viewcell

Figure 12: A simpli(cid:2)cation plane is valid for the face [M; N]
if all face points remain inside their corresponding validity
region after being transferred.

A plane can be represented by its Hough transform: a nor-
mal and an offset from the origin [Hou62]. Fixing a normal
(and thus projection direction) leaves us with the question of
(cid:2)nding the possible offsets for a valid simpli(cid:2)cation plane.
For a single mesh point the offset is given via the validity
region extents. For a mesh face, this is more dif(cid:2)cult.

From eq. (8), we observe that for a line viewcell the ex-
tents of a validity region vary linearly with the distance of
the mesh point to the viewcell. In this case it is suf(cid:2)cient to
ensure validity at the face’s extremities to obtain validity for
all points on the face. This also holds in the 3D case for hy-
perplane viewcells. Thus if all the max viewpoints fall inside
the segment viewcell, we encounter a linear behavior and it
is actually suf(cid:2)cient to test the vertices of the face.

This observation leads to the idea of decomposing the

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

mesh face into several parts, for which we will determine
the offsets separately. Having detected the linear part, we
will see that the remaining parts are non-linear, but involve
only one single viewpoint. Once offsets have been found for
each part, an intersection leads to the correct solution for the
face. An empty set means that there is no valid simpli(cid:2)ca-
tion plane for this projection direction, hence at least one
point cannot be simpli(cid:2)ed. Realize that for each face there
are always valid simpli(cid:2)cation planes, in particular the one
containing the face itself.

linear part

M

d

N

viewcell

Figure 13: Validity extents in direction ~d of the face’s points
form the shape above, which contains a linear part. Accord-
ingly the face will be decomposed into a linear region, where
it is suf(cid:2)cient to test the extremities and the non-linear re-
gions, which have to be dealt with separately.

Detecting the Linear Part: The determination of the linear
part is actually equivalent to the detection of those points on
the face for which the max viewpoint of the corresponding
line viewcell falls into the segment viewcell. Due to eq. (7),
we can determine for each point on the face the correspond-
ing coordinates of the max viewpoint for a line viewcell.
Actually there is a small subtlety; eq. (7) corresponds to a
mesh point in the upper half-space, therefore faces should
be clipped, see appendix B. There is a linear correspondence
between the position of the mesh point and the max view-
point for hyperplane viewcells. Now, if the face is extended
to a line, we have two points on this line for which the max
viewpoint corresponds to an extremity of the segment view-
cell. These borders of the linear part can be inferred by solv-
ing for (m1; m2)> in eq. (7) where the max viewpoint corre-
sponds to the segment viewcell’s extremities ((cid:2)g. 13).

Supposing the face is given by the segment [M; N] we will
refer to the line through the face, as the face line, here given
by l(a) := M + a( ~MN) = M + a(w1; w2)>. Without loss of
generality, one viewcell extremity is (e; 0)>. Thus, the equa-
tion to solve is: Vmax(l(a)) = (e; 0)>. The solution is given
by:

ae =

e (cid:0) (m1 + cm2)

w1 + cw2

; c :=

sin Qd1 (cid:6) cos Qd2

(cid:6) cos Qd1 (cid:0) sin Qd2 + 1

(10)

((cid:6) corresponds to the two sides of the bicircle). If (w1 +
cw2) = 0 all mesh points share the same max viewpoint. If
this viewpoint lies inside (respectively outside) the segment,
the whole face is linear (respectively non-linear).

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

Dealing with the non-linear part: The way we detected the
linear part actually implies one property of the non-linear
part; it only depends on a single viewpoint: one extremity of
the viewcell. Thus we only need to examine how the validity
region of a face behaves for a single viewpoint.

We will consider the validity region extent of points on a
face line. For each such point P, the validity region extent is
given by the intersection of a line passing through P in the
projection direction and the viewpoint’s view cone. If each
side of the cone is treated separately as a line and we plot
those intersections for every point on the face line, we get a
graph as shown in (cid:2)g. 14. It may contain "false" intersections
which represent intersections with the line instead of the ray.
This is unproblematic, as a false intersection implies a more
restrictive intersection for the other view cone ray. The right
part of (cid:2)g. 20 shows an example.

ray
face line
asymptote
projection direction

VRface(a)

Q

face(a)

viewpoint

Figure 14: The validity region extents of the mesh points on
the face are given by the intersection between a ray from
viewpoint with angle Q and a line from the mesh point in
projection direction.

The graph visualizes the validity region extents of all
points on the face line. A valid simpli(cid:2)cation plane has to
remain inside the hull described by the portion of the graph
corresponding to the mesh face (blue region in (cid:2)g. 14). Thus
to (cid:2)nd the offsets of our plane, we need to (cid:2)nd tangents with
normal ~d at the contained curve parts.

The following reasonings will have to be performed for
Q and (cid:0)Q (both branches of the view cone). The resulting
graphs delimit the simpli(cid:2)cation plane’s offset. Both cases
are similar and we will only focus on Q.

Let’s develop a mathematical description. Given a point
M, the viewpoint V and the projection direction ~d, we are
looking for the intersection between the two lines l1(a) :=
M + a~d and l2(a) := V + aRQ(V (cid:0) M), where RQ describes
a rotation of angle Q.

To ease the calculus, but without loss of generality, we
can assume that V = (0; 0)>, ~d = (0; 1)>. M is on the face
line given by f ace(a) = (0; m)> + a(cos g; sin g)>. This last
assumption is actually a restriction, as it is now impossible
that the face describes a vertical segment, not lying on the y-
axis. On the other hand, this is not crucial as the projection
direction was assumed to be vertical. We simply exclude this

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

case where a face would be simpli(cid:2)ed to a point. This makes
sense and the remaining case could be treated separately. The
(cid:2)nal curve corresponds to:

evaluated, otherwise only the face’s extremities need to be
checked. The process is repeated for (cid:0)~d, to get the lower
offset bound for the simpli(cid:2)cation plane.

VR f ace(a) := a

a sin(Q + g) + m cos Q cos g
a cos(Q + g) (cid:0) m sinQ cos g

(11)

We are now interested in the tangent points with a normal
equal to the projection direction. As the projection direction
has been chosen to be (0; 1)>, we are actually interested in
local minima and maxima of this quadratic rational. The cur-
vature can only have two different signs, one for each side
of the de(cid:2)nition gap. Thus any point for which the deriva-
tive vanishes is automatically an extremum, there cannot be
any saddle points and the function remains monotonic for
the branches separated by the extremum. Due to this mono-
tonicity, it is suf(cid:2)cient to test the extremities of the face if
the extrema do not correspond to mesh points.

Finding extrema is equivalent to (cid:2)nding roots of the
derivative. The resulting expression is at most quadratic and
therefore possible to solve. The discussion is quite technical,
because the function varies from a line, to a parabola, hyper-
bola and a "real" rational function depending on the angle
between the face and the projection direction. The resulting
formulae can be found in appendix C.

Concluding Face Validity: To summarize, let’s explain a
way to detect the validity of a face. (To accelerate the ap-
proach a more profound discussion of the functions would
be necessary and the interested reader is referred to [Eis04]).

For both parts of the bicircle, that is to say for both cir-
cles we (cid:2)nd the linear region on the face. Then we calculate
the maximum offset in the projection direction for the linear
part by evaluating eq. (6) for its extremities. For the remain-
ing non-linear parts there is only one viewcell extremity to
be considered. The tangents at the curve are found for Q
and (cid:0)Q. If the extrema correspond to mesh points these are

tangent points
projection direction

valid simplification plane
mesh face

viewpoint

Figure 15: For Q and (cid:0)Q we obtain functions represent-
ing the validity extents of all points on the face line. We
are actually only interested in those points on the face line
corresponding to mesh points. Therefore both functions are
cropped. There are two cases: an extremum corresponds to
a mesh point (upper curve) or only the extremities have to be
tested because of monotonicity (lower curve).

6. Discussion
In this paper we examine the exact error in the case of
viewcell-dependent simpli(cid:2)cation and describe how they
can be visualized and represented geometrically. We treat
several 3D cases and provide closed-form solutions for the
2D situation.

The innovative contribution is the notion of validity re-
gions, which correspond exactly to the region of points
which are close enough to be used as a simpli(cid:2)cation. We ex-
plain how their exact calculation can be achieved. Thus, we
were able to establish an exact error bound. In other words,
we give an answer to the question whether a simpli(cid:2)cation
is valid, how much we can simplify and for which viewpoint
the error will be most evident.

In addition, we point out the importance of considering
all points in a face to respect texture. The error measure
naturally leads to silhouette and parallax effect preservation.
This approach combines local point with mesh information
and avoids sampling. Movement of the observer is not re-
stricted and arbitrary polygonal viewcells are possible. As
mentioned before heuristics that only test observed vertex
distances or edge lengths can result in arbitrarily large errors.
Figure 16 depicts such a situation where the error converges
to in(cid:2)nity. It is impossible to perform an unbiased compari-
son.

viewcell

Figure 16: The vertical edges are small as seen from the
viewcell, but their collapse makes the triangles disappear.

The evaluation of the validity regions is very fast due to
its closed-form representation. It takes (cid:25) 1 sec. for 290.000
point validity extents ((cid:25) 0.0036 ms per evaluation) on a
Pentium 1.5 GHz (face validity is usually about 3-4 times
slower). Nevertheless we completely acknowledge that good
heuristics can be simpler and often lead to acceptable results
(especially for (cid:2)nely tesselated models). This is not surpris-
ing, as for far away geometry a small viewcell behaves like
a point viewcell and small triangles behave like points, but it
is not equivalent. This paper allows to evaluate the error re-
sulting from simple heuristics and compare to the now avail-
able exact reference. E.g. for impostors [SDB97] often a sin-
gle viewpoint is chosen. This necessity becomes apparent in
form of a common problem of viewcell-based approaches.
Representations can change drastically from one viewcell to
the other. This is especially true because little attention has
been paid to the actual error committed by the replacement.
In our approach the proximity is guaranteed throughout the

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

original

VDBBC

Figure 17: A city model (Courtesy of J. Dorsey) is simpli(cid:2)ed on only 115 quads. The viewcell is a halfspace at the bottom of
the image. Even though from above both representations seem to differ a lot (left, middle), seen from the inside of the viewcell
both look quite similar (right). In each of the three sample views the original is on the top and the simpli(cid:2)cation underneath.

viewcell and everywhere on the geometry. Overlapping of
viewcells or blending thus become meaningful.

Theoretically this metric could be useful in several con-
texts, like simpli(cid:2)cation envelopes [CVM(cid:3)96]. Geometry
modi(cid:2)cations are accepted if the shape is close enough to
the initial one. This approach would be applicable for any
edge-collapse or vertex deletion algorithm if a simpli(cid:2)ca-
tion function can be de(cid:2)ned. This is also possible for point
clouds or by sampling in 3D (for example at texture resolu-
tion). This is somewhat related to [COM98], but involving
viewcells. Our distance metric can also be directly used dur-
ing the simpli(cid:2)cation process [Fre00]. Other papers could
bene(cid:2)t from our work too. One example, is a recent paper on
soft-shadows [AHL(cid:3)06]. Here the occluder was represented
using a depth map and the error was estimated based on the
gap between depth samples. Our analysis allows a classi(cid:2)-
cation of this error and predicts the region on the ground for
which the error is biggest.

We also implemented a view-dependent billboard clouds
(VD-BBC) approach whose run-time scales linearly with the
geometric complexity. BBC [DDSD03] are a simpli(cid:2)cation
via planes. These planes are represented via textured and al-
pha mapped quads on which geometry is projected. The se-
lection is performed based on a heuristic, working on a dis-
cretization of the plane space. Following the density (a value
representing the amount of geometry (faces) that can be sim-
pli(cid:2)ed on the plane) the algorithm greedily proceeds until all
faces have been simpli(cid:2)ed. For VD-BBC, we exploit the va-
lidity regions to determine on which planes a face can be
projected in two dimensions.

A (cid:2)rst example is shown in (cid:2)gure 17. The method was
applied to a 4194 triangle city model. Due to its simplic-
ity the model does not seem to leave much possibilities to
simplify. Nevertheless, the resulting representation contains
only 115 textured quads while maintaining a proximity of
0:1(cid:14) ((cid:25) 5 pixels) neglecting the vertical error. The viewcell
in this example is a halfspace situated at the lower bottom of

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

the image. In particular it is interesting to see how the struc-
ture of the city is maintained for nearby parts, whereas far
away areas are aggressively simpli(cid:2)ed. Especially the struc-
ture becomes unrecognizable from above, but appears close
to the original as seen from the viewcell. As in the original
BBC approach small cracks might be visible where neigh-
boring faces project to different planes, but these openings
are completely bounded by our approach.

The second example is shown in Fig. 18. The scene is a
billboard forest around a centering segment viewcell. The
left part depicts the 2D representation to which we applied
the VD-BBC approach. The upper left quadrant shows a
quarter of the scene and its geometric complexity. The lower
left quadrant shows that our method successfully simpli(cid:2)es
distant geometry. The red segments show the orientation of
the created billboards and all shown green segments have
been simpli(cid:2)ed on these. The (cid:2)gure shows only those bill-
boards representing more than 100 trees. Finally the right
half shows an example of this simpli(cid:2)cation. All green trees
simplify to the same billboard whose orientation is shown
in red. In particular you might notice that the simpli(cid:2)ed ge-
ometry forms a star. This results from the segment viewcell,
which is aligned horizontally. The parallax effects are thus
less pronounced along this direction. All in all we realize that
even exact bounds still allow for aggressive simpli(cid:2)cation in
higher polygon count scenes. Only < 2:3% of the original
complexity remained. On the one hand this does not have a
real signi(cid:2)cation because we could simply add more geom-
etry to further improve these statistics. On the other hand it
gives a good idea of the quality of the approximation.

7. Future Work
Lots of interesting avenues arise from this work. We solved
validity in 3D for the special case of hyperplanes and
point validity in a numerically stable way. An analytical
closed form expression, as the one we presented for the 2D
case, would be an interesting result. Treating arbitrary (non-
polytope) viewcells also remains a challenge.

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

quarter  of original scene

viewcell

original

> 100 faces per 
billboard

faces on a 
single billboard

view dep. BBC

Figure 18: The left two quadrants of the left part of the (cid:2)gure show the original scene complexity (top) and a selection of
billboards containing more than 100 trees (the red segments indicate the billboards, the green elements the simpli(cid:2)ed trees). In
this scene the viewcell is a centered segment. Its shape in(cid:3)uences the validity regions and leads to a star like set of trees that
are simpli(cid:2)ed on the same plane. Seen from the viewcell the original and the billboard cloud representation look very similar,
even though less than 2:3% (compared to the original) of the geometry is involved.

At the moment visibility is not involved in the calculation
of the validity region. For two-dimensional scenes, several
algorithms exist to calculate the visible part of the view-
cell (e.g. [Hal02]). This information could be used, but al-
gorithms are generally computationally expensive and might
have numerical issues.

Perception starts playing an important role in simpli(cid:2)ca-
tion [WLC(cid:3)03, LT00] and we would like to incorporate this
kind of information in our approach. In particular we want
to investigate what visual errors arise from a representation.
Due to the way rasterization works on current cards, bill-
boards can have a different appearance for grazing angles.

We would like to further explore other applications of our
work, in the spirit of Cornish et al. [CRL01]. One particular
idea consists in considering a light source as an observer to
create simpler but more or less equivalent shadow casters.

Acknowledgments Thanks go to S. Lefebvre for his
help with pBuffers and 3DSLib and the reviewers, P. Barla,
S. Camerer, M. Eisemann, S. Grabli, S. Hornus, S. Paris, E.
Turquin and H. de Almeida Bezerra for their comments.

References
[AHL(cid:3)06] ATTY L., HOLZSCHUCH N., LAPIERRE M.,
HASENFRATZ J.-M., HANSEN C., SILLION F.: Soft
shadow maps: Ef(cid:2)cient sampling of light source visibil-
ity. Computer Graphics Forum (2006). (to appear).

[Cla76] CLARK J.: Hierarchical geometric models for vis-
ible surface algorithms. In Communications of the ACM
19(10) (1976).

Appearance-preserving simpli(cid:2)cation.
GRAPH (1998), ACM Press.

In Proc of SIG-

[CRL01] CORNISH D., ROWAN A., LUEBKE D.: View-
dependent particles for interactive non-photorealistic ren-
dering. In Proc. of Graphics Interface (2001).

[CVM(cid:3)96] COHEN J., VARSHNEY A., MANOCHA D.,
TURK G., WEBER H., AGARWAL P., BROOKS F.,
WRIGHT W.: Simpli(cid:2)cation envelopes. In Proc. of Com-
puter graphics and interactive techniques (1996), ACM
Press.

[DDSD03] D(cid:201)CORET X., DURAND F., SILLION F.,
DORSEY J.: Billboard clouds for extreme model simpli-
(cid:2)cation. In Proc. of SIGGRAPH (2003), ACM Press.

[DSSD99] D(cid:201)CORET X., SILLION F., SCHAUFLER G.,
DORSEY J.: Multi-layered impostors for accelerated ren-
dering. Proc. of Eurographics 18, 3 (1999).

[Eis04] EISEMANN, ELMAR:

View-Dependent Object
Simpli(cid:2)cation and its Application in the Case of Billboard
Clouds. Dea, UJF/INPG/ENSIMAG, 2004.

[ESSS01] EL-SANA J., SOKOLOVSKY N., SILVA C. T.:
Integrating occlusion culling with view-dependent render-
ing. In Proc. of the conference on Visualization (2001),
IEEE Computer Society.

[ESV99] EL-SANA J., VARSHNEY A.: Generalized view-
dependent simpli(cid:2)cation. In Computer Graphics Forum
(1999).

[Fre00] FREY P. J.: About surface remeshing. In Proc. of

9th International Meshing Roundtable (2000).

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

[COM98] COHEN J., OLANO M., MANOCHA D.:

[Hal02] HALL-HOLT, OLAF: Kinetic visibility. Ph. D.

E. Eisemann & X. DØcoret / On Exact Error Bounds for View-Dependent Simpli(cid:2)cation

thesis, Department of Computer Science, Stanford Uni-
versity (2002).

[Hop96] HOPPE H.:

Progressive meshes. Computer

Graphics 30, Annual Conference Series (1996).

[Hop97] HOPPE H.: View-dependent re(cid:2)nement of pro-

gressive meshes. In Proc. of SIGGRAPH (1997).

[Hou62] HOUGH P.: Method and means for recognizing

complex patterns. US Patent 3,069,654 (1962).

[JW02]

JESCHKE S., WIMMER M.:

Textured depth
meshes for real-time rendering of arbitrary scenes.
In
Proc. of EuroGraphics Workshop on Rendering (2002),
Eurographics Association.

[JWS02]

JESCHKE S., WIMMER M., SCHUMAN H.: Lay-
ered Environment-Map Impostors for Arbitrary Scenes.
In Proc. Graphics Interface (2002).

[LE97] LUEBKE D., ERIKSON C.: View-dependent sim-
pli(cid:2)cation of arbitrary polygonal environments. In Proc.
of SIGGRAPH (1997).

[LKR(cid:3)96] LINDSTROM P., KOLLER D., RIBARSKY W.,
HODGES L., FAUST N., TURNER G.: Real-time contin-
uous level of detail rendering of height (cid:2)elds. In Proc. of
SIGGRAPH (1996).

[LT00] LINDSTROM P., TURK G.: Image-driven simpli(cid:2)-

cation. ACM Transactions on Graphics 19, 3 (2000).

[MS95] MACIEL P. W. C., SHIRLEY P.: Visual navigation
of large environments using textured clusters. In Proc. of
Symp. on Interactive 3D graphics (1995), ACM Press.

[SDB97] SILLION F., DRETTAKIS G., BODELET B.: Ef-
(cid:2)cient impostor manipulation for real-time visualization
of urban scenery. In Proc. of Eurographics (1997).

[WLC(cid:3)03] WILLIAMS N., LUEBKE D., COHEN J. D.,
KELLEY M., SCHUBERT B.: Perceptually guided sim-
pli(cid:2)cation of lit, textured meshes. In Proc. of Symposium
on Interactive 3D Graphics (2003).

[WM03] WILSON A., MANOCHA D.:

Simplifying
complex environments using incremental textured depth
meshes. In Proc. of SIGGRAPH (2003), ACM Press.

[XV96] XIA J. C., VARSHNEY A.: Dynamic view-
dependent simpli(cid:2)cation for polygonal models. In Proc.
of the conf. on Visualization (1996), IEEE-CS Press.

Appendix A: Vmax classi(cid:2)cation

d

M

Q

viewcell

Q

 

Q

Q

Figure 19: If the angle of the projection direction and line
viewcell lies in [p (cid:0) Q; p + Q], there is no meaningful max
viewpoint for this side of the bicircle.

Working with two circles instead of the bicircle might lead

c(cid:13) The Eurographics Association and Blackwell Publishing 2006.

to an intersection with the part that lies in the interior of the
bicircle. It can be shown that no meaningful max viewpoint
occurs if the angle between ~d and the line viewcell lies in
[p (cid:0) Q; p + Q]. The case p (cid:0) Q leads to no intersection at all.
For this "side" of the bicircle, the validity region extent is
unbounded ((cid:2)g. 19). Even without this test, false detections
will be unproblematic (in the worst case, one unnecessary
evaluation is performed).

Appendix B: Clipping faces
Faces intersected by the extension of a segment viewcell to
a line, should be split because eq. (7) assumes the point M to
lie in the upper half space. Of course, it is possible to deduce
a similar equation for the lower one, but splitting and culling
for polygonal viewcells implies that less geometry needs to
be considered. The correctness is proven similar to the proof
that max viewpoints lie on the boundary.

Appendix C: Tangents for Face Validity
If one supposes that the function can be simpli(cid:2)ed to ca
(with c 6= 0) by division, we obtain a(sin(Q + g) (cid:0) c cos(Q +
g)) + m cos g(cos Q + c sin Q) = 0 as cos g 6= 0. Assuming
m 6= 0, the constant part implies c = (cid:0) cot Q. Leading to
sin(Q + g) + tan Q cos(Q + g) = 0, and thus cos g = 0. This
case had been excluded, as the face would be vertical. If
m = 0, VR f ace simpli(cid:2)es to tan(Q + g)a. A linear function,
except if cos(Q + g) = 0, then the ray becomes parallel
to the projection direction (0; 1)> (validity extents are un-
bounded).
The case sin(Q + g) = 0 leads to a real hyperbola and both
branches are monotonic. There cannot be a tangent with nor-
mal (0; 1)> at a hyperbola. One exception occurs if the nu-
merator is completely zero (therefore m = 0), here we have
a linear function, the x-axis. ((cid:2)g. 20).
The case cos(Q + g) = 0 leads to a parabola ((cid:2)g. 20) except
for m = 0, when the function is always unde(cid:2)ned (see (cid:2)rst
case). In the parabola case the extremum is at

aparabola = (cid:0)

m sin Q cos g
2 sin(Q + g)

cotQ

(12)

For a quadratic numerator, a linear denominator that can-

not be simpli(cid:2)ed by division the extrema are:

a1;2 =

m cos g

cos(Q + g)

(sin Q (cid:6)

cos g sin Q
sin(Q + g)

)

s

(13)

QV

M
2

-2

M’

-2

Q

V

2

M

2

Q

-2

2

-2

Figure 20: Special Cases: Left: line, Right: Parabola (right
cone is an example for the false intersections

