A Quantitative Assured Forwarding Service (cid:3)

Technical Report: University of Virginia, CS-2001-21

Nicolas Christin

J¨org Liebeherr

Tarek F. Abdelzaher

Department of Computer Science

University of Virginia

Charlottesville, VA 22904

Abstract

The Assured Forwarding (AF) service of the IETF DiffServ architecture provides a qualitative ser-
vice differentiation between classes of trafﬁc, in the sense that a low-priority class experiences higher
loss rates and higher delays than a high-priority class. However, the AF service does not quantify the dif-
ference in the service given to classes. In an effort to strengthen the service guarantees of the AF service,
we propose a Quantitative Assured Forwarding service with absolute and proportional differentiation of
loss, service rates, and packet delays. We present a feedback-based algorithm which enforces the de-
sired class-level differentiation on a per-hop basis, without the need for admission control or signaling.
Measurement results from a testbed of FreeBSD PC-routers on a 100 Mbps Ethernet network show the
effectiveness of the proposed service, and indicate that our implementation is suitable for networks with
high data rates.

Key Words: Quality-of-Service, Service Differentiation, Buffer Management, Scheduling, Feedback Control.

(cid:3)This work is supported in part by the National Science Foundation through grants NCR-9624106 (CAREER), ANI-9730103,

and ANI-0085955.

1 Introduction

The Assured Forwarding (AF, [14]) service of the Differentiated Services (DiffServ, [6]) architecture is an
attempt to provide a scalable solution to the problem of service differentiation in the Internet. In the AF
service, ﬂows with similar QoS requirements are grouped into classes, using the DiffServ CodePoint ﬁeld
(DSCP, [26]) in the IP header. An attractive feature of the AF service is that it does not require admission
control or per-ﬂow classiﬁcation, and is therefore scalable on both the control and data paths. However, the
AF service only provides qualitative differentiation between classes, in the sense that some classes receive
lower delays and a lower loss rate than others, but the differentiation is not quantiﬁed, and no absolute
service bounds are offered.

Recently, research efforts have tried to strengthen the guarantees that can be provided within the con-
text of the AF service without sacriﬁcing its scalability and its simplicity, either by trying to quantify the
difference in the level of service received by different classes, or by offering absolute bounds on service pa-
rameters, e.g., delays, to a speciﬁc set of classes. For instance, the proportional service differentiation model
[9, 10] quantiﬁes the difference in the service by making the ratios of delays or loss rates of different classes
roughly constant. This type of service can be implemented through scheduling algorithms [9, 10, 11, 24, 25]
and/or buffer management algorithms [7, 10]. Recent works have tried to combine the scheduling and drop-
ping decisions in a single algorithm [20, 31]. Most scheduling and/or buffer management algorithms aim at
proportional differentiation, but do not support absolute service guarantees.

In a different approach to strengthening the AF service, the Alternative Best-Effort (ABE) service con-
siders two trafﬁc classes. The ﬁrst class obtains absolute delay guarantees, and the second class has no delay
guarantees, but is given a better loss rate than the ﬁrst class. Scheduling and buffer management algorithms
for the ABE service are presented in [16]. The service model in [19] also supports absolute delay bounds,
and qualitative loss and throughput differentiation, but no proportional differentiation.

These recent efforts to strengthen the AF service raise questions on the best possible class-based service
model that can be achieved by entirely relying on scheduling and dropping algorithms at routers, and without
admission control, trafﬁc policing, or signaling. In an attempt to explore the limits of such a class-based
service, we deﬁne in this paper a “Quantitative Assured Forwarding” 1 service that offers, on a per-hop
basis, both absolute and proportional guarantees to classes. Each node enforces any mix of absolute and
proportional guarantees. Absolute guarantees apply to loss rates, delays, or throughput, and deﬁne a lower
bound on the service received by each class. Proportional guarantees apply to loss rates and queueing delays.
As an example of the guarantees in the Quantitative Assured Forwarding service for three classes of trafﬁc,
one could specify service guarantees of the form “Class-1 Delay
Class-1
Delay”, “Class-2 Loss Rate
Class-2 Loss Rate”, and “Class-3 Service Rate
1 Mbps”. Clearly, without admission control, it is not feasible to satisfy all absolute guarantees at all
times. Thus, when absolute constraints cannot be satisﬁed, we allow that some service guarantees can be
temporarily relaxed according to a speciﬁed order.

1%”, “Class-3 Loss Rate

2 ms”, “Class-2 Delay

4

2

(cid:20)

(cid:25)

(cid:20)

(cid:25)

(cid:21)

(cid:1)

(cid:1)

We present a formal description of the Quantitative Assured Forwarding service, and we devise an
algorithm that enforces guarantees on loss, delay and throughput for classes by adjusting the service rate
allocation to classes and by selectively dropping trafﬁc. We apply linear feedback control theory for the
design of the algorithm, and, to this effect, make assumptions which approximate the non-linearities in the
system of study, similar to [15, 21, 22, 28].

1The name “quantitative differentiated service” was recently used in [19].

2

This paper is organized as follows. In Section 2, we deﬁne the Quantitative Assured Forwarding service.
In Sections 3 and 4, we describe the algorithms which provide the Quantitative Assured Forwarding service.
In Section 5, we present an implementation of these algorithms in FreeBSD PC-routers. We evaluate the
algorithms using the implementation in Section 6, and present brief conclusions in Section 7.

2 The Quantitative Assured Forwarding Service

In this section, we describe the Quantitative Assured Forwarding Service, and outline a solution for an
algorithm that realizes this service.

2.1 Formal Description

(

n

n

N

+ 1)

trafﬁc dropped (‘lost’) at the

-th event in the current busy period2, and
-th events. We use

We assume that all trafﬁc that arrives to the transmission queue of the output link of a router is marked
to belong to one of
classes. We use a convention whereby a class with a lower index receives a better
service. We consider a discrete event system, where events are trafﬁc arrivals. We use
to denote the
time of the
-th
and
arrivals and the amount of
class-
to denote the service rate allocated to class-
is a fraction of the output link capacity, which
at the time of the
can vary over time, and is set to zero if there is no backlog of class-
trafﬁc in the transmission queue.
For the time being, we assume bursty arrivals with a ﬂuid-ﬂow service, that is, the output link is viewed
as simultaneously serving trafﬁc from several classes. Such a ﬂuid-ﬂow interpretation is idealistic, since
trafﬁc is actually sent in discrete sized packets. In Section 5, we discuss how the ﬂuid-ﬂow interpretation is
realized in a packet network.

and
-th event. We use

to denote the time elapsed between the

-th event. The service rate of a class

, respectively, to denote the class-

(cid:1)

n

n

n

n

n

n

n

n

a

r

(

(

)

)

)

)

(

)

(

(

t

t

i

i

i

i

i

l

i

i

i

All service guarantees are enforced over the duration of a busy period. An advantage of enforcing
service guarantees over short time intervals is that the output link can react quickly to changes of the trafﬁc
load. Further, enforcing guarantees only within a busy period requires little state information, and, therefore,
keeps the implementation overhead limited. As a disadvantage, at times of low load, when busy periods are
short, enforcing guarantees only with information on the current busy period can be unreliable. However, at
underloaded links transmission queues are mostly idle and all service classes receive a high-grade service.

t

(0)

The following presentation speciﬁes the service differentiation independently for each busy period. Let
, is the total trafﬁc that
deﬁne the beginning of the busy period. The arrival curve at
has arrived to the transmission queue of an output link at a router since the beginning of the current busy
period, that is

-th event,

A

n

n

(

)

i

The input curve,

, is the trafﬁc that has been entered into the transmission queue at the

-th event,

n

R

n

(

)

in

i

2The beginning of the current busy period is deﬁned as the last time when the transmission queue at the output link was empty.

X

A

n

a

k

:

(

) =

(

)

i

i

in

i

R

n

A

n

l

k

:

(

) =

(

) (cid:0)

(

)

i

i

n

k

=0

n

k

=0

X

3

Ai
Rin
i

Rout

i

c
i
f
f

a
r
T

 
i
 
-
s
s
a
C

l

Dropped

Bi(n)

Di(n)

t(n1)

t(n2)

t(n)

time

Figure 1: Delay and backlog at the transmission queue of an output link.
the input curve and

is the output curve.

out

R

i

is the arrival curve,

is

in

R

i

A

i

The output curve is the trafﬁc that has been transmitted since the beginning of the current busy period, that
is

out

R

n

r

k

t

k

:

(

) =

(

)(cid:1)

(

)

i

i

n(cid:0)

1

k

=0

In Figure 1, we illustrate the concepts of arrival curve, input curve, and output curve for class-
any time
times

trafﬁc. At
, the service rate is the slope of the output curve. In the ﬁgure, the service rate is adjusted at

and

.

X

n

(

)

t

i

t

n

; t

n

t

n

(

)

(

)

(

)

1

2

As illustrated in Figure 1, for event
curves, respectively, denote the class-
have

i

n

, the vertical and horizontal distance between the input and output
-th event, we

and the class-

. For the

delay

backlog

B

n

i

D

n

n

(

)

i

(

)

i

and

B

n

R

n

R

n

;

(

) =

(

) (cid:0)

(

)

i

i

i

in

out

D

n

t

n

t

k < n

R

n

R

k

:

(

) =

(

) (cid:0)

maxf

j

(

) (cid:21)

(

)g

i

i

i

out

in

Eqn. (4) characterizes the delay of the class-

(cid:0)

i

trafﬁc that departs at the

-th event.

(cid:1)

n

We deﬁne the ‘loss rate’ to be the ratio of dropped trafﬁc to the arrivals. That is

A

n

R

n

(

) (cid:0)

(

)

i

in

i

p

n

(

) =

i

:

A

n

(

)

i

Since, from the deﬁnition of
are computed only over the current busy period,
they correspond to long-term loss rates only if busy periods are long. We justify our choice with the obser-
vation that trafﬁc is dropped only at times of congestion, i.e., when the link is overloaded, and, hence, when
the busy period is long.

, the

and

R

A

in

n

n

n

p

)

)

)

(

(

(

i

i

i

With these metrics, we can express the service guarantees of a Quantitative Assured Forwarding service.

An absolute delay guarantee on class

is speciﬁed as

i

(3)

(4)

(5)

(6)

8

:

(

) (cid:20)

n

D

n

d

;

i

i

4

c
i
f
f

a
r
T

 
i
- 
s
s
a
C

l

Rin
i

di

slope =

ri,min(n)

Di(n)

di-Di(n)

Rout

i

Bi(n)

t(n)

time

Figure 2: Determining service rates for delay guarantees.

where

d

i

is the delay bound of class

. Similarly, an absolute loss rate bound for class

i

i

is deﬁned by

An absolute rate guarantee for class

is speciﬁed as

i

8

:

(

) (cid:20)

n

p

n

L

:

i

i

The proportional guarantees on delay and loss, respectively, are deﬁned, for all

such that

n

B

n

>

(

)

0

i

8

:

(

)

0

(

) (cid:21)

n

B

n

>

; r

n

(cid:22)

:

i

i

i

B

n

>

(

)

0

i

+1

, as

and

D

n

(

)

i

+1

=

k

;

i

D

n

(

)

i

p

n

(

)

i

+1

=

k

;

0

i

p

n

(

)

i

(7)

(8)

and

(9)

(10)

where

and

k

k

i

0

i

are constants that quantify the proportional differentiation desired.

2.2 Rate Allocation and Drop Decisions

C

and buffer size

We now sketch a solution for providing the service guarantees speciﬁed in Eqs. (6)-(10) at the output link
of a router with capacity
. We assume per-class buffering of incoming trafﬁc, thus,
each class is transmitted in a First-Come-First-Served manner. In the proposed solution, the service rates
so that the constraints deﬁned by
Eqs. (6)-(10) are met. If not all constraints in Eqs. (6)-(10) can be met at the
-th event, then some service
guarantees need to be temporarily relaxed. We assume that the order in which guarantees are relaxed is
given.

and the amount of dropped trafﬁc

are adjusted at each event

B

n

n

n

n

r

(

)

(

)

l

i

i

The absolute delay guarantee on class

,

, imposes a minimum required service rate in the sense that

i

d

i

all backlogged class-

trafﬁc at the

-th event will be transmitted within its delay bound if

i

n

B

n

(

)

i

r

n

:

(

) (cid:21)

i

d

D

n

(cid:0)

(

)

i

i

5

This condition can be veriﬁed by inspection of Figure 2. If the condition holds for any
is never violated. If class
rate needed by class

has, in addition, an absolute rate guarantee

-th event, becomes 3

at the

(cid:22)

i

i

i

n

, the delay bound

n

d

i

, the expression for the minimum

r

n

; (cid:22)

(cid:31)

:

i;min

(

) = max

i

(cid:1)

B

n

>

i

(

)

0

B

n

(

)

i

d

D

n

(cid:0)

(

)

i

i

(12)

(cid:26)

(cid:27)

is upper bounded by the output link capacity minus the

The service rate that can be allocated to class
minimum service rates needed by the other classes, that is,

i

Therefore, the service rate can take any value

with

r

n

(

)

i

r

n

C

r

n

:

(

) =

(cid:0)

(

)

i;max

j;min

j 6

i

=

X

r

n

r

n

r

n

;

(

) (cid:20)

(

) (cid:20)

(

)

i;min

i

i;max

subject to the constraint
proportional delay differentiation.

n

r

(

i

i

. Given this range of feasible values,

can be selected to satisfy

) (cid:20)

C

r

n

(

)

i

We view the computation of

P

in terms of the recursion

r

n

(

)

i

(15)

(16)

r

n

r

n

r

n

;

(

) =

(

(cid:0) 1) + (cid:1)

(

)

i

i

i

i

)

(

r

n

n

(cid:1)

. From Eqs. (3) and (4), the delay

where
event
By monitoring
sulting from past service rate allocations, and infer the adjustment
this deviation.

is selected such that the constraints of proportional delay differentiation are satisﬁed at
.
we can thus determine the deviation from the desired proportional differentiation re-
needed to attenuate

-th event is a function of

at the

with

k < n

) =

(cid:1)

D

D

D

))

n

n

n

n

n

k

f

r

r

)

(

)

(

)

(

(

(

(

i

i

i

i

i

If no feasible service rate allocation for meeting all delay guarantees exist at the

-th event, or if there
-th event, trafﬁc must be dropped, either from a new arrival or from the current

is a buffer overﬂow at the
backlog. The loss guarantees determine which class(es) suffer(s) trafﬁc drops at the

-th event.

n

n

n

To enforce loss guarantees, we rewrite the loss rate, deﬁned by Eqn. (5), as a difference equation

p

n

p

n

:

(

) =

(

(cid:0) 1)

+

i

i

A

n

l

n

(

(cid:0) 1)

(

)

i

i

A

n

A

n

(

)

(

)

i

i

n

From Eqn. (16), we can determine how the loss rate of class

at the
-th event. Thus, we can determine the set of classes that can suffer drops without violating absolute loss
guarantees. In this set, we choose the class whose loss rate differs by the largest amount from the objective
of Eqn. (9).

evolves if trafﬁc is dropped from class

i

i

Having expressed the service rate and the loss rate in terms of a recursion, we can characterize the
service rate allocation and dropping algorithm as feedback control problems. In the next sections, we will
describe two feedback problems: one for delay and absolute rate differentiation (‘delay feedback loop’), and
one for loss differentiation (‘loss feedback loop’). We describe the interaction of the two feedback problems
in Section 5.

3For any expression ‘

’, we deﬁne

= 1 if ‘

’ is true and

= 0 otherwise.

expr

expr

(cid:31)

expr

(cid:31)

expr

6

3 The Delay Feedback Loop

In this section, we present feedback loops which enforce the desired delay and rate differentiation given by
Eqs. (6), (8), and (9). We have one feedback loop for each class with proportional delay guarantees. In the
feedback loop for class
by approximating the non-linear
effects of the service rate adjustment on the delays by a linear system, and derive stability conditions for the
linearized control loop.

, we characterize changes to service rate

(cid:1)

n

r

)

(

i

i

3.1 Objective

Let us assume for now that all classes are offered proportional delay guarantees. Later, this assumption will
be relaxed. The set of constraints given by Eqn. (9) leads to the following system of equations:

m

k

i >

m

i

n

i

j

1

=

1

= 1

for

, and

. We deﬁne a ‘weighted delay’ of class

Q

(cid:17)

(cid:16)

at the

-th event, denoted

Let
by

i(cid:0)

1

j

=1

D

n

(

)

(cid:3)

i

, as

Q

By multiplying each line of Eqn. (17) with
ation is achieved for all classes if

, we see that the desired proportional delay differenti-

A

(17)

(18)

(19)

D

n

k

D

n

;

(

) =

(cid:1)

(

)

2

1

1

...

D

n

k

D

n

:

(

) =

(

)

N

j

1

N (cid:0)

1

j

=1

(cid:3)

i

D

n

m

D

n

:

(

) =

(

)

k

i

0

1

N

k

; k 6

i

=1

=

Y

@

j 6

i

=

m

j

Q

(cid:3)

(cid:3)

8

8

:

(

) =

(

)

i; j ;

n

D

n

D

n

:

i

j

8

8

:

(

) =

(

)

i; j ;

n

D

n

D

n

;

(cid:3)

i

(cid:3)

(cid:3)

1

D

n

D

n

:

(

) :=

(

)

(cid:3)

i

N

i

X

Eqn. (19) is equivalent to

where

i

j

(cid:3)

(cid:3)

(

)

(cid:3)

(

n

n

)j

(cid:0)

D

D

D

of class

from the common set point

to be the set point common to all delay feedback loops. The feedback loop for class

We set
the difference
Remark: We view event numbers,
, as sampling times on a virtual time axis in which events are equidistant.
Hence, convergence of the control loop applies to virtual time. However, the relationship between delay
and rate is independent of the time axis chosen. By virtue of this independence, and since real-time is
monotonically increasing with virtual time, we make the assumption that the skew between virtual-time and
real-time can be neglected, and that the convergence condition we present later applies to real-time as well.

reduces

.

D

n

n

)

(

(cid:3)

i

i

3.2 Service Rate Adjustment

Next, we determine how to adjust the service rate to achieve the desired delay differentiation. Let
referred to as “error”, denote the deviation of the weighted delay of class

from the set point, i.e.,

i

,

e

n

(

)

i

e

n

D

n

D

n

:

(

) =

(

) (cid:0)

(

)

i

(cid:3)

(cid:3)

i

(22)

7

Note that the sum of the errors is always zero, that is, for all

,

n

e

n

N D

n

D

n

:

(

) =

(

) (cid:0)

(

) = 0

i

(cid:3)

(cid:3)

i

i

i

X

X

If proportional delay differentiation is achieved, we have
to compute the service rate adjustment
entiation constraints. From Eqn. (22), we note that if
high with respect to the desired proportional delay differentiation. Therefore,
versely,
adjustment
a monotonically decreasing function. We choose

indicates that class
is a decreasing function of the error

delays are too low, and

needed for class

, written as

,

) = 0

(cid:1)

(cid:1)

(cid:1)

D

>

<

n

n

n

n

n

n

0

0

e

e

e

e

r

r

r

r

(

)

)

(

(

(

(

)

)

(

(

)

i

i

i

i

i

i

i

i

i

for all classes. We use the error

e

n

(

)

i

i

(

)

(cid:3)

(cid:3)

n

> D

to satisfy the proportional delay differ-
, class
delays are too
must be increased. Con-
must be decreased. Hence, the rate
is

, where

n

n

n

r

)

(

(

)

)

i

i

n

f

e

n

f

:

(

) =

(

(

))

(

)

i

i

(cid:1)

(

) =

(

) (cid:1)

(

)

r

n

K

n

e

n

;

i

i

(

)

n

K

where
, which, in feedback control terminology, is the controller. An advantage of this controller is
that it requires a single multiplication, and hence is easily implemented in a real system. Another advantage
is that, at any

, we have

<

0

n

(cid:1)

(

) =

(

)

(

) = 0

r

n

K

n

e

n

:

i

i

i

i

Therefore, the controller produces a work-conserving system, as long as the initial condition
is satisﬁed. Note that systems that are not work-conserving, i.e., where the link may be idle even if there is
a positive backlog, are undesirable for networks that need to achieve a high resource utilization.

(0) =

X

X

P

C

r

i

i

(

K

We now express limits on

limits are imposed by two different factors. We derive a ﬁrst condition on
loops are stable, in the sense that they attenuate the errors
differentiation. We then derive a second condition on
a violation of the absolute delay and rate constraints.

so that we can characterize the service rate adjustment needed. These
so that the feedback
over time, thereby achieving proportional
do not create

so that the rate adjustments

K

K

(cid:1)

n

n

n

n

n

e

r

(

)

)

)

(

)

)

(

(

i

i

(24)

(25)

3.3 Deriving a Stability Condition on the Delay Feedback Loop

Our goal is to derive a stability condition
, so that we can ensure that the delay feedback loops enforce
proportional delay differentiation. To derive the stability condition, we ﬁrst model the effect of the rate
adjustment

on the delay

.

K

n

)

(

(cid:1)

(

)

(

)

r

n

D

n

i

i

We note that the relationship between delays and rates is non-linear. We thus have two possible strategies
for deriving a stability condition on the delay feedback loop of class
[30]. We can either derive a stability
condition on the non-linear system, or deﬁne the operating point of the system as a triplet
,
linearize the non-linear system of study around the operating point, and derive a stability condition on the
linearized model. In an effort to get a simple stability condition, we choose the second approach, hence we
will linearize the relationships between delays and rates around the operating point, so that we can apply
tools provided by linear control theory. This linearization technique has been ﬁrst described by Lyapunov in
[23], which “serves as the fundamental justiﬁcation of using linear control techniques in practice” [30].

; D

; r

B

(cid:0)

(cid:1)

i

i

i

i

We start our modeling of the relationship between rate and delays, by ﬁrst deﬁning

as:

(cid:28)

n

(

)

i

D

n

t

n

t

n

(cid:28)

n

:

(

) =

(

) (cid:0)

(

(cid:0)

(

))

i

i

8

c
i
f
f
a
r
T

 
i
- 
s
s
a
C

l

Rin
i

slope =

Di(n)
ri(n)

Rout

i

t(n- t

i)

t(n)

time

Figure 3: Deﬁnition of the average rate,

. This ﬁgure shows the relationship between

,

and

r

n

(

)

i

D

n

(cid:28)

(

)

i

i

.

r

n

(

)

i

i

)

(

(cid:28)

n

In other words,
of events. Let us make a ﬁrst assumption,
Assumption (A1). The delay of class-
can write

i

denotes the delay of class-

trafﬁc departing at the

-th event, expressed as a number

i

n

trafﬁc does not vary signiﬁcantly between events

and

. We

n

n

(

+ 1)

which implies

D

n

D

n

;

(

+ 1) (cid:25)

(

)

i

i

We will, from now on, refer to

and

as

.

(cid:28)

n

(cid:28)

n

(cid:28)

(

)

(

+ 1)

i

i

i

(cid:28)

n

(cid:28)

n

:

(

) (cid:25)

(

+ 1)

i

i

Let us deﬁne

as the average rate experienced by the class-

trafﬁc departing at the

-th event over

i

n

r

n

(

)

i

the time this class-

i

trafﬁc was backlogged. Using Assumption (A1), we have

B

n

(cid:28)

(

(cid:0)

)

i

i

r

n

;

(

) =

i

D

n

(

)

i

which we illustrate in Figure 3. To model the effects of a rate adjustment
ﬁrst express the relationship between
Assumption (A2). The backlog of class-

on

(cid:1)

n

n

r

r

(

(

)

)

i

i

i

. For this, we make a second assumption,

trafﬁc does not vary signiﬁcantly between events

(

(cid:0)

)

n

(cid:28)

i

and

on the delay, we can thus

(cid:1)

(

)

r

n

i

(

+ 1 (cid:0)

)

n

(cid:28)

i

. Then we can write

With Assumptions (A1) and (A2), on the virtual time axis described in the remark at the end of Subsec-

B

n

(cid:28)

B

n

(cid:28)

;

(

+ 1 (cid:0)

) (cid:25)

(

(cid:0)

)

i

i

i

i

tion 3.1, where events are equally spaced, we get

r

n

:

(

+ 1) =

i

(

(cid:0) 1)

(

) +

(

)

(cid:28)

r

n

r

n

i

i

i

(cid:28)

i

We just characterized the relationship between the service rate at event
experienced by class-

trafﬁc departing at event

. Let us now deﬁne

n

i

(

+ 1)

n

and the average rate that will be

(29)

(31)

(32)

(cid:1)

(

+ 1) =

(

+ 1) (cid:0)

(

)

r

n

r

n

r

n

:

i

i

i

9

Combining Eqs. (31) and (32), we get

(cid:1)

(

+ 1) =

r

n

i

:

(

(cid:0) 1)(cid:1)

(

) + (cid:1)

(

)

(cid:28)

r

n

r

n

i

i

i

(cid:28)

i

(33)

Eqn. (33) characterizes the relationship between a change in the service rate and a change in the average
rate.

We now characterize the relationship between

and a change in the delay of class

, denoted as

i

(cid:1)

(

)

r

n

i

(cid:1)

(

)

D

n

i

, and deﬁned by

Since we have

and

we get

(cid:1)

(

+ 1) =

(

+ 1) (cid:0)

(

)

D

n

D

n

D

n

:

i

i

i

B

n

(cid:28)

(

(cid:0)

)

i

i

D

n

;

(

) =

i

r

n

(

)

i

D

n

;

(

+ 1) =

i

B

n

(cid:28)

(

+ 1 (cid:0)

)

i

i

r

n

(

+ 1)

i

(cid:1)

(

+ 1) =

(cid:0)

D

n

:

i

B

n

(cid:28)

B

n

(cid:28)

(

+ 1 (cid:0)

)

(

(cid:0)

)

i

i

i

i

r

n

r

n

(

+ 1)

(

)

i

i

We introduce here a third assumption:
Assumption (A3). The variations in the average rate are small compared to the average rate. In other words,

We now linearize Eqn. (37), using Assumptions (A1), (A2), and (A3), and obtain

(cid:1)

(

+ 1) (cid:28)

(

)

r

n

r

n

:

i

i

(cid:1)

(

+ 1) = (cid:0)

(cid:1)

(

+ 1) +

(

)

D

n

r

n

!

n

;

i

i

i

B

n

(cid:28)

(

(cid:0)

)

i

i

2

r

n

(

)

i

where
delay variations and the delay is given by

!

n

(

)

i

is an error resulting from Assumptions (A1), (A2) and (A3). Then, the relationship between

D

n

D

k

;

(

+ 1) =

(cid:1)

(

)

i

i

n

+1

k

=0

X

D

n

D

n

(

+ 1)

(

+ 1)

i

e

n

(

+ 1)

i

is used to compute

(cid:3)

i

, using Eqn. (18) which characterizes the new deviation

at the next sampling time (i.e., the next time a rate adjustment is performed). This remark completes the
description of a linearized model of the delay feedback loop. We can now turn to the derivation of a stability
condition for our linearized model.

ing

The derivation of the stability condition on the linearized model relies on a modeling of the loop us-
by
-transforms in Figure 4. Eqs. (18), (22), (24), (39)

-transforms of the equations we presented above. We denote the

. We represent the delay feedback loop using

-transform of a function

n

f

z

z

)

(

z

Z

f

n

[

(

)]

are unchanged when using

-transforms. Eqn. (33) yields

z

(37)

(38)

(39)

(40)

Z

r

n

(cid:28)

;

[(cid:1)

(

+ 1)] = (

(cid:0) 1) (cid:1)

+

i

i

Z

r

n

Z

r

n

[(cid:1)

(

)]

[(cid:1)

(

)]

i

i

(cid:28)

(cid:28)

i

i

10

Z[D*(n)]

Z[e i (n)]

+

-

Z[D ri(n)]

K(n)

z
i-t

zt

i+1

Z[D ri(n+1)]

-Bi(n-t

i)

+

+

Z[D Di(n+1)]

z
z-1

Z[Di(n+1)]

Z[Di

*(n+1)]

j=i m j

Z[w

 i(n)]

2(n)
ri

Z[Di

*(n)]

1
z

Figure 4: The class-
Section 3.2.

delay feedback loop. This model uses

-transforms of the relationships derived in

i

z

which gives, using the property that for any continuous function

,

f

Z

f

n

Z

f

n

[

(

)] =

[

(

+ 1)]

1

z

,

Z

r

n

(cid:28)

;

[(cid:1)

(

+ 1)] = (

(cid:0) 1) (cid:1)

+

i

i

Z

r

n

Z

r

n

[(cid:1)

(

+ 1)]

[(cid:1)

(

)]

i

i

z(cid:28)

i

(cid:28)

i

and by simple reordering of the terms, we obtain,

which is equivalent to

Z

r

n

;

[(cid:1)

(

+ 1)]

1 (cid:0)

=

i

(cid:28)

Z

r

n

(cid:0) 1

[(cid:1)

(

)]

i

i

z(cid:28)

(cid:28)

i

i

(cid:18)

(cid:19)

Z

r

n

Z

r

n

:

[(cid:1)

(

+ 1)] =

[(cid:1)

(

)]

i

i

z

z(cid:28)

(cid:28)

(cid:0)

+ 1

i

i

Similarly, using

-transforms, Eqn (40) becomes

z

Also, the relationship between the weighted delay at the

-th and

-th iterations is given by

(

+ 1)

n

n

Z

D

n

Z

D

n

:

[

(

+ 1)] =

[(cid:1)

(

+ 1)]

i

i

z

z

(cid:0) 1

(cid:3)

(cid:3)

Z

D

n

Z

D

n

:

[

(

)] =

[

(

+ 1)]

i

i

1

z

We ﬁrst notice that in our model, some quantities (e.g.,
) are time-dependent. This does not cause
stability problems if the product of all individual blocks in Figure 4 (called the ‘loop gain’), is non-increasing
over time. Since the coefﬁcient
so that the loop gain
is non-increasing over time.

is time-dependent, we will have to select

,

,

K

K

B

n

n

r

(cid:28)

)

)

(

(

i

i

i

Denoting the loop gain by

, a necessary and sufﬁcient condition for the loop to be stable is that the

G

z

(

)

roots of the so-called characteristic equation

have a module less than one [13]. Taking the products of all blocks in Figure 4, we get

1 +

(

) = 0

G

z

;

1

z

z

j 6

i

=

m

B

n

(cid:28)

K

n

(

(cid:0)

)

(

)

j

i

i

G

z

(

) = (cid:0)

:

z

z

(cid:0) 1

r

n

(

)

i

z(cid:28)

(cid:28)

(cid:0)

+ 1

i

i

(cid:16)

(cid:17)

2

Q

11

S
S
P
is too compli-
The negative sign comes from the negative feedback
cated to yield a stability condition usable in a high-speed computation. We thus approximate the gain of the
second block,

. This approximation is motivated by the fact that we have

. The expression obtained for

by

G

(cid:0)

z

)

(

1

z

z

z(cid:28)

(cid:0)(cid:28)

i

i

+1

1

After this approximation, we get a new loop gain,

0

G

z

(

)

such that

(cid:1)

(

+ 1) (cid:20) (cid:1)

(

)

r

n

r

n

:

i

i

0

1

z

j 6

i

=

m

B

n

(cid:28)

K

n

(

(cid:0)

)

(

)

j

i

i

G

z

(

) = (cid:0)

;

z

z

(cid:0) 1

r

n

(

)

i

(cid:16)

(cid:17)

Q

2

The characteristic equation on the approximate system is

1

j 6

i

=

m

B

n

(cid:28)

K

n

(

(cid:0)

)

(

)

j

i

i

1 (cid:0)

= 0

;

z

(cid:0) 1

r

n

(

)

i

(cid:16)

(cid:17)

Q

2

which has exactly one root,

We then obtain the following stability condition

j 6

i

=

m

B

n

(cid:28)

K

n

(

(cid:0)

)

(

)

j

i

i

z

= 1 +

:

(cid:16)

(cid:17)

Q

2

r

n

(

)

i

or, equivalently,

j 6

i

=

m

B

n

(cid:28)

K

n

(

(cid:0)

)

(

)

j

i

i

1 +

(cid:20) 1

;

(cid:12)

(cid:12)

(cid:16)

(cid:17)

Q

2

r

n

(

)

i

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

j 6

i

=

m

B

n

(cid:28)

K

n

(

(cid:0)

)

(

)

j

i

i

(cid:0)1 (cid:20) 1 +

(cid:20) 1

:

(cid:16)

(cid:17)

Q

2

r

n

(

)

i

All quantities in Eqn. (54), with the exception of
scribed by Eqn. (54) simply reduces to

K

n

(

) (cid:20) 0

, are positive. Hence, the rightmost condition de-

K

n

(

)

. The leftmost condition in Eqn. (54) becomes

K

n

:

(

) (cid:21) (cid:0)2 (cid:1)

2

r

n

(

)

i

j 6

i

=

m

B

n

(cid:28)

(

(cid:0)

)

j

i

i

Since, from Eqn. (29), we have

(cid:16)

(cid:17)

Q

Eqn (55) becomes

The condition given by Eqn. (56) requires to keep a history of the backlogs, which may be difﬁcult to im-
plement at high speeds. To alleviate this problem, we replace Assumption (A2) by the stronger assumption:

Q

(cid:16)

(cid:17)

B

n(cid:0)(cid:28)

i

i

(

)

2

2

2

r

n

(

)

i

D

n

i

(

)

=

B

n

(cid:28)

B

n

(cid:28)

(

(cid:0)

)

(

(cid:0)

)

i

i

i

i

B

n

(cid:28)

(

(cid:0)

)

i

i

=

;

D

n

(

)

i

2

K

n

:

(

) (cid:21) (cid:0)2 (cid:1)

B

n

(cid:28)

(

(cid:0)

)

i

i

j 6

i

i

=

m

D

n

(

)

j

2

12

(54)

(55)

(56)

Assumption (A2’). The backlog of class-
We can write

i

trafﬁc does not vary signiﬁcantly between events

(

(cid:0)

)

n

(cid:28)

n

i

and

.

which allows us to get a simpliﬁed expression for the stability condition for the class-

delay feedback loop:

i

B

n

(cid:28)

B

n

;

(

(cid:0)

) (cid:25)

(

)

i

i

i

(cid:0)2 (cid:1)

(cid:20)

(

) (cid:20) 0

K

n

:

B

n

(

)

i

j 6

i

i

=

m

D

n

(cid:1)

(

)

j

2

Since

K

n

(

)

must be common to all classes for Eqn. (25) to hold, we ﬁnally get

Q

(cid:0)2 (cid:1) min

(cid:20)

(

) (cid:20) 0

K

n

:

B

n

(

)

i

i

m

D

n

(cid:1)

(

)

j

(

)

j 6

i

i

=

2

(59)

The condition (59) ensures that the delay feedback loops will not engage in divergent oscillations, provided
that:

Q

Assumptions (A1), (A2’), and (A3) hold,

(cid:15)

(cid:15)

(cid:15)

The approximation that the gain of the second block in Figure 4 is less than one (or equal to one)
holds, and

The clock skew between the virtual-time axis (where events are equally spaced) and the real-time axis
(where events are not equally spaced) can be neglected.

However, in practice, we cannot be certain of the validity of these assumptions. Thus, while we cannot
make any claim as to the stability of the delay feedback loops resulting from the analysis presented here, the
numerical data in Section 6 suggests that the loops converge adequately well.

3.4 Including the Absolute Delay and Rate Constraints.

)

(

n

K

We have obtained a stability condition on
, which is necessary to enforce proportional differentiation.
However, so far, we have not considered the absolute delay and rate constraints in the construction of the
delay feedback loops. These absolute delay and rate constraints can be viewed as a “saturation constraint”
on the rate adjustment, and yield a second bound on
, we
may need to clip
when the new rate is below the minimum. This, however, may violate the work-
conserving property resulting from Eqn. (25). Hence, we use the following to compute
that would
satisfy the saturation constraint

. To satisfy the constraints

i;min

) (cid:21)

K

K

(cid:1)

n

n

n

n

n

r

r

r

)

)

(

(

)

(

(

)

(

i

i

and apply that

to all control loops. The above implies that we must have

K

n

(

)

r

n

K

n

e

n

r

n

;

(

(cid:0) 1) +

(

)

(

) (cid:21)

(

)

i

i

i;min

If

K

n

:

(

) (cid:21) max

r

n

r

n

(

) (cid:0)

(

(cid:0) 1)

i;min

i

i

e

n

(

)

i

(cid:18)

(cid:19)

(61)

r

n

r

n

(

) (cid:0)

(

(cid:0) 1)

i;min

i

max

>

;

0

i

e

n

(

)

i

(cid:18)

(cid:19)

13

(

)

0

n

<

K

. In other words, we cannot satisfy absolute delay and rate guarantees
we see that we cannot have
and proportional delay differentiation at the same time. In such a case, we relax either Eqn. (59) or (61)
according to the given precedence order on the service guarantees.
Remark: If proportional delay differentiation is requested for some, but not for all classes, constraints as in
Eqn. (17) can be deﬁned for each group of classes with contiguous indices. Then, the feedback loops are
constructed independently for each group.

4 The Loss Feedback Loop

We now describe the feedback loop which controls the trafﬁc dropped from a class
to satisfy proportional
loss differentiation within the limits imposed by the absolute loss guarantees. As before, we assume that all
classes have proportional loss guarantees. The assumption is relaxed similarly as described in the remark at
the end of Section 3.

i

Trafﬁc must be dropped at the

n

cannot be satisﬁed given the current backlog. To prevent buffer overﬂows at the
condition must hold:

-th event either if there is a buffer overﬂow or if absolute delay guarantees
-th event, the following

n

B

B

n

a

n

l

n

t

n

C :

(cid:21)

(

(cid:0) 1) +

(

) (cid:0)

(

)

(cid:0) (cid:1)

(

(cid:0) 1)

k

k

k

N

k

=1

X

To provide absolute delay and rate guarantees, the following condition must be satisﬁed

(cid:0)

(cid:1)

B

n

r

n

t

n

a

n

l

n

(

(cid:0) 1) (cid:0)

(

(cid:0) 1)(cid:1)

(

(cid:0) 1) +

(

) (cid:0)

(

)

k

k

k

k

C

(cid:21)

max

; (cid:22)

(cid:31)

:

k

(cid:1)

B

n

>

(

)

0

k

(cid:26)

(cid:27)

d

D

n

(cid:0)

(

)

k

k

N

k

=1

X

To choose the amount of trafﬁc to drop from each class so that Eqs. (63) and (64) hold, we deﬁne the

weighted loss rate to be

N

(cid:3)

0

p

n

m

p

n

;

(

) =

(

)

i

i

j

0

1

j

; j 6

i

=1

=

Y

where

0

0

0

i(cid:0)

1

for

and

. With this deﬁnition, Eqn. (10) is equivalent to

A

@

m

k

i >

m

=

1

= 1

i

j

j

=1

1

Q

(cid:3)

(cid:3)

8(

)

8

:

(

) =

(

)

i; j

;

n

p

n

p

n

:

i

j

We choose the following set point for the loss feedback loop

(63)

(64)

and we use the set point to describe an error

To reach the set point, the error is decreased by increasing
Let

h

i

; i

; : : : ; i

R

i

1

2

be an ordering of the class indices from all backlogged classes, that is,

(cid:3)

0

for classes that have

p

n

(

)

e

n

>

(

)

0

i

i

as follows.
for

B

n

>

(

)

0

i

k

1 (cid:20)

(cid:20)

(

) (cid:21)

(

)

h

k

R

e

n

e

n

i

< i

i

; i

; : : : ; i

1

2

R

i

i

s

i

r

s

r

, such that

0

0

if

. Trafﬁc is dropped in the order of

.

(cid:3)

(cid:3)

p

n

p

n

;

(cid:22)

(

) =

(

)

i

1

N

i

X

0

(cid:3)

(cid:3)

e

n

p

n

p

n

:

(

) = (cid:22)

(

) (cid:0)

(

)

i

i

14

Absolute loss guarantees impose an upper bound,

, on the trafﬁc that can be dropped at event

l

n

(

)

n

(cid:3)

i

from class

. The value of

i

l

n

(

)

is determined from Eqs. (7) and (16) as

(cid:3)

i

(cid:3)

i

l

n

A

n

L

p

n

A

n

:

(

) =

(

)

(cid:0)

(

(cid:0) 1)

(

(cid:0) 1)

i

i

i

i

If the conditions in Eqs. (63) and (64) are violated, trafﬁc is dropped from class

until the conditions
has been dropped. Then trafﬁc is dropped from

1

i

, and so forth. Suppose that the conditions in Eqs. (63) and (64) are satisﬁed for the ﬁrst time if

are satisﬁed, or until the maximum amount of trafﬁc
class
trafﬁc is dropped from classes
we obtain:

; : : : ; i

k(cid:0)

=

; i

j

2

1

1

^

2

i

i

, and

(cid:3)

1

i

l

n

(

)

x

n

l

n

^

(

) (cid:20)

(

)

(cid:3)

^

k

trafﬁc is dropped from class

(cid:3)

j

l

n

(

)

, then

i

^

k

(70)

l

n

; i

; : : : ; i

;

(

)

2

^

k(cid:0)

1

l

n

i

(

) =

x

n

;

^

(

)

(cid:3)

i

8

>

<

0

i

i

1

=

if
if
otherwise

=

k

^

i

i

:

l

If
other words, condition (64) is relaxed.

for all

) =

=

; i

n

n

k

k

k

(

(cid:3)

1

)

2

(

i

l

; : : : ; i

>

R

:

, we allow absolute delay and rate conditions to be violated. In

The loss feedback loop never increases the maximum error

and more than one class
is backlogged. Thus, the errors remain bounded and the algorithm presented will not engage in divergent
oscillations around the target value
. Additionally, the loss feedback loop and the delay feedback loops
are independent of each other, since we always drop trafﬁc from the tail of each per-class buffer, losses do
not have any effect on the delays of trafﬁc admitted into the transmission queue.

, if

>

n

n

n

p

0

e

e

(cid:3)

)

(

)

)

(

(

i

i

0

0

5 Implementation

We implemented the algorithms presented in Sections 3 and 4 on PC-routers running the FreeBSD v4.3 [1]
operating system, using the ALTQ v3.0 package [8]. ALTQ allows programmers to modify the operations of
the transmission queue in the IP layer of the FreeBSD kernel. We will discuss the operations performed in
our implementation when a packet is entered into the transmission queue of an IP router (packet enqueuing)
and when a packet is selected for transmission (packet dequeuing).

We use the DSCP ﬁeld in the header of a packet to identify the class index of an IP packet. The DSCP

ﬁeld is set by the edge router; in our testbed implementation, this is the ﬁrst router traversed by a packet.

In our implementation, we chose the following precedence order for relaxing constraints. Absolute
loss guarantees have higher precedence than absolute delay and rate guarantees, which have in turn higher
precedence than proportional guarantees.

5.1 Packet Enqueuing

The enqueue procedure are the operations executed in the IP layer when a packet is entered into the
transmission queue of an output link. Since the FreeBSD kernel is single-threaded, the execution of the
enqueue procedure is strictly sequential.

The enqueue procedure performs the dropping decisions and the service rate allocation. We avoid
ﬂoating point operations in the kernel of the operating system, by expressing delays as machine clock cycles,
service rates as bytes per clock cycle (multiplied by a scaling factor of
32) , and loss rates as fractions of
32. Then, 64-bit (unsigned) integers provide a sufﬁcient degree of accuracy.

2

2

15

In our modiﬁed enqueue procedure, the transmission queue of an output link has one FIFO queue
for each class, implemented as a linked list. We limit the total number of packets that can be queued to
. Whenever a packet is entered into the FIFO queue of its class, the arrival time of the packet is

B

= 200

recorded, and the waiting times of the packets at the head of each FIFO queue are updated.

The enqueue procedure uses the loss feedback loop described in Section 4 to determine if and how
much trafﬁc needs to be dropped from each class. In our implementation, the algorithm of Section 4 is run
twice. The ﬁrst time, buffer overﬂows are resolved by ignoring condition (64); The second time, violations
of absolute delay and rate guarantees are resolved by ignoring condition (63).

Next, the enqueue procedure computes new values for

service rates, using Eqs. (15) and (24), with the constraints on
feasible value for
proportional delay guarantees.

from Eqn. (12), and determines new
given in Eqs. (59) and (61). If no
exists, Eqn. (59) is ignored, thus, giving absolute delay guarantees precedence over

i;min

K

K

n

n

n

r

(

(

)

(

)

)

5.2 Packet Dequeuing

The dequeue procedure selects one packet from the backlog for transmission.
In our implementation,
dequeue selects one of the trafﬁc classes, and picks the packet at the head of the FIFO queue for this class.

The dequeue procedure uses a rate-based scheduling algorithm to adapt the transmission rates

r

n

(

)

i

from a ﬂuid-ﬂow view to a packet-level environment. Such an adaptation can be performed using well-
known rate-based scheduling algorithm techniques, e.g., as VirtualClock [32] or PGPS [27]. These schedul-
ing algorithms translate a rate allocation, into ‘virtual’ deadlines of individual packets. In our implementa-
tion, we use a modiﬁed Deﬁcit Round Robin (DRR, [29]) scheduling algorithm. Let
denote the
number of bytes of class-
trafﬁc that have been transmitted in the current busy period, the scheduler selects
a packet from class

for transmission if

Xmit

n

)

(

i

i

i

i

R

n

Xmit

n

:

= arg max

(

) (cid:0)

(

)

k

k

out

k

In other words, the dequeue procedure selects the class which is the most behind its theoretical output
curve.

(cid:9)

(cid:8)

6 Evaluation

We present experimental measurements of our implementation of the Quantitative Assured Forwarding ser-
vice on a testbed of PC routers. The PCs are Dell PowerEdge 1550 with 1 GHz Intel Pentium-III processors
and 256 MB of RAM. The system software is FreeBSD 4.3 and ALTQ 3.0. Each system is equipped with
ﬁve 100 Mbps-Ethernet interfaces.

In our experiments we determine if and how well our algorithm provides the desired service differen-
tiation on a per-node basis. In addition, we want to observe the stability of the feedback loops, and their
robustness to changes in the network topology and in the service guarantees. To that effect we propose four
experiments, with different network topologies, service guarantees, and trafﬁc patterns. We then present an
evaluation of the overhead associated to our proposed algorithm.

16

Figure 5: Experiments 1 and 2: Network Topology. All links have a capacity of 100 Mbps. We measure
the service provided by Router 1 at the indicated bottleneck link.

Source

1

Source

2

Sink 1

Router

1

Router

2

Bottleneck

Sink 2

Class

Service Guarantees

d

L

(cid:22)

k

k

i

i

i

i

1
2
3
4

3 ms

0.1 %

–
–
–

–
–
–

35 Mbps

–

–
–

–
2
2

0

i

–
2
2

N/A N/A

Table 1: Experiments 1 and 2: Service guarantees. The guarantees are identical at each router.

6.1 Experiment 1: Single-node topology, near-constant load

We use a local network topology using point-to-point Ethernet links as shown in Figure 5. All links are
full-duplex and have a capacity of
Mbps. Two PCs are set up as routers, indicated in Figure 5 as
Router 1 and 2. Other PCs are acting as sources and sinks of trafﬁc. The topology has a bottleneck, which
is the link between Routers 1 and 2. As mentioned earlier, the buffer size at the output link of each router is
set to

packets.

= 100

C

B

= 200

We consider four trafﬁc classes with service guarantees as summarized in Table 1. Sources 1 and 2 send
trafﬁc to Sinks 1 and 2, respectively. Source 1 transmits trafﬁc from classes 1 and 2, Source 2 transmits
trafﬁc from classes 3 and 4. The trafﬁc mix, the number of ﬂows per class, and the characterization of the

Source Class No. of
ﬂows

Type

Protocol

1

2

1
2
3
4

6
10
10
10

UDP
TCP
TCP
TCP

Trafﬁc
On-off
Greedy
Greedy
Greedy

17

Table 2: Experiment 1: Trafﬁc mix. The on-off UDP source sends bursts of 25 packets during an on-
period, and have a 150 ms off-period. All TCP sources are greedy, i.e., they always have data to transmit,
and run the NewReno congestion control algorithm [12].

140

120

100

80

60

40

20

y
t
i
c
a
p
a
c
 
k
n
i
l
 
f
o
%
n
i
 
d
a
o
l
 

 

 

d
e
r
e
f
f

O

0

0

10

20

30

Time (s)

40

50

60

Figure 6: Experiment 1: Offered Load. The graph shows the offered load at Router 1.

ﬂows for each source is as shown in Table 2. Class 1 trafﬁc consists of on-off UDP ﬂows, and the other
classes consist of greedy TCP ﬂows. All sources start transmitting packets with a ﬁxed size of 1024 Bytes at
time
seconds. Trafﬁc is generated using the netperf v2.1pl3
tool [3]. The network load is initially zero and quickly ramps up to generate an overload at the bottleneck
link of Figure 5. Congestion control at the TCP sources then maintains the total load at a level of about 99%
of the link capacity, as shown in Figure 6.

until the end of the experiments at

= 60

= 0

t

t

We measure the delay, the loss rate, and the throughput of each trafﬁc class at the output link of Router 1,
which is the bottleneck link. Delays are measured as the waiting time of a packet in the transmission
queue, i.e., as the difference of the times read of the machine clock when the packet enters and departs the
transmission queue. Throughput and loss rates are obtained from reports generated every 0.5 sec by the
OS kernel. In the plots, which summarize our measurements, we depict delay measurements of individual
packets. Measurement of delay ratios, loss rates, ratios of loss rates and throughput are shown as averages
over a sliding window of size 0.5 sec.

In Figure 7, we present our measurements of the service received at the bottleneck link. Fig. 7(a) depicts
the ratios of the delays of Classes 4 and 3, and the delays of Classes 3 and 2. The plots show that the target
value of
(from Table 1) is achieved. The plots indicate that the delay feedback loops appear to
be stable, despite the simpliﬁed model we used for determining

in Section 3.

= 2

=

k

k

2

3

K

n

(

)

<

1%

In Fig. 7(b) we show the delay of Class-1 packets at Router 1. The delay bound of

ms is satisﬁed,
with few (
) exceptions at times when it is not possible to satisfy simultaneously absolute loss and delay
guarantees; as discussed in Section 5, such a conﬂict is resolved by giving precedence to the loss guarantee.
Note that even if delay bounds are violated, no class-1 packet experiences a delay which exceeds 4 ms.
Delay values, averaged over sliding windows of size 0.5 s, of other classes are shown in Fig. 7(c) and are in
the range 10-40 ms.

= 3

d

1

In Figs. 7(d) and (e), we show the measurements of the loss rates. Fig. 7(d) depicts the ratios of loss
rates for Classes 4 and 3, and for Classes 3 and 2. The desired ratios of
are maintained most
of the time. As Fig. 7(e) indicates, the bound on the loss rates for Class 1 of
% is always kept
(Recall that we give highest precedence to absolute loss guarantees.) We also note that the maximum loss
rate of classes 2–4 is below 1% over the entire experiment. Since all TCP sources start transmitting at the
same time, i.e., the TCP ﬂows are synchronized, we observe a transient effect shortly after the beginning of
the experiment, at time 0.5 s. We believe that this transient effect is due to the slow-start mechanism in TCP,

= 0

= 2

=

L

k

k

1

1

2

3

:

0

0

18

Class 3/Class 2
Class 4/Class 3

0

10

20

30
Time (s)
(a) Ratios of Delays.

40

50

60

0

10

20

40

50

60

30

Time (s)

(b) Class-1 Delays (individual).

Delay Bound

Class 1

Class 3/Class 2
Class 4/Class 3

Class 4

Class 3

Class 2
40

50

60

10

20

30

Time (s)

(c) Classes 2, 3 and 4 Delays

(averaged over a sliding window of 0.5 s)

Class 1
Class 2
Class 3
Class 4

0

10

20

50

60

30
Time (s)

40

(d) Ratios of Loss Rates.

Total

Class−2 Guarantee

Class 4

Class 3

Class 2

Class 1

s
y
a
l
e
D

 
f
o

 

o
i
t
a
R

5

4

3

2

1

0

50

40

30

20

10

)
s

m

(
 

y
a
l
e
D

0

0

)

%

(
 
e
t
a
R
 
s
s
o
L

1

0.8

0.6

0.4

0.2

0
0

10

20

30

40

50

60

10

20

30

40

50

60

Time (s)
(e) Loss Rates.

Time (s)
(f) Throughput.

Figure 7: Experiment 1. The graphs show the service obtained by each class at the output link of Router 1.

14

12

10

8

6

4

2

0

5

4

3

2

1

0

)
s
m

(
 
y
a
l
e
D

s
e
t
a
R
 
s
s
o
L
 
f
o
o
i
t
a
R

 

100

)
s
/
b
M

(
 
t
u
p
h
g
u
o
r
h
T

80

60

40

20

0
0

19

140

120

100

80

60

40

20

y
t
i
c
a
p
a
c
 
k
n
i
l
 
f
o
%
n
i
 
d
a
o
l
 

 

 

d
e
r
e
f
f

O

0

0

10

20

30

Time (s)

40

50

60

Figure 8: Experiment 2: Offered Load. The graph shows the offered load at Router 1.

Source Class No. of
ﬂows

Protocol

Type

1

2

1
2
3
4

6
10
10
10

UDP
TCP
TCP
TCP

Trafﬁc
On-off

Greedy/On-off
Greedy/On-off
Greedy/On-off

Table 3: Experiment 2: Trafﬁc mix. The on-off UDP source sends bursts of 25 packets during an on-
period, and have a 150 ms off-period. TCP sources are greedy during time intervals
, and
, and transmit chunks of 8 KBytes with a pause of 175 ms between each transmission during time

,

[20

30

10

[0

s;

s;

s

s

]

]

[40

50

]

s;

s

intervals

[10

20

]

[30

40

]

[50

60

]

;

s

;

s

s;

s

,

, and

. TCP sources run the NewReno congestion control algorithm.

which increases the sending rate of each source exponentially at the beginning of a sending period. With a
network initially empty, all TCP ﬂows suffer their ﬁrst packet drops for at the same time.

Finally, in Fig. 7(f) we include the throughput measurements of all classes. We observe that the rate
Mbps is maintained. The total throughput of all classes, labeled in

guarantee for Class 2 of
Fig. 7(f) as ‘Total’, is close to the link capacity of 100 Mbps at each router.

= 35

(cid:22)

2

6.2 Experiment 2: Single-node topology, highly variable load

The second experiment uses the same network topology, buffer size at routers, and service guarantees as in
Experiment 1. Thus, Table 1 and Figure 5 apply to Experiment 2. The difference between Experiments 1
and 2 consists in the trafﬁc generation of TCP ﬂows. Instead of using greedy TCP sources over the whole
experiment, we conﬁgured the TCP sources to be greedy during time intervals
and
. In the remaining time intervals, the TCP sources send chunks of 8KB of data and pause for
175 ms between the transmission of each chunk. We summarize the trafﬁc mix for Experiment 2 in Table 3.
This modiﬁcation to the behavior of the TCP sources results in an highly variable offered load at Router 1,
which we present in Figure 8.

,

[40

[20

50

10

30

[0

s;

s;

s;

s

s

s

]

]

]

Similar to Experiment 1, we measure the delay, the loss rate, and the throughput of each trafﬁc class at

the bottleneck link and present our results on Figure 9.

In Fig. 9(a), we present the ratios of the delays of Classes 4 and 3, and the delays of Classes 3 and 2.

20

s
y
a
l
e
D

 
f
o

 

o
i
t
a
R

5

4

3

2

1

0

50

40

30

20

10

)
s

m

(
 

y
a
l
e
D

0

0

2.5

1.5

2

1

0.5

)

%

(
 
e
t
a
R
 
s
s
o
L

0
0

Class 3

Class 2

Class 1
Class 2
Class 3
Class 4

Class 3/Class 2
Class 4/Class 3

Delay Bound

Class 1

0

10

20

30
Time (s)
(a) Ratios of Delays.

40

Class 4

50

60

0

10

20

40

50

60

30

Time (s)

(b) Class-1 Delays (individual).

Class 3/Class 2
Class 4/Class 3

10

20

30

Time (s)

(c) Classes 2, 3 and 4 Delays

(averaged over a sliding window of 0.5 s)

40

50

60

0

10

20

50

60

30
Time (s)

40

(d) Ratios of Loss Rates.

Class−1 Guarantee

Class 2

Class 3

Class 4

Total

Class 1

10

20

30

40

50

60

Time (s)
(e) Loss Rates.

0
0

10

20

30

Time (s)
(f) Throughput.

40

50

60

Figure 9: Experiment 2. The graphs show the service obtained by each class at the output link of Router 1.

14

12

10

8

6

4

2

0

5

4

3

2

1

0

)
s
m

(
 
y
a
l
e
D

s
e
t
a
R
 
s
s
o
L
 
f
o
o
i
t
a
R

 

100

)
s
/
b
M

(
 
t
u
p
h
g
u
o
r
h
T

80

60

40

20

21

Class

Service Guarantees

d

L

(cid:22)

k

k

i

i

i

i

1
2
3
4

8 ms

1 %

–
–
–

–
–
–

35 Mbps

–

–
–

–
2
2

0

i

–
2
2

N/A N/A

Table 4: Experiments 3 and 4: Service guarantees. The guarantees are identical at each router.

]

]

]

3

2

s

s

s

k

k

s;

s;

s;

[0

=

10

50

30

[20

[40

= 2

,

, and

We observe that when the load is high, in time intervals
, the target
value of
is achieved. Conversely, when the load is low, we observe oscillations in the ratios of
delays. These oscillations do not characterize an unstable feedback loop, but come from the work-conserving
constraint. As can be seen in Figs. 9(b) and (c), the delays of all classes are close to zero: if a packet arrives
when the transmission queue is empty, it is forwarded immediately, regardless of the service guarantees.
Given that the delays of all classes are extremely low during periods of underload, the delay ratios do not
carry a lot of meaning during such periods. We also see that, at times
, when the
load increases abruptly over a short period of time, the delay differentiation is realized almost immediately,
which tends to show that the delay feedback loops are robust to rapid increases in the offered load. As
was the case with Experiment 1, Fig. 9(b) shows that the absolute delay guarantee of Class 1,
ms
is enforced with a few exceptions at times when it is not possible to satisfy simultaneously absolute loss
and delay guarantees. In Experiment 2, the delay bound violations occur for less than 0.15% of all Class-1
transmitted trafﬁc.

and

,

= 40

= 20

= 3

= 0

d

1

t

t

t

In Figs. 9(d) and (e), we plot the measurements of the loss rates. We see that, in periods of packet drops,
) are satisﬁed. Thus,

proportional loss guarantees (
the algorithm for loss differentiation exhibits robustness to changes in the offered load.

) and absolute loss guarantees (

= 2

= 0

1%

=

L

k

k

2

3

1

:

0

0

t

2

(cid:22)

= 35

= 10

We include the throughput measurements for all classes in Figure 9(f). The rate guarantee for Class 2
(
Mbps) is maintained whenever Class 2 is sending at more than 35 Mbps, but cannot be satisﬁed
during periods of underload. We also notice a quick increase in the transmission rate of Class 4 (and, to
a lesser extent, in the transmission rate of Class 3) at times
and, less noticeably, at
time
. We offer the following explanation for this increase. netperf uses a request-response type of
protocol at the application level [3]. When netperf generates on-off TCP trafﬁc over a time interval
, the
receiver estimates the total amount of data that it must receive by the end of the interval
. Due to the high
delays, and relatively low throughput, encountered by Classes 3 and 4 during times of overload, the receiver
is still waiting on some outstanding data at times
and does not notify the sender that
the transmission is over. At these times, there is almost no Class 1 and 2 trafﬁc in the routers anymore,
and thus, the outstanding data is transmitted in about two seconds. This explanation is consistent with the
netperf reports we observed, which indicated that the transmission of some Class 3 and 4 ﬂows lasted almost
12 seconds instead of the 10 seconds we speciﬁed.

and

and

= 50

= 30

= 50

= 30

T

T

t

t

t

t

6.3 Experiment 3: Multiple node topology, near-constant load

We consider now a multiple node topology. We use a local network topology using point-to-point Ethernet
links as shown in Figure 10. All links are full-duplex and have a capacity of
Mbps. Three PCs are

C

= 100

22

Figure 10: Experiments 3 and 4: Network Topology. All links have a capacity of 100 Mbps. We measure
the service provided by Router 1 and 2 at the indicated bottleneck links.

Source

2

Source

3

Source

1

Router

1

Router

2

Router

3

Sink 1

Bottleneck

Bottleneck

Sink 2

Sink 3

Class No. of
ﬂows

Type

Protocol

1
2
3
4

6
6
6
6

Trafﬁc
On-off
Greedy
Greedy
Greedy

UDP
TCP
TCP
TCP

Table 5: Experiment 3: Trafﬁc mix. The trafﬁc mix is identical for each source-sink pair. The on-off UDP
sources send bursts of 20 packets during an on-period, and have a 150 ms off-period. All TCP sources are
greedy, i.e., they always have data to transmit, and run the NewReno congestion control algorithm.

set up as routers, indicated in Figure 10 as Router 1, 2 and 3. Other PCs are acting as sources and sinks of
trafﬁc. The topology has two bottlenecks: the link between Routers 1 and 2, and the link between Routers 2
and 3. As mentioned earlier, the buffer size at the output link of each router is set to

packets.

B

= 200

We consider four trafﬁc classes with service guarantees as summarized in Table 4. The proportional
service guarantees are the same as in Experiments 1 and 2, but the absolute delay and loss guarantees are
different.

Sources 1, 2 and 3 send trafﬁc to Sinks 1, 2 and 3, respectively. Different from Experiments 1 and 2,
each source transmits trafﬁc from all four classes. The trafﬁc mix, the number of ﬂows per class, and the
characterization of the ﬂows, is identical for each source, and as shown in Table 5. Each source transmits
6 ﬂows from each of the classes. Class 1 trafﬁc consists of on-off UDP ﬂows, and the other classes consist
of greedy TCP ﬂows. All sources start transmitting packets with a ﬁxed size of 1024 Bytes at time
until the end of the experiments at
seconds. The network load is initially zero and quickly ramps up
to generate an overload at the bottleneck links of Figure 10. The offered load at both of Routers 1 and 2 is
shown in Figure 11.

= 60

= 0

t

t

In Figures 12 and 13, we present our measurements of the service received at the bottleneck links of
Routers 1 and 2, respectively. Figs. 12(a) and 13(a) depict the ratios of the delays of Classes 4 and 3, and
the delays of Classes 3 and 2. The plots show that the target value of
(from Table 4) is achieved. The
plots indicate that the delay feedback loops appear to be stable in the case of a multiple node topology. This
result, coupled to the result we obtained in Experiment 1, also suggests that the delay feedback loops are

= 2

k

23

140

120

100

80

60

40

20

y
t
i
c
a
p
a
c
 
k
n
i
l
 
f
o
%
n
i
 
d
a
o
l
 

 

 

d
e
r
e
f
f

O

0

0

140

120

100

80

60

40

20

y
t
i
c
a
p
a
c
 
k
n
i
l
 
f
o
%
n
i
 
d
a
o
l
 

 

 

d
e
r
e
f
f

O

0

0

10

20

30

Time (s)

(a) Router 1.

40

50

60

40

50

60

10

20

30

Time (s)

(b) Router 2.

Figure 11: Experiment 3: Offered Load. The graphs show the offered load at Routers 1 and 2.

robust to changes in the network topology.

1

d

= 8

ms is satisﬁed, with few (

In Figs. 12(b) and 13(b) we show the delay of Class-1 packets at Router 1 and Router 2. The delay bound
of
) exceptions, due, again, to the precedence order we chose for
our absolute guarantees. No class-1 packet ever experiences a delay higher than 10 ms at either Router 1 or
2. Figs. 12(c) and 13(c) indicate that delay values of other classes, averaged over sliding windows of size
0.5 s, are in the range 10-50 ms.

5%

<

1

:

0

0

2

3

k

k

L

=

= 2

In Figs. 12(c) and (d), and Figs. 13(c) and (d), we show the measurements of the loss rates. Figs. 12(c)
and 13(c) depict the ratios of loss rates for Classes 4 and 3, and for Classes 3 and 2. The desired ratios of
are maintained most of the time. As Figs. 12(d) and 13(d) indicate, the bound on the loss
rates for Class 1 of
% is always kept. We also see that, contrary to Experiments 1 and 2, the loss
rate of Class 1 may be higher than the loss rate of other classes. This is result can be explained by the
absence of proportional guarantees on Class 1, which excludes Class 1 from the ordering of Section 4. Our
implementation always drop ﬁrst from Class 1, until the loss bound
as been reached, before using the
ordering provided by proportional loss guarantees. Note that much less trafﬁc is dropped at Router 2. This
comes from the fact that Router 2 receives trafﬁc from Source 3 and Router 1, instead of receiving trafﬁc
from two sources. Therefore, half of the trafﬁc arriving at Router 2 has already been policed by Router 1.

= 1

L

1

1

Finally, in Figs. 12(e) and 13(e) we include the throughput measurements of all classes. We observe that
Mbps is maintained. The total throughput of all classes, labeled in

the rate guarantee for Class 2 of
Figs. 12(e) and 13(e) as ‘Total’, is close to the link capacity of 100 Mbps at each router.

= 35

(cid:22)

2

6.4 Experiment 4: Multiple node topology, highly variable load

For the sake of completeness, we run a fourth experiment, which uses the same network topology and service
guarantees as Experiment 3, described in Table 4 and Figure 10. The difference between Experiments 3 and
4 consists in the trafﬁc generation of TCP ﬂows. Instead of greedy TCP sources, we use TCP sources which
behave in the same manner as in Experiment 2, that is, which alternate between greedy transfers and on-
off transfers. We summarize the trafﬁc mix in Table 6 and obtain a variable load at each router, shown in
Figs. 14(a) and (b).

We present the results of Experiment 4 in Figures 15 and 16. The measurements obtained conﬁrm the
results we obtained in the previous experiments. In Fig. 15(f) and 16(f) we note the same apparent problem

24

Class 3/Class 2
Class 4/Class 3

Delay Bound

Class 1

0

10

20

30
Time (s)
(a) Ratios of Delays.

40

50

60

0

10

20

40

50

60

30

Time (s)

(b) Class-1 Delays (individual).

Class 3/Class 2
Class 4/Class 3

Class 3

Class 4

Class 2
50

60

10

20

30

Time (s)

40

(c) Classes 2, 3 and 4 Delays

(averaged over a sliding window of 0.5 s)

Class 1
Class 2
Class 3
Class 4

0

10

20

50

60

30
Time (s)

40

(d) Ratios of Loss Rates.

Class-2 Guarantee

Total

Class 2

Class 3

Class 1

Class 4

s
y
a
l
e
D

 
f
o

 

o
i
t
a
R

5

4

3

2

1

0

50

40

30

20

10

)
s

m

(
 

y
a
l
e
D

0

0

2.5

1.5

2

1

0.5

)

%

(
 
e
t
a
R
 
s
s
o
L

0
0

10

20

30

40

50

60

10

20

30

40

50

60

Time (s)
(e) Loss Rates.

Time (s)
(f) Throughput.

Figure 12: Experiment 3: Router 1. The graphs show the service obtained by each class at the output link
of Router 1.

14

12

10

8

6

4

2

0

5

4

3

2

1

0

)
s
m

(
 
y
a
l
e
D

s
e
t
a
R
 
s
s
o
L
 
f
o
o
i
t
a
R

 

100

)
s
/
b
M

(
 
t
u
p
h
g
u
o
r
h
T

80

60

40

20

0
0

25

Class 3/Class 2
Class 4/Class 3

Delay Bound

Class 1

s
y
a
l
e
D

 
f
o

 

o
i
t
a
R

5

4

3

2

1

0

50

40

30

20

10

)
s

m

(
 

y
a
l
e
D

0

0

2.5

1.5

2

1

0.5

)

%

(
 
e
t
a
R
 
s
s
o
L

0
0

Class 1
Class 2
Class 3
Class 4

0

10

20

30
Time (s)
(a) Ratios of Delays.

40

50

60

0

10

20

40

50

60

30

Time (s)

(b) Class-1 Delays (individual).

Class 3/Class 2
Class 4/Class 3

Class 3

Class 4

Class 2

10

20

30

Time (s)

(c) Classes 2, 3 and 4 Delays

(averaged over a sliding window of 0.5 s)

40

50

60

0

10

20

50

60

30
Time (s)

40

(d) Ratios of Loss Rates.

Class-2 Guarantee

Total

Class 2

Class 3

Class 4

10

20

30

40

50

60

Time (s)
(e) Loss Rates.

Class 1
40

30

10

20

Time (s)
(f) Throughput.

50

60

Figure 13: Experiment 3: Router 2. The graphs show the service obtained by each class at the output link
of Router 2.

14

12

10

8

6

4

2

0

5

4

3

2

1

0

)
s
m

(
 
y
a
l
e
D

s
e
t
a
R
 
s
s
o
L
 
f
o
o
i
t
a
R

 

100

)
s
/
b
M

(
 
t
u
p
h
g
u
o
r
h
T

80

60

40

20

0
0

26

Class No. of
ﬂows

Protocol

Type

1
2
3
4

6
6
6
6

Trafﬁc
On-off

Greedy/On-off
Greedy/On-off
Greedy/On-off

UDP
TCP
TCP
TCP

Table 6: Experiment 4: Trafﬁc mix. The trafﬁc mix is identical for each source-sink pair. The on-off
UDP sources send bursts of 20 packets during an on-period, and have a 150 ms off-period. TCP sources are
greedy during time intervals
, and transmit chunks of 8 KBytes with a
pause of 175 ms between each transmission during time intervals
. TCP
sources run the NewReno congestion control algorithm.

, and

, and

,

,

[20

[50

[10

[30

[40

10

20

40

60

50

30

[0

s;

s;

s;

s;

s

s

s

s

s

s

]

]

;

]

;

]

]

]

140

120

100

80

60

40

20

y
t
i
c
a
p
a
c
 
k
n
i
l
 
f
o
 
%
n
i
 

 

d
a
o
l
 

d
e
r
e
f
f

O

0

0

10

20

30

Time (s)

(a) Router 1.

40

50

60

40

50

60

10

20

30

Time (s)

(b) Router 2.

Figure 14: Experiment 4: Offered Load. The graphs show the offered load at Routers 1 and 2.

140

120

100

80

60

40

20

y
t
i
c
a
p
a
c
 
k
n
i
l
 
f
o
 
%
n
i
 

 

d
a
o
l
 

d
e
r
e
f
f

O

0

0

27

Class 3/Class 2
Class 4/Class 3

Delay Bound

Class 1

s
y
a
l
e
D

 
f
o

 

o
i
t
a
R

5

4

3

2

1

0

50

40

30

20

10

)
s

m

(
 

y
a
l
e
D

0

0

2.5

1.5

2

1

0.5

)

%

(
 
e
t
a
R
 
s
s
o
L

0
0

Class 1
Class 2
Class 3
Class 4

0

10

20

30
Time (s)
(a) Ratios of Delays.

40

50

60

0

10

20

40

50

60

30

Time (s)

(b) Class-1 Delays (individual).

Class 3/Class 2
Class 4/Class 3

Class 4

Class 3

Class 2

10

20

30

Time (s)

(c) Classes 2, 3 and 4 Delays

(averaged over a sliding window of 0.5 s)

40

50

60

0

10

20

50

60

30
Time (s)

40

(d) Ratios of Loss Rates.

Total

Class 3

Class 4

Class 2

10

20

30

40

50

60

Time (s)
(e) Loss Rates.

0
0

10

20

30

Time (s)
(f) Throughput.

Class 1
50

40

60

Figure 15: Experiment 4: Router 1. The graphs show the service obtained by each class at the output link
of Router 1.

14

12

10

8

6

4

2

0

5

4

3

2

1

0

)
s
m

(
 
y
a
l
e
D

s
e
t
a
R
 
s
s
o
L
 
f
o
o
i
t
a
R

 

100

)
s
/
b
M

(
 
t
u
p
h
g
u
o
r
h
T

80

60

40

20

28

Class 3/Class 2
Class 4/Class 3

Delay Bound

Class 1

s
y
a
l
e
D

 
f
o

 

o
i
t
a
R

5

4

3

2

1

0

50

40

30

20

10

)
s

m

(
 

y
a
l
e
D

0

0

2.5

1.5

2

1

0.5

)

%

(
 
e
t
a
R
 
s
s
o
L

0
0

Class 1
Class 2
Class 3
Class 4

0

10

20

30
Time (s)
(a) Ratios of Delays.

40

50

60

0

10

20

40

50

60

30

Time (s)

(b) Class-1 Delays (individual).

Class 3/Class 2
Class 4/Class 3

Class 3

Class 4

Class 2

10

20

30

Time (s)

(c) Classes 2, 3 and 4 Delays

(averaged over a sliding window of 0.5 s)

40

50

60

0

10

20

50

60

30
Time (s)

40

(d) Ratios of Loss Rates.

Total

Class 3

Class 4

Class 2

10

20

30

40

50

60

Time (s)
(e) Loss Rates.

0
0

10

Class 1
30

20

Time (s)
(f) Throughput.

40

50

60

Figure 16: Experiment 4: Router 2. The graphs show the service obtained by each class at the output link
of Router 2.

14

12

10

8

6

4

2

0

5

4

3

2

1

0

)
s
m

(
 
y
a
l
e
D

s
e
t
a
R
 
s
s
o
L
 
f
o
o
i
t
a
R

 

100

)
s
/
b
M

(
 
t
u
p
h
g
u
o
r
h
T

80

60

40

20

29

Set

Enqueue

Dequeue

Pred.

X

s

X

s

(cid:21)

1
2
3
4

15347
11849
2671
2415

2603
2798
1101
837

4053
3580
3811
3810

912
970
826
858

pred

(Mbps)

186
234
557
580

Table 7: Overhead Measurements. This table presents, for the four considered sets of service guarantees,
the average number of cycles (
) consumed by the enqueue and dequeue operations, the standard deviation
(
), and the predicted throughput
(in Mbps) that can be achieved. In the 1 GHz PCs we use, one cycle
corresponds to one nanosecond.

pred

X

(cid:21)

s

with the netperf sources as we did in Experiment 2. An oddity occurs at time
s, where the throughput
of Router 1 seems to be greater than the offered load at Router 2. In fact, we monitor the offered load at the
output link of Router 2, but the output link of Router 1 is connected to an input link of Router 2, which we
do not monitor. By inspecting reports from the OS kernel of Router 2, we saw that the “receive” buffer of
the input link of Router 2 overﬂowed at
s, and that packets were discarded at the input link, which
explains this anomaly.

(cid:25) 35

(cid:25) 35

t

t

In summary, the measurement experiments of a network with single or multiple bottlenecks, constant or
variable load, show that our feedback algorithms achieve the desired service differentiation, and utilize the
entire available bandwidth, while maintaining stability throughout and are robust to changes in the network
topology, the trafﬁc mix or the service guarantees.

6.5 Analysis of Overhead

In Subsections 6.1–6.4, we saw that our implementation can fully utilize the capacity of a 100 Mbps link,
without overloading the PC router. We next present a detailed analysis of the overhead of our implemen-
tation, where we attempt to predict the data rates that can be supported by our PC router implementation,
and where we measure the sensitivity of our implementation to the number of service constraints. We will
show measurements of the enqueue and dequeue operations for four different sets of service guarantees,
tested for four trafﬁc classes.

Set 1: Same as Table 4.
Set 2: Set 1 with absolute guarantees from Set 1 removed.
Set 3: Set 2 with proportional guarantees from Set 1 removed.
Set 4: No service guarantees.

In the measurements we determine the number of cycles consumed for the enqueue and dequeue
procedures. The timestamp counter register of the Pentium processor is read at the beginning and at the end
of the procedures, for each execution of the procedure.

We compiled our implementation with a code optimizer, in our case, we use the gcc v2.95.3 compiler
with the “-O2” ﬂag set. The results of our measurements are presented in Table 7, where we include the

30

machine cycles consumed by the enqueue and dequeue operations. The measurements are averages of over
500,000 datagram transmissions on a heavily loaded link, using the same topology and trafﬁc pattern as
in Subsection 6.3. The measurements in Table 7 were collected at Router 1. Measurements collected at
Router 2 showed deviations of no more than

compared to Router 1.

(cid:6)5%

Since the enqueue and dequeue operations is invoked once for each IP datagram, we can predict the

maximum throughput of a PC router with

(cid:21)

P ;

=

(cid:1)

pred

F

(cid:11)

(cid:12)

+

(72)

(cid:12)

F

denotes the CPU clock frequency in Hz,

denotes the number of cycles consumed by the dequeue operation, and

where
operation,
of a datagram. In the case of our implementation on 1 GHz PCs, we have
report [4] indicates that the average size of an IP datagram on the Internet is
values for
implementation can be run at data rates of at least 186 Mbps.

denotes the number of cycles consumed by the enqueue
is the average size
9. Data from a recent
bytes. Using these
in Eqn. (72) shows that, in the four sets of constraints considered, we estimate that our

and

= 451

= 10

11

F

P

F

(cid:11)

P

P

:

We next evaluate the sensitivity of the performance as a function of the number of constraints. Note
from Section 4 that the number of cycles consumed by the dequeue operation is independent of the set
of constraints. From Table 7, we see that the overhead associated to the absolute service guarantees (Set
3) is of approximately 10% compared to a set with no service guarantees (Set 4). The overhead is 29%
when comparing a set with absolute and proportional service guarantees (Set 1), to a set with proportional
guarantees only (Set 2). We thus see that the overhead incurred by absolute constraints is dependent on the
presence of proportional guarantees, but remains relatively low. Proportional guarantees seem to incur more
overhead than absolute guarantees. However, in the set of constraints we consider, there is a larger number
of classes with proportional guarantees than classes with absolute guarantees, and thus, more computations
are needed to enforce proportional guarantees.

7 Conclusions

We presented the Quantitative Assured Forwarding service, which provides proportional differentiation on
loss and delay and absolute service guarantees on loss, throughput and delay for classes of trafﬁc. We
proposed a feedback based algorithm for realizing the Quantitative Assured Forwarding service at a router.
The algorithm does not require prior knowledge of trafﬁc arrivals, and does not rely on signaling. At times
when not all absolute service guarantees can be satisﬁed simultaneously, the algorithm relaxes some of the
guarantees by using a priority order. The algorithm has been implemented in FreeBSD PC-routers. Through
experiments in a network of PC-routers, we showed that the proposed algorithm could fully utilize the
available capacity of 100 Mbps. The measurements showed that the service guarantees of the Quantitative
Assured Forwarding service are enforced. In future work, we will extend the approach presented in this
paper to TCP congestion control mechanisms [5, 12, 17, 18]. We are also considering an implementation of
our algorithm in programmable gigabit routers, such as the Intel IXP1200 [2].

References

[1] The FreeBSD project. http://www.freebsd.org.

31

[2] Intel’s IXP 1200 network processor. http://developer.intel.com/design/network/products/npfamily/ixp1200.htm.

[3] The public netperf homepage. http://www.netperf.org.

[4] Packet sizes and sequencing, May 2001. http://www.caida.org/outreach/resources/learn/packetsizes/.

[5] M. Allman, V. Paxson, and W. Stevens. TCP congestion control. IETF RFC 2581, April 1999.

[6] S. Blake, D. Black, M. Carlson, E. Davies, Z. Wang, and W. Weiss. An architecture for differentiated services.

IETF RFC 2475, December 1998.

[7] U. Bodin, A. Jonsson, and O. Schelen. On creating proportional loss differentiation: predictability and perfor-

mance. In Proceedings of IWQoS 2001, pages 372–386, Karlsruhe, Germany, June 2001.

[8] K. Cho. A framework for alternate queueing: towards trafﬁc management by PC-UNIX based routers.

In

Proceedings of USENIX ’98 Annual Technical Conference, New Orleans, LA, June 1998.

[9] C. Dovrolis. Proportional differentiated services for the Internet. PhD thesis, University of Wisconsin-Madison,

December 2000.

[10] C. Dovrolis and P. Ramanathan. Proportional differentiated services, part II: Loss rate differentiation and packet

dropping. In Proceedings of IWQoS 2000, pages 52–61, Pittsburgh, PA., June 2000.

[11] C. Dovrolis, D. Stiliadis, and P. Ramanathan. Proportional differentiated services: Delay differentiation and

packet scheduling. In Proceedings of ACM SIGCOMM ’99, pages 109–120, Boston, MA., August 1999.

[12] S. Floyd and T. Henderson. The NewReno modiﬁcation to TCP’s fast recovery algorithm. IETF RFC 2582,

[13] G. F. Franklin, J. D. Powell, and M. L. Workman. Digital control of dynamic systems. Addison-Wesley, Menlo

[14] J. Heinanen, F. Baker, W. Weiss, and J. Wroclawski. Assured forwarding PHB group, June 1999. IETF RFC

April 1999.

2597.

Park, CA, 3rd edition, 1998.

[15] C. V. Hollot, V. Misra, D. Towsley, and W. Gong. On designing improved controllers for AQM routers supporting
TCP ﬂows. In Proceedings of IEEE INFOCOM 2001, volume 3, pages 1726–1734, Anchorage, AK, April 2001.

[16] P. Hurley, J.-Y. Le Boudec, P. Thiran, and M. Kara. ABE: providing low delay service within best effort. IEEE

[17] V. Jacobson. Congestion avoidance and control. In Proceedings of ACM SIGCOMM ’88, pages 314–329, August

Networks, 15(3):60–69, May 2001.

1988. Stanford, CA.

[18] V. Jacobson. Modiﬁed TCP congestion avoidance algorithm. Note sent to end2end-interest mailing list, April

1990. ftp://ftp.isi.edu/end2end/end2end-interest-1990.mail.

[19] R. R.-F. Liao and A. T. Campbell. Dynamic core provisioning for quantitative differentiated service. In Proceed-

ings of IWQoS 2001, pages 9–26, Karlsruhe, Germany, June 2001.

[20] J. Liebeherr and N. Christin. JoBS: Joint buffer management and scheduling for differentiated services.

In

Proceedings of IWQoS 2001, pages 404–418, Karlsruhe, Germany, June 2001.

[21] C. Lu, J. A. Stankovic, G. Tao, and S. H. Son. Feedback control real-time scheduling: Framework, modeling and
algorithms. Journal of Real Time Systems, 2001. Special Issue on Control-Theoretical Approaches to Real-Time
Computing. To appear.

[22] Y. Lu, A. Saxena, and T. Abdelzaher. Differentiated caching services; A control-theoretical approach. In Pro-
ceedings of the 21st International Conference on Distributed Computing Systems, pages 615–624, Phoenix, AZ,
April 2001.

32

[23] A.M. Lyapunov. The general problem of motion stability, 1892.

[24] Y. Moret and S. Fdida. A proportional queue control mechanism to provide differentiated services. In Proceed-
ings of the International Symposium on Computer and Information Systems (ISCIS), pages 17–24, Belek, Turkey,
October 1998.

[25] T. Nandagopal, N. Venkitaraman, R. Sivakumar, and V. Barghavan. Delay differentiation and adaptation in core

stateless networks. In Proceedings of IEEE INFOCOM 2000, pages 421–430, Tel-Aviv, Israel, April 2000.

[26] K. Nichols, S. Blake, F. Baker, and D. Black. Deﬁnition of the differentiated services ﬁeld (DS ﬁeld) in the IPv4

and IPv6 headers. IETF RFC 2474, December 1998.

[27] A. K. Parekh and R. G. Gallagher. A generalized processor sharing approach to ﬂow control in integrated services

networks: The single-node case. IEEE/ACM Transactions on Networking, 1(3):344–357, June 1993.

[28] S. Parekh, N. Gandhi, J.L. Hellerstein, D. Tilbury, T.S. Jayram, and J. Bigus. Using control theory to achieve
service level objectives in performance management. Journal of Real-Time Systems, 2001. Special Issue on
Control-Theoretical Approaches to Real-Time Computing. To appear.

[29] M. Shreedhar and G. Varghese. Efﬁcient fair queueing using deﬁcit round-robin. IEEE/ACM Transactions on

Networking, 4(3):375–385, June 1996.

[30] J.-J. E. Slotine and W. Li. Applied nonlinear control. Prentice-Hall, Englewood Cliffs, NJ, 1991.

[31] A. Striegel and G. Manimaran. Packet scheduling with delay and loss differentiation. Computer Communica-

[32] L. Zhang. Virtual clock: A new trafﬁc control algorithm for packet switched networks. IEEE/ACM Trans.

tions, 2001. To appear.

Comput. Syst., 9(2):101–125, May 1991.

33

