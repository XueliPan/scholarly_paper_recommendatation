persistence dynamic code transformation janapa dan department electrical computer engineer corporation university colorado boulder abstract dynamic code transformation broadly group three distinct optimization translation instrumentation face critical challenge minimize overhead incur transformation since execution interleave execution application common task incur overhead identification frequently execute code sequence costly analysis program information creation write new code sequence cost work amortize repeat execution transform code however step apply general code regardless execution frequency substantial overhead impact application performance challenge effectively deploy dynamic transformation fix performance paper explore technique eliminate overhead incur exploit persistent application execution share across different application technique implement evaluate pin dynamic instrumentation engine version pin refer persistent pin initial experimental result indicate use information prior run reduce dynamic instrumentation overhead spec much ninety everyday like web display render program one introduction dynamic code transformation potential impact design use modern computer since perform number task profile optimization translation inherent advantage static access collect execution turn use adapt code execution target application however since execution interleave execution application substantial overhead penalty code transformation context performance analysis program behavior tool overhead may acceptable nonetheless overhead major barrier transformation real use application execution overhead application run determine primarily two one transformation overhead two performance translate code transformation overhead deter mine level complexity analysis transformation apply code likewise overhead component fix depend application program tremendous amount code execute time able amortize overhead cost code sequence performance translate code control factor whether optimization apply whether instrumentation code add transformation traditionally design primarily focus achieve give transformation task single execution instance program repeat exploit persistent code information previous drawback since tend exhibit identical across show five exploit share behavior dramatically reduce overhead since time spend analysis optimization repeat invocation avoid paper solution address transformation overhead issue propose strategy aim exploit persistent application recur across independent cache information prior cost transformation minimize since subsequent application may require limit amount new code generation persistence support direct cache many type information optimization program state target paper illustrate fundamental challenge materialize persistent cache instrumentation information experimental framework capture persistent code implement evaluate pin dynamic instrumentation system capable cache instrument reuse previously cache run increase size cache execution new generate due new input set also capable support large multithreaded persistence pin reduce instrumentation overhead spec program much much ninety cost everyday web graphics render text remainder paper organize follow section two present detail argument support cache dynamic program section three present overview solution along computer architecture news vol five oration challenge deploy persistence real system section four evaluation persistence binary instrumentation system finally section five summarize paper two dynamic code transformation dynamic code transformation well know topic domain instrumentation performance analysis optimization one dynamo two three mojo four adore six performance monitor application execution behavior apply best suit improve native binary performance daisy boa binary execute comply one architecture another pin seven eight use compilation perform application introspection via use instrumentation focus accomplish task monitor single instance program attempt leverage information past reduce overhead subsequent improve application performance challenge face dynamic code transformation execute single execution instance present next section challenge experience primary challenge overhead since execution interleave execution application overhead summation time spend execute generate code translate code overhead overhead involve generate code transformation overhead translate code overhead determine number factor include original code modification code optimization add instrumentation transformation transparently maintain original application functionality absence code optimization instrumentation dynamic execution count translate code still overhead code include branch vary target require special handle amount overhead check branch target well direct application execution system new code compilation overhead also add base layout translate code memory since determine memory system performance overhead primarily dominate translate code execution cost transformation overhead determine compilation step amount code require compilation cost vary base execution application program large tend stress infrastructure heavily like relatively smaller code size small footprint execute unique code less control intensive transformation overhead figure one show usage pin fig one time spend pin system various reference spec input set every point represent compilation new trace straight line reflect time spend run translate code fig two cumulative percentage number trace dominate program execution piler infrastructure five spec reference input set vertical axis time horizontal axis number time pin virtual machine enter across entire run program straight line without data point indicate time spend code generate translate code point signify compile new program path previously see code transformation figure evident lot time spend compile new code near end majority time spend execute translate application data corroborate slowdown pin system repeat code transformation degrade performance since effect invoke architecture similar process context switch insight gain data large footprint consume substantial transformation time amount transformation time spend infrequently execute code another interest characteristic evident figure compile application exhibit identical transformation behavior usage compiler different input around invocation different input computer architecture news seventy vol five due complexity tend stress instrumentation aggressively instance program memory check pin tool experience slowdown simply due transformation overhead separate program different input set would therefore result identical transformation slowdown use persistence first invocation application need incur performance penalty rest may reuse cache generate first invocation result incur minimal amount transformation overhead result new take application due input variation three persistence persistent system figure three illustrate control flow persistent system system start may proceed basic step past phase check see prior execution exist persistence cache prior execution cache exist proceed initialize memory allocate space data structure translate code memory pool live across application memory pool cache persistence make available reuse binary graphic translate code transformation execution time time four seven fourteen ten thirteen ninety table one distribution translate code execution time versus transformation overhead phase graphic deviate different code transformation behavior infrequently execute code transformation overhead another source transformation overhead result trait common cold code code execute time cold code execution challenge problem rely amortize cost transformation overhead repeat translate code sequence figure two show sort distribution code sequence generate pin compiler cover complete execution program evident data execution time spend trace except average spend majority execution time trace application code footprint therefore require individual trace greater cover entire execution table one show distribution time spend execute translate code versus generate phase graphic amount time spend transform code even faster compiler able overcome transformation overhead code consist execute infrequently table one figure two conclude transformation overhead pin due large number infrequently execute trace require transformation address problem therefore critical improve performance code transformation work paper aim reduce overhead transformation cost code transformation system suggest strategy minimize overhead cache program end run maintain system methodology refer persistence five show tend share common code across multiple thus believe approach practical effective solution minimize incur transformation evaluate persistence benefit work solution implement binary instrumentation system persistent cache instrumentation particularly beneficial large development complex usually put form daily regression test ensure development change source break application feed multiple input set ensure enough code touch ensure robustness fig three overview persistent code transformation system dot line indicate persistence specific state past phase system default step normally take dynamic binary code transformer take explain section two end execution translate code sequence relevant store persistence subsequent system application trigger system check prior execution instance cache one exist system initialize require state computer architecture news vol five allow reuse cache execution proceed program previously see demand code transformation translation since already exist memory system get invoke new execution sequence end program new code sequence generate may append already cache execution new persistent cache file may create challenge realize persistence dynamic system lend many complex need address make practical solution section fundamental challenge believe generic elaborate consistency cache execution reuse application binary modify since last invocation application modify cache particular application invalidate new persistent cache file generate identify change require signature current execution instance signature generate verify prior execute first instruction cache execution may generate use randomize address space ras nine operate support randomize address space capable load share different address across problem since maintain translation map original translate scenario problematic system two share b originally load address x swap load address x respectively second run interchange break application second run cache execution reuse incorrect first instruction address look cache execution incorrectly return translate instruction address x really second run possible solution update program time map return valid result current execution instance address translate code load different address across create yet another problem specific translate example system may translate call instruction push jump pair push instruction place return address onto stack maintain call instruction relocate sequent run due ras literal push instruction need update reflect new return address call instruction possible solution generate translate code form regardless code load translate code work correctly another solution generate relocation translate code code prior execution technique similar loader program address space large footprint tend exhaust allocate space quickly respond reclaim space allocate code generate current instance execution cache program termination limit performance persistence initially see cache version therefore subsequent run system regenerate lose result transformation overhead rather lose prior space reclamation better generate persistent cache every time allocate space reclaim multiple cache reuse individually system later self modify code code dynamically modify cache persistent cache generate end contain final version code may modify lifetime program code may maintain persistent may swap detect optimization certain perform code transformation system one execution instance propagate across since might dependent input example constant propagation often tend input dependent therefore order reuse already exist execution input may match case system apply optimization persistent system design important challenge persistent system must handle design system overlook persistence rely state application also state correspond system develop simultaneously multiple require comprehend persistence cater likely diminish rate development increase system complexity therefore important design system manner presence constrain object orient program feature prove important concept exploit ease implementation persistence system actively develop register class persistent memory manager ensure object cache properly available subsequent run four evaluation persistence persistence binary system pin base instrumentation engine support instrumentation via use pin tool export rich user interface perform application introspection pin perform various code cache trace link register allocation liven analysis generate code minimize overhead incur memory system translate code cache special area memory persistent pin specifically design reduce overhead dynamic instrumentation overhead computer architecture news vol five fig four persistent pin performance comparison native pin performance result pin generate new trace execute application see yet generate require instrumentation introspection code impact overhead architecture may view similar effect regular operate system context switch overhead reduction process involve phase generate cache file disk later make available reuse subsequent application pin either identical vary input cache file consist translate code memory necessary data structure support code reuse across thus reuse much code possible prior run guarantee smaller overhead see require pin compilation evaluate spec everyday latter suite interactive graphics comprise virtual manager media player last two multithreaded choose characterize reflect aggressive demand behavior comparison spec program poor everyday application result gather machine main memory run seventy operate system pin support various evaluate preliminary design platform experiment perform divide two group characterize one effectiveness persistence reduce overhead lifetime program two effectiveness minimize cost motivation clearly present benefit persistence overhead reduction program lifetime traditional dynamic code transformation rely amortize overhead repeat code already translate current execution instance therefore system cover enough program footprint overhead become negligible thus essential carefully analyze effective persistence length program execution first evaluation persistence pin run fig five pin service request translate code pin without instrumentation without instrumentation pin highly representative generic see pin function translator pin default transparency incur overhead figure four show execution time spec run original binary pin use already cache execution spec integer performance report since show seven pin affect spec float point performance significantly data show two first effective across reduce code transformation overhead second performance improvement limit performance translate code code transformation overhead reduction confirm reduce number pin service request evident figure five service request occur pin call generate new code handle system call service still likely occur base execution application environment benefit persistence improvement thirty execution time show persistence effective complex control flow large since tend stress infrastructure heavily code transformation phase show figure one exhibit dramatic gain relatively smaller small easy work code transformation code translate cache memory system frequently invoke code transformation therefore easily amortize initial cost repeat cache code sequence also show dramatic eighty service request however figure four confirm execution time improvement affect performance translate code two high dynamic execution indirect branch indirect branch challenge handle dynamic code transformation system contribute amount overhead challenge handle branch elaborate detail two seven task propose solution thus computer architecture news vol five five conclusion paper persistence propose solution reduce overhead incur dynamic binary code transformation persistence process cache reuse subsequent persistence evaluate pin binary instrumentation engine create system know persistent pin capable cache instrument program reuse cache instrument separate also capable cache new code subsequent application change behavior prior support multithreaded persistence model prove effective pin experimental data show code transformation overhead ninety graphic program cost spec instrument reference one j fink grove hind p f adaptive optimization conference page two v e dynamo transparent dynamic optimization system proceed zero conference program language design implementation page june three garnett infrastructure adaptive dynamic optimization three proceed international symposium code generation optimization page computer society four r mojo dynamic optimization system workshop dynamic optimization five k hazelwood smith characterize interapplication optimization persistence workshop explore trace space dynamic optimization page san ca june six j h r fu b yew performance data cache dynamic optimization proceed international symposium seven r r muth h g v j k hazelwood pin build program analysis tool dynamic instrumentation proceed conference program language design implementation june eight n j program proceed supervision framework workshop verification nine pax web site fig six execution time instrumentation use persistent pin pin percentage pin show fig seven execution time persistent pin pin instrumentation everyday start immediately shutdown worst case scenario illustrate benefit cache cold code discuss proceed evaluation persistence instrumentation basic block profile instrumentation apply spec integer figure six indicate average save execution time regular pin reuse cache subsequent program prove cache instrument program beneficial worthy investigation cost reduction phase difficult part system constantly invoke generate new code see yet apply interactive program difficult tolerate especially long pause slowdown result lot share library cold code bad way amortize overhead incur phase figure seven show execution time start graphic program shut completely ready user interaction case instrumentation apply well basic block profile collect show persistence highly effective handle overhead average improvement ninety execution time save instrument dramatic improvement possible graphics program exhibit tremendous amount sequence instance program rely interact fifty share eighteen load memory initialize ready user interaction code rarely reuse thus overhead amortize use service computer architecture news vol five