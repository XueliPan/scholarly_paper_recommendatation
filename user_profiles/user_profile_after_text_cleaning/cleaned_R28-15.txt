latent semantic index variable number orthogonal center web research university chile factor abstract seek insight latent semantic index establish method identify optimal number factor approximation matrix define reasonable property approximation hold derive new query expansion method extensive numerical experiment confirm value new method latent semantic analysis query expansion information retrieval text mine singular value decomposition introduction task retrieve document relevant user query large text complicate fact different author use different word express relate latent semantic analysis interpret variability associate expression concept noise use linear algebra isolate perennial concept variable noise follow word author latent semantic analysis approach take advantage implicit structure association term document semantic structure order improve detection relevant document basis term find query particular technique use singular value decomposition large term document matrix decompose set ca orthogonal factor original matrix approximate linear combination document represent ca item factor weight query represent form weight term document cosine value return large number factor weight provide approximation close original term document matrix retain much noise hand many factor discard information loss large first objective work identification optimal number orthogonal factor finally propose method associate different number dimension term section one define representation document associate document retrieval method introduce original latent semantic method section two common modification section three paper present two new method section four identify appropriate number singular value new kind latent semantic index name method section five method require user specify number orthogonal factor use curve section six compare method latent semantic index one representation discuss paper rely representation document replace vector attribute attribute usually present document information like time span stem use model see tate yang vector naught correspond attribute absent document unity present term weight refinement take account frequency appearance word within among document location appearance title abstract section header popular weight scheme variation model vector representation document give di wi wi one expression wi term frequency number time term wi occur document wi inverse document frequency inverse number document word wi occur representation use retrieve document relevant user query vector representation derive query way regular document compare representation use suitable measure distance similarity formally call matrix document n attribute form document q vector representation query di dissimilarity measure di compute di q order document respect similarity query simple measure similarity product normalize document di query q write two three di extend document q previously normalize vector write measure find al representation usually lead matrix include several attribute cause serious term computational complexity conceptual term goal design efficient algorithm process several filter approach lead reduction size vector representation prune consist remove infrequent frequent word usually carry little information replace inflect word root order regroup form semantic content two latent semantic analysis problem former retrieval method mention introduction similarity query give document underestimate user document author use different express latent semantic index claim al one successfully overcome problem take account synonymy polysemy synonymy refer existence equivalent similar term express idea polysemy refer fact word multiple unrelated mean account synonymy lead overestimate dissimilarity relate document account polysemy lead erroneously find document idea behind reduce dimension information retrieval problem project document n attribute matrix adequate subspace lower dimension achieve base singular value decomposition v orthogonal matrices diagonal matrix dimension n denote one p p min n one two p matrix k dimension k rank term norm obtain set zero k equivalent reduce v k first k first row denote reduce matrices k v k k respectively base three rewrite similarity measure follow k v k four five equivalent use v k send document query k dimensional space compare new reduce subspace number document attribute large involve manipulation large sparse matrices possible improve performance memory significantly use data representation model specially design handle matrices present formal similarity latent semantic analysis probabilistic latent semantic analysis another method take synonymy polysemy account start point call aspect model two consider latent manifest latent observe directly manifest condition model dependency possible retrieve underlie reference problem concept express different analogy make latent variable concept one hand vocabulary use express manifest hand three correlation method former section five understand method send document query k dimensional subspace another possible interpretation go follow v k v k symmetric full matrix v k v k contain typically term five thus equivalent query expansion base term document lead naturally use correlation matrix instead factor v k v k provide query expansion computation become six intuitive motivation behind use correlation matrix lie fact present document correlate take account well even explicitly present present document obscure choice specific vocabulary instead decompose document matrix correlation method apply singular value decomposition correlation matrix seven eight nine ten eleven twelve number document ad vector represent document mean ie one ad unbiased covariance matrix write c one one ad ad correlation matrix define base covariance matrix c si j j j correlation matrix symmetric singular value decomposition write v diagonal matrix order singular value interpret send document query k dimensional subspace k k twelve k k k k twelve k q k k twelve q k compare document last subspace section two correlation matrix dimension depend number number document correlation method able handle several hundred document moreover correlation matrix need update time batch new document enter data base long new document introduce new ie sufficiently similar exist document aspect particularly important context electronic network new data become continuously available see handle problem see thirteen discussion advantage correlation method four validity rank present criterion determine number singular value necessary correctly distinguish dictionary along definition understand correctly distinguish single term query clear rank k provide adequate approximation rank problem impose basic condition meet start imagine follow give collection document identify set n term compute correlation matrix singular value decomposition create new corpus document contain one term n document namely impose follow condition rank k issue query term retrieve correlation matrix approximation ie document ti top item list base ten result follow condition six j k k j representation query ti coincide equal vector set zero equal one inequality thirteen easily simplify k k k k give k symmetric term k mean even though diagonal equal unity greater nondiagonal row column matrix symmetric provide us criteria k rank single term query set k n decrease value fourteen satisfy validity rank term equal k condition verify k k one next property singular value decomposition enable computation k one base k simplify computation rank k k sake later discussion introduce next say valid rank k satisfy fourteen say rank k k one value fourteen verify case k validity rank show significance condition give approximation rank information contain query use noise introduce two term query extend development multiple term query case query two term redefine artificial corpus set document compose two start impose query term j rank document contain document contain j express j six n follow k k k k k k k k k k k similarly also need k k k k search two term query j n return j first combine sixteen seventeen result necessary condition k k n six j combine fourteen give k k j n impose common validity rank although always possible meet condition result rank k numerical experiment recommend also intuitively unappealing two word perfect correlation might happen practice condition eighteen impose rank k equal full rank nevertheless expect query two term satisfy thirteen fourteen fifteen sixteen seventeen eighteen five optimal rank method global rank saw section term different validity rank simple method estimate optimal global rank correlation matrix approximation consist require large proportion valid rank example large enough inferior equal run numerical experiment section six test idea term rank last approximation appear accurate clearly useful method require adjustment user would better ten show rank approximate k k twelve k k k k nineteen section saw validity rank term reason instead truncate row term truncate row validity rank correspond term row set zero index also set diagonal matrix unity saw section four diagonal term term way matrix define exact diagonal approximation term six numerical experiment use different text test present paper corpus compute curve correlation method different value k identify optimal experimental rank e compare rank estimation define subsection also compare e method describe subsection curve approximation correlation loose quality document long estimation take account word distance term cut document piece consecutive word corpora document short enough correlation matrix compute base shorter numerous document precision find higher apply method set number relevant document b number retrieve document precision recall define precision b recall use plot precision versus recall compare different different method strictly better another precision associate recall value see van detail explanation evaluation comparison methodology use corpora associate smart blake project data lewis section take verbatim explain great clarity method associate generation query relevant document main difference test collection set standard query correspond relevant document however document cod allow us use tag number manually assign subject cod test collection compare document representation use first describe lewis method describe first r define set document collection set partition two equal size q query set test set method use partition r choose random assignment document one two method ensure group document cover common theme would evenly distribute q next define set subject cod assign least one document q least one document pick one subject cod perform retrieval example suppose perform retrieval subject code crude first document q tag crude select perform relevance feedback use select document pair generate form query query use retrieve set result rank document list examine see rank document tag crude appear position tag document use produce figure conservative interpolation technique outline van use transform figure precision value ten standard recall level one two ten process repeat subject code time produce another set precision value precision value average give overall set value ten standard recall level partition use subject cod classic test collection create collection search set query generate q element set relevant document query document tag respective element use relevance feedback generate query place verbose user generate query mean form retrieval liken iteration relevance feedback retrieval session particular experiment present apply follow procedure one divide randomly two set document give subject code q set two approximately number document two create one large document compose document q three identify four term higher score generate four term query four five find optimal number term see four compute pair recall equal five one two nine ten select subject cod twenty associate document repeat procedure fifteen random initial set provide total document pair use test different curve compute use conservative method mention smart smart collection propose seven namely cran time set query list document relevant query discard time cran analysis simple cosine correlation give poor result precision around five best case probably representation document entail much loss information regard associate query summarize corpora table one size number number query corpus size document query one table one corpora result reliable smart much size higher number query global rank show one three five seven nine eleven conservative approximation curve six ignore curve label unit right figure show number term valid sense fourteen function number experiment term valid relatively low number validity last term obtain significantly number v compute suggest stop computation new reasonable number term valid like ninety vocabulary experiment compare rank v lead large proportion term valid optimal experimental rank e deduce observation one three five seven nine eleven single optimal rank difficult estimate general determine experimentally curve tend cross hand analytical estimation v depend proportion valid term require instead define threshold choose identify v observation histogram figure second column give number term use representation corpus term e fifty fifty v fifty table two range optimal rank tend underestimate roughly compatible experimental sophisticate method global rank approximation find comparison correlation method label unit one three five seven nine eleven identify eleven circle correspond point conservative precision evaluate method describe figure one figure two rank figure three figure four rank figure five figure six rank figure seven figure eight rank figure nine figure ten rank figure eleven figure twelve rank three simply cosine distance query document curve result correlation method various value rank k report figure see method sometimes significantly better sometimes significantly worse correlation report literature method give result close correlation method rank set experimental optimum data give small one size query compare query believe result enough invalidate method reliable experiment also favorable method fig eleven precision either insignificantly experimental optimal global rank base simple expect correlation method derive new way estimate optimal rank stop singular value decomposition similar lead new way estimate data appropriate query scheme method extensively test experimental data set small medium size compare favorably traditional correlation method term curve require user set number orthogonal factor conclusion reference r learn apprentice world wide web spring symposium information gather heterogeneous distribute r b modern information press latent variable model factor analysis second edition vol seven library statistics blake c c repository machine learn r greedy attribute selection international conference machine learn g index latent semantic analysis journal society information science g latent number orthogonal factor latent semantic analysis proceed annual international conference research development retrieval press amend parallel analysis optimal dimensionality estimation latent semantic index technical report technical report probabilistic latent semantic index proceed annual conference research development information retrieval fifty j unsupervised learn dyadic data technical report ca probabilistic analysis algorithm text categorization international conference machine learn g h r k irrelevant feature subset selection problem international conference machine learn journal version available vector space model search cluster mine invite paper berry comprehensive survey text mine springer thirteen major outlier cluster analysis use dynamic document proceed text mine workshop crystal city g efficient estimation singular value search large dynamic web ninth world wide web conference l h retrieval rank document patent lewis text categorization test collection lewis incremental cluster category drift use competitive network text mine berlin j identify interest web sit spring symposium machine learn information access lecture note computer science eleven g c automatic structure retrieval large text file two test collection b prototype feature selection sample random mutation hill climb international conference machine learn tate learn revise user profile identification interest web sit tate advance plan technology park press learn revise user profile identification interest web sit machine learn van c j information retrieval edition computer science university yang expert network effective efficient learn human text categorization retrieval annual international conference research development information retrieval