zero one zero two p e nine one c c one v five six six three nine zero zero one v x r dynamic data cache scientific two computer science four physics astronomy ani one center university university three computer science university dame abstract modern scientific grow rapidly size increasingly interest view latest data part query result current scientific cache however assume static thus answer scientific query latest data query instead rout repository data cache refresh scientific discipline astronomy indiscriminate query rout data refresh often result runaway network cost severely affect performance make poor use cache system present delta dynamic data cache system scientific delta key component decision framework adaptively data keep data object cache heavily query keep data object repository heavily update algorithm profile incoming search optimal data reduce network cost leverage formal network flow problem robust evolve scientific evaluate efficacy delta prototype implementation run query trace collect real astronomy survey dynamic data cache network traffic vertex cover robust one introduction data collection science undergo transformation remarkably see astronomy survey sloan digital sky survey forty collect data average rate collect data add repository process new repository periodically release however recent survey panoramic survey telescope rapid response system thirty large synoptic survey telescope add new data average rate considerably consequently data collection revise facilitate continuous addition data repository eighteen transformation data collection impact data make available remote data employ deploy data improve data availability reduce access time network traffic three critical component cache store repository data close proximity answer user query behalf remote cache work well old batch method data collection release data continuously add cache copy data rapidly become stale serve stale data unacceptable astronomy increasingly interest latest latest exist new astronomical body play fundamental role study analysis keep cache copy data fresh repository could continuously propagate update cache result runaway network cost indeed transform data cache dynamic data rapidly grow scientific challenge scientific dominant render dynamic data cache propose untenable firstly scientific data intensive instance expect daily data query traffic day consequently primary concern minimize network traffic previously propose dynamic data cache commercial retail web stock market data dissemination primary goal minimize response time minimize network traffic orthogonal cache incorporate latest change either invalidate cache data propagate update ship query b propagate update fix rate blind actual query receive thus generate unacceptable amount network traffic secondly scientific query exhibit constant evolution query data object query specification phenomenon characteristic nature science evolution often result entirely different set data object query short time period addition single query template dominate thus often hard extract representative query evolve challenge make robust save network cost remain profitable long sequence previously propose dynamic data cache often assume representative point range query five nine ten paper present delta dynamic data cache system rapidly grow scientific delta address challenge incorporate two crucial design unless query demand new data addition repository propagate cache system query demand latest change delta first invalidate currently available stale data cache invalidation unlike previous six follow indiscriminate ship query update delta incorporate decision framework continually compare cost propagate new data cache cost ship query server adaptively decide whether profitable ship query ship update b delta make base assume degree stability often assume prior indicator future access make statistical correlation pattern lead inefficient especially case scientific exhibit constant evolution effectively implement design decision framework delta data object choose host data object propagate update host data object ship query approach naturally minimize network traffic query update access single object problem require simple computation cost query object server exceed cost keep update cache cache otherwise however scientific consist query reference multiple data object general problem consist update query multiple data object show general problem combinatorial optimization problem develop novel algorithm solve general problem incremental algorithm develop algorithm network flow problem minimize network traffic profile cost incoming make best network cost optimal available hindsight robust change pattern decision make ground analysis algorithm also adapt well space constrain cache track object usage make load eviction give time set object cache satisfy maximum number query cache demonstrate advantage data framework delta present benefit base greedy algorithm also data object similar benefit commonly employ commercial dynamic data cache perform detail experimental analysis test validity framework real astronomy survey implement benefit experimentally evaluate performance use three astronomy collect sloan digital sky survey also compare three replica experimental result show delta use reduce traffic nearly half even cache size server repository outperform benefit factor vary different condition adaptability help maintain steady performance scientific query follow clear pattern discuss relate work section two science application ie definition data object specification query update describe section three section also describe problem data object repository cache approach data problem describe section section four describe approach data problem approach make stability alternative approach benefit base stability describe section five demonstrate effectiveness benefit section six finally section seven present future work two relate work framework propose delta minimize network traffic improve access latency similar hybrid ship model process sit either ship data client ship query server process paradigm also explore recently use content distribution network efficiently deliver data however none consider propagate update data delta framework include data mobility include query ship update propagation data object load al ten consider proxy cache stock market data adaptively either update data object push server pull client method limit primarily single value object stock price point query query ship update propagation explore view materialization twenty primary focus minimize response time satisfy currency query unlimited cache size assume compare benefit develop algorithm use similar algorithm develop algorithm minimize network traffic instead response time experiment show perform poorly scientific recent work sixteen focus minimize network traffic however problem focus communicate current value single object result propose scale scientific object multiple value alternatively al consider approach reduce network cost approach specify precision query instead currency tolerance staleness scientific zero tolerance approximate incorrect value real attribute imprecise result directly impact scientific accuracy finally several dynamic data cache maintain currency cache data include one three fourteen recent thirteen provide comprehensive dynamic data cache infrastructure include ship query update define data object granularity specify currency however lack decision framework adaptively choose query ship update propagation data load data communication method deem sufficient query currency fig one delta architecture three delta dynamic data cache describe architectural delta data exchange server repository cache see figure one data scientific repository store relational system provide natural partition data form table often spatial indices available partition data object different size repository receive update data object data pipeline update predominantly insert data case modify exist data object data never delete due archival reason model repository set data object incoming update affect one object common scientific data object store cache system improve data availability reduce network traffic cache locate along close thus far repository cache often much less capacity original server repository thus model cache subset data object c object cache entirety part cache simplify load object object cache invalidate update arrive server user query q query access data set data object b q cache answer query repository behalf query answer cache rout repository answer directly quantify need latest data query may include user system specify currency form tolerance staleness q define follow give q answer q must incorporate update receive object b q except arrive within last q time similar syntax specify q describe fourteen lower tolerance user need current data satisfy query per tolerance staleness cache choose three available communication update ship b query ship c object load ship update system send update specification include data insertion modification apply cache data object ship query system redirect query repository result send directly client object load mechanism cache load object previously cache provide available space load three differ term semantics cost use network traffic instance update ship newly insert object ship whereas object load entire data object include update ship system record cost use data communication mechanism delta currently focus network traffic cost due use latency cost discuss section four network traffic cost assume proportional size data communicate thus object load load cost proportional object size add total network traffic cost query q update ship network cost q proportional size q result size data content add respectively proportional assumption rely network exhibit linear cost scale object size true network transfer size substantially frame size quantitative difference cost three describe example section delta difference term cost use communication mechanism lead formulation data problem first describe problem word ease presentation also provide formulation data problem data problem give set object repository sequence user query cache sequence update repository problem decide object load cache repository object evict cache query ship repository cache update ship repository cache object cache never exceed cache size b query answer per currency requirement c total cost describe next minimize total cost sum load cost object load ship cost query ship ship cost update ship formulation problem give set object cache visualize graph g v e vertices graph query update data object data object vertices two one cache cache graph edge draw query vertex update vertex update affect query b query vertex data object vertex object cache access query graph presentation edge update vertex object cache query vertex object cache draw graph construction help capture query update object term graph interaction graph edge involve mutual decision data communication mechanism use problem correspond determine data communication use since right combination minimize network traffic cost interaction graph fundamental data problem determine optimal right combination data communication use must also robust incoming query update since slight change lead entirely different data communication become optimal see design one one section one demonstrate next subsection example example demonstrate different become optimal entire sequence query update accompany cost know advance cache size determine optimal objective algorithm data problem make query ship update ship object load cost incur network traffic minimize base incoming pattern difficulty determine optimal combination decision arise slight variation ie change cost ship query ship update query currency threshold result entirely different combination optimal best illustrate example fig two graph sample sequence notation ten imply size object ten also network traffic load cost one imply update object network traffic ship cost fifteen imply query access object network traffic ship cost tolerance staleness among four data object object load cache break line object currently cache solid line available load space consider sequence update query next eight second base graph formulation problem draw edge query update object query access set edge since either ship use data communication mechanism necessary namely load ship since object cache dependence update necessary satisfy currency access set edge note edge ship necessary till object load cache load arrive edge add edge since tolerance staleness permit answer cache copy need update example right choice action evict load begin appropriate step ship update query satisfy currency incur network traffic cost crucial best decision tolerance staleness allow us omit ship case entirely different set become optimal include load ship query network cost combination minimize network traffic example focus internal interaction graph cache object form nod observe determine optimal decision choice correspond find vertex cover eight lack space omit description vertex cover directly state correspondence follow theorem theorem one min weight vertex cover let entire incoming sequence query update internal interaction graph g know advance let v c vertex cover g optimal choice ship query update whose correspond nod v c proof sketch entire incoming sequence query update know claim optimal choice one choose every query q either ship update interact q ship two make choice total weight nod choose ship minimize true since sum weight nod choose equal actual network traffic cost incur choice correspond vertex cover problem see definition twelve vertex cover problem general however specific case bipartite graph edge exist amongst set query nod set update nod query update nod thus still solve vertex cover problem reduce maximum network flow problem fifteen polynomial time algorithm maximum network flow problem algorithm eight algorithm base fact flow maximum augment path algorithm repeatedly find augment path augment flow augment path exist primary challenge employ algorithm maximum network flow problem delta know sequence advance b extend limit size cache computation equivalently determine flow change different knowledge future become available example know would happen time know everything would load instead ship arrive would ship thus different partial knowledge future lead different cost obtain computation apply object cache still need mechanism profitably load object cache four algorithm data problem determine object query must ship object update must ship algorithm make fashion use minimal information incoming also address second challenge cache overall algorithm show figure three algorithm rely two internal make two query arrive first determine object access query cache object cache query present choose ship outstanding update require query ship query instead query arrive access least one object cache ship query server also present decide background whether load miss object describe behind one two three four five six seven eight invocation arrive query q access object b q network traffic cost q objective choose invoke ship q invoke object b q cache query q else ship q server forward result client background query q fig three main function build upon framework present section make query update arrive incorporate new query exist internal interaction graph g add nod update interact establish correspond edge compute vertex cover use algorithm find maximum network flow graph however instead run network flow algorithm time query service use incremental algorithm find change flow since previous computation figure four result vertex cover computation query ship accordingly line update ship nine ten eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen twenty cache invocation query q access object b q network traffic cost q objective choose ship q ship outstanding interact update update interaction graph update interact q ship execute q cache send result client add query vertex q weight q exist internal interaction graph g get g object b q mark stale outstanding update add update vertex g weight ship cost already present update vertex interact q add edge q g compute vertex cover v c g use incremental algorithm q v c q already execute cache ship q server forward result client fig four cache key observation compute incremental vertices edge add delete graph change previous flow computation thus previous flow remain valid flow though may maximum algorithm therefore begin previous flow search augment would lead maximum flow result sequence query update total time spend flow computation single flow computation network correspond entire sequence network n nod edge time eight much less time version take record entire sequence query update make algorithm always work remainder instead make query update see far remainder form exist exclude update nod pick vertex cover point query nod pick vertex cover exclusion one let g previous internal interaction graph h correspond network construct previous iteration two let g current internal interaction graph three add source sink vertices g correspond capacitate edge describe fifteen construct network h four find maximum flow h base know maximum flow h five determine vertex g maximum flow value h de scribe fifteen fig five single iteration incremental network flow algorithm safely do select cover point ship update justify base past query interact future query update therefore never part future cover selection make compute cover robust change technique also drastically reduce size work make algorithm efficient practice manage load invoke determine useful load object cache save network cost ship correspond query decision make incoming query access one object cache difficulty make decision due query access multiple object contribute vary fraction query total cost q objective still find fashion right combination object reside cache total network cost minimize query algorithm build upon popular algorithm seven proxy cache object cache algorithm calculate object usage cache base frequency usage cost size object heavily use evict object object load soon request load policy much network traffic show minimize network traffic important ship query object server ship cost equal object load cost incur request object must load object cache object usage cache measure frequency recency use thus eviction make similar base object usage cache query access multiple object use simple twist algorithm still ensure find right combination randomly assign query ship cost among object query access b defer calculate object usage cache random assignment ensure expectation object make load cost attribute equal load cost candidate load consider consider random sequence set object access query line figure six point ship cost could attribute object load manager employ two make use efficient explain need explicit track total cost due query object inefficient load manager eliminate explicit track total cost use randomize load line lead implementation algorithm counter object maintain ship cost single query cover entire load cost object object immediately make candidate load else make probability equal ratio cost attribute query object load cost give subsequence load request generate q say om possible give load evict accommodate later subsequence clearly load useful iron use lazy version case object load system ensure update come object load apply object mark fresh cache server cache invocation query q access object b q network traffic cost q objective load useful object thirty c q b q object cache c zero object b q cache c l lazy input c c l else probability lazy input c zero load evict object accord lazy lazy load server cache mark fresh l load cost randomize load fig six cache give object cache algorithm discussion several would like highlight first delta focus reduce network traffic consequently present include reduce network traffic naturally decrease response time query access object cache query update need apply may delay weather prediction similar minimize overall response time equally important improve response time performance delay query update ie send server lack space omit improve overall response time query direct reader accompany technical report delta architecture data update correspond predominantly data insert section three true scientific however decision make independent update specification imply data modification insert delete modify thus choose use term update adopt randomize mechanism load object obviate maintain counter object efficiency motivate issue remote data access cache data several sit finally implementation require semantic framework determine map query q data object b q access complexity framework depend upon granularity data object define object table map determine specification query object find map apriori difficult however map find exploit semantics instance astronomy query specify spatial region object also spatially partition thus find map do describe section six five benefit alternative approach problem present algorithm exploit combinatorial structure compute cover within data problem make adaptive use borrow four alternative approach solve data problem exponential algorithm make base term algorithm benefit inherently greedy decision make benefit divide sequence query update size begin new window object currently cache compute benefit accrue keep cache past window one define network cost object save answer query cache less amount traffic cause update ship server since query answer cache may access multiple object cost ship save divide among object query access proportion size form divide cost find useful cache well object currently cache compute similarly benefit would accrue cache window one reduce benefit cost load object forecast benefit object accrue next window compute use exponential smooth one forecast previous window zero one learn parameter next consider object positive value rank decrease order window greedily load object order cache full object already present cache window one reload lack space benefit present paper include accompany technical report benefit reliance similar previously propose view materialization however suffer foremost benefit ignore combinatorial structure within problem divide cost ship query among object query access proportion size difference benefit performance prove analytically however combinatorial structure lead mathematical bind performance detail proof performance reader direct technical report benefit decision make heavily dependent size window choose also need maintain state object value query access irrespective whether cache six empirical evaluation section present empirical evaluation delta real astronomy query data experiment validate use data framework minimize network traffic experimental result show delta use reduce traffic nearly half even cache size server outperform benefit factor vary different condition experimental setup choice survey data rapidly grow currently unavailable public use thus use data query trace experimentation periodically publish update via new data release build rapidly grow repository simulate update trace consultation use data validate delta reasonable choice similar open public use estimate query similar setup prototype system consist server cache implement processor memory run run server sequence data update apply server query currency specification criteria arrive concurrently cache satisfy query latest data server cache use server replica management system ship query update necessary use bulk copy object load use data communication mechanism dictate optimization framework delta implement store server cache server data server partition spatial data object build spatial data object use primary table call table store data astronomical body include spatial location physical attribute size table roughly table partition use quad treelike index call hierarchical triangular mesh nineteen index conceptually divide sky partition partition translate roughly data object partition sky therefore data depend upon level index choose experiment use level consist partition ignore query contain data partition give one choice object base cache granularity experiment explain section data object vary low fifty high ninety growth data update form new data insert apply spatially define data object simulate expect update pattern astronomy survey consultation telescope collect data scan specific sky along great circle systematic fashion forty update thus cluster sky base pattern create update size update proportional density data object query extract query query receive trace consist several query include range query spatial query simple selection query well aggregation query trace involve remove query query log trace query network traffic due query due table view define query query bypass ship server cost traffic cost ship query actual number result current traffic cost ship update choose match expect update traffic day sample query update event sequence show figure seven sequence along event update put blue diamond next affect update event query put yellow dot next access query even though rough figure show sample update query include correspond cost ship support discover experiment query eleven twelve thirteen thirty update figure also indicate query follow clear pattern fig seven correspond query red ring update blue cross event query evolve cluster around different object time b cumulative traffic cost almost good outperform two three compare core algorithm delta benefit heuristic algorithm forecast use exponential smooth also compare performance two three act algorithm consider poor excellent perform better worse use cache ship query server algorithm case benefit performance worse clearly use replica let cache large server contain server data satisfy query current data ship update cache soon arrive server benefit respect cache size limitation perform better replica clearly good decide best static set object cache see entire query update sequence conceptually decision equivalent single decision benefit use large entire sequence manner implement algorithm load object need begin ever evict object update arrive object cache ship algorithm see query update advance performance close outstanding default parameter value period unless specify otherwise follow experiment set cache size thirty server size window size benefit choice obtain vary experiment obtain optimal value cache undergo initial period benefit large period characteristic particular trace query small query cost occur trace result object low probability load period cache remain nearly empty almost query ship general update event traffic cost query update event experience trace similar size show range warm period anywhere focus interest post period show cost incur period result minimize traffic cost cumulative network traffic cost along event sequence two three figure seven clearly superior benefit query update arrive continue perform better end trace improvement factor least two benefit replica factor fifteen replica load cost cache size ignore data intensive query arrive benefit barely better closely follow event diverge lead final cost forty higher closer examination make algorithm discover hindsight determine four would useful cache load begin discover cost query arrive object load around event thus pay query ship cost load cost vary number update cache algorithm dynamic data maintain performance face different rat update query figure eight b plot final traffic cost algorithm different query different number update simplistic yardstick replica take account relative number update query since query remain cost steady number update increase cost replica go threefold increase number update result threefold increase replica cost three contrast show slight increase cost number update increase work choose appropriate object cache update compensate keep object cache slight increase cost due query ship cost pay object longer viable cache experiment illustrate well benefit delta irrespective relative number query update choice object figure eight plot cumulative traffic cost along event sequence different data object choice correspond different level quad tree structure set ten object correspond set object correspond set cover entire sky contain entire data performance improve dramatically number number object increase size reduce reach begin slightly worsen initial improvement object become smaller size less space cache waste finer grain thus effective trend reverse object become small since likelihood future query entirely contain object cache reduce explain next observe scientific likely future query access data fig eight traffic cost vary number update b cumulative traffic cost different object set close relate rather exact data access current query astronomy partly several task scan entire sky consecutive query seven conclusion science grow rapidly size also increasingly interest time dimension thus demand latest data part query result current cache provide minimal support incorporate latest data repository many assume static often result runaway network cost paper present delta dynamic data cache system rapidly grow delta base data separate object rapidly grow object heavily query effective framework naturally minimize network cost delta rely robust adaptive algorithm data object examine cost usage currency base sound graph theoretical make solution nearly optimal evolve scientific compare performance benefit greedy heuristic commonly employ dynamic data cache commercial experiment show benefit scale poorly scientific respect deployment delta would need also consider several issue reliability communication future depend scalable facilitate access data large number presence overload network delta step towards meet challenge author sincerely thank motivate problem us describe network management issue design cost number cumulative traffic cost query update event object survey ani acknowledge support project reference one k park r dynamic data cache web l data engineer two c li achieve communication efficiency partition semantic space disseminate dynamic information knowledge data engineer eighteen ten three c c h b cache highly scalable l management data four r computation competitive analysis university press five k w li q w p enable dynamic content cache web sit l management data six k li q enable dynamic content cache web sit record thirty two seven p proxy cache symposium eight c r c stein introduction press nine dar j franklin b tan semantic data cache replacement l large ten p k p adaptive disseminate dynamic web data l world wide web eleven al story knowledge data engineer two one twelve intractability guide freeman company san thirteen c b c scalable query result cache web l large fourteen h p r j support relax currency consistency l management data fifteen editor approximation publish company sixteen r sloan divergence cache client server international conference parallel distribute information seventeen n kaiser optical survey telescope array telescope one page eighteen n kaiser al large synoptic survey telescope array nineteen p hierarchical triangular mesh mine sky workshop twenty n materialization record two n explore performance data freshness web journal thirteen three c p f data model record seventeen three large synoptic survey telescope malik r burn bypass cache make scientific good network l data engineer malik r burn n approach query estimation innovative data research malik x wang p little r robust cache scientific c b loo j adaptive precision set cache approximate value record thirty c c b c service dynamic web c j cache synchronization source l management data thirty survey telescope rapid response system g content distribution network preprint p protopapas r c fast identification transit journal reference mon soc sloan digital sky survey j storage resource essential grid academic v singh j gray r j b b traffic report first five technical report technical report wa algorithm design manual springer w illustrate vol one pub boston p r w new architecture distribute data conference data engineer p w sah j c distribute system journal five one forty j gray r p z malik j c j public access sloan digital sky server data l management data time ten team data management application tier international conference data engineer x wang malik r burn unit cache replacement cache advance volume page e w vertex cover wolfram web resource