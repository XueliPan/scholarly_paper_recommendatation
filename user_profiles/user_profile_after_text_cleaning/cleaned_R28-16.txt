latent number orthogonal factor latent semantic analysis abstract seek insight latent semantic index establish method identify optimal number factor reduce matrix represent method demonstrate duplicate document contain term insert new document replace examine number time term identify search term precision use differ range dimension find lower rank dimension identify relate term dimension discriminate subject information search retrieval retrieval model general term correlation method latent semantic analysis information retrieval text mine singular value decomposition introduction task retrieve document relevant user query large text complicate fact different author use different word express relate latent semantic analysis interpret variability associate expression concept noise use linear algebra isolate perennial concept variable noise follow word author six latent semantic analysis approach take advantage implicit structure association term document semantic structure order improve detection relevant document basis term find query particular technique use singular value decomposition large term document matrix decompose set ca orthogonal factor original matrix approximate linear combination document represent ca item factor weight query represent form weight permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee three one canada copyright term document cosine value return large number factor weight provide approximation close original term document matrix retain much noise hand many factor discard information loss large objective work identification optimal number orthogonal factor section one define representation document present associate document retrieval method section two original latent semantic method present method inspire latent semantic analysis develop research laboratory fifteen present section three extend section four enable determination adequate number orthogonal factor numerical experiment section five validate method one representation discuss paper rely representation document replace vector attribute two attribute usually present document information like time span stem use model one twenty vector naught correspond attribute absent document unity present term weight refinement take account frequency appearance word within among document location appearance title abstract section header popular weight scheme variation model vector representation document give di wi wi one wi term frequency number time term wi occur document wi inverse document frequency inverse number document word wi occur representation use retrieve document relevant user query vector representation derive query way regular document compare representation use suitable measure distance similarity distance angle commonly use measure possible five eleven sixteen formally call matrix document n attribute form document q vector representation query dissimilarity measure compute q order document respect dis similarity query representation usually lead matrix include several attribute cause serious term computational complexity conceptual term goal design efficient algorithm process several filter approach lead reduction size vector representation prune consist remove infrequent frequent word usually carry little information ten replace inflect word root order regroup form semantic content two latent semantic analysis problem former retrieval method mention introduction similarity query give document underestimate user document author use different express claim latent semantic index six one successfully overcome problem take account synonymy polysemy synonymy refer existence equivalent similar term express idea polysemy refer fact word multiple unrelated mean account synonymy lead overestimate dissimilarity relate document account polysemy lead erroneously find document idea behind reduce dimension information retrieval problem project document n attribute matrix adequate subspace lower dimension achieve base singular value decomposition two v orthogonal matrices diagonal matrix dimension n denote one p p min n one two p matrix k dimension k rank term norm obtain set zero k equivalent reduce v k first k first row denote reduce matrices k v k k respectively order reduce dimensionality problem k singular value maintain instead compare n dimensional represent document original space define compare k dimensional subspace base k projection original document representation give k k one v k compare result operation query vector q project subspace three four document query q identify reference dissimilarity function k min zero q k v k five document retrieve way th row second third later number document attribute large involve manipulation large sparse matrices possible improve performance memory significantly use data representation model specially design handle matrices fourteen present formal similarity latent semantic analysis probabilistic latent semantic analysis eight another method take synonymy polysemy account start point call aspect model three nine two consider latent manifest latent observe directly manifest condition model dependency possible retrieve underlie reference problem concept express different analogy make latent variable concept one hand vocabulary use express manifest hand three covariance method instead decompose document matrix covariance method fifteen apply singular value decomposition covariance matrix covariance matrix dimension depend number number document covariance method able handle several hundred document moreover covariance matrix need update time batch new document enter data base aspect particularly important context electronic network new data become continuously available see nineteen eighteen handle problem see twelve thirteen discussion advantage covariance method number document number attribute method involve manipulation large sparse matrices number document ad vector represent document mean ie one ad covariance matrix write c ad ad matrix symmetric singular value position write c v orthogonal diagonal matrix order singular value reduce k ie singular value project space k dimensional subspace six seven q k q k k one v k k q k eight compare document last subspace section two motivation behind multiplication document matrix covariance matrix approximation lie fact present document correlate take account well even explicitly present present document obscure choice specific vocabulary four embed send covariance matrix onto subspace dimension imply loss information see interpret merge mean general concept encompass example cat mouse might merge concept mammal merge concept animal result latent semantic index covariance method course expect clean example illustrate understand underlie concept present criteria determine number singular value necessary correctly distinguish dictionary along definition understand correctly distinguish correlation method method use base correlation matrix otherwise identical covariance method present former section correlation matrix define base covariance matrix c si j nine j matrix symmetric singular value decomposition write seven result decomposition use send document k dimensional subspace eight use correlation rather covariance matrix result different weight correlate justification model remain otherwise identical validity consider follow property singular value de composition four ten use notation easy see rank k approximation k write k eleven k n also definition n k approximation correlation matrix argue favor follow argument approximation correlation matrix correctly represent give correlate attribute term k mean even though diagonal equal unity greater nondiagonal row column matrix symmetric give condition write k k one n twelve simplify later discussion introduce next say valid rank k satisfy twelve say rank k k one value twelve verify case k validity rank five numerical experiment numerical experiment base data base collection article extract complete information please refer seventeen seven collection article time purpose study use paragraph document result collection document form extract stem word use porter algorithm remove appear either less two user specify present result base different map document use representation describe one facilitate read refer one base form even though stem form use experiment first experiment claim give correctly represent rank k approximation correlation matrix k least equal validity rank order verify conduct experiment describe one select example extract text data base document contain two produce new copy document replace select arbitrary new example replace one translation word three add new document original data base vocabulary four compute correlation matrix singular value decomposition extend new data base define new subspace send document retrieval note far correlation matrix concern perfect five send original data base ie data base without attribute new subspace issue query hope find document contain first conduct experiment different approximation k correlation matrix compare precision define precision ratio number correctly retrieve document ie document contain example total number retrieve document two n c e r p zero zero one zero eight zero six zero four zero two zero vocabulary use translation commerce exist drop precision reach validity rank low still present usual validity rank precisely define drop precision observe soon rank reach fig three use vocabulary duplicate network validity rank precision rank value well sixty higher rank zero twenty forty sixty eighty document validity rank figure one replace curve correspond rank start null precision remain curve lower validity rank choose various vocabulary discuss representative result choose highly poorly correlate trade frequent appear less half percent document network study significantly statistics relevant find table one trade duplicate stem vocabulary count doc rank yes ten yes five network yes three table one vocabulary entry refer number vocabulary count number time stem appear doc percentage document contain rank validity rank vocabulary extract rank valid fig one plot proportion document contain number retrieve document precision compute different number orthogonal factor refer rank figure legend rank inferior equal start remain higher achieve rank superior precision increase rank validity rank reach drop sometimes quite dramatically illustration provide result two experiment two trade replicate n c e r p five nine nine five eight nine five seven nine zero twenty forty sixty eighty document validity rank figure two trade replace precision improve rank rank identical precision range document performance deteriorate value beyond validity rank might wonder property validity rank verify correlation matrices specific text experiment conduct show second assumption correct correlation matrices base random text contain document meaningful fail observe correspondence retrieval quality validity rank interpret result follow first range validity rank add orthogonal factor improve information explain precision gain second range validity rank full rank subspace contain enough information distinguish synonym pair like trade consequently search return document contain precision search return document contain trade experiment show relation concept associate concept actual low rank k augment number orthogonal factor help identify concept common orthogonal factor beyond validity rank help distinguish synonym n c e r p zero zero one zero eight zero six zero four zero two zero r zero one eight zero six zero four zero two zero zero zero zero twenty forty sixty eighty document validity rank rank figure three network replace precision validity rank deteriorate drastically beyond figure four r hit vocabulary validity rank second experiment return versus experiment former interpretation correct number return document contain must approximately equal number document contain long number orthogonal factor lower validity rank exceed document contain exact query retrieve fig four show result experiment conduct verify hypothesis increase number orthogonal factor represent abscissa identify group g fifty similar document query plot ordinate ratio r document contain divide total number document contain either also plot number divide g fifty certain number retrieve document large enough r make sense see forecast r approximately equal fifty rank valid beyond rank document contain largely dominate group third experiment give correctly represent validity rank histogram validity rank whole vocabulary use determine number orthogonal factor beyond much information gain compute subspace see eight five six present first figure around orthogonal factor seem sufficient vocabulary apply approximately require vocabulary use conclusion examine dependence latent semantic structure number orthogonal factor context correlation method analyze explicitly claim follow latent semantic analysis provide method take account synonymy propose method determine number orthogonal factor give best represent associate latent semantic concept show concept correspond give capture first orthogonal factor validity rank define remain orthogonal factor help distinguish also show optimal number orthogonal factor depend query well document collection give upper bind number orthogonal factor need represent correctly might include extension multiple query six author would like thank comment also want thank correct seven reference one r learn apprentice world wide web spring symposium information gather heterogeneous distribute two r b modern information press three martin latent variable model factor analysis second edition library statistics volume seven four w berry w use linear algebra intelligent information retrieval technical report five rich greedy attribute selection international conference machine learn page histogram validity rank zero zero eight zero zero six zero zero four zero zero two zero zero zero zero one zero zero eight zero zero six zero zero four zero zero two zero zero zero rank rank figure five validity rank vocabulary figure six validity rank vocabulary eight probabilistic latent semantic six g index latent semantic analysis journal society information science seven harman e special publication proceed fifth text retrieval conference page department commerce national institute technology index proceed annual conference research development information retrieval page august nine unsupervised learn dyadic data technical report ca ten probabilistic analysis algorithm text categorization international conference machine learn page eleven h irrelevant feature subset selection problem international conference machine learn page journal version available twelve major outlier cluster analysis use dynamic document proceed text mine workshop crystal city page thirteen thirteen vector space model search cluster mine invite paper berry comprehensive survey text mine springer publish fourteen g efficient estimation singular value search large dynamic web ninth world wide web conference fifteen l h retrieval rank document patent fill june sixteen map volume thirty springer series information springer berlin new york second edition seventeen lewis text categorization test collection distribution ten eighteen incremental cluster category drift nineteen use competitive network text mine berlin twenty j identify interest web sit spring symposium machine learn information access lecture note computer science eleven f porter algorithm suffix strip program vol fourteen three page g c automatic structure retrieval large text file two b prototype feature selection sample random mutation hill climb international conference machine learn page tate learn revise user profile identification interest web sit tate advance plan technology park press machine learn yang expert network effective efficient learn human text categorization retrieval annual international conference research development information retrieval