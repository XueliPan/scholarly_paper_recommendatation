brief announcement towards soft optimization parallel cognitive chi computer laboratory university subject program concurrent program parallel program general term performance optimization cognitive parallel program parallel one introduction world data grow exponential rat deal glut information computer must able understand interpret data ways provide practical knowledge one process ever increase data set often within cognitive stress performance memory storage modern meet performance even relatively small data set three parallel multicore share memory provide scalable performance necessary theory cognitive task map well parallel node process subset input data operate portion current state knowledge practice however many issue lead suboptimal cognitive parallel task use irregular data structure sparse array graph frequently lead work imbalance synchronization excessive communication across nod poor cache locality parallel paper suggest soft optimization cognitive run share memory goal eliminate execution discover additional higher performance motivation cognitive exhibit soft compute six conventional transaction process operate precise data strict accuracy hand cognitive process inherently noisy input must handle uncertainty eventually produce acceptable approximation correct answer hence may able skip large amount computation communication among concurrent thread order improve performance without necessarily degrade quality output significantly suggest follow soft promise performance correctness redundancy computation communication pattern inherent six four base propose four type general optimization target common bottleneck parallel specifically reduce copyright hold seven june san mitigate work imbalance reduce communication decrease synchronization overhead paper review optimization summarize major performance correctness convince case study evaluate loopy belief propagation five aggressive parallel system demonstrate soft lead large performance aggressive parallel system without significantly impact application accuracy believe soft compute valuable resource algorithm application target parallel program model system two soft focus soft correctness redundancy computation communication pattern inherent suggest follow four set soft reduce computation first set exploit various type order reduce work per thread without significantly reduce output accuracy data drop cognitive task receive superfluous incoming data small portion data carry critical actually new information usually critical accuracy lazy computation task converge node allow decide independently whether continue compute lazily base neighbor convergence solution prune aggressively prune low fitness unlikely optimal one significantly reduce work per thread mitigate imbalance two major source imbalance parallel program imbalance occur unevenly distribute work across thread region imbalance occur thread work idle synchronization point barrier wait thread catch deal suggest follow adaptive discard deal imbalance make busy thread reduce computation aggressively idle thread selective reduce region imbalance allow thread selectively skip skip iterative may thread use slightly date input run ahead thread however thread synchronize reasonable frequency iterative nature allow thread eventually operate input reduce communication frequent communication thread expensive especially parallel suggest follow technique reduce communication adaptive communication task graph node communicate message neighbor convergence portion graph reach convergence early additional message redundant drop reduce synchronization synchronization lock necessary correctness lead performance block thread operate parallel cognitive relax correctness adapt reduce synchronization frequency use follow imprecise update cognitive task common scan test update global active work set next iteration since number distribution know advance static distribution may possible synchronization use heavily many case apply imprecise update noncritical cod accuracy eliminate synchronization significantly enhance performance remove synchronization case conflict thread expect rare remove synchronization completely rare case conflict occur may localize error application state correct time iterative process three case study loopy belief propagation understand impact soft application performance correctness develop follow optimize parallel code iterative cognitive application calculate propagate graph five adaptive message version one version reduce communication computation sender receiver converge sender calculate send new belief message technique may also mitigate thread assign nod often drop thread less nod adaptive message version two version reduce communication computation well sender converge create send message new neighbor regardless state neighbor skip message aggressively compare version one expect performance reason version one technique would also mitigate lazy belief computation version focus computation reduction node go lazy mode difference previous current within certain threshold lazy mode node calculate new go back busy mode new message arrive evaluate optimize simulate aggressive share memory hardware support transactional memory two figure one show normalize execution time execution time normalize base sequential code time ten bar break time execute useful time spend service cache miss synchronization time due imbalance communication time commit time spend atomic block roll back violate base version suffer imbalance due uneven graph partition apply useful synchronization time significantly reduce primarily figure one normalize execution time additional misclassification rate base optimize due fact thread assign nod drop message show better performance drop message aggressively compare also reduce useful computation compare perform worse consider neighbor node eliminate work adaptive message technique finer grain elimination rightmost bar represent combine optimization expect version provide best possible performance overall base version also verify soft lead higher performance gain scale parallel figure one also present additional miss classification rate version use metric accuracy qualitatively indicate many additional occur apply classification model compare base version algorithm numerically define miss throughout accuracy loss within two indicate outstanding tolerance soft drop large percentage redundant belief calculation message critical accuracy lead large performance gain interest note produce higher accuracy original code probabilistic nature cognitive sometimes allow soft optimization deliver better performance higher accuracy benefit present robust across multiple data set omit detail result due space four reference one cass winner fountain knowledge one two h al scalable nonblocking approach transactional memory international symposium high performance computer architecture three p recognition mine synthesis move era tera technology magazine page four x li exploit soft compute increase fault tolerance proceed workshop architectural support integration june five k murphy al loopy belief propagation approximate inference empirical study proceed annual conference uncertainty artificial intelligence page san ca morgan six l fuzzy logic neural network soft compute three execution loss