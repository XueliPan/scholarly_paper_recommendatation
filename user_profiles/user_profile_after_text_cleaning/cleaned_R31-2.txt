efficient query distribute provenance store kim sri international park ca malik university west lafayette abstract current project collection provenance information use centralize architecture manage result provenance gather remote host submit central provenance management service contrast develop completely decentralize system computer maintain authoritative repository provenance gather model several advantage scale large amount generation provide access provenance local data avoid need synchronization central service operate disconnect network let retain control data provenance record describe spade project support track data provenance distribute include query optimize provenance sketch cache subject information information search retrieval provenance lineage query distribute storage one introduction provenance piece data utility wide range demonstrate numerous research industrial develop sixteen fifteen particular interest data distribute among several heterogeneous autonomous information often combine make useful analysis key issue collection provenance information record especially material base upon work support national science foundation grant find express material author necessarily reflect view national science foundation concern data flow across system equally important question query efficiently nine eighteen current provenance record fifteen sixteen one use centralize architecture manage result provenance gather remote host distribute system periodically submit central provenance management service ensure consistency data however increasingly observe centralize approach scalable provenance audit finer granularity grow exponentially number record step often become actual data six transport large amount central service introduce network overhead create substantial latency provenance query seventeen provenance similarly data must distribute large handle distribute provenance model several attractive advantage access provenance local data need synchronization central service operate disconnect network maintenance user privacy retain complete control data provenance record latter aspect particularly vital distribute distribute provenance model introduce challenge well first question arise audit movement file loss couple file content associate even file move due large size user able subsequently retrieve file associate track distribute provenance require audit process network ideally audit require modification extant user program another challenge efficiently trace back distribute provenance audit view direct graph data structure trace path direct graph query know expensive operation twenty case distribute provenance become expensive term network well since provenance unlikely locate locally spade support provenance audit distribute decentralize system computer node maintain authoritative repository provenance gather system perform passive monitor driver kernel intercede specific system call record data flow process network compute node collect provenance data store locally relational oblivious spade provenance collection distribution distribute provenance query answer permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior june file two read open close file one read open close process execution time file three process owner open file three write close file one file two figure one track data flow process provenance graph representation automatically create transparently efficiently spade rely two crucial optimize query execution local cache store provenance data compute nod sketch efficient storage provenance answer path query provide background provenance section two section three outline data model capture provenance information distribute section four outline improve latency provenance query describe relate cache work section five conclude section six two background provenance gather divide three depend upon whether data centrally locate data distribute transport central location periodic basis data distribute central data model introduce lineage file system insert kernel record process creation destruction open close truncate link file initial read write file socket pipe creation output periodically transfer local storage system pass audit monitor incorporate record hardware execute process provide integration data store record use port pass design use single node although design extend file server paradigm pass provenance record query server way transmit architecture also employ project recent model sixteen extract provenance information automatically arbitrary monitor execution environment log record much granularity pass follow centralize model log execution output data transport central location disadvantage approach collect requirement restrict expressible specific language addition limit scope possible require master exclusively use specific author environment sixteen several provenance need trace across tiple system requirement describe centralize model pass thirty sixteen well several distribute three nineteen distribution provenance primarily allow data several heterogeneous autonomous information grid distribution consider necessary efficiently answer query data example replica location service ten provide mechanism register existence discover service distribute reduce update query load rely periodic update keep state become stale another example storage resource broker federate store pair divide zone forty efficient scheme query provenance data also receive considerable attention recently describe new language query provenance leverage query optimization propose provenance index improve execution forward backward provenance query query optimization compress provenance data also consider twenty recently underlie architecture single central provenance store describe challenge query distribute provenance network cost dominate three record provenance distribute assume host within distribute environment common allow host freedom maintain independent accompany distribute correspond general framework distribute computation data share across organizational provenance record infrastructure overlay coherent framework facilitate reason data distribute environment particular infrastructure track data flow within host across host record provenance track data flow require system identify source piece data define granularity piece data track single host immediate source piece data process may turn use data write process execute host addition data flow within single host process may read data host network event cat figure two vertex show circle represent execution process every vertex show rectangle represent file network vertex depict use rectangle round corner represent data flow protocol provenance data modify process must also include provenance data read remote host adopt convention identify data location system time last modify ensure previous statement hold true even multiple process modify file since different point time single kernel mediate access local even multiple core host granularity track provenance data object affect overhead introduce system advantage audit level assembly system call example information flow trace precisely allow output exact ascertain reconstruct exercise portion control flow graph relevant process disadvantage system performance perceptibly degrade monitor generate large provenance since persistent data manage file granularity reasonable compromise level abstraction track data provenance define term file read write first type element provenance graph file vertex include various attribute associate file host size file last time modify hash content provenance file discuss root associate provenance graph vertex correspond file adopt convention identify file use logical location last time modification different file avoid cycle provenance graph second type element provenance graph process vertex contain range attribute name process operate system identifier owner group vertex also include parent process host process run creation time process command line initiate value environment edge provenance graph direct signify data flow edge file vertex indicate file read edge file vertex write file analogously edge lead process read operation perform process edge process vertex write operation consequently read write process model data flow graph depict figure one context provenance define semantics primitive operation output file process generate set input file read course execution example program read number data set disk compute result record file primitive operation perform process modify number file separate instance representation use output file primitive combine compound operation instance result append together several data set program cat sort particular order use another program sort execute separate process combination append sort compound operation thus provenance every file represent compound operation direct acyclic graph consistent model use grid project consider simple example operation span multiple host user identity user machine name use connect remote host run cat program output content file output redirect file host command invoke effectively copy content remote file local file user cat similar command analogous file transfer like commonly use large distribute move input data idle retrieve result execution complete provenance track restrict query provenance level f level f f level two f e x e r e v f h h p r g l l f path figure three sketch facilitate path query without reconstruct entire provenance graph level one one vertex file would able establish connection file machine one approach address gap describe record information host process run file locate provide mechanism transfer provenance file move one computer another record refer part provenance graph originate remote host explicitly use host attribute scheme ensure provenance query answer destination host incur considerable storage overhead seventeen alternate approach would avoid replicate provenance record destination host file transfer instead provenance store destination would provide pointer back relevant provenance source host however provenance query destination would require source host contact slow response time decrease reliability since remote host may unreachable example distribute data flow take form file transfer practice data may also flow network directly one process another case series call make one host another pass document include request correspond return value accommodate flow introduce fourth type element provenance graph network vertex figure two depict simplify version provenance graph file would arise execution command describe key point note provenance vertex network connection example independently construct host two end network connection allow complete decentralization provenance record distribute system host provenance infrastructure operate independently yet time provenance record generate piece together yield coherent complete reconstruction distribute data flow four query provenance spade allow user ask wide range question data store program run system include query provenance challenge international provenance annotation workshop well query program use create file program run file write file program read could data flow file file sequence process file read write lead flow query query require access entire provenance graph output file provenance path provenance graph specific input output vertices user wish ask query employ spade query tool interact local provenance store query resolve local information user must contact source network typical provenance graph associate file span numerous necessitate commensurate number high latency network reconstruct entire provenance record improve efficiency execute distribute provenance query spade currently implement two approach reduce latency query first optimize query execution use summary structure describe section second employ provenance record remote host file transfer use overload eighteen section describe cache still design stage provenance sketch current provenance query one six assume access entire provenance graph run query since assumption associate retrieval cost decentralize spade explore scheme exploit semantics query type avoid retrieval provenance information possible benefit easily see input vertices provenance record local remote store nothing replicate remote node output map procedure vertex v choice vertex choice transfer remote node evict nod initialize gain improve unlock vertices unlock vertex find best vertex choice perform choice lock vertex gain gain figure four strategy pairwise exchange record distribute provenance store system example depict figure three consider case provenance graph consist tree level f vertex except leave path query need information rather f present entire graph f grow retrieve many instead many f reduce delay substantially one strategy effect path query optimization implement provenance sketch contain representation attribute file process modify file combination input sketch store output provenance sketch consequently try determine computer particular input originate provenance sketch use pick correct one turn allow provenance query resolve traverse back sink source without inspect irrelevant may require network data originate salient feature approach provenance sketch opaque allow propagate without compromise privacy provenance source decentralize global knowledge provenance file distribute system facilitate optimal selection enable development cluster approach previously describe eighteen however many access feasible make aware fact begin investigate need nightingale project aim let monolingual query information document multiple input data transform multiple time automatic speech recognition machine translation distillation extract query nightingale pipeline several step perform multiple develop parallel fifteen since functionality different tool also differ description tool produce piece data serve input subsequent tool pipeline currently maintain file accompany data low latency access provenance data available maintenance accompany file would obviate low latency significance would enable query determine tool pipeline yield output since project loose collaboration independent approach rely access everyone provenance would face administrative challenge instead scalable approach would bootstrap system optimize cache within cluster share occur practice subsequently data cross system could augment record provenance use information would also allay privacy concern limit provenance store communication trust provenance gossip instead collect provenance record entire system attempt decide place decentralize approach operate follow gossip protocol use provenance store pair host system periodically interact algorithm build fourteen use circuit design algorithm attempt minimize wire chip circuit partition among contrast algorithm replicate vertex different partition potentially evict extant one gain warrant action cache original algorithm action possible consider two vertices different partition either swap nothing framework wish allow also introduce possibility replicate vertex partition address fact finite amount storage use cache copy provenance occur remote host must also allow vertex delete evict local cache correspond operation perform local host vertices local must never delete since figure five provenance flow query client provenance store cache cache transparent client aim minimize total network traffic generate provenance store sum traffic load update cache query result bypass cache send directly client definitive copy may retrieve copy evict gain function decide action take vertex gain function utilize gain define difference benefit cost function framework agnostic specific function use allow us consider multiple criteria query response time host reliability joint request originate multiple host simple benefit function would compute maximum likelihood query would use vertex consideration host vertex originate reachable within time similarly cost could define sum storage use vertices weight probability use answer query system even use gain function depend expect application query although efficacy strategy remain validate map algorithm original framework use two nest loop perform map provenance vertices associate cache eviction action inner loop action vertices compare estimate would result gain none would yield gain one would impose least penalty select ensure algorithm subject local maxima select vertex lock signify consider successive inner loop unlock vertices available inner loop proceed complete vertex use compare current map vertices compute map new map yield higher cumulative gain replace current map outer loop continue long gain improve run inner loop outset iteration outer loop vertices unlock essence process illustrate figure four cache client store make provenance query may host different provenance gather example provenance may gather nod grid cluster computation farm machine perform data analysis may run provenance audit system cache place provenance store provide twofold benefit transfer computational load provenance store cache improve query reduce congestion result drop network traffic query cache process locally fetch necessary vertices evaluate query cache alternatively query pass provenance store evaluate result return directly client third option use semantic cache twelve query partially evaluate remainder ship provenance store cache use web eleven fifty translate well provenance context cache exploit page link structure web make cache objective web proxy case maintain popular set file cache order maximize hit minimize expect remote access cost file request find cache cache make assumption request associate exactly one file case provenance cache request involve multiple vertices provenance graph query service relevant vertices cache since vertices independent share multiple request vital cache exploit link structure make inform cache bypass cache cache strategy aim load cache set vertices maximize probability arrive request find vertices need cache previous cache research assign equal importance object greedily cache provide network save approach diverge previous cache research two ways first aim exploit link structure vertices determine important vertices cache second attempt greedily cache vertices improve latency throughput query instead balance amount network traffic cache manager generate greedy cache detrimental performance use provenance query least three possible case instance would preferable result bypass cache return directly client instead illustrate figure five first case occur future query use retrieve vertices expect produce relatively little network data traffic second case arise incoming vertices expect short lifetime cache third case materialize different file rapidly generate invalidate result provenance query every case benefit serve future request cache worth cost evict vertices load cache retrieve vertices therefore preferable force future query retrieve vertices provenance store exploit link structure introduce concept employ cache determine importance vertices eight seven use treat link page page b vote b highly link page important page link back link page high count link page low follow vertex high rank sum rank back link high however also measure depth vertex provenance graph thus two vertices back link one recent ancestry distinguish give vertex higher rank unlike suffer problem compute direct acyclic graph eight account network utility capture good approximation usefulness derive direct link structure provenance graph however capture network utility vertex important measure reduce latency capture measure probability access quantity data actually use provenance query since query may filter aggregate partial information vertices account make substantial difference efficacy cache eviction policy similarly calculate network utility assign variable benefit vertices depend upon frequency access much data actually use query result five relate work web grid adopt object cache model eleven variable size cost cache algorithm fifty first introduce variable fetch cost io page model algorithm adapt technique object web cache eleven find compare favorably heavily handle variable size retrieval cost add semantic information track access frequency improve object cache recognize request often arrive different file know bundle rather single file provenance model similar object cache model variable size cost need cache improve performance query however provenance query differ web request since object provenance graph link structure manner cache mechanism must account order exploit available locality reference especially true cache recursive lineage query centralize management also address concern use cache time ten two use cache avoid bottleneck central server four support structure data cache edge cache large number overlap dynamically change materialize view hierarchical cache construct analytical process primary goal cache improve application performance query latency reduce network traffic consider secondary provenance data cache require reduction latency network cost scientific geographically distribute network bind address combine issue latency network traffic cache tailor web model need distribute scientific dramatically reduce demand improve latency however scientific witness explosion number object occur provenance relational object also exhibit graph structure see provenance graphical structure provenance analogous web graph manage social network web sit thirteen seven eight algorithm provide effective rank mechanism large structure rank web page include hit algorithm use five current research handle graph examine interaction web page rank cache management six conclusion spade system audit provenance distribute describe spade stitch provenance graph collect different host use summary data structure cache answer distribute provenance query spade adopt decentralize model record provenance keep local host generate move demand user spade thus reduce cost expensive network transfer provide complete control local provenance record seven reference one p ad c j trio system data uncertainty lineage international conference large data base two q c h b g l brown cache web application international conference management data three j apply provenance distribute organ transplant management springer lecture note computer science vol four park dynamic data cache web international conference data engineer five six k issue automatic provenance collection springer lecture note computer science vol seven brin l page anatomy file system extensibility reliability web search engine world wide web conference use master thesis state university new york stony brook eight brin l page citation rank wang efficiency bring order web university technical report provenance query international conference data engineer nine chapman h v issue build practical b w lin heuristic procedure provenance data engineer ten al n c r performance replica location service high performance distribute compute eleven p proxy cache symposium technology twelve dar j franklin b tan semantic data cache replacement international conference large data base thirteen fourteen c r linear time heuristic improve network partition annual conference design fifteen foster j chimera virtual data system represent query data derivation international conference scientific statistical management sixteen j p slaughter automatic capture reconstruction computational provenance concurrency computation vol twenty five seventeen bonsai balance lineage authentication annual computer security conference computer society eighteen kim step toward manage lineage grid cluster theory practice provenance affiliate conference file storage nineteen p l provenance record service second hand meet twenty g efficient lineage track scientific international conference management data k choose data model query language provenance international provenance annotation workshop page replacement page web cache symposium theory compute z web proxy cache international conference distribute compute z web cache exploit two source temporal locality web request stream computer vol two p w b c tan adaptive network distribute cache result international conference management data partition graph bell system technical journal vol two authoritative source environment journal vol five thirty j c da k sensor data storage international workshop network meet malik r approach federate conference innovative data research malik r burn bypass cache make scientific good network international conference data engineer connect scientific data scientific experiment provenance international conference grid compute luck l model provenance data autonomous international joint conference autonomous l b r bower g chin b e l foster j j j c j p j kim g j b n v e c k first provenance challenge concurrency computation practice experience vol twenty five n z p nain new efficient cache policy world wide web workshop server performance novel information gather harvest intelligence global autonomous language exploitation e optimal cache forty wan r w g c b r storage resource distribute data grid computer society journal vol four storage annual technical conference lineage file system l b survey data provenance record vol three support provenance audit distribute j gray telescope science vol condor grid grid compute make global infrastructure reality r malik g v j gray prototype distribute query web service virtual observatory bulletin astronomical society meet vol time ten team data management application tier international conference data engineer r proxy cache estimate page load delay international conference fifty n e young cache cache size vary symposium discrete