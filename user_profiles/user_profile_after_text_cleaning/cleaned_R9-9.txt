data min disc automatically counter imbalance empirical relationship cost v hall joshi receive eleven accept eight springer media abstract learn data set present convolute problem model cost particular class great interest occur relatively rarely case fraud instance disease interest correspondingly high cost misclassification rare data set often generate model high minority class accuracy however sample face common important criticism automatically discover proper amount type sample address problem propose wrapper paradigm discover amount data set base optimize evaluation function like area roc curve cost cost dependent analysis wrapper twofold first report interaction different evaluation wrapper optimization function second present set result environment include unknown change cost matrices responsible editor n v b department computer science engineer university dame dame l hall joshi department computer science engineer university south l hall hall joshi al also compare performance wrapper approach versus learn find wrapper outperform environment lastly obtain cost per test example compare result aware cup intrusion detection data set classification unbalance data learn one introduction imbalance class distribution pervasive variety include limit finance biology medicine minority positive class often interest also accompany higher cost make typical example problem fraud detection instance fraud population generally small proportion often neighborhood two however quite important able detect fraudulent transaction time also important minimize false result investigation cost also result lose customer thus distribution cost associate false false negative another example simulation dollar cost attach like may fraud detection cost attach time spend pore uninteresting simulation know interest typically rare bowyer al al hence intelligent tool accurate identify interest without many false alarm provost observe naturally occur distribution always optimal thus one need modify data distribution condition evaluation function add minority positive class remove majority negative class give data set become de standard counter curse imbalance various numerous paper case study exemplify advantage al ling li provost ferri al al al al however one common critique various work one effectively identify potentially optimal sample technique give data set accompany question imbalance generalize across drive important pertinent question appreciative problem sample highly data dependent propose wrapper framework discover sample fill important hole application sample counter problem class imbalance comprehensively demonstrate efficacy wrapper paradigm goal evaluate usefulness popular counter class imbalance tune validation set report performance test set work thus far report best performance test set apply different sample thus empirical estimate automatically counter imbalance generalization capacity addition evaluate generalization performance learn data set large variety experimental want analyze flexibility learn model dynamic environment since misclassification cost often unknown al may change investigate relationship choose best sample strategy via wrapper method relationship classification environment especially cost unknown change thus overarch question utilize measure counter class imbalance well framework main paper center around follow research question effectively discover sample give classifier domain propose wrapper paradigm counter imbalance guide criteria area receiver operator characteristic curve perform well test environment compare use cost directly wrapper mode guide search change cost unknown cost effect performance wrapper environment potential advantage account imbalance first apply sample compare classifier al remainder article organize follow section two introduce wrapper framework discover couple sample method correspond classifier domain section three present experimental framework empirical analyse first illustrate efficacy wrapper framework across data set use evaluation measure sect four sect five impact introduce cost test demonstrate use variety finally sect six discuss result two wrapper paradigm popular solution class imbalance problem however one persistent limitation sample automatically discover amount type sample apply give data set address limitation propose comprehensive wrapper infrastructure apply first discover best amount use synthetic minority technique smite al minority class introduce synthetic along line segment join k minority class nearest neighbor depend upon amount require neighbor k nearest neighbor randomly choose synthetic sample generate follow way take difference feature vector sample consideration nearest neighbor multiply difference random number zero one add feature vector consideration cause selection random point one input list minority class two list majority class three number fold n four output wrapper select majority class wrapper select smite minority class al class five class six seven end eight class nine ten end eleven f old one n twelve class zero build classifier train fold f old evaluate validation set update thirteen fourteen end fifteen empty sixteen w rap p er n p seventeen end eighteen empty nineteen w rap p er e twenty end output fig one wrapper smite algorithm along line segment two specific feature approach effectively force decision region minority class become general obviously search entire space smite quickly become intractable proceed stepwise fashion strategy remove excess majority class reduce size train data set also make learn time tractable smite use add synthetic minority class increase generalization performance classifier minority class figure one show algorithm extend multiple majority minority class metric value indicate performance criterion discuss subsequent section analyze approach use sect outline wrapper approach select sample level survey wrapper search evaluation metrics sect use guide sample wrapper approach optimize independent validation set avoid bias performance test data end construct careful framework first split data set ten partition partition use test fold remain ninety train fold result ten pair train test fold form basis comparison different split train fold independently five partition internal fivefold automatically counter imbalance wrapper apply independent validation stage fold discover appropriate sample give method classifier combination discover classifier relearn original train fold use discover test correspond test fold thus purpose internal fivefold guide independent wrapper stage keep original test fold separate unbiased assessment performance note procedure repeat furthermore due inherent random nature smite process train test wrapper select smite do total five time get average stable performance measure summarize five different run construct fold fivefold apply discover amount smite final report average fifty set five run ten fold explore heuristic function use optimize sample level algorithm select algorithm use wrapper approach perform search parameter space majority class es use choose learn algorithm part evaluation function fivefold train data purpose search sample level parameter space highest evaluation score guide heuristic function search parameter space restrict train data avoid estimation bias thus utilize fivefold train set discover amount wrapper start majority class obtain result train data traverse search space sample decrement case ten greedy iterative fashion increase performance minority class without sacrifice performance majority class start imply majority class retain remove majority class ten time search process continue long hamper performance minority class minor metric value drop performance majority class major metric value amount specify min use increment min five experiment algorithm terminate performance threshold violate class specify major list minor list detail present fig two note minor metric value major metric value dependent evaluation function guide wrapper algorithm select smite data set amount discover previous step choose first want first eliminate majority class add improvement evaluation metric moreover also al one ten two five three class four five end six repeat seven class lag class f eight nine ten eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen twenty lag class f class f old one n class f old f old build classifier train set evaluate validation set end update average average average average one zero class class lag class true update else end end end lag least one class true fig two wrapper algorithm reduce size train set speed learn performance estimate minority positive class minor metric value obtain become new guide wrapper decide smite improve performance wrapper smite algorithm evaluate different amount smite step one greedy search step new performance estimate become new initial performance obtain via wrapper smite improve performance margin increment min set five experiment see line seventeen algorithm performance achieve smite become new amount smite sample increment another evaluation perform check performance increase new smite amount least greater increment min process repeat greedily performance gain observe amount smite add one step denote sample increment algorithm automatically counter imbalance fivefold previously describe use guide wrapper however important caveat search avoid trap local maximum average improve five verify settle local maximum look ahead two step increase amount smite result improvement performance amount smite reset value discover prior do allow smite introduce additional aim improve performance however addition help go back use lesser amount smite discover prior pseudo code wrapper smite algorithm present fig three check major metric value primarily interest optimize performance minority class stage premise true important false one two three three class four lag class f class one five six end seven repeat eight class lag class f nine ten eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen twenty class class f old one n f old f old build classifier sample train set evaluate validation set end update average average class class class one ten class class class lag class true else end else end end end update class one thirty lag least one class true fig three wrapper smite algorithm al evaluation metrics way determine optimal sample level empirical analysis require sample must determine train data one question remain give sample space one determine best sample level thus explore four classifier evaluation criteria deploy test cost optimize sample level improve overall cost logical evaluation criteria cost cost calculate show one assume c c zero cost rate c rate c one therefore classification occur phase wrapper calculate validation cost use information select optimal sample level approach dependent knowledge cost relationship class different cost may selection different optimal sample level thus generate different subsequent discussion refer wrapper approach use cost tend use information retrieval composite metric base precision recall al lewis precision recall define follow precision r true false true negative false negative composite statistic calculate precision recall summarize effect two type f measure two precision recall recall precision desirable increase recall without sacrifice precision therefore effective wrapper strategy determine sample level maximize classifier two three four automatically counter imbalance reduce error relatively expensive minority class maintain accuracy majority class wrapper evaluation function advantage wrapper knowledge cost matrices require generate classifier consistently applicable throughout alternative unseen class cost subsequent discussion refer wrapper approach use measure vary another wrapper evaluation criterion base alternate derivation previously outline separate factor incorporate introduce element relative importance recall precision f measure one two precision recall two recall precision decrease importance precision diminish adapt behavior framework value must depend cost ratio therefore set five six c c minority become costly relative majority improve recall affect heavily precision therefore minority class accuracy become important cost become divergent like wrapper metric dependent cost matrix subsequent discussion refer wrapper approach use vary wrapper area roc curve receiver operate characteristic curve roc curve obtain modify learn algorithm get different true positive two class produce class vary threshold probability belong class apply get different operate point threshold three would mean probability greater three class consider label obtain set point graph point connect line approximate curve area curve provide method compare one indicate classifier get true correct false five would indicate every true positive classifier generate false positive greater better classifier obtain true false like wrapper metric cost independent classifier construct term flexible wide range cost al subsequent discussion refer wrapper approach use scalable implementation heel wrapper system computation time due exploration different however propose wrapper framework smite lend well distribute compute paradigm also offer optimal utilization idle machine department institution use condor framework al enable distribute computation university dame machine result significantly reduce time obtain final figure four show general implementation framework discuss one first partition data distribute fold different computer two partition train fold wrapper subsequently also distribute five different three sample use simultaneously average performance estimate compute first search undertake best find smite phase start smite apply simultaneously performance estimate aggregate best combination smite find search stop exploit inherent parallelism parameter search able achieve order average thirty time discuss sect worth note data set contain use data set may affect parallel either negatively positively use two different machine learn experiment base decision tree learner release eight rule learner ripper convert leaf produce decision tree probability estimate apply smooth provost ripper generate base rule confidence proportion single class versus total cover modify smooth introduction class prior probability also consider class prediction set probability threshold describe system generate optimal two class problem base know cost matrix interest probability threshold two condor university condor automatically counter imbalance fig four distribute wrapper implementation predict one class another therefore consider condition expect cost decision equivalent p x c p x c p x c p x c seven give p p x p x one p x two class assumption one p c p c p c one p c eight rearrange equation yield p c c c c c c c c zero may therefore drop term consideration p c c c therefore observe probability estimate p test example optimal decision generate compare p threshold p p p example label positive class otherwise predict belong negative class nine ten al three experimental framework use variety data set study include cup data set eight data set associate cost call unfixed cost data set summarize table one four data set repository four acquire different source establish context briefly introduce eight unfixed cost data set fix cost cup data set discuss separately sect five one phoneme data set use distinguish nasal oral sound base five feature project distribution nasal oral sample two segment data set blake al originally consist six equally distribute class image segmentation problem transform two class problem consider one class size minority class rest class single majority class three estate data set al consist state series compound national cancer institute yeast anticancer drug screen activity class either least one single yeast strain inhibit seventy yeast strain inhibit seventy data set sample sample active compound four page data set al consist block page layout document detect segmentation process data set originally five class convert two class text five data set blake al originally contain six class purpose use conversion outline provost al class receive one label part class produce data set majority class minority class table one data set increase order class imbalance data set feature class balance phoneme segment estate page oil train test five nineteen twelve ten twenty six automatically counter imbalance six north fundamental market information various active inactive publicly hold company provide annual income statement balance sheet statement cash flow supplemental data extract various financial filter company base rat total train set test set make problem resemble scenario train set comprise data test set comprise data interest reader acquire data set author seven oil data set provide al data set oil slick sample slick sample eight data set al total use trivial classifier would yield default accuracy however classifier would likely yield poor total cost particularly cost ratio skew use five random run framework data set since already associate test set want retain complexity original test set derive different time period data set devoid know test cost inject range cost carefully establish generality wrapper framework compare learn convention use notation experimental cost value smite ripper ripper ripper apply wrapper use metrics select optimal sample level beta cost roc static misclassification cost generate scalar comparison performance also evaluate generate cost curve fig five experiment overview al indicate cost ratio make false negative error false positive error instance ratio indicate twice costly make false negative make false positive align premise costly call positive minority class negative call negative majority class positive compare wrapper several cost first consider case cost know train test time investigate situation cost remain unknown train test time finally study generalization cost space also compare impact different evaluation criteria wrapper mode ripper learn data set compare classifier al use base ripper use weka classifier frank figure five provide overview experiment four result unfixed cost data set first discuss analysis use present result analysis first experiment consider effect use guide wrapper search eleven cost environment experiment allow us observe interaction objective function wrapper sample level evaluation metric test set table two three summarize result ripper base respectively result average fifty run five different random trial standard also show beside average performance measure cost column represent cost make eleven thus essentially total number instance data set use wrapper amount smite fourteen majority class remove test set find smite generally help base learn different data set result carry significance ripper see table three irrespective wrapper evaluation function sample always result improve base classifier two case also improve two norm page data set page marginal deterioration base classifier data set result drop base classifier however always improve believe artifact higher focus minority class less detrimental automatically counter imbalance table two average sample level performance measure eleven cost matrix equal cost classifier include standard us cost phoneme base segment base base base base estate page oil base base thirteen twenty six two eight three three six four two two fifteen fourteen fifty nine six five three seven four five nineteen nineteen sixteen six seven eight fifteen nineteen eighteen twelve twelve three nine eighteen eighteen seventeen nineteen eleven eight eight six thirty thirteen four six nineteen ten fourteen result average five different random run wrapper evaluation indicate evaluation function use guide wrapper mode smite indicate amount smite discover wrapper subsequent indicate evaluation function use test set base indicate base classifier without sample best performance show bold note distinct positive correlation correspond final evaluation instance improve four data set use wrapper evaluation metric rather question become happen attribute nature two metrics tune fix threshold five mean fix point threshold five become unstable believe result generalize use wrapper evaluation function essentially goal identify one less prone reach local maximum wrapper scheme measure generally result different amount smite optimize different classifier expect use different also result different level sample al table three average sample level performance measure eleven cost matrix equal cost ripper classifier us cost phoneme base segment base estate page oil base base base base base convention table two hold nine six five nine five six seven six five nine eighteen fourteen eleven nine four six four seven five four sixteen sixteen eight nine ten sixteen fourteen seventeen fourteen fifteen sixteen zero zero eighteen twelve fifteen twenty seven six seven zero eighteen seventeen eleven six seventeen thirteen posit amount smite dependent class skew feature space consider estate data set amount smite yet certainly unbalance data set look statistics ripper poor performance estate however significant improvement offer sample believe wrapper method allow one discover relevant amount sample certainly intrinsically tie data lastly expect base classifier achieve cost eleven equally costly table four show average time second take data set single fold show time take sequential distribute wrapper framework representative show time method especially give result amount time automatically counter imbalance table four time second different approach data set ripper ripper estate oil page phoneme segment average thirty seven two nine sequential version distribute version fourteen two sixteen five sample measure exactly underlie part sequential distribute run distribute provide significant improvement time make wrapper competitive approach average take ripper complete wrapper search encourage especially light performance note wrapper ripper faster wrapper relatively lower amount smite ripper base classifier time take entire wrapper paradigm largely function number minority class associate learn complexity drive search smite amount comparison want examine empirical relationship learn data set classification effectively handle problem imbalance achieve lower cost test compare al wrap stage around classifier effectively minimize cost estimate conditional probability data set via bag combine probability estimate simple framework j p c j essentially class select class train data expect cost minimize classifier learn data evaluate test set method draw new train set accordance example misclassification cost however cost highly skew tend occur limit number heavily counteract rejection al sample use newly draw train set keep select example probability c z c misclassification cost z select constant greater maximum cost original train set show use two first use cost trend indicate total cost cost ratio vary second use cost curve cost trend compare wrapper framework counter class imbalance classifier consider various cost use cost previously consider study build without utilization generate posterior correspond cost test set scenario use cost completely unknown train generate posterior probability distribution test set depend cost environment test stage effectively reflect cost threshold decision make derive operate cost ratio see ten however relearn base classifier measure fall umbrella allow us directly compare effectiveness deal imbalance without incorporate cost train phase would like point reader appendix show benefit reflect cost apply smite hand incorporate cost learn wrapper perform assumption already optimize objective function attune particular cost thus generate multiple different cost figure six seven show range cost obtain across eight data set different cost figure show different data set show normalize cost normalize cost zero one enable better display result result show interest trend generally result lower cost however increase cost particularly wrapper base begin result lower cost directly train correspond cost measure make compel case higher cost without use cost train able often outperform result hold ripper thus combination sample approach counter class imbalance effective overcome cost fact find automatically counter imbalance fig six cost trend base classifier beta wrapper cost measure quite effective across cost range conjecture outcome improvement quality estimate thus result reduce overall cost effective treatment imbalance without use cost train result robust posterior probability estimate applicable variety cost test certainly desirable especially cost unknown change test ripper former effective classifier reduce cost test lastly result lower cost base classifier cost thus treat imbalance change objective function always prefer estimate base classifier find might disconnect learn data set learn contrary however believe attribute lack sufficient search sample parameter space resort default sample point really default sample data set classifier show use sample data set able achieve lower cost know method lastly cost function constrain extend study however comprehensive experiment data set include discuss cup data set demonstrate treat data set imbalance first often beneficial compare al fig seven cost trend ripper base classifier beta wrapper cost cost curve condition particular rate rate cutoff may immediately establish expect generalization capacity classifier may appropriate gauge performance across range rate rate thus cost curve found expect cost may yield clearer understand within operate environment curve plot performance expect cost normalize zero one axis function give ne c one rate rate eleven x axis combine cost class distribution follow manner p c p c p c twelve c cost positive example negative c cost negative example positive p probability positive example p one p probability negative example multifaceted tool enable sophisticate analysis classifier performance fluid condition overall cost curve allow visualization interplay weight importance two class wax wane correspondence point roc space line cost space single rate rate pair roc space get translate line segment cost space automatically counter imbalance thus different operate point roc curve represent different line cost space clarity presentation show lower envelop cost curve follow four measure want draw among optimize measure incorporate cost learn construct cost curve follow train different cost draw follow eleven result thirteen pair rate rate total thirteen seven cost curve plot possible cost curve different retain correspond lower envelop reflect best operate range figure eight nine show cost curve ripper respectively figure represent probability cost function represent normalize expect cost see figure generally overlap result lower envelop increase begin separate lower result slightly lower cost wrapper data set increase advantage treat data set class imbalance stand base across data set find treat data set imbalance use wrapper mode result effective set across range classifier produce envelope optimal across entire range corroborate find previous subsection lower envelop measure generally dominate especially higher cost thus use first counter class imbalance problem generally also find either comparable better measure recommend optimization criterion result quite compel imply optimize class imbalance without incorporate cost often optimal strategy find result lower cost use base classifier trend get reverse ripper believe rely heavily instability base classifier give bootstrap five fix cost cup intrusion data set consider intrusion detection data set cup data set provide actual cost make different type also demonstrate propose wrapper framework data set cost matrix use score competition show table five data set follow many duplicate original five million example train set duplicate remove also normal do class remove al fig eight cost curve occur train data one table five normal class train data two normal class note set experiment test set remain unchanged table six show result see approach ripper classifier produce cost per example normal class automatically counter imbalance fig nine ripper cost curve train data two apply smite class keep class unchanged better winner contest better subsequent result literature also use base classifier smite result lower cost publish note respective amount smite discover via wrapper table five cost matrix use score cup competition al do probe normal do probe normal zero two two two two two zero two two two two two zero two two one two two zero one two three four one zero table six comparison result obtain original cup test data win strategy decision tree amor al naive bay amor al use train data one zero use ripper train data one zero use train data two cost per test example use ripper train data two zero al number beside indicate smite percentage utilize experiment six work wrapper approach utilize determine percentage minority add train set percentage majority class use variety data set different class include number real world data set wrapper approach work perform guide search parameter space evaluation function apply fivefold train set best smite find use build classifier update train set apply unseen test set demonstrate ability optimize sample level evaluation function result effective generalization performance also wish view impact use threshold function produce classifier generate optimal problem note appendix cost work particularly well reduce total cost classifier particularly operate higher cost ratio thus may assume sample allow develop calibration better suit higher cost connect question posit sect one summarize follow automatically counter imbalance propose paradigm use different evaluation function effective automatically discover potentially optimal amount sample data set effective counter train test well show learn sample discover use metrics retain effectiveness cost introduce test stage metrics effective compare base classifier demonstrate test set thus change data distribution important learn domain also compare approach analysis raw total cost find strong tendency measure generally outperform wrapper evaluation function moreover higher cost also dominate another set among do use cost curve use lower envelope form multiple learn different cost also possible examine evaluation metric throughout cost section note tend produce result effective generalization space even better optimize different cost space also show combination smite offer significant advantage several number realistic cost include champion level performance cup challenge grateful provide cost curve oil data set partially support j fellowship thankful guest helpful comment appendix cost comparison leaf estimate table contain cost comparison decision tree learn use measure call table respectively follow decision leaf base default five threshold follow technique outline sect use posterior know cost ratio generate threshold test subsequent table indicate total misclassification cost different learn manner however differ method evaluation unseen note tend better higher cost case lower cost better performance higher cost desirable elect use decision process throughout article table cost comparison eleven al estate phoneme segment page oil fifty seventy amor z naive bay decision tree intrusion detection proceed symposium apply compute hall lo bowyer spatially disjoint data proceed sixth international conference multiple classifier study behavior several balance machine learn train data six one reference automatically counter imbalance blake repository machine learn bowyer hall lo te parallel decision tree builder mine large visualization proceed international conference man cybernetics l bag machine learn two bowyer hall lo smite synthetic minority technique j hall lo joshi computation evaluation sample workshop data mine n proceed workshop learn data set ration six one sixteen n editorial learn calibration power pet unbalance department computer science engineer university dame fast effective rule induction international machine learn morgan city ca learn text international workshop provost f turney p proceed workshop p general method make knowledge dis inductive logic program learn data mine c class imbalance cost sensitivity beat proceed three workshop learn data set c cost curve improve method visualize classifier performance machine learn one j inductive learn text categorization seventh international conference information knowledge management c result classifier learn contest c learn proceed seventeenth international joint conference artificial intelligence f g learn document recognition ferri c p j n first workshop roc analysis ai machine learn detection oil spill satellite radar image machine learn thirty address curse train set one side selection proceed fourteenth international conference machine learn morgan lewis comparison two learn text categorization annual symposium document analysis information retrieval ling c li c data mine direct market proceed fourth international conference knowledge discovery data mine press new york learn data set cost unequal unknown proceed three workshop learn data set feature selection unbalance class distribution naive bay provost p tree induction rank machine learn three provost case accuracy estimation compare induction fifteenth international conference machine learn program machine learn morgan al g application machine learn intrusion detection misuse detection context proceed international conference machine learn model distribute compute practice condor experience concur g k b learn sample best handle unbalance class unequal error cost g provost f learn train data costly effect class distribution tree induction j frank e data mine practical machine learn tool morgan k doss c bowyer j c comparative evaluation pattern recognition detection j pattern seven six b c learn make cost unknown proceed sixth international conference knowledge discovery data mine b j n learn example weight z x train neural network address class imbalance problem knowledge data eighteen one