performance model dynamic binary translation instruction set simulator institute compute architecture school university forum street unite kingdom abstract instruction set vital tool compiler processor architecture design space exploration verification use dynamic binary translation able simulate complex embed speed however functional provide observability contrast slow simulate force revert paper demonstrate possible run speed instruction set surpass simulation speed extend engine augment generate code verify processor model approach model configuration rely prior profile instrumentation compilation work target embed processor implement instruction set architecture achieve simulation speed standard computer industry standard suit introduction play important role design today high performance support exploration processor speed power consumption accurately predict different architectural model information gather enable select efficient processor design fabrication slightly higher level instruction set provide platform experimental instruction set test new may develop verify help reduce overall development time new allow concurrent engineer design phase especially important embed soc design may extend support specific however increase size complexity embed challenge current technology example encode decode execute similarly advance audio cod decode playback six minute excerpt requiem use sample rate bite rate result execute figure clearly demonstrate need fast technology keep performance demand embed broad introduction multicore form exacerbate strain simulation technology widely acknowledge improve simulation performance key make simulation multicore viable option paper concern use recently develop dynamic binary translation combine interpretive compile simulation order maintain high speed observability flexibility however achieve accurate state even observability remain tension high speed simulation fact none exist maintain detail performance model paper present novel methodology fast performance model processor pipeline instruction data cache memory within main contribution simple yet powerful pipeline model together instruction operand dependency analysis pass allow retain execution model without compromise observability essential idea reconstruct pipeline state execute instruction less complex term implementation execution model reduce work pipeline state update order magnitude maintain additional data structure relate processor pipeline cache emit lightweight call function update processor state generate code order maintain flexibility achieve high simulation speed approach performance model functional simulation thereby eliminate need extensive rewrite simulation framework accommodate change fact strict separation concern functional simulation performance model enable automatic generation pipeline performance model processor specification write architecture description language however beyond scope paper evaluate performance model methodology industry standard suit encore embed processor implement faithfully model interlock encore processor pipeline see figure forward logic instruction set zero overhead loop static dynamic branch prediction branch delay slot set associative data instruction cache also provide result encore processor pipeline variant model across speed simulation reach standard computer outperform implementation encore processor performance model fig dynamic binary translation flow integrate main simulation loop motivate example take detail look engine propose performance model code generation approach provide motivate example order highlight key consider block figure take identify block code compile native machine code use sequence step illustrate figure block map onto function denote address see label figure instruction translate semantically equivalent native code faithfully model architectural state see label figure order correctly track state augment translate instruction call function see label figure responsible update underlie model see figure figure demonstrate hardware pipeline map onto model capture behaviour improve performance state update emit several performance model update function tailor instruction kind ie arithmetic logical branch section describe model detail block trace translate block record block block simulation translate record translate block target instruction dependency performance model code emit batch block translate link compiler finally translate block map update address newly translate block subsequent encounter previously translate block simulation present translate block map execute directly among paper development time model embed adapt different independent implementation functional integration time model engine improve speed instruction set simulation level higher implementation processor core without compromise accuracy extensive evaluation industry standard suit interpretive mode verify calibrate actual hardware implementation encore embed processor implement full overview remainder paper structure follow section provide brief outline encore embed processor serve simulation target paper addition outline main feature describe basic functionality engine follow description approach performance model generate code section present result extensive empirical evaluation section discuss body relate work section finally conclude section background encore embed processor order demonstrate effectiveness approach use processor implement namely encore encore base interlock pipeline forward logic support zero overhead loop freely instruction encode static dynamic branch prediction branch delay slot predicate exist two pipeline encore processor namely see figure variant variant additional align stage fetch decode stag additional register stage decode execute stag performance model fig dynamic binary translation represent architectural state update function pipeline basic block structure state see figure implementation extern global processor void pipeline pipeline pipeline pipeline pipeline pipeline pipeline compare branch instruction delay slot pipeline ignore fe branch penalty fetch speculative fetch due branch set register set delay slot bite else delay slot instruction pipeline branch take clear delay slot bite set set total cycle count end block return translate block performance structure pipeline fe fetch de decode ex execute memory write back stag stag stage processor r general purpose register auxiliary register char l z n c v h status flag h halt bite stag per stage cycle count avail per register cycle count cycle total cycle count ignore use produce result configuration use set associative instruction data cache block replacement policy cache miss expensive replacement policy require us exactly model cache behaviour avoid large cycle count although configuration use work processor highly pipeline depth cache size block replacement well order ie big little bus size instruction set specific instruction set processor fully onto fully work silicon recently instruction set simulator work extend target adaptable simulator extensive support simulator implement processor memory subsystem include sufficient simulate interactive operation complete system simulator provide follow simulation mode work standard hardware simulation tool use hardware performance verification interpretive simulation mode target adaptable simulation mode model processor pipeline cache mode calibrate pipeline variant encore processor functional simulation mode capable simulate embed system speed approach even exceed silicon whilst faithfully model processor architectural state profile simulation mode orthogonal deliver additional statistics dynamic instruction detail per register access statistics per instruction latency detail cache statistics execute delay slot well various branch predictor statistics common encore processor simulator highly architectural feature register file size instruction set set branch condition auxiliary register set well memory map io specify via set well define configuration furthermore feature pipeline depth per instruction execution cache size cache block replacement memory subsystem layout branch prediction well bus memory access fully use experiment list table detection dynamic binary translation simulation time partition epoch define interval two successive within epoch frequently performance model fig encore hardware pipeline model sample generate model encore pipeline hardware fetch memory pipeline generate fetch account instruction fetch latency fe fetch invariant see section processor pipeline model fe de fe de decode determine operand availability time de fe de ex de ex execute account execution latency destination availability time ex de ex ex memory account memory latency destination availability time ex execute basic block ie detect record trace see figure epoch record trace ie frequently execute trace pass engine native code generation recently extend detection capability find translate large translation consist multiple trace increase size translation possible achieve simulation performance simulation attribute improve locality time spend simulate within translation unit greater scope compiler across multiple block methodology paper describe approach combine cycle accurate simulation order provide architectural observability speed exceed extend engine pass responsible analyse instruction operand additional code emission pass emit code performance model update see label figure follow section outline generic processor pipeline model describe account instruction operand availability visibility time also discuss cache memory model show integrate control flow branch prediction performance model processor pipeline model granularity execution hardware simulation cycle base designer want find many cycle take execute instruction program necessary simply count number cycle execution model work well hardware detail slow purpose therefore fast functional execution model execution model yield faster simulation speed usually compromise observability detail pipeline model together instruction operand dependency analysis pass allow retain execution model without compromise observability essential idea reconstruct pipeline state execute instruction thus processor pipeline model array many pipeline stag see definition stag label figure pipeline stage add correspond store instruction ready leave respective stage line label figure demonstrate fetch stage fe add amount cycle take fetch correspond instruction current cycle count stage next line figure label invariant ensure instruction leave pipeline stage instruction immediately follow stage ready proceed figure contain detail example performance model determine cycle count sample instruction performance model fig encore pipeline model example use final instruction basic block depict figure demonstrate reconstruction pipeline state instruction execute bold red number denote change respective pipeline stag bold green number denote already commit pipeline fe de fe de fe fetch initial state de ex de ex de fe initial state ex ex ex de ex initial state ex initial state memory final pipeline initial state pipeline stage cycle instruction operand side effect order determine instruction ready leave decode stage necessary know become available ie modify content register need remember become visible avail array see label figure encode information operand emit call update function engine pass source operand availability time destination operand availability determine dependency analysis see label figure information subsequently use compute instruction leave decode stage see label figure record become visible execute memory stage see label figure modify general purpose register two source exist several highly state update function function outline figure demonstrate one several possible control flow branch prediction deal control flow jump branch branch compare special care must take account various type speculative execution allow delay slot encore processor simulator support various static dynamic branch prediction scheme code highlight label figure demonstrate branch penalty apply branch pipeline penalty depend pipeline stage branch outcome target address know see target address availability control flow figure availability delay slot instruction one also must take care speculatively fetch execute case branch cache memory model cache miss memory access significantly contribute towards final cycle count maintain accurate cache memory model default configuration encore processor implement block replacement policy content shift register use order determine victim block eviction rotation shift register must trigger time hardware require faithful model specify flexible powerful memory access simulation critical aspect full system describe detail memory access simulation implement accurate model target memory semantics preserve whilst simulate load store highest possible rate performance model vendor model number processor type clock frequency frequency c core duo processor cache table simulation host configuration empirical evaluation extensively evaluate performance model approach section describe experimental setup methodology present discuss result experimental setup methodology evaluate simulation approach use suite comprise comprehensive set life science also use industry standard embed suit comprise automotive consumer network office cod build arc port compiler full enable ie simulate manner without underlie operate system isolate behaviour background interrupt virtual memory effect measure include simulation run input available web site configure use large iteration count execute least simulate completion consist simulate shutdown sequence kernel configure run typical embed system two interrupt console page virtual memory system main interest simulation speed therefore measure maximum possible simulation speed use various simulation speed interpretive mode mode see figure table list configuration detail simulator target processor perform computer detail table condition low system load compare simulation speed show figure use speed grade clock fig pipeline simulation rate use compare interpretive simulation mode b implementation c novel simulation mode fig pipeline simulation rate use compare interpretive simulation mode b implementation c novel simulation mode interpretive accuracy graph use journal interpretive rate accurate simulation rate small long run embed interpretive accuracy interpretive accurate simulation life science rate cycle count deviation cycle accurate interpretive encore encore slow fast rate stage stage interpretive accuracy graph use journal interpretive rate accurate simulation rate small long run embed interpretive accuracy interpretive accurate simulation life science rate cycle count deviation cycle accurate interpretive encore encore slow fast rate stage stage pipeline performance model processor pipeline execution order branch prediction register set instruction set memory system instruction data replacement policy bus divisor instruction set simulator simulator compiler io system call interlock encore yes register none hardware associative associative none emulate table configuration setup simulate target outline use verification simulation speed initially discuss simulation achieve novel simulation mode compare verify interpretive simulation mode processor pipeline variant primary motivation work finally also outline result different pipeline variant namely pipeline version encore summary result show figure figure propose simulation mode pipeline variant three time faster average verify interpretive mode even outperform implementation encore processor clock new mode twice fast implementation explain fact contain sequence map particularly well onto simulation host furthermore frequently execute block contain result generation execution simpler state update function simulation achieve average simulation rate life science application program suite figure outperform previously outline implementation time faster due relatively high cycle per instruction metric cycle accurate simulation slightly interpretive cycle accurate simulation entirely due shorter abundance application keep engine busy result slowdown due compilation simulation mode pipeline variant figure twice fast average verify interpretive mode outperform implementation encore processor variant clock new mode almost twice fast implementation average simulation rate figure pipeline figure demonstrate outperform implementation twice fast interpretive simulation introductory sample application perform decode playback requiem outline section mode capable simulate sustain rate pipeline pipeline enable simulation shutdown sequence kernel fast simulation mode achieve pipeline result highly responsive interactive environment clearly demonstrate capable simulate effect interrupt virtual memory efficiently still provide full observability profile simulation mode orthogonal simulation note performance result full profile enable include dynamic instruction execution profile per instruction latency detail cache statistics execute delay slot well various branch predictor statistics relate work previous work instruction set simulation tend focus compile hybrid mode whilst interpretive simulator spend time repeatedly fetch decode target compile simulator fetch decode instruction spend time perform fast instruction set simulation simulator employ macro expansion show run three time faster interpretive simulator target code statically translate host machine code execute directly within switch statement performance model fig pipeline simulation rate use compare interpretive simulation mode b implementation c novel simulation mode fig pipeline simulation rate use compare interpretive simulation mode b implementation c novel simulation mode interpretive accuracy result graph use journal interpretive rate accurate simulation rate small long run embed interpretive accuracy interpretive accurate simulation life science rate stage stage interpretive accuracy result graph use journal interpretive rate accurate simulation rate small long run embed interpretive accuracy interpretive accurate simulation life science rate stage stage pipeline dynamic translation use overcome lack flexibility inherent mimic simulator simulate translate group target basic block host shade use translation cache order increase simulation speed instruction set simulator improve performance simulation use binary translation take full advantage host architecture cache compile simulation execute cache function function fetch instruction set compile simulation simulator design high performance flexible functional simulator achieve instruction decode process perform compile stage whilst interpretation enable simulation time full system simulator translate target intermediate format interpretation simulation intermediate process interpreter call correspond service fast simulator use original dynamic translator target instruction divide simple sequence set object file simulation code generator access object file concatenate form host function emulate target within block recent approach present apart different target approach differ granularity translation basic block page code generation target language commercial simulator simulator employ technology target use paper achieve simulation speed contrast operate functional simulation mode performance model fast instruction set dynamic binary translation approach architectural simulation introduce dynamically map onto order take advantage underlie time model approach enable hardware design space exploration provide faithful performance model actual implementation relevant work performance estimation approach hybrid simulation environment merge native host execution detail application partition operation cost introduce intermediate representation imitate operation compiler apply generic code expect apply actual compiler target simulation platform furthermore call stub function insert code handle access data manage also cache model locate believe number approach first executable target platform ever generate hence simulate code approximation actual target performance model compiler would generate second detail pipeline model maintain hence cost reflect actual instruction assume fix average instruction even relatively simple assumption hold furthermore evaluate implement detail pipeline model hence accuracy figure report refer close performance estimate come obtain unclear figure accurately reflect actual target platform finally evaluate similar hybrid approach target energy estimation propose statistical performance estimation smart propose approach potentially fast require application accurately model smart unlike accurate pipeline model introduce statistical error entirely avoid machine learn base performance model propose recently mature approach present initial train performance estimation achieve high simulation rat limit speed faster functional similar smart however approach suffer inherent statistical reliable detection statistical still unsolved problem summary demonstrate approach easily surpass whilst provide detail architectural profile feedback statistics main contribution simple yet powerful pipeline model conjunction instruction operand dependency analysis pass integrate enable simulation speed without compromise observability model approach portable independent implementation functional importantly capable capture even complex interlock processor novel pipeline model approach adaptable performance model functional simulation automatically generate future work plan improve generate code perform performance model update show fast multicore simulation feasible approach reference august chang open simulation environment library complex architecture design collaborative development computer architecture letter j r e w l performance estimation design tool proceed cod f fast portable dynamic translator proceed annual conference annual technical conference association ca p g w data analysis method performance prediction date proceed conference design test li li v suite evaluate computer architecture proceed international symposium characterization fast accurate simulation use compiler framework workshop rapid simulation performance evaluation tool performance model dynamic binary translation instruction set simulator proceed international symposium model simulation cain dynamic binary translation approach architectural simulation computer architecture news vol march b shade fast simulator execution profile proceed conference measurement model computer press new york fast instruction set simulation proceed international workshop embed lei rainer fast generic hybrid simulation approach use c virtual machine case proceed international conference architecture synthesis embed lei rainer integrate performance estimation approach hybrid simulation framework mob annual workshop model simulation lei rainer performance estimation use hybrid simulation proceed annual design conference g e j b faster flexible program analysis mob proceed workshop model simulation high speed simulation use dynamic binary translation lecture note computer science vol lei rainer fast simulation framework embed development proceed international conference system synthesis performance model c may mimic fast simulator paper symposium interpretive press york c mill j fowler compile instruction set simulation practice experience hybrid simulation embed energy estimation proceed annual conference design press new york hybrid simulation energy estimation embed design integrate circuit g r h universal technique fast flexible architecture simulation proceed conference design press new york f f r accurate performance estimation use domain classification neural network proceed use continuous statistical machine learn enable performance prediction hybrid instruction set proceed international conference system synthesis w j x approach accelerate portable simulation proceed international conference system synthesis press new york p n instruction set compile simulation technique fast flexible instruction set simulation proceed conference design press new york g h architecture implementation use machine description language proceed south pacific design conference high speed simulation use binary translation mob annual workshop model simulation e fast machine simulation proceed international conference measurement model computer press new york r e f b j c hoe smart accelerate proceed simulation via rigorous statistical sample annual international symposium computer architecture j instruction set simulator date proceed conference design test p press new york tool set version computer architecture news vol instruction set architecture retrieve encore embed processor retrieve instruction set simulator retrieve simulator retrieve embed consortium suite