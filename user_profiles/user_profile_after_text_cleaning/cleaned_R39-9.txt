enable ultra low voltage system operation tolerate cache amin advance computer architecture laboratory department electrical engineer computer science university michigan ann arbor mi shoe abstract extreme technology integration submicron regime come rapid rise heat dissipation power density modern dynamic voltage scale widely use technique tackle problem high performance need however minimum achievable supply voltage often bound since fail faster rate logic work propose novel cache architecture internal organization efficiently tolerate arise operate ultra low voltage region use approach operational voltage processor reduce translate eighty dynamic leakage power save subject memory structure reliability test general term design reliability dynamic voltage scale cache low voltage operation one introduction power consumption heat dissipation become key challenge design high performance grow power consumption reduce device also affect cost thermal package cool electricity six dynamic voltage scale widely use reduce power consumption exploit fact dynamic power quadratically scale voltage linearly frequency consequently lower minimum operational voltage dramatically improve energy consumption battery life medical motivation work come observation large structure limit extent operational reduce modern delay increase higher rate logic delay supply voltage decrease thirteen increase systematic random process variation deep submicron failure rate structure rapidly increase ultra low voltage regime permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee nine august san copyright figure one bite error rate cell vary value technology dominant factor limit operational voltage structure logarithmic highlight extremely fast growth failure rate decrease two horizontal mark failure rat mention structure operate least manufacture yield ultimately minimum sustainable entire cache structure determine one bite within entire system highest require operational voltage force utilize large voltage margin order avoid cache figure one depict failure rate cell base operational voltage technology node nine minimum operational voltage cache select ensure high expect yield figure one see write margin mostly dictate minimum expect operate due dominate failure rate cache number consistent predict measure value report two literature several propose improve dynamic leakage power cache thirteen usage gate leakage power reduction turn cache line describe four approach reduce leakage power cache turn cache line likely access near future simultaneous usage adaptive body bias present seven reduce power derive method find optimal supply voltage body bias give frequency duration operation meng eight propose method minimize leakage overhead consider manufacture scheme give artificial priority cache ways smaller leakage resize cache avoid higher leakage factor instead turn block drowsy cache three state preserve approach two different supply voltage recently inactive cache block periodically fall low power mode read write however low value amount power save restrict due structure figure two basic structure propose scheme two cache bank eight line line consist four equally size data chunk black box cache line represent chunk least one faulty bite memory fault map essential propose scheme also show contrast objective work enable push operate voltage ultra low voltage region low power mode preserve correct functionality cache idea initially propose eleven later fourteen improve architecture enable operation even lower hand many st five also propose allow structure operate lower conventional cell large area overhead shortcoming since extra area translate performance gain operate high power mode consequently try minimize overhead normal high power mode operation work propose cache intertwine set n one partially functional cache line together give appearance n functional line overhead approach small performance penalty five less fifteen area overhead cache apply scheme cache evaluate achievable power reduction two architecture section describe architecture flexible cache one allow scheme adaptively absorb fail discuss decrease operational ie enter mode cause many within cache fail example accord figure one number faulty one block high five scheme provide appearance fully functional cache tolerate end partition set cache large group one sacrificial line group set aside serve redundant group remainder paper refer every cache may contain multiple block line approach line divide multiple data chunk chunk label faulty least one faulty bite two line collision least one faulty chunk position example second data chunk line faulty line three six collision similarly figure two line ten fifteen objective scheme form group two line within group figure two line four ten fifteen form group cache line four label sacrificial line furnish redundancy need accommodate faulty chunk line ten fifteen order minimize access latency overhead sacrificial line four data line ten fifteen figure three example configuration algorithm give distribution fault cache bank bank eight line faulty chunk cache configuration algorithm form five group cache disable line fifteen furthermore group correspond sacrificial normal line also show different bank sacrificial line access parallel original data line cache architecture cache access first index memory map supply location data line correspond sacrificial line two line access respective bank layer use compose fault free block select appropriate chunk line layer receive input indirectly fault map give data line fault map determine chunk faulty replace chunk sacrificial line aid encode decode information unique address assign line within group group address instance figure two line fifteen second line data chunk sacrificial line fault map store group address line data chunk assign entry assign fault map contain one two indicate first chunk devote one fourth chunk dedicate two second third chunk assign line finally layer get input set compare group address line fifteen two read memory map fault map since every group require sacrificial line dedicate solely redundancy scheme strive minimize total number group must form give number line fix within cache achieve objective imply group prefer smaller maximize number functional line cache need minimize number sacrificial line require enable operation previously discuss single sacrificial line devote every group line sacrificial line data line since store independent data word sacrificial line contribute usable capacity cache depend number group form effective capacity cache vary dramatically figure three show process form group give fault pattern cache group formation iterative process iteration algorithm new group form group consist sacrificial line one bank set line bank still assign group assign possible set line sacrificial line algorithm try minimize number sacrificial line require operation order form group configuration algorithm start top line first bank mark sacrificial line first group ie next switch second bank find set line potentially assign first group purpose keep add line top second bank group line cause collision algorithm simply skip result line nine add first group mark one however since line ten collision line one add group line eleven take place first group form switch bank number already assign line ie second bank mark first unassigned line bank sacrificial line second group ie line ten addition line two three assign group first bank process continue line bank get either disable assign group cache line get disable one contain many faulty chunk make repair unjustified two assign exist group size greater one due particular fault pattern note back forth switch bank allow algorithm minimize number line get disable figure three present five group form configuration algorithm depict figure three line fifteen disable since contain three faulty chunk repair cost effective number nonfunctional line summation number sacrificial disable line objective configuration algorithm minimize number nonfunctional line give fault pattern cache figure three six nonfunctional cache line consist five sacrificial line one disable line cache instance number line fault map array equal number sacrificial line ie five however due presence process variation large population fabricate chip different fault pattern expect evaluation employ monte simulation generate population cache instance total number fault map line determine base maximum number sacrificial line achieve yield low power mode operation first time processor switch low power mode self test module scan cache potential faulty determine faulty chunk cache line processor switch back high power mode form group describe provide information require store memory fault map configuration information store write memory map fault map system time addition memory map fault map tag array protect use well study cell two area overhead relatively small structure able meet target voltage work without fail however use protection large structure data array since impose much higher overhead fourteen high power mode operation high power mode scheme turn order minimize unwanted one cache line functional sacrifice cache capacity two negligible overhead dynamic power due switch bypass consist layer additional mux bypass memory map three leakage power overhead remain however power gate use leakage mitigation three evaluation section evaluate effectiveness cache architecture reduce power processor keep low methodology performance evaluation use validate simulator base figure four process determine minimum achievable chunk size fraction nonfunctional cache line also area overhead fault map structure limit ten one processor configure show table one model cacti leverage evaluate delay power area structure ten lastly standard use evaluate remain miscellaneous logic ie bypass give set cache chunk size monte perform use configuration algorithm describe section two identify portion cache disable generate configuration algorithm target yield word one manufacture configure cache allow exhibit operate mode result figure four show process determine minimum achievable system since protect harder due longer line size fourteen protection cost dictate minimum operate voltage system order evaluate scheme set chunk size four eight easier protect mode fault memory map array remain idle leak power crucial minimize size structure size memory map essentially fix number line cache fault map size however vary significantly depend configuration motivate closer look size fault map important design factor consequently limit area overhead fault map ten total cache area furthermore since cache size strong correlation system performance limit scheme disable ten cache line evident figure four decrease increase nonfunctional portion cache also area fault map array however beyond certain point area overhead fault map start decrease phenomena due large fraction cache line get disable lower lead increase error rat precipitous increase faulty chunk vertical line table one target system configuration value technology clock frequency nominal cache cache register rob reorder buffer queue instruction fetch buffer issue queue fu functional unit float point unit main memory branch predictor branch history table ras return address stack branch target buffer ninety nineteen twelve v two bank data two bank instruction split set associative four cycle hit latency one port block size two bank unify set associative ten cycle hit latency one port block size eighty integer float point four four two memory system port four one cycle high power cycle low power combine bimodal associative lastly evaluate power save achieve use scheme base similar assumption fourteen assume dynamic power scale quadratically linearly frequency furthermore leakage power scale cube result scheme allow potentially save eighty dynamic power leakage power four conclusion aggressive scale deal power dissipation become challenge design issue consequently large amount effort devote development dynamic voltage scale tackle problem decrease operational voltage modern large cache structure first fail tolerate allow target lower value preserve core frequency scale trend work propose flexible cache architecture allow achieve translate eighty dynamic leakage power save target system amount save come performance overhead less fifteen area overhead cache five research support arm national science foundation grant research center one five research center fund focus center research program semiconductor research corporation program six reference one e infrastructure computer system model two two b international circuit conference page three k n kim martin drowsy cache simple reduce leakage power annual international symposium computer architecture page four h cache decay exploit generational behavior reduce cache leakage power annual international symposium computer architecture page five j p kulkarni k kim k fully differential robust trigger base international symposium low power electronics design page new york six r k n p p heterogeneous multicore potential processor power reduction annual international symposium page seven martin k combine dynamic voltage scale adaptive body bias lower power dynamic international conference computer aid design page new york eight k meng r process variation aware cache leakage management international symposium low power electronics design page nine h h k h design environment symposium circuit page june ten n r n p optimize wire large cache cacti sixty micro page eleven n kim cache device scale limit effective fault repair future technology conference digital system design tool page august twelve e g b automatically characterize large scale program behavior tenth international conference architectural support program operate page new york thirteen k h cell international circuit conference one fourteen c h r z trade cache capacity reliability enable low voltage operation annual international symposium computer architecture figure five scheme cache cell use protect fault map memory map tag array note area leakage power overhead system mostly determine base due significantly size scheme minimal highlight minimum achievable base ten limit disable line result select minimum ie mode operate voltage lower violate ten limit figure five summarize scheme leakage overhead high power mode correspond fault map memory map miscellaneous logic mention also account use two protect tag fault map memory map array mode note memory map far greater contributor area leakage power overhead reason behind one four line overall size one fault map major component overhead due large size attendant leakage area dominate processor warrant close study fault map figure four dynamic power overhead mode mainly attribute bypass since assume clock gate fault map memory map array propose scheme mode memory map layer critical path cache access base time analysis translate one additional cycle latency two additional cycle mode order evaluate performance penalty scheme mode run suite early twelve assume one extra cycle latency two extra cycle cache size also reduce base fraction nonfunctional line cache average performance penalty see mode figure six eleven due cache capacity loss however one note mode performance usually major concern high power mode enough slack access time cache cacti result fit small bypass additional delay without add extra cycle access time word performance loss mode however one might cache design without slack available scenario add additional cycle translate performance drop figure six amount performance scheme low power mode use