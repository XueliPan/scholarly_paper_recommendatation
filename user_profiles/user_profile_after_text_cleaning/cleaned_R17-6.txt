international conference parallel process achieve parallelism stream program model computer science federal de brazil state university fireman architectural trend chip design result machine multiple process well efficient communication network lead wide availability provide multiple level parallelism inter develop efficiently make use challenge specially paper present new version anthill program environment efficiently exploit parallelism experimental result demonstrate efficiency anthill base model model decompose set filter communicate stream already show efficient express parallelism replace filter environment originally version new version allow efficiently express parallelism within compute node program abstraction evaluate solution dual machine two data mine eclat drop execution time nearly proportional number core single machine use cluster machine close linear number available core confirm anthill perform well inter parallelism level introduction many current computer involve expensive large data time demand interactive response time high create demand compute power way beyond single computer fuel continuous drop cost per unit work partially support cap increase power shelf current trend high performance compute make use large set machine fast network interconnect hand latest arena bring chip chip use machine large cluster computer aggregate lead multiple level parallelism system take full advantage must build parallelism mind level single machine level program efficient parallel particular heterogeneous remain complex problem one common environment use combination parallelism thread parallelism number computer demonstrate capacity achieve high compute rat many become widely use tool many field task lay shoulder less experience application domain actual demand compute bridge program gap arise therefore become central issue computer science several program propose aim ease development efficient execution parallel several however assume dedicate fix resource allocation simplify application semantics embarrassingly parallel fail provide desire performance expect large pool anthill one framework make possible broad class take advantage parallelism loosely couple heterogeneous allow parallelization several dimension partition set filter communicate use stream model filter distribute platform execution allow multiple filter create transparently previous result show efficient scalable range complex parallel image process two three parallel data mine one four five achieve use anthill one although conceptually model already suit express parallelism original implementation better job level single machine program interface force programmer build filter instance separate sequential process go loop read new data process forward result paper present novel version anthill filter program interface allow system better utilize available within one compute node approach change original orient system demand drive one better suit data flow approach instead create process loop get call must become responsible whole control flow responsible write necessary process data unit upon arrival system use architecture issue process code new data become available available new interface filter spawn multiple execution thread transparently take advantage multiple core may available new interface change program interface expose environment provide higher level abstraction simplify programmer task several complicate issue address general way example previously hard programmer code filter able receive data one multiple stream time require one stream filter implement internally function recover notion independent stream indicate process must take place data unit arrive stream rest avoid programmer generate code may contain unexpected unnecessary block point might lead form contention therefore loss efficiency data process may data different data still able express system take care schedule synchronization whenever find evaluate solution implement two data mine use new interface eclat k nearest neighbor result show new system take full advantage multiple core available process nod experiment also show anthill expose enough parallelism order make full utilization large number multicore nod paper organize follow section describe program model anthill framework section present anthill develop work section present experimental evaluation relate work present section v finally discuss result future work section anthill anthill framework inspire program model implement six model use approach decompose set process refer filter data transfer filter use communication stream allow data buffer transfer one filter next application decomposition process lead possibility task parallelism application become set filter connect like direct graph execution time multiple transparent copy filter compose application several machine system stream connect source transparent copy mechanism allow vertex application graph replicate many nod execution platform data go filter may partition among copy create data parallelism show figure one several natural decomposition cyclic graph execution consist multiple filter application start data represent initial set possible pass filter new candidate create turn pass network also process experience develop anthill notice behavior also lead asynchronous sense several candidate possibly different process simultaneously similar unroll parallel loop anthill therefore try exploit maximum parallelism use three discuss task parallelism data parallelism divide computation multiple pipeline stag one replicate multiple time parallelism since happen execution mostly bottleneck free fig one anthill regard transparent copy mechanism care take filter replicate state ideally state partition happen incoming message filter need sort respect state update deliver appropriate transparent copy mechanism guarantee anthill call label stream label associate message send stream stream check label hash function select one copy deliver message guarantee message associate label consequently state deliver always transparent copy current program interface expose filter set three function need implement initialize process finalize system invoke three appropriately interface expose one problem interface force filter programmer write loop within method process pretty much iterate work do loop create application able deal data synchronization may arise among several filter comprise application moreover turn filter big loop easily benefit available hardware unless write experience programmer anthill section describe novel version anthill provide new filter interface discuss previously alleviate mention bring anthill closer data flow model idea create demand drive version anthill control loop move application code filter code code within anthill programmer provide function invoke whenever data available process schedule handle within system since process available multiple may trigger parallel effectively unroll original loop multiple process available computation feature useful exploit full capability current multicore without force application keep parallelism level mind explicitly benefit version anthill originally notion parallelism filter process function declare sequential loop execute desire programmer may use another abstraction exploit multiple execution available rely communication thread parallelism example however major like possible incompatibility use different make anthill add different conflict abstraction actually close implementation gap model program interface filter process data flow possibly change nature data pass next filter programmer define filter worry transformation function process run data unit turn may internally data forward next filter decide process take place except explicitly indicate data task filter framework concern programmer possible implementation true use system control easily decide event raise may process give hardware available programmer relieve task determine level parallelism employ long available pending execution may continue also remove another limitation original anthill data filter may build receive input multiple independent stream case data must process soon receive independent source programmer must resort asynchronous communication nonblocking io able probe continuously different source search data clearly undesirable burden programmer another possibility system multiplex data stream one communication entity require programmer implement function determine stream originate data information need also desirable since add otherwise unnecessary overhead programmer may indicate do upon arrival data stream even different action source system better condition control nonblocking io necessary choose right process function event base programmer approach derive heavily program model pioneer seven later extend include explicit coyote eight emphasize expressive power parallelization strategy developer use single abstraction model simple program interface anthill may create exploit parallelism inter cluster processor focus filter communicate filter upon arrival data b implementation one order support program extend anthill incorporate several depict figure two create event layer divide three communication module event queue controller event handler discuss next fig two architecture communication module responsible monitor input flow send message target filter instance implement separate thread deal multiple communication operation essentially consist create event respective event queue whenever message associate stream arrive filter instance event queue controller responsible control event queue associate filter instance component determine order queue process call appropriate filter process function event handler contain code input stream developer create function process data receive register system whenever event associate give stream trigger register function get execute receive input event handle ie data process keep apart application programmer isolate control assign system make easier schedule load balance implement without affect programmer code special schedule create monitor module event queue controller back without require change application code make anthill good environment experiment dynamic schedule new load balance experimental evaluation use two different data mine evaluate performance impact propose paper eclat k nearest neighbor describe experimental setup present result briefly describe association analysis association analysis consist identify causal frequent name association rule first step compute determine set appear frequently give threshold traditional algorithm solve problem name eclat nine previously parallelize use anthill four anthill implementation eclat depict figure three base principle order set k frequent k one also need frequent algorithm start initial set include size one compute actual frequency find frequent combine produce new size two test algorithm continue create new fashion new check partial occurrence c n e r v e r f e r candidate frequent c n e g e n e r r fig three eclat filter figure three show three filter develop parallelize eclat algorithm counter filter responsible count frequency candidate verifier filter check whether overall frequency particular give threshold candidate generator filter create new base previous frequent eclat algorithm implement anthill exploit way counter filter process different typically several simultaneously use different transparent copy counter filter implementation first partition transaction available process candidate frequency check process generate local count exchange information process generate global frequency count candidate complete candidate frequency check process locally generate k one size application find frequent none candidate find frequent one candidate last iteration frequent b classification classification data mine predictive task want assign class unknown object usually call test set use model base preclassified object train set classic algorithm object classification neighbor first introduce e fix j ten base intuition neighborhood object contain similar object thus analyze neighborhood able determine class practice since define neighborhood may hard use k object term attribute explain algorithm denomination anthill implementation use three filter reader classifier merger show fig ure four reader filter responsible send train object classifier filter train divide among classifier instance test broadcast strategy affect performance algorithm since train usually much test instance classifier filter compute object test base distance object train assign instance select object send merger filter merger filter receive object classifier instance sort select global object assign object one class fig four filter also implement use compare anthill version version read train set one node replicate rank perform test set partition send final classification one process c experimental setup use synthetic train contain object fifty dimension test contain object ten class also use synthetic eclat consist one attribute generate use procedure describe four mimic retail environment experiment run cluster thirteen connect use fast switch node r core two two main memory run operate system also use one r r main memory evaluate solution quad core machine experiment vary number instance counter eclat classifier filter intensive filter case remain filter run single machine never saturate experiment result section first analyze application execution time single machine use show use cluster machine one single machine analysis figure five show execution time eclat use dual quad core machine figure five five b execution two vary number thread dual core machine reduce execution time add second thread gain third thread since two core available configuration single thread execution time eclat reduce fifty respectively execution time show figure five c five execution time reduce increase number thread latter reach number core gain case schedule overhead actually lead longer execution time four thread execution time reduce thirty single thread version eclat respectively difference performance gain eclat explain relation data access pattern design quad core processor architecture like processor two set two core set share cache two thread run different set access datum may duplicate cache case present high degree reference locality may scale linearly number core occur available cache space optimize due cache entry two application figure six show two implement use anthill result nearly linear expect algorithm regular communication computation pattern still scale well thirty core eclat result show anthill outperform implementation two similar theory although anthill implementation leverage time parallelism inherent application expose use program model anthill implementation scale extremely well implementation plague irregular nature computation result show implementation anthill successful pro n c e e n c e e zero zero zero zero n c e e n c e e zero zero zero zero p e e p l e v thirty twenty fifteen ten five zero thirty twenty fifteen ten five zero one two three four one two three four number thread number thread eclat dual core execution time b dual core execution time one two three four five six one two three four five six number thread number thread c eclat quad core execution time quad core execution time fig five different evaluation transparent flexible scalable strategy exploit parallelism even irregular eclat hand find development may improve even anthill seem good environment implement give level abstraction implement v relate work several exploit parallelism although many focus specific level program section discuss al create develop call exploit distribute share eleven framework use number data mine compute generalize distribute common operation class author also evaluate different synchronize data access avoid reduction operation although framework achieve good performance show program model linear core anthill zero five ten fifteen twenty thirty number core eclat linear core anthill zero five ten fifteen twenty thirty number core b fig six number core generic one present paper since exploit share distribute memory map model base consider achieve anthill linear number available core case al twelve present parallelism cell processor propose different schedule map execute task process cell explore parallelism although interest bound solution use embarrassingly parallel program model restrict sense chai panda thirteen present detail evaluation multicore measure different communication cost core cluster multicore machine evaluate overall performance although present solution problem efficiently explore parallelism study present paper help understand design program future work paper present event drive version anthill allow system better utilize available within compute node particularly important scenario multicore result show achieve good performance two classic data mine eclat strategy exploit multicore process succeed dual quad core machine eclat execution time single machine reduce dual core thirty quad core execution time use one thread execution time fifty dual core quad core single thread execution also achieve almost linear number available core future work currently investigate mechanism schedule thread use mechanism intend better exploit reference locality execution also avoid undesirable thread core future work refer exploration heterogeneous environment use filter automatically adapt number process thread accord power available machine reference one r w l b g r g anthill scalable environment data mine symposium computer architecture compute two g r w pan j support efficient execution scientific distribute international symposium computer architecture high performance compute brazil three hastings pan k r j support distribute execution scientific vol three four j r g asynchronous anticipatory base parallel algorithm frequent mine four proceed conference practice knowledge discovery new york new york five r g g w r scalable parallel algorithm gene expression analysis international journal parallel program six r filter storage storage available j h archival symposium mass scientific large seven w l l dynamic network architecture vol ten two eight n r w coyote system construct communication service vol sixteen four nine r r fast mine association rule large chile june ten e fix j discriminatory analysis discrimination consistency school aviation medicine field computer science technical report eleven r g combine distribute memory share memory parallelization data mine international workshop high performance data mine pervasive data stream mine twelve f c dynamic parallelization cell engine seven proceed symposium practice parallel program new york impact multicore thirteen l chai q k panda understand cluster compute case grid system seventh international symposium available cluster compute study architecture