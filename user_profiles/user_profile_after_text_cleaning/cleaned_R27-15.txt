report report doucet p de alan martin abstract investigate focus retrieval structure document provide large test structure document uniform evaluation measure forum compare result paper report evaluation campaign consist wide range track ad book efficiency entity rank interactive link mine one introduction traditional search identify whole document relevant user information need task locate relevant information within document leave user next generation search perform task identify relevant part relevant document search engine perform task refer focus discipline know focus retrieval main goal promote evaluation focus retrieval provide large test structure document uniform evaluation measure forum compare result focus retrieval take many form hence evaluation campaign con wide range track ad track investigate effectiveness passage retrieval three ad retrieval task focus relevant context best context book track investigate support read search navigate full digitize book efficiency track investigate effectiveness efficiency rank retrieval approach real data real query entity rank track investigate entity retrieval rather text retrieval one entity rank two entity list completion interactive track investigate behavior interact document retrieval approach effective track investigate link discovery document file level element level track investigate structure document mine especially cluster document addition initial step launch question answer track investigate technology access data use address interrogative information need vandalism track try predict edit reversal rest paper discuss aim result track relatively section ad track section two book track section three efficiency track section four entity rank track section five interactive track section six link track section seven mine track section eight two ad track section briefly discuss aim ad track task setup use measure result try formulate clear find detail fourteen aim task ad track study retrieval information retrieval literature retrieval describe simulation library might use involve search static set document use new set principle difference library consist document query may contain content structural condition response query arbitrary may retrieve library general aim system find relevant information give topic request case retrieval article contain relevant information choice whole hierarchy different return hence within regard relevant result result contain relevant information result exhaustively discuss topic contain little information possible result specific topic traditional document retrieval first condition apply measure solely base retrieval highlight text simplify task highlight text retrieval assume return highlight text compare character text retrieve search engine number location character text identify relevant assessor best context discuss use distance best entry point run identify assessor ad track feature three task focus task nonoverlapping result must return evaluate early precision relative highlight believe relevant text retrieve relevant context task nonoverlapping result must return group document evaluate mean average generalize precision generalize score per article base retrieve highlight text best context task single start point element start tag passage offset per article must return also evaluate mean average generalize precision generalize score per article base distance assessor point test collection use corpus base early contain total article three average article contain nod original syntax convert use general tag layout structure like article section paragraph title list item typographical tag like bold emphatic frequently occur pioneer creation since total ad search create addition query derive total structure query default query add assess follow precise use new assessment system assist highlight relevant text topic ask mark relevant text pool document assess article relevance separate best entry point decision make assessor relevance freeze time seventy fully assess moreover eleven judge two separate without knowledge official result refer seventy first assign assessor typically topic original author main consist seventy human create judge specific measure evaluate three task addition every article contain highlight text evaluate document retrieval effectiveness result attractive document retrieval test collection use freely available document genre moreover also available derive every click article relevant would light traditional test data collect log file result total official group distribute evenly across three task report main find refer detail discussion result top score run fourteen examine relative effectiveness find task best score run use query contrast result show structural hint help promote initial precision part explanation may low number comparison number seventy judge query majority query make reference particular tag structural may diminish value query comparison give put fair comparison element passage retrieval approach number passage disappoint eighteen use range passage result whereas use element result consistent result use evidence element retrieval saw passage base approach competitive superior element base approach saw article retrieval reasonably effective task run rank relatively high look article rank inherent ad track ie evaluate traditional document retrieval saw best article rank obtain run element passage result suggest evidence still valuable article retrieval compare system rank term article retrieval system rank term retrieval task exact topic set see reasonable correlation especially two context task best performance ad task also tend best article rank since find relevant article consider prerequisite come surprise addition encyclopedic structure relatively short article cover single topic result relevant article contain large fraction relevant text mean text highlight straightforward define task measure strongly favor precision recall natural route would try elicit focus information need natural answer short excerpt text look different topic set derive proxy log shallow set click page rather test collection see notable give low number relevant article eighteen average compare ad seventy average click page focus exclusively precision lead different system rank although still agreement best group two set require analysis outlook finally ad track two main research question first main research question comparative analysis element passage retrieval approach hop would light value document structure provide markup although number retrieval run submit low draw definite find best perform system use predominantly element result provide evidence usefulness document structure second main research question compare focus retrieval directly traditional article retrieval find best score ad track also tend best article rank best article rank generate use evidence build success ad track number excite change first foremost new collection base dump million article present test scale infrastructure well individual second additional topic creation aim promote focus information request example collection enrich semantic annotation allow information need naturally cast structure query third although ensure comparability suggest run task new collection active debate variant task highlight three book track section briefly discuss book track detail refer seventeen setup second year book track seventeen focus three theme interest relevant information retrieval human computer interaction digital search digitize book b c increase accessibility content digitize book base four task define investigate one book retrieval task aim compare traditional document retrieval exploit feature back book index associate like library catalogue information frame within user task build read list give topic two page context pic task aim test value apply focus retrieval approach book expect point directly relevant book part three structure extraction se task aim evaluate automatic derive structure layout build table content digitize book four active read task art aim explore suitable user enable annotation review summary across multiple book test collection total register track fifteen take part actively throughout year contribute run relevance test collection test collection base digitize book total provide live search archive include history book literary study religious teach reference work essay proceed poetry full text book mark format refer develop document layout team development center contain markup table content book also come associate marc record contain publication author title classification information addition full corpus reduce version compress also make available word word remove pic task build full corpus art could select book use user study se task use different set book page image original file essentially page level structure distribute forty new id contribute merge thirty create last year pic task id combine set use pic task relevance collect use book search system available develop research allow search browse read annotate book test collection gather game call book competition model base two compete explorer task locate mark relevant content check quality work provide addition judge relevance book scale collection relevance freeze total unique book unique page judge across highlight box draw seventeen detail collect data please refer seventeen result book retrieval page context task evaluation pic task use separate relevance assessment set multiple relevance label assign multiple average rank book pic task evaluate traditional document retrieval rank book part pic task evaluate page level book treat page document average run main find note since vary greatly across treat preliminary task eighteen run submit four group experiment various use book content marc record information rank book document score best element score rank book percentage page retrieve well incorporate evidence best perform run map run submit rank book percentage page retrieve use page level index general conclusion however three group experiment simple book content base perform better attempt combine evidence improve performance suggest still plenty do discover suitable rank book pic task thirteen run submit two group mostly experiment ways combine document element level score best perform run submit university find focus able locate relevant text within book page level evidence limit use without context whole book structure extraction task evaluation se task generate compare manually build create hire use structure label tool build development center precision define ratio total number correctly recognize total number return recall ratio total number correctly recognize total number seven run submit two group implement two different approach best performance harmonic mean precision recall obtain development center team f extract first recognize page book contain print group rely title detection within body book achieve score f active read task main aim art explore hardware tool read provide support engage variety read relate fact find memory task learn goal investigation derive user consequently design usable tool support active read practice do run comparable individualize set study contribute elicit user usability issue relate novelty take involve engage art study run two participate group still ongoing thus yet result report continue art plan work toward raise awareness interest relate yet involve outlook book track attract lot interest grow double number however active participation remain challenge group due high initial setup cost build infrastructure nonetheless lot achieve year result establish infrastructure evaluation various task include evaluation measure user study build latter present one biggest challenge due huge effort require devise collective relevance gather method implement game find method feasible reliable eighteen one require community support ie seventeen address currently look use mechanical turk service well investigate possibility open book search system allow create save search book plan run modify task se task run international conference document analysis recognition set book task shape around user task compile read list select article aim expand pic task tree retrieval one art continue four efficiency track section discuss general setup result efficiency track newly introduce detail refer overview new efficiency track provide common forum evaluation effectiveness efficiency rank retrieval approach real data real query oppose purely synthetic still prevalent retrieval task efficiency track continue tradition use rich pool manually assess relevance measure retrieval effectiveness thus one main attract group community able study rank retrieval broad audience efficiency track significantly extend track systematically investigate different type query retrieval classic search query expansion query deeply nest structure available well twenty like track efficiency track use version collection three version article initially introduce slightly revise although collection particularly large rather irregular structure many deeply nest particularly challenge traditional approach use path available topic type one main distinguish efficiency track traditional retrieval cover range query type typical query mostly use either none little structural information condition target element query thus two natural one extend give query query two issue specific call new aim increase amount structural query condition without sacrifice process query summary efficiency track focus follow type represent different challenge efficient effective retrieval type take previous track use constitute major bulk use efficiency track represent classic focus passage element retrieval similar focus task combination query topic take track thus allow reuse type b derive interactive query expansion run kindly provide royal school library information science investigate context interactive track intend simulate query expansion topic evaluate conjunctive manner expect pose major challenge kind search engine evaluation strategy respective expansion run submit also track relevance available track type c seven new newly develop submit efficiency track represent retrieval set query deeply nest structure condition originally intend get accomplish efficiency track well skip due low amount newly propose type c low respective impact overall result effectiveness compare already come readily assess evaluation however remain interest set type c well reuse type b lead track readily available additional conversion new version tool format need incorporate assessment file make available track task metrics efficiency track particularly encourage use style query result submission format include mark run latter correspond traditional submission format use either focus ie nonoverlapping thorough overlap article retrieval mode automatic run may use either title field include title additional narrative description field well automatic query desire oppose track reconsider thorough retrieval mode use initially intentionally allow overlap return since remove overlap may mean substantial burden different assess quality retrieve result efficiency track apply metrics use track run focus article mode evaluate interpolate precision metric fifteen use evaluation convert new format run thorough mode evaluate metric implement nine convert old assessment format result receive overall amount run submit five different group accord run submit vary classic rank highly specialize efficiency average run time per topic vary second entire batch nineteen second type second type b second seven type c respectively similarly track result run generally yield good efficiency result clearly constitute easier retrieval mode however also comparable effectiveness level overall effectiveness result generally comparable track albeit use different best run achieve value nineteen interpolate early precision value one recall one ten recall ten respectively none make use topic format lead conclusion far previously use also use efficiency track summary efficiency track continue focus specifically difficult topic type new collection base dump million article already expect major challenge classic retrieval thus efficiency track continue provide interest complementary set track five entity rank track section briefly discuss entity rank track detail two search support type search return instead web page would enable simplification many search task start entity rank track provide forum may compare evaluate return list entity rank entity list completion goal evaluate well rank response user query set rank assume loosely define generic category give query example entity retrieval characterize type search goal evaluate build return instead document specific case track assign article use define entity type result retrieve compose set entity type list completion task set relevant entity task two main task entity rank list completion concern information need represent triple type query category entity category entity type specify type object retrieve query free text description attempt capture information need entity attribute specify set example instance give entity type er run give input query category attribute run base query entity case system return relevant page page play role entity surrogate additionally perform entity relation search ers pilot task motivation task may want know detail previously retrieve specifically example relation search seek exhibit van locate system need first find number relevant establish correct correspondence museum city ers task could help explore information retrieval relate field like information extraction social network analysis natural language process semantic web question answer ers concern type query category entity query category entity already define entity rank task form free text describe relation entity target entity specify type target entity specify example instance target entity type compose title query user provide system description narrative natural language explanation information need additionally category field set example contain topic ers also contain field ie title description narrative example entity pair eleven create small number partial entity correspond topic text candidate correspond name article loosely belong example may subcategory corpus general guideline topic title type explanatory ie human assessor able understand title type retrieve extend ers pilot task test collection test collection create consist adapt format add strata information evaluation script use official evaluation measure perform stratify sample top retrieve run evaluation script available create specifically track almost assess original topic author originally propose less seven relevant relevant exclude test collection would unstable incomplete respectively three drop one request topic assessor two due unfinished result final test collection consist ers part final collection relevance ers task perform together create set sixty available evaluate entity retrieval result use language model underlie infrastructure build entity rank er task best perform approach use topic difficulty prediction mean classification step use feature base definition document collection obtain improvement second best approach experimental investigation show help easy link structure help difficult also show last edition best perform group use score propagation provide work context er twenty third best perform approach use link sixteen exploit distance document target well link structure propagate relevance information show category information lead biggest task perform well additionally sixteen also use relevance feedback use example thirteen adapt language model create expert search task incorporate category information language model also try understand category term query text six interactive track section briefly discuss interactive track detail refer nineteen introduction purpose interactive track study interaction information retrieval focus end react exploit potential provide access part document addition full document track run first time repeat although task content focus fundamental premise force throughout common subject recruit procedure common set user task data collection instrument common log procedure interaction understand collect data make available ensure manageable effort participant access rich comparable set data user background user behavior sufficient size level detail allow qualitative quantitative analysis analysis task document collection use use track extract article decide experiment two search task searcher instruct select one three alternative search construct track two task consist task category one research task category two task generate represent information need believe typical first category represent search task request specific information topic example task seven summit highest seven climb regard mountaineer challenge would like know summit first climb successfully second category research represent search task require information topic find collect information several document example research task write term paper political process unite state want focus presidential unite state find material describe procedure select presidential two participate group seven group initially express interest participate track end two group able perform experiment system experiment design track run use retrieval system build within daffodil framework five reside server maintain university system return search result consist vary granularity full article section article group document result list three high rank show per document searcher choose examine document system show entire full text document background highlight high rank addition show table content draw format searcher choose individual section closer examination experiment give questionnaire collect demographic data search task precede questionnaire establish search task task ask fill questionnaire contain question intend learn use opinion various feature search system relation task complete experiment close questionnaire ask general opinion search system questionnaire data log system design assess relevance item look could full article article five different relevance score available score express two dimension relation solve task one much relevant information part document contain may highly relevant partially relevant relevant two much context need understand element may right less search sessions log save find base log file involve test total sessions successfully record fourteen analysis log still ongoing result far concentrate performance relation two search task general result indicate satisfy complete research task compare task questionnaire find test regard research task easier satisfy search result find relevant information research task plausibly relate task type test regard information relevant useful search research task task require specific precise answer may diminish additional value explore wide range search result find consistent relevance assessment result transaction log find relevant article complete research task compare task also sessions result significantly article research sessions log see test perform query fact find session spend time solve research task word test examine individual thorough complete research task could relate find test find relevant result research task explanation also support result questionnaire state test less certain complete task compare research task general result seem system better support research task task particularly interest since test claim use research task seven link track section briefly discuss link track comprehensive discussion find ten link discovery centralize document repository challenge task focus link discovery take process step system must link anchor text new document best entry point target document incoming link also focus new anchor identify exist document link respective best entry point new document grow collection approach help keep link graph link graph maintenance requirement motivation track link track offer two task link discovery link discovery task document randomly select link remove evaluation discover link perform original collection link task fifty nominate link discover pool exhaustively manually assess run evaluate use standard precision recall measure map interpolate graph result suggest link discovery solve problem evaluation link discovery must base manual assessment exist link methodology collection use dump consist article topic track orphan article document goal extensively link track run first time task run ninety task extend randomly select outgo incoming link require per topic new task fifty anchor discover anchor five link total ten group eight different participate track run submit task task link already total run submit task run task pool manual assessment link already document also add pool assessment pool exhaustively evaluate contain link pool consequence approach link already present manually assess tool develop facilitate efficient manual assessment figure one show figure one link assessment tool program pool right link document middle orphan topic anchor embed leave decide relevance topic document bunch link within anchor mouse click could position appropriate position alternatively link could declare irrelevant entire assessment process topic take four six finish evaluation submit link perform use two set one set derive exist link derive manual evaluation link base standard measure treat submit list link rank list measure assessment set relevance binary either zero one relevant evaluation relevance measure adapt include proximity proximity manually designate measure character distance take account derive score link result main link discovery utilize run base two approach anchor link analysis page name analysis former approach due eleven latter due seven approach first see best anchor link analysis run submit university twelve best page name analysis run submit institute correct minor cod issue best run third run generate take first fifty link original document figure two evaluation manual figure two graph show result outgo link analysis two set set link present document manual set link assess relevant human assessor six line see upper three assessment whereas lower three assessment manual difference performance three run large compare slight compare manual discussion link discovery base anchor link analysis perform compare link already present base page name analysis however compare manually assess link performance difference gap link expectation apparent since subjectively eliminate unnecessary link link year page track raise question determine difference link human assessor would relevant question examine track eight mine track section briefly discuss mine track detail discussion four aim task document mine track launch explore two main first identify key mine document new challenge emerge field second study assess potential machine learn deal generic machine learn task structure domain ie classification cluster semi structure document track run four since fifth edition currently launch among many open handle structure data track focus two generic task apply train set final label train set final label figure three supervise classification task figure four unsupervised cluster task information retrieval precede track concern supervise unsupervised cluster independent document track classification cluster document organize graph document goal track therefore explore algorithmic theoretical practical issue regard classification cluster interdependent document deal document particularly challenge task document define logical structure content hence name data moreover large majority case web example document also structure link document example link different type correspond different information example one collection provide hierarchical link model develop field simultaneously use content information internal structure document list model rarely use external structure collection ie link document focus problem document organize graph precisely track compose single label classification task goal find single category document task consider context train phase whole graph document know label part give see figure three single label cluster task goal associate document single cluster know document link document see figure four collection corpus provide subset corpus three extract set document link document link correspond link provide author article note keep link concern document corpus remove link point article provide corpus compose direct link correspond document corpus document point link average provide link document number link directly depend size document mean large document cite small characteristic specific fit well web graph global corpus topology dense corpus compose one giant component large majority document link small document link component collection contain possible one document belong many order provide single label label document subset original choose randomly whole set keep subset fifteen allow reasonable supervise classification task use naive bay classifier categorization task provide label ten document train set label choose randomly amongst document corpus evaluation result submission blind evaluate test corpus categorization ask submit one category document test set evaluate much find correspond real document category compute recall correspond percentage document category correctly cluster task submit cluster index document test set evaluate obtain cluster correspond real document submit cluster compute purity measure recall cluster consider cluster belong category majority document also use micro average purity macro average purity order summarize different model document cluster note evaluation cluster still open problem particularly document cluster correspond structural cluster thematic cluster measure propose give idea much model able find fifteen unsupervised way four model submit cluster task five supervise classification detail result give four classification two best model recall obtain use classical vector appropriate document representation mainly use content information link three model better use graph structure perform term recall cluster task purity obtain best submit model fifteen cluster around fifty note purity directly compare recall obtain supervise show supervision improve unsupervised learn nine complete seven track track cover various focus retrieval wide range information retrieval task report touch upon various approach apply task effectiveness formal proceed publish springer series eight volume contain track overview paper well paper participate group main result however great number test use future experiment see excite change first foremost creation new collection base crawl contain million article make four time current collection track continue similar task new collection entirely new task address focus retrieval reference one p g structural relevance common basis evaluation structure document retrieval eight proceed conference information knowledge management page new york two g p de j overview entity rank track al eight three l p corpus forum forty one four l p overview mine track june al eight five n c p daffodil integrate support search federate digital conference research advance technology digital page six n j focus access document international workshop initiative evaluation retrieval number springer berlin seven query link discovery al six page eight j advance focus retrieval international workshop initiative evaluation retrieval springer berlin nine n g overview initiative evaluation retrieval n n g workshop page ten overview link track al eight eleven k c university ad track al six page twelve j workshop page thirteen j w x adapt expert search model rank al eight fourteen j overview ad track al eight fifteen j j g evaluation measure al six page sixteen r j find use link seventeen g doucet overview book track eighteen g n j towards collective gather quality control relevance submit publication nineteen n r k n overview interactive track al eight al eight al eight twenty h ride p de p efficient entity retrieval university eight al eight r overview efficiency track j v topic difficulty prediction entity al eight rank al eight