build block resilient amin advance computer architecture laboratory university michigan ann arbor mi shoe abstract although feature size scale source dramatic performance gain lead mount reliability concern due increase power give plague semiconductor highly dependent significantly higher failure rat project future technology traditional deal device rely redundancy maintain service face fail work challenge practice identify inability scale high failure rate investigate advantage use study motivate design embed architecture design inception reliability first class design constraint rely network replicate processor pipeline stag maximize useful lifetime chip gracefully degrade performance toward end life paper address basic build block name processor core comprise network pipeline stag naive slice design result approximately slowdown verse traditional processor due longer communication delay pipeline however several small design change eliminate interstage communication minimize communication reduce overhead eleven average provide high level adaptability subject hardware reliability test computer system organization processor architecture general term design reliability performance multicore reliability architecture pipeline permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee case eight copyright one introduction device scale trend regime lead increase current power rise result increase device failure rat lead technology begin warn device reliability begin deteriorate node onward seven current indicate future compose many unusable manufacture time many degrade performance even fail expect lifetime processor ten assuage reliability concern computer must directly address reliability computer innovative source computer system widespread range transient fault due energetic particle strike forty electrical noise permanent cause phenomenon thirteen time dependent dielectric breakdown recent industry invest effort build resistant transient fault soft though evidence suggest grow rate soft future technology ten problem actively address research contrast much less attention pay problem permanent fault specifically transistor due degradation semiconductor time concern primarily due increase power current lead increase three show heavily influence four fact exhibit exponential dependence temperature seventeen thirteen furthermore device scale increase susceptibility shrink thickness gate increase interconnect current density traditional deal transistor involve extra provision logic circuit know account expect performance degradation time however increase degradation rate project future technology imply traditional margining insufficient necessitate revolutionary new design identify adapt challenge tolerate permanent fault broadly divide three requisite task fault detection fault diagnosis system fault detection eight five use identify presence fault fault diagnosis sixteen twelve use determine source nature fault system recovery consist number different task base nature fault example fault transient incorrect state may correct simply flush processor pipeline five however fault permanent recovery mechanism leverage system may necessary avoid propagate fault use fail component third last task system usually require additional redundant decommission noncritical example many computer provide ability repair faulty memory cache inclusion spare memory thirty recently begin extend support spar additional branch eleven register classical dual redundancy also use address problem system recovery six thirty recent popularity multicore traditional approach able leverage inherent redundancy present large chip one however historical design modern emphasis redundancy incur high hardware overhead tolerate small number defect increase defect rate semiconductor technology uncommon see rapid degradation throughput single device entire core decommission oftentimes majority core still intact functional may appropriate costly term area power embed domain contrast paper argue case redundancy finer granularity provide control enable isolation replacement individual structure within processor core allow effective provision spare part ie replicate susceptible failure also minimize waste permit design right salvage healthy die core time fail system gracefully degrade performance maximize useful lifetime focus work propose efficient solution maintain redundancy enable requisite task detect diagnose source failure assume already place discussion beyond scope paper work present basic build block highly adaptable compute substrate network pipeline stag collectively act logical processor flexible interconnect easily isolate adaptively rout around faulty stag either leverage spare case large system stage adjacent consist multiple stitch together would possess inherent redundancy capable maintain higher throughput duration system life even extend lifetime compare conventional multicore design sea pipeline stag disposal intelligent reliability management system dynamically configure meet change reliability performance demand conceptually design relatively straightforward however introduce network switch heart processor pipeline inevitably lead poor performance due high communication low communication tween stag key create efficient design rethink organization basic processor pipeline effectively isolate operation individual stag specifically interstage communication must either remove namely break loop design volume data transmit must reduce paper present design efficient attack reduce overhead acceptable level primary paper include design space exploration highly adaptive suitable resilient bust design examination help realize design detail evaluation performance compare conventional embed processor two granularity architecture tolerate permanent fault must ability refer variety range decommission noncritical processor structure swap cold spare architecture recovery entail isolate defective component incorporate spare structure need support achieve various level granularity grain ability replace individual logic gate design focus isolate entire processor core choice present complexity implementation potential lifetime enhancement finer grain provide greater lifetime significantly cost generally speak law diminish return place lower limit granularity section present experiment study draw upon result motivate design experimental setup order effectively model reliability different design model core use lifetime reliability experiment core conventional pipeline design representative commercially available embed core synthesize place rout use industry standard cad tool library characterize process final along several attribute design show figure one study impact granularity chip calculate individual module determine estimate effect common mechanism core run representative employ empirical model similar find equation one present formula use calculate detail obtain nine use similar experimental setup one v e x one v operate voltage temperature k constant b x z fit base similar analysis do include negative bias threshold inversion hot carrier injection em replacement replacement replacement f n e e r c n n e c r e p zero zero overlay top place rout implementation core core area power clock frequency data cache size instruction cache size technology node eight eight b implementation detail figure one embed purpose study assume fail component design one determine operational lifetime core use data next subsection discuss advantage disadvantage hardware different level granularity granularity granularity use describe unit isolation within processor core implicitly also define granularity redundancy leverage system important note strictly necessary use cold spar replace fail certain isolation noncritical faulty suffice various order increase granularity follow gate level level system replace individual logic gate design fail unfortunately design typically impractical require precise fault diagnosis tremendous overhead due redundant wire rout area module level scenario processor core break structure branch predictor design active research fifteen biggest downside level maintain redundancy full coverage almost impractical additionally case simple core even exist isolation since almost unique design stage level entire pipeline stag treat single monolithic replace level challenge one pipeline stag tightly couple performance loss two cold spar pipeline stag expensive area overhead fifty percent area overhead figure two gain addition cold spar granularity pipeline stag processor core base system single core machine gain show cumulative spare add order expect fail indicate time cold spare add system higher slope indicate better return area investment time involve design complexity core level level entire processor core isolate system event failure core level also active area research one perspective system designer probably easiest technique implement however return term lifetime extension therefore might able keep increase defect rate figure two demonstrate effectiveness include study due complexity implementation individual core compute describe previously define minimum module belong stage similarly core level define minimum across figure show potential lifetime enhancement function much area designer will allocate cold spar study evaluate cold spar also view investigate efficiently natural redundancy exploit reliability figure overlay three separate plot one level redundant spar allow add much area overhead data show figure two demonstrate go towards categorically beneficial far gain concern overlook design complexity aspect problem tend exacerbate hardware challenge support redundancy logic wire overhead circuit time management time coarse grain also ideal candidate since scale poorly area overhead therefore compromise solution desirable one manageable hardware better life expectancy stage level position good candidate follow reason one stag provide clean natural logically stag convenient boundary pipeline divide work level stag like fetch decode pipeline one pipeline two pipeline three r e g n n r g f n c pipeline figure three architecture slice equivalent logical process core figure show slice one crossbar switch keep pipeline stage order tolerate rare albeit possible failure switch term circuit implementation stag intuitive boundary data signal typically get latch end every pipeline stage two scale well increase available redundant spar see figure two three lastly vision ability share stag neighbor make system inherently redundant next section introduce architecture scalable fault tolerant pipeline design allow stage level three mi show previous section pipeline stage granularity effective tool combat future reliability challenge one ways allow granularity pipeline stag word remove direct communication stag replace switch base interconnection network conceptual picture chip use philosophy present figure three call design processor core within design part high speed stage processor pipeline correspond node network horizontal slice architecture equivalent logical processor core call use switch allow complete flexibility pipeline stage depth x communicate stage depth even different system isolate nod pipeline stag defective configure share certain stag nod eventually fail exhibit graceful degradation performance gradual decline throughput advantage architecture come free certain associate design namely area performance area overhead arise switch interconnection network stag depend upon switch design variable number cycle require transmit stag lead performance overview conventional embed processor pipeline two three usually consist five stag namely fetch decode issue see figure although block sometimes separate multiple stag sake simplicity generality treat single stage work start basic pipeline design figure show transform begin replace pipeline latch combination crossbar switch buffer graphical illustration pipeline design show figure ignore shade box inside pipeline stag significance portion address later section maximize performance propose use full crossbar switch since allow nonblocking access input b small number input output prohibitively expensive furthermore channel width crossbar vary trade performance area addition forward feedback loop architecture also need go similar switch different share thus require exchange result instance result say execute stage might need direct b issue stage due introduction crossbar switch three fundamental challenge overcome one global communication global pipeline signal fundamental functionality pipeline stall signal send stag pipe case multicycle memory access similarly flush signal necessary squash fetch along control stag global broadcast signal infeasible two forward data forward crucial technique use pipeline avoid frequent stall would otherwise occur data consecutive data forward logic rely precisely time architectural sense communication execute later stag use combinational link variable amount delay switch presence intermediate buffer forward logic within feasible three performance lastly even two solve communication delay stag still expect result hefty performance penalty rest section discuss design overcome challenge also propose recover lose performance branch feedback forward register fetch h c l decode issue h c l h c l register file h c l gen branch predictor simple pipeline branch feedback register e l b r e f f b fetch gen branch predictor e l b r e f f b packer decode e l b r e f f b e l b r e f f b register file scoreboard issue e l b r e f f b e l b r e f f b bypass e l b r e f f b b pipeline stag interconnect use full crossbar switch shade portion highlight present regular pipeline figure four traditional pipeline design functional need stream identification basic pipeline lack global communication signal global signal traditional approach flush upon branch applicable first addition basic pipeline stream identification register target problem design show figure certain shade order distinguish find traditional pipeline one additional stream identification register stag single bite register arbitrarily consistently across stag initialize zero one course program execution value change whenever branch take place every instruction carry stream id use stag distinguish correctly predict path incorrect path former process allow proceed latter squash single bite suffice pipeline model one resolve branch outstanding give time follow branch squash word stream id work cheap efficient mechanism replace global branch signal detail register value modify discuss basis fetch every new instruction stamp current value store register branch detect fetch use branch update stage toggle register flush program counter point onwards fetch stamp update stream id decode register update stream incoming cycle old stream id store decode match stream id incoming instruction branch detect decode flush instruction buffer issue maintain register along addition register register update stream id instruction perform register value update stream id last success fully issue instruction instruction reach issue stage stream id compare register value match eligible issue mismatch imply branch recent past knowledge require determine whether new incoming instruction correct path incorrect path register gather importance mismatch new instruction stream id indicate new instruction correct path execution hence eligible issue match imply otherwise new instruction squash complete significance make clear next subsection compare stream id incoming register event mismatch instruction squash otherwise instruction execute branch instruction toggle register value store stage along stream id branch resolution information send back fetch stage initiate change register value store branch instruction also update issue stage thus cycle update complete summarize normal operate condition ie go switch interconnection fabric get issue execute write back compute result occur use stream id mechanism incorrect execution path systematically squash time scoreboard second important component require proper functionality scoreboard reside issue stage scoreboard essential design forward unit normally handle register value feasible often scoreboard already present pipeline issue stage hazard detection scenario minor need tailor conventional scoreboard need pipeline pipeline need scoreboard order keep track register result outstanding therefore invalid register file one input register invalid stall issue stage scoreboard table two see figure one maintain valid meta information fill entirely decode stage list list assemble decode value populate issue stage list operation destination list source source point either list destination previous list list assemble decode value populate stage id mid length branch information stream id zero one zero one j figure five structure bite register second store id last modify instruction case branch scoreboard need wipe clean since get update wrong path execution recognize issue stage maintain register store stream id last issue instruction whenever issue stage find new incoming instruction stream id differ know branch take place point scoreboard wait receive receive already branch instruction finally wait period scoreboard clear new instruction issue give instruction x id last write instruction input register x scoreboard decide whether issue stall difference less depth bypass cache require input register guarantee present bypass cache assume maximum one destination therefore instruction issue outstanding input guarantee present bypass cache stall otherwise furthermore issue stage also perform selective register operand fetch value go available bypass cache optimization reduce number transfer issue stage stage network flow issue macro stall automatically handle maintain network back pressure switch interconnection crossbar forward value buffer subsequent stage stage stall similar way network queue handle stall implementation guarantee instruction never drop throw away buffer producer consumer base system transfer latency variable double buffer standard technique use make transfer latency overlap job cycle producer consumer stag input output latch double buffer enable optimization performance enhancement functional discuss previous section bring design point functionally correct however present state much leave table term performance section introduce address shortcoming bypass cache due lack forward logic frequent stall expect register alleviate performance loss add bypass cache stage see figure job cache store value generate recently execute within stage follow use cache value need stall issue fact cache large enough result every instruction issue write back retain would completely eliminate stall arise register manner bypass cache emulate work forward logic fifo replacement policy use cache older less likely produce result incoming instruction scoreboard unit issue stage make aware bypass cache size system first configure discuss scoreboard maintain id last instruction write particular register know size bypass cache absolute difference id performance design suffer significantly overhead transfer stag since every instruction go switch network variable amount delay instance instruction take three cycle transfer stag one cycle execute system perfect cache assume branch would four another way look since stag usually take single cycle execute instruction idle majority time wait arrive natural optimization would increase granularity communication bundle multiple two advantage one work multiple available stag work wait next arrive two eliminate temporary intermediate value generate within small sequence therefore give illusion data compression underlie interconnection fabric collection do statically compile time dynamically hardware keep overall hardware overhead low form statically compiler approach involve select subset belong basic block keep two set one number two number use simple greedy policy similar fourteen maximize number minimize number ideal one computational cost roughly equivalent communication cost effectively idea pipeline transfer computation complete structure show figure five compiler embed internal data flow information program binary decode packer structure responsible identify assemble leverage hint embed program binary packer assign branch resolution handler instruction buffer incoming next predict next x update branch predictor fetch controller mid packer logic outgo macro response request fetch b decode branch resolution incoming macro macro latch incoming macro macro latch reg id valid last mid last zero one two sixty zero one one zero one one zero one seventeen seventeen register issue controller c issue outgo macro functional unit reg id reg value outgo macro counter ex mem controller bypass scoreboard register file response request figure six pipeline stag gray block highlight add transform traditional pipeline unique id mid every flow pipeline stag also modify work instead simple particularly true stage controller cycle across individual comprise execute sequence however stag modify continue process one instruction per cycle imply register file port execution memory port increase number capability design overhead primarily arise new structure add every stage elaborate next subsection stage section go pipeline stag sum add fetch make fetch stage figure restrict addition register small amount logic toggle upon branch decode decode stage figure collect fetch instruction buffer instruction buffer common structure find pipeline design add register incoming instruction different stream id register toggle instruction buffer flush decode stage also augment packer packer logic read buffer identify assign id fill structure attribute issue issue stage figure modify include scoreboard track register ready issue register file read populate issue stage also maintain two register order identify branch flush scoreboard appropriate time stage figure house bypass cache partially emulate forward logic stage also first update register upon branch order handle execution controller modify go one time compute result save bypass cache later use four result discussion evaluation infrastructure evaluation infrastructure design consist two major one compilation framework two architectural simulator ten select variety evaluate differ condition include media encryption audio encode audio decode use compilation system first component selection algorithm implement compiler pass intermediate code representation pass code augment miscellaneous attribute figure five final code generate compiler use nineteen architectural simulator develop use liberty simulation environment functional emulator also develop within system two flavor simulator implement sufficient detail provide cycle accurate result first simulator model simple five stage pipeline also two four six eight bite e n r e z l r n six five four three two one zero e n r e z l r n two fifteen one five zero e n r e z l r n sixteen fourteen twelve one eight six four two zero three e g seven two g seven two one e one e c n c e e id c p c one r r w w r c four n c di io b e l e l v e r g e three e g seven two g seven two id c p c one r r w w r c four n one one e e c n c e e c di io b e l e l v e r g e figure seven pipeline bypass cache compare pipeline slowdown see issue stage stall reduce size bypass cache increase figure eight performance crossbar channel width crossbar find present good enough area performance mop three mop four mop five mop six experiment second simulator implement architecture propose table one list common attribute architectural base pipeline branch predictor level one id cache level two unify cache memory double buffer bite crossbar switch global history predictor sixteen one cycle hit latency five cycle hit latency forty cycle latency table one architectural attribute simulation result evaluate present performance result follow successive addition feature increase efficiency base performance performance basic comparison bar one two show figure seven basic imply configure stream identification logic scoreboard double buffer size keep fix one bypass cache result normalize processor average slowdown see price pay flexibility bypass cache addition bypass cache result drastic overall performance figure seven experiment size keep fix one bypass cache depth vary two eight depth bypass cache indicate number store figure seven bypass cache size beyond six hardly performance improvement follow fact bypass cache size increase almost outstanding register value get cache performance return progressively diminish average slowdown hover around addition bypass cache still quite high vary crossbar channel width channel width crossbar determine number cycle take transfer instruction two stag bigger value go improve performance time present higher area overhead figure eight illustrate impact vary crossbar channel width performance three data point present every channel width channel width infinite channel width add show maximum potential gain performance crossbar channel width use three e g seven two g seven two one e one e n c e c e c p c one r r w w r c four n c b e l e l v e r g e figure nine pipeline bypass cache capability handle compare pipeline optimal resource constraint vary find give best performance subsequent experiment average slowdown see crossbar might still consider costly trade flexibility achieve bypass cache performance result show figure nine bypass cache statically select bundle mop bypass cache size six large enough accommodate outstanding value bar plot except one two different configuration mop selection algorithm result show beyond certain limit relax selection result performance improvement prior reach limit relax help form longer thereby balance transfer time computation time beyond limit relax result longer merely increase transfer time without actually increase number distinct encode best result average slowdown eleven achieve constraint four register poor branch prediction rat perform worst see figure ten fact performance strongly correlate number per thousand expect use additional cycle spend data transfer stag cause design behave like deep pipeline future work look could eliminate branch code use similar scheme area overhead area overhead design arise additional structure add branch prediction accuracy branch miss c r c c ninety eighty seventy sixty fifty forty thirty twenty ten zero twenty fifteen ten five zero n c r n zero zero zero one e three e g seven two g seven two one e one e c n c e e id c p c one r r w w r c four n b e l e l c di io figure ten branch predictor accuracy number miss per thousand interconnection fabric compose crossbar switch area show use core see section figure area scoreboard bypass cache estimate take similar structure core resize appropriately scoreboard area estimate base register file bypass cache base require associative finally area double buffer base length maximum size store size structure do accord configuration achieve best performance crossbar switch area base model interconnection area connect pipeline stag crossbar switch discuss since challenge estimate without complete layout area bus link expect order magnitude smaller crossbar fabric design block synthesize place rout use industry standard cad tool library characterize process overall area overhead approximately crossbar switch total five make total area overhead twenty however actual area overhead slightly lower one conservative estimate two crossbar switch share system five construct see area overhead twelve five relate work concern reliability issue future technology spawn new wave research recent work address entire spectrum reliability fault detection diagnosis system repair recovery follow section focus relevant subset recent work propose tolerate adapt presence fault server design reliability design constraint around typically rely coarse grain replication provide high degree reliability six thirty however dual triple modular redundant incur term area power furthermore still remain susceptible since base premise fault unlikely impact redundant simultaneously condition obey give redundant execute identical experience similar age effect without additional traditional although effective detect fault significantly extend lifetime pro cessor give cost energy complexity overhead approach appropriate server embed computer elastic slightly different architectural vision fault tolerance exploit circuit monitor health individual core author propose dynamic reliability management throttle eventually turn core age time yet elastic rely upon redundancy management core level similar isolation one within framework system must provision massive number redundant core face prospect rapidly decline process throughput single fault disable entire core much work also do redundancy maintenance bulletproof fifteen spar array structure eleven structure scheme typically rely inherent redundancy core difficult leverage full coverage nevertheless approach incorporate system additional benefit since apply redundancy management finer granularity research focus build reliable future expect inherently processor grid twenty design recursive system black box employ unique fault tolerance project boast amount defect tolerance come overhead term redundant structure differ dramatically previously propose goal minimize amount hardware use solely redundancy importantly enable granularity pipeline stage make possible single core tolerate multiple much lower cost work extension eighteen explore potential pipeline stage level parallel al propose multicore architecture name core cannibalization architecture also exploit stage level allow subset lend stag break thereby avoid full crossbar interconnection unlike maintain feedback link avoid major change although design reduce overall complexity exist compare base six conclusion technology continue evolve must employ counter effect ever demand reliability challenge fault detection diagnosis must leverage together form comprehensive solution problem unreliable silicon work contribute area recovery propose radical architectural shift processor design motivate need network pipeline stag identify effective cost reliability enhancement although performance suffer first result dramatic change basic pipeline able reclaim much lose ultimately design exchange modest amount performance eleven area twelve overhead return highly adaptable pipeline robust enough withstand rapidly increase device failure rat expect future technology nod router width area percent overhead twelve design block area scoreboard bypass cache eighteen buffer percent overhead fourteen router area different channel width b area specific figure eleven area overhead crossbar switch seven graciously thank many answer question liberty simulation environment help cadence encounter also gratitude go anonymous referee provide excellent feedback work research support arm national science foundation grant research center one five research center fund focus center research program semiconductor research corporation program also kindly thank corporation equipment use carry research eight reference one n p n p j e smith isolation build high availability commodity multicore annual international symposium computer architecture page two arm three arm four j association failure model semiconductor technical report solid state technology association march five diva reliable substrate deep submicron design annual international symposium page six b p r j j nonstop advance architecture international conference dependable network page june seven k scale tutorial presentation eight j detection annual international symposium page nine j time analysis detection workshop architectural reliability page ten design reliable unreliable challenge transistor variability degradation micro six eleven f bower p g j tolerate hard fault array structure international conference dependable network page twelve f bower j mechanism diagnosis hard fault annual international symposium page thirteen electronic device degradation sons fourteen n clark al scalable map acyclic computation international conference architecture synthesis embed page fifteen k al bulletproof switch architecture international symposium computer architecture page sixteen k v detection hardware defect architectural support evaluation annual international symposium page seventeen oxide reliability summary silicon oxide breakdown reliability world scientific publish eighteen j fabric resilient adaptive architecture workshop nineteen v b architecture specification version eleven technical report twenty al recursive processor grid reliable system architecture unreliable international conference dependable network page june li p v diagnosis permanent hardware fault international conference dependable network june comprehensive error detection simple core micro one w dally delay model speculative architecture international symposium computer architecture page b f j core cannibalization architecture improve lifetime chip performance multicore processor presence hard fault international conference parallel compilation p c exploit redundancy defect tolerance international conference computer design page al reliable computer design evaluation edition ak j j kim j hoe b efficient resource share concurrent error detect annual international symposium page j c b gold b j c hoe reunion multicore redundancy annual international symposium page thirty l parallel enterprise server fault tolerance historical perspective journal research development six j v p bose j case lifetime annual international symposium computer architecture page june j v p bose j impact technology scale lifetime reliability international conference dependable network page june j v p bose j exploit structural duplication lifetime reliability enhancement annual international symposium computer architecture page june sylvester e elastic adaptive architecture unpredictable silicon journal design test six infrastructure research n j malik august liberty simulation environment deliberate approach system model computer three estimation likelihood capacitive couple noise design conference page c weaver fault tolerant approach design international conference dependable network page computer society e al interplay voltage temperature acceleration oxide breakdown gate electronics forty j terrestrial cosmic ray journal research development one