international symposium computer architecture high performance compute profile general purpose department computer science federal de brazil abstract witness increase adoption perform general purpose computation usually know main challenge develop often fit model require graphics process limit scope may benefit compute power provide even application fit model obtain optimal resource usage complex task one work propose profile tool tool use profile strategy base performance predicate able quantify major source performance degradation provide hint improve use tool program able understand improve performance one introduction despite evolution various computer program environment tool design implement scalable efficient parallel particular irregular still challenge one two wide availability open whole new scenario must better exploit understand particular witness continuous development improvement graphic card ie enable use beyond image render work partially support cap become general purpose however effective concurrent use available computational power creation efficient parallel challenge address work currently sake general purpose process almost always use main processor handle portion computation need perform fashion application development begin implement function interest call change original application code insert call function side application also perform necessary data transfer give initial version application normally inefficient pursue optimization step create code fully exploit process power port general purpose may observe performance degradation phase usage three four first since data may transfer carefully evaluate whether worth use consider amount computation perform need understand extent able use process capacity depend parallelism exploit later important observe application data access pattern use improve read instance coalesce data access configuration use execute code within also important deeply affect achieve performance five three one massive parallel program scenario responsible develop fully exploit eleven power also important create tool assist application development thus paper propose profile tool tool use profile strategy base predicate define set orthogonal complete performance help programmer understand potential source performance degradation quantify experimentally instrumentation besides describe profile strategy implementation illustrate tool may use understand performance issue two program possible perceive tool two architecture overview stand compute unify device architecture new hardware architecture issue manage compute device provide c extension program language alleviate burden programmer five program model view compute device suitable data parallel act accelerate host machine high number memory may run high number parallel thread thread group block turn group grid structure set thread launch kernel code process data store device memory thread block may share data fast unsynchronized memory require access synchronization must explicitly add programmer different block thread independent synchronize termination kernel figure one depict architecture example stream eight stream core three thread execute core single instruction multiple data model schedule unit use within warp group thread execute every four cycle execute warp thread alternate warp execution switch thread figure one organization three profile strategy section describe strategy profile start describe perform thread level combine generate performance profile several profile challenge lack interrupt due lack choose measure time instead periodic sample great challenge transparently switch thread way account many cycle spend thread programmer run multiple warp tool report cycle take thread action report cycle take perform action thread profile thread profile basis profile strategy since level combine take thread level implement tool read assembly six code generate instrument code assume last argument kernel array one integer thread run kernel use return profile data version programmer must manually add last argument call profile routine read code tool add code register instrumentation code virtual instruction set abstract architecture detail like register declare like c twelve use register example measure explicit add code read time store register barrier calculate elapse time add third register whose value write last argument vector allow code call time measure use system call measurement do read clock cycle counter register measure thread level take kernel basis perform kernel thread combine obtain start point measurement application execution time measure kernel execution time measure inside divide execution time kernel execute thread follow eight orthogonal idle active calculate subtract kernel execution time communicate time application execution time communicate c data transfer perform host process take place use system call measure time spend function compute p process calculate subtract kernel execution time read memory read r use clock cycle counter register measure time spend load write w write memory use clock cycle counter register measure time spend store explicit synchronization b block explicit synchronization execute function appear code instruction thus read clock cycle counter register measure time spend instruction implicit synchronization thread warp may take divergent execution compiler insert thread synchronize event time block distinguish implicit explicit synchronization former consequence code implicit appear explicitly code always insert label measure elapse time pass label single instruction count assign time excess waste computation w order avoid thread warp perform branch execute small code segment architecture allow conditional execution may efficient approach execute predicate variable true allow removal branch thread warp execute together predicate false instruction execution time account w warp profile take thread level combine warp level distinguish two group first group comprise thread basically average provide quantitative measure warp level communicate c compute p read r write w explicit synchronization b implicit synchronization waste computation w idle time split among inactive idle inactive characterize existence thread compute idle mean enough thread keep busy instance efficient use execute minimum thread fifty occupation consider current contain thirty application split thread parallelism level may possible many idle characterize simultaneous inactivity thread inactivity associate portion code execute intuition measure amount computational power use application profile overall application profile determine combine warp profile two dimension kernel application kernel profile average warp level profile warp provide perspective profile well time idle combine application profile start point understand performance thirteen four experimental evaluation experiment run machine dual two sixteen ram dual channel disk memory connect gen one slot bus connection provide section present program use evaluate framework matrix multiplication matrix multiplication choose canonical example program development optimization step well know hand seven evaluate irregular highly optimize application performance difficult understand follow subsection discuss program matrix multiplication matrix multiplication widely use many discuss canonical example program operation multiply give matrix scalar another matrix without loss generality example multiply two square matrices b store result third matrix c seven efficient sort algorithm suitable highly parallel multicore graphics design take advantage high minimize amount bookkeeping synchronization need achieve use design keep synchronization low coalesce read constrain thread memory access keep minimum also take advantage atomic synchronization find hardware available improve performance partition iteration new pivot value pick result two new create sort independently enough available thread block assign one reason algorithm two albeit rather similar phase first less partition thread block thread need work together sequence second thread block work one partition algorithm use place sort would require expensive thread synchronization would quickly increase application use thread main reason use place sort good cache locality cache algorithm write sort data auxiliary buffer end iteration buffer change partition allocate space write data thread count number greater smaller pivot compute calculate thread write data expensive operation use even thread block work partition result matrix multiplication order evaluate development process guide profiler create two kernel optimize second version show time spend profile category process kernel instrument normally execute first version matrix multiplication whose code show figure two multiple block kernel version create thread calculate single element result matrix thread group multiple block responsible different result matrix call tile thus begin kernel thread identify data index process accord block thread experiment kernel version perform use matrices divide sixteen block sixteen sixteen configuration sixteen block choose avoid concurrency block thus responsible one block figure three present time spend warp cate fourteen rename row index arow column index b float zero thread compute one element block k zero k width k b multiple block figure two matrix multiplication kernel cod zero float float load input tile b compute result tile zero c b share memory tile version divide source matrices b tile read share memory reuse thread show figure two b thread block read data element share memory synchronize guarantee whole tile read latter compute multiplication use data share memory provide faster access data store faster memory also optimize global memory load data access contiguously figure four share memory finally result last version show figure four average execution time kernel warp reduce factor two also show appear negligible implicit store relate synchronization introduce behind warp thread fifteen figure three multiple warp configuration kernel able execute warp divide among sixteen group eight warp time spend show memory load expensive category memory access identify application bottleneck programmer verify efficiently application exploit memory architecture simple analysis multiple block version sufficient perceive read element matrices b global memory may efficient approach thus read share memory reuse data could reduce amortize memory access cost therefore optimize memory access implicit kernel faster store cost increase higher level concurrency io mechanism important understand optimization present could easily detect kernel simple complex require better may difficult understand performance implementation algorithm discuss section divide two phase implement use multiple first algorithm phase implement use three count many number smaller pivot data copy kernel implement step copy data one partition new pivot create pivot writer write pivot position copy data second phase implement kernel last three divide partition block execute multiple performance reason partition size equal smaller use sort section evaluate three time relevant copy data although experiment execute sixteen block second phase require power two number block would like evaluate hardware instance sixteen use one thread block execute multiple thus input data use experimentation sixteen million unsigned figure five five b show result data copy present last warp higher idle time due application intrinsic use less thread last call final first phase figure five c figure six respectively see second phase kernel entire execution become evident second phase dominate execution time responsible also important note result show high load unbalance thread warp seven second set warp time dominate idle category reason detect load unbalance directly relate pivot choice strategy analyze application first pivot figure six entire application figure seven entire application balance partition choice saw first two partition number respectively responsible order verify hypothesis manually modify first pivot value get balance division first two partition actually value performance new execution present figure seven reduce execution time thirteen use hardware gain derive better utilization load unbalance idle time reduce common approach optimize application execution time execute maximum number thread parallel may better exploit available instance warp run may io due also evaluate application increase number warp execute figure eight show average time spend thread warp per category number warp increase sixteen b data copy kernel c figure five evaluation dominate total another tool nine parallel application profiler tool able insert instrumentation dynamically restrict intrusion part code analyze tool first implement profile distribute modify al ten support multithreaded beside recent work power multithreaded specific benefit although address general tool develop optimize complex environment boyer al present system eleven analyze two class common race condition share memory bank conflict employ approach automatic instrumentation cod latter execute emulation mode run although profiler interest identify analyze class work fail measure impact memory bank conflict application run work present approach profile instrument intermediary assembly code able measure impact important task perform execution visual profiler twelve provide help application development process create application profile use different counter coalesce access global memory local load store divergent branch profile least three important address work one counter use base within warp indication actual performance figure eight increase warp per result first show increase number thread run parallel may efficient execution time reduce factor three also important see increase number thread warp parallelism negligible store become important whole execution time also show expensive task computation load impact less application dilute thread run parallel five relate work several work profile sequential parallel program optimize code base profile gnu profiler tool measure performance program record number call function amount time spend basis eight function consume large fraction identify easily output speed program concentrate first seventeen application real impact category performance measure show number cycle spend two analysis base one useful irregular different warp run several profile three system able create profile show profile entire kernel specific work three study processor organization feature optimization adopt achieve high performance six future work paper address performance profile approach define complete orthogonal set may measure current illustrate effectiveness approach two program able detect measure understand source performance degradation future work include analyze program well improve instrumentation instance distinguish coalesce memory access finally also intend investigate whether integration dynamic static profile better option sake performance understand reference one c stone j w w program optimization space prune multithreaded eight symposium code generation optimization new york two lee min r compiler framework automatic translation optimization symposium practice parallel program new york three c stone b kirk w w eighteen optimization application performance evaluation multithreaded use symposium practice parallel program new york four p b k r j j j clinical evaluation cone beam compute tomography proceed medical image compute intervention five program guide corp version six compute parallel thread execution corp june version twelve seven p practical algorithm graphics eight proceed annual symposium berlin eight l graham p b k call graph execution profiler program language design implementation new york nine b p miller j j k r b k l k parallel performance measurement tool computer vol eleven ten z b p miller dynamic instrumentation thread symposium practice parallel program new york eleven boyer k w dynamic analysis program third workshop tool multicore twelve corp visual profiler