fast compiler evaluation use base performance prediction member institute compute architecture university university member alchemy group abstract performance tune important time consume task may repeat new application platform although iterative process still require many different program execution time frequently limit factor number transform program consider need mechanism automatically predict performance modify program without actually run paper present new machine learn base technique automatically predict modify program use performance model base code feature tune program unlike previous approach require prior learn suite furthermore use predict performance tune restrict prior see transformation space show deliver high correlation coefficient use dramatically reduce cost search subject program program optimization artificial intelligence general term performance experimentation performance model compiler architecture machine learn artificial neural network one introduction tune improve performance important tedious time consume task performance critical find embed per permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee seven may copyright form new application new platform programmer first make potentially beneficial program modification compile transform program finally execute new program record execution time cycle must repeatedly perform sufficient performance gain achieve programmer run time much work area iterative aim process seven nine ten eleven sixteen nineteen approach focus choose good program number cycle reduce although possible find good performance improvement automatically iterative still require many different program execution time frequently limit factor number transform program consider need mechanism automatically predict performance modify program without actually run ideally predictor would independent platform program importantly restrict certain class program scheme would allow many different rapidly evaluate dramatically reduce time produce tune application alternatively amount time many program could consider increase performance achieve paper present new technique automatically predict modify program use performance model base code feature tune program build model first randomly transform program tune run target platform number time code feature modify program plus execution time use train machine learn base model learn model able predict new modify version program without execute unlike previous work four need run extensive train suite build predictor need run program tune limit fix transformation space case model four instead use feature code predict performance modification program paper show able effectively predict performance large number tune program sample use sixteen sample predict performance correlation coefficient sample rise eight highly accurate predictor furthermore show technique use guide iterative process help select likely give good performance four time faster random search thirteen different program list table three restrict attention sequence length five give different program see section five detail apply transformation sequence seventeen compress program run correspond transform program embed platform instrument cluster processor result apply transformation sequence show figure one curve label real actual achieve various tune apply compress obtain apply transformation sequence simply transformation sequence sort increase actual program give best achieve want build predictor predict behaviour base small number program sample example randomly generate transform program execute order build predictor able predict remain point space performance prediction scheme show line label feature predictor visually apparent model able fairly accurately predict performance program apply different transformation sequence require run randomly generate transformation sequence program learn model represent less one whole space model predict performance remain transformation sequence apply program first may surprise small train set size sufficient capture huge space however transform program large similar behaviour capture furthermore use code feature model automatically determine performance region transform code belong mean predictor mean absolute error although scheme appear perform well important fair comparison default scheme order evaluate naive scheme one always predict base average value transform program perform experiment frequently enough naive predictor always predict mean value space thus call mean predictor show line label mean predictor figure one role mean predictor become apparent consider metrics quantify quality commonly accept metric mean absolute error define mae predict real n n represent total number observe value figure two mae predictor compare mean predictor plot function number run use build model model improve number run exhibit similar mae however know figure one mean predictor poor performance prediction distinguish different program fact mae mean predictor give information variance space formally variance space equal mean square error mean predictor strongly relate mae figure one space compress program represent transform program sort order increase denote value correspond transform program original program curve label real denote actual performance curve label feature predictor predict value scheme use randomly transform program focus paper use prediction avoid execution new platform much potential application ability automatically predict program performance particularly early stag processor design typically use allow easy exploration different cost drastically increase execution time overhead simulation make program tune prohibitively expensive actual hardware available able build accurate performance predictor would overcome cost simulation allow program processor architecture paper structure follow motivation example first provide section two illustrate benefit use performance predictor show simple error metric poor measure performance prediction show correlation coefficient better fit section three briefly describe various model evaluate paper follow section four describe detail program feature use build model section five describe experimental set use section six evaluate different model one main benefit approach ability predict performance unseen section seven show predictor use select good program unseen transformation space follow brief review relate work section eight finally section nine conclude paper two motivation section illustrate predictor use estimate different program describe ways accuracy may evaluate want compare predict performance different program actual value order give realistic evaluation rather evaluate automatically generate many different program use one eleven twelve thirteen fourteen fifteen sixteen predictor mean absolute error b correlation coefficient figure two evaluation performance compress program sample size logarithmic scale represent number different compress program train data need train model model train fifty time use different random train sample value show thus average correlation coefficient although mae give insight accuracy predictor good distinguish good poor program evaluate quality predictor therefore choose use correlation coefficient metric explain section take value zero one neglect sign closer one value better predictor figure two b show correlation coefficient predictor mean predictor mean predictor correlation zero mean unable predict shape curve predictor able improve accuracy number train sample increase scale logarithmic point six represent sample run correlation coefficient accurate predictor detail performance particular version predictor already show figure one correlation coefficient therefore good metric since allow us quantify single number well predict value follow real figure three search large space compress program represent number transform program show amount performance improvement achieve eight search use model eight prior train random denote simple random search use predictor find good point another way evaluate quality predictor use search good point previously unseen transformation space word well predict performance program transform manner never see use guide search good figure three show random search predictor perform search new space new space contain transformation sequence length twenty select refer large space see table four detail random search perform randomly select transformation sequence space run result program repeat time best transformation sequence find far keep curve label eight show performance predictor build use eight sample small element space show figure one use follow initially random point select execute new space different sequence describe section seven code feature extract refer space large space predictor rank sample base predict performance figure one show predictor accurate determine absolute best perform option good identify good prediction base search eight start execute version best predict execution time second best time interest notice use scheme mean predictor result random search mean predictor assume equally good prediction hence randomly select see figure three predictor dramatically outperform random search predictor use search new space train use eight sample small different space still useful search space transformation sequence never see unlike previous approach four example illustrate one way model use performance tune zero five one fifteen two one two three four five six seven eight size power two feature predictor zero two four six eight one one two three four five six seven eight size power two feature predictor one eleven twelve thirteen fourteen fifteen sixteen seventeen zero ten twenty thirty forty fifty sixty seventy eighty ninety artificial neural network model second model prefer model ann main advantage linear neural network three regressor model nonlinear space ann one hide layer contain one five hide weight standard algorithm use train ann alternative compare model mean predictor sequence predictor approach neither use code feature mean predictor introduce section two mean predictor act predictor use feature always predict mean point sample value compute train set tend towards mean space enough sample take space mean space constant value mean absolute error mae therefore make good base case predictor sequence predictor approach similar code predictor use vector encode sequence instead program feature input model choose encode take account order simply presence give transformation sequence predictor last predictor consider scheme describe four like previous predictor directly use sequence apply program input learn model four addition use signature program input signature refer correspond obtain sequence apply program behaviour program major difference present paper require extensive prior train suite effect build model correlate transformation sequence show work well straightforward use four source code feature main distinctive characteristic methodology use program feature mean build accurate performance model section describe essential program feature extract transform program order build model since feature extract source level platform independent unlike approach right feature critical performance accuracy follow section describe provide justification selection description feature feature program derive information describe within program three show table one roughly correspond computation address since feature extract use twelve consider simply base intermediate representation use within figure four train use predictor train phase set transformation sequence apply original c program pair value gather feature extract transform program execute pair value compose train set use train model use iterative process model train use predict new transformation feature extract new transform program use input model three learn predictive model section describe approach build accurate predictor use small number run transform program associate code feature approach also consider later use comparative evaluation section six predictor figure four show feature base predictor train use train set randomly select transformation sequence apply target c program result transform program feature extract value collect run program create set pair use train model model train new transformation sequence apply program feature new program extract feed model provide prediction unlike reaction base approach four need train prior suite instead simply use code feature transform program predict performance type code feature use describe detail section four description give summary overall approach however give pair number model approach consider build predictor consider two scheme linear model linear regression one basic model often use make prediction compute weight sum statistic input weight determine mean square error train set advantage method reside simplicity problem find optimal weight simply reduce matrix optimal weight one n compute prediction make simple weight sum input f f f performance evaluate section six computation load constant value conversion load memory store memory branch comparison use jump copy shift rotation arithmetic operation multiplication division logical operation function call array access memory operation array reference return function address computation load constant value conversion label lod rot log cal mem ret label ary label loop body loop test loop statement table one three consider feature extraction computation memory access figure five four class feature represent factor influence performance class feature use four separate class feature base three different program show figure five feature consider good program performance feature class code size determine simply count number occurrence operation program second class derive count number execute use profile information original program see next section detail level parallelism available third feature class assume ideal machine execute operation one cycle unlimited give profile information total number cycle require execute program quickly approximate finally estimate number distinct memory access statically source code four feature class easy determine provide signature program behaviour relative feature interest relative original program figure six profile information extraction need record difference feature transform program therefore feature vector extract take relative difference feature transform program feature vector thus contain null value mean correspond feature original code transform code extract execution frequency certain feature determine statically instance number loop might unknown hence profile information use determine execution frequency basic block extraction information figure six counter insert original c source code dynamic structure profile information collect original program first run negligible overhead fact similar develop fifteen original program annotate information information available subsequent transformation apply profile information update way able extract accurate feature subsequent modify version without affect program behaviour reduction dimensionality total number feature extract per c program mean model input unfortunately ann every input correspond neuron since number free increase number need keep number small first step consist remove redundant feature instance float point drop program perform float point operation filter do automatically model train leave average feature result feature thus specific program stay different program reduce number input apply well know technique call principal analysis three linear transformation transform data new system variance projection data come lie first call first principal component second second setup keep main account total variance case number input typically reduce five use technique table two program use experiment correspond maximum available small space program compress edge detect fir histogram spectral estimation maximum transformation loop unroll factor loop nest loop conversion break load constant common elimination dead code elimination hoist loop hoist move copy propagation table three thirteen use generate program five experimental setup section provide brief description program use evaluation seventeen twenty suite contain small well compose complex size program range twenty line code program use list table two represent widely use embed despite fact program relatively small compare suit approach still use bigger program bigger program locally instance basis predictor build individual function consider available compiler one twelve select describe table three arbitrarily consider four loop unroll factor increase number consider thirteen exhaustively evaluate sequence length five select thirteen possible transformation sequence since transformation appear twice sequence however since unroll appear sequence one possible unroll factor decrease total number possible sequence evaluate per platform instrument float point run processor contain internal memory program compile use ti code composer studio tool version compiler highest level flag generate large memory model code figure seven correlation coefficient feature ann predictor five hide correlation plot function train set size logarithmic scale per program basis mean predictor constant zero correlation statistical significance train involve randomly select sample possible transformation sequence order get statistically behaviour repeat sample fifty time thus sample size show average result fifty appropriate record standard deviation addition train set need one execution program compute relative subsequent six experimental result section compare quality scheme use different model propose section different describe section correlation coefficient show motivation section mae though important metric good measure predict right shape trend space want use predictor discriminate good bad transform program need metric capture model accuracy shape space x analyse quality model therefore use correlation coefficient correlation two define x x x represent standard deviation variable x respectively x covariance variable x correlation coefficient take value one one value relation two ignore sign extreme correlation one mean perfectly positively correlate one variable express product one linear relation correlation zero mean linear relationship two figure seven show coefficient vary number run use train model program model use model use five hide since lead best average performance see next section line correspond particular program point line correspond correlation coefficient give train set size logarithmic scale give sufficient train data predictor perform extremely well case except even smaller train set one zero one two three four five six seven eight nine one one two three four five six seven eight size power two coefficient correlation coefficient b standard deviation correlation coefficient figure eight correlation coefficient standard deviation different model average across fifty run per program function train set size logarithmic scale scheme still perform well average correlation coefficient expect mean predictor perform badly across unsuitable mean distinguish fast slow program comparison model previous section show scheme perform well require program run plus associate program feature accurately predict performance large number program section evaluate different model propose section figure eight show correlation coefficient different model line represent performance particular model average across entire suite point describe correlation coefficient particular train set size feature ann base approach outperform linear regression small sample size linear regression improve performance greater train run however best feature base scheme across entire train set size one use ann five hide enough sample train set correlation coefficient greater eight show model work extremely well figure nine comparison different predictor average across correlation coefficient function train set size logarithmic scale give model base random sample transformation space build train set useful know standard deviation clearly volatile predictor useful figure eight b show standard deviation vary train sample size logarithmic scale scheme show decrease standard deviation increase sample size expect ann model use five hide outperform model standard deviation comparison figure nine show comparison predictor expect mean predictor worst correlation coefficient predictor base encode sequence input need approximatively four time many sample best scheme approach four ann five perform similarly train sample per program independently train size behaviour explain fact train model do run require program interest use train model thus small number run necessary even gain train phase program regressor perform worst approach two run section show use program feature allow construction good performance next section evaluate use select good performance improve seven predict new sequence one main advantage use code feature ability predict performance new transformation sequence code order evaluate use combination unseen randomly generate different program use different list table four length twenty new space refer large space motivation section lead approximately unique sequence one zero one two three four five six seven eight nine one two three four five six seven eight size power two ann ann ann linear zero one two three four five one two three four five six seven eight size power two standard deviation ann ann ann zero one two three four five six seven eight nine one two three four five six seven eight size power two ann ann ann predictor transformation loop unroll factor loop tile tile size one nine split deep loop one nine loop flatten loop turn imperfectly nest loop perfectly nest loop hoist loop move guard induction variable detection array pad pad one nine extract array upper bound improve array bind information reconstruct explicit array reference constant array reference aggressively constant array reference expression tree breakup one nine reassociation control simplification forward propagation copy propagation constant propagation constant fold bound comparison substitution common elimination replace constant reduction detection dead code elimination bite pack hoist control flow replace array deliberation form array chain multiple array reference dismantle dismantle dismantle dismantle array dismantle branch dismantle dismantle spill index variable dismantle modify index variable dismantle empty dismantle empty symbol table lift call eliminate copy eliminate local static global variable put explicit nonlocal eliminate enumeration type table four use large space order find good sequence large space perform search use predictor ann five hide predictor train sample small space describe use predictor evaluate use find good transformation sequence new large space search space figure ten show result obtain predictor use search large space build different amount train data eight small space show diagram compare random search predictor use predict program order base predict decrease order search occur program version highest predict execute second best see graph sample use train phase eight better search result case model train prior run achieve seventy available ten run take forty random achieve search alternative way use predictor search space consist randomly search within point predict figure ten search large space good sequence predictor use ann five hide train size vary eight sample within x maximum instance choose x one sequence whose prediction within one maximum predict value search reason apparent figure one show several predict maxima order decrease order start best one predictor get stick one local maxima keep point within give percentage maximum prediction filter away poor without get stick local maxima assume real maximum value space lie within percent maximum prediction figure eleven show assumption hold three model vary amount train data eight use search large space model first approach denote line show perform well initially fail provide substantial improvement later scheme denote x x represent threshold apply show slightly worse initial performance able sustain performance gain throughout search seem threshold set five lead best trade allow substantial improvement first method twenty run obviously choice strategy depend number available allow less tight filter need overall scheme consistently deliver good performance level five faster number require random search interest note threshold correspond random search section show predictive model good predict performance transform program also use find good new transform program employ iterative search new transformation space eight relate work prior work focus predict good rather predict performance rely program program instance al eighteen al al one use static loop nest feature feature may capture static program best predict program apply al five describe use ten twenty thirty forty fifty sixty seventy eighty zero ten twenty thirty forty fifty sixty seventy eighty ninety available improvement train sample b eight train sample c train sample figure eleven graph show predictor train different amount train data line correspond performance correspond search technique supervise learn control whether apply instruction schedule al eighteen use classifier base decision tree learn determine loop unroll look performance compile program spec suite use two different al use machine learn best unroll loop factor give loop nest improve orc compiler heuristic approach successful automatically generate compiler code segment rather predict eventual performance select whole program rather predict impact single transformation look search two six nine ten eleven sixteen nineteen best set sequence particular program cooper al six propose number solve compilation phase order problem technique search best phase order particular program approach give impressive performance perform time new application compile model also need construct new application use accurately predict quality unseen thus train sample kulkarni al sixteen introduce allow exhaustive enumeration distinct function instance would produce different fifteen exhaustive enumeration allow construct different pass use construct probabilistic batch compiler dynamically determine apply next depend one highest probability enable al ten develop technique speed program iterative use static time consume code section phase detection scheme technique speed iterative search several order magnitude beneficial train data generation stage model pan al nineteen partition program tune section develop fast find best combination tune section able reduce ten twenty thirty forty fifty sixty seventy eighty ninety zero ten twenty thirty forty fifty sixty seventy eighty ninety available improvement one five ten random ten twenty thirty forty fifty sixty seventy eighty ninety zero ten twenty thirty forty fifty sixty seventy eighty ninety available improvement one five ten random ten twenty thirty forty fifty sixty seventy eighty ninety zero ten twenty thirty forty fifty sixty seventy eighty ninety available improvement one five ten random time find good approach typically use conjunction technique order deal bigger program al one build model good transformation sequence train data per program basis use guide iterative search new program unlike paper attempt predict good apply rather predict performance impact particular transformation predict performance significantly difficult problem require precise capture architecture behaviour although little work predict performance program arbitrary transformation space relate work perform architecture design space exploration al fourteen propose analytical model hardware exploration capture key performance feature model potentially use exploration construction model ad complex process make difficult replicate al eight smart framework two independent approach use statistical simulation similarly capture processor generate synthetic trace later run simplify simulator program transformation new trace require full functional simulation need generate approach use exploration thus approach suitable exploration recently thirteen propose distinct method considerably speed hardware exploration process idea train ann predict impact hardware parameter cache size memory latency performance behaviour target architecture train less five design space model accurately predict performance less two error though note mean discriminate compare mean predictor also modification program binary apply program transformation require train new model use several result approach also suitable exploration approach similarly rely machine learn build performance model accommodate new program transformation without retrain nine conclusion future work paper show possible automatically derive performance predictor tune program use program feature show construct use machine learn base approach unlike previous approach require train run per program prior train suite addition predictor restrict previously see incorporate approach single hide layer ann show high level predictive accuracy achievable furthermore show predictor use find good transformation sequence unseen transformation space future work combine technique architectural performance prediction allow automatic performance prediction space ten reference one f e j b g f p j c k use machine learn focus iterative optimization six proceed international symposium code generation optimization march computer society two l cooper k j reeve w l waterman find effective compilation sequence four proceed conference tool embed new york press three bishop c neural network pattern recognition university press four j c f e f p g automatic performance model construction fast exploration new hardware design case six proceed international conference architecture synthesis embed new york press five j j moss b induce decide whether schedule four proceed conference program language design implementation new york press six cooper k reeve l waterman search compilation sequence tech rep rice university seven cooper k j reeve l waterman acme adaptive compilation make efficient five proceed conference tool embed new york press eight l r h b b k l k control flow model statistical simulation accurate efficient processor design study news two nine b j g probabilistic embed program five proceed conference tool embed new york press ten g practical method quickly evaluate program proceed international conference high performance embed eleven g p evaluate iterative compilation proceed workshop parallel twelve hall w j p murphy b r e lam maximize performance compiler computer twelve thirteen e r de b r efficiently explore architectural design space via predictive model proceed international conference architectural support program operate five fourteen smith j e processor model proceed annual international symposium computer architecture four p fifteen k r g h application source code profile design five proceed annual conference design new york press sixteen kulkarni p w moon h cho k j bailey k find effective optimization phase sequence proceed conference tool embed seventeen lee c suite eighteen f r machine learn approach automatic production compiler two proceed international conference artificial intelligence methodology nineteen pan z r fast automatic performance tune pact six proceed international conference parallel compilation new york press twenty chow p lee c comparison traditional architecture compile proceed international workshop compiler architecture support embed case predict unroll factor use supervise classification five proceed international symposium code generation optimization computer society n august compiler exploration three proceed international symposium code generation optimization computer society f r e b hoe j c accurate simulation sample perform rev one r e f b hoe j c smart accelerate simulation via rigorous statistical sample three proceed annual international symposium computer architecture new york press