predictability system real world tan department computer science north state university computer become increasingly complex system become major concern system management paper present comprehensive measurement study quantify predictability different system anomaly prediction allow system foresee impend take proper action mitigate anomaly impact anomaly prediction approach combine feature value prediction statistical classification conduct extensive measurement study investigate anomalous behavior three real world smart hard drive data system observe real world system exhibit predictability predict high accuracy lead time introduction modern computer cloud compute one two enterprise data center massive data analytics three web host service become increasingly complex grow scale functionality unfortunately complexity make vulnerable various performance bottleneck resource service level objective various system often overwhelm task correct system time pressure thus imperative provide automatic system anomaly management achieve robust computer previous system anomaly management work four five six seven eight nine two one reactive approach take corrective action anomaly happen two approach take preventive action system beforehand reactive approach prevention cost prolong service often unacceptable continuously run data stream process moreover reproduce perform anomaly diagnosis may limit effectiveness reactive anomaly correction contrast approach offer better system reliability incur prohibitive overhead end explore new predictive anomaly management approach foresee impend system intelligent prediction take steer system away abnormal state often difficult achieve efficient predictive anomaly management one big challenge provide high quality system anomaly prediction although previous work ten eleven twelve address anomaly detection problem anomaly prediction need capture raise advance anomaly alert anomaly happen thirteen present initial design anomaly prediction scheme however one big question whether real system exhibit certain predictability whether anomaly prediction scheme efficiently capture predictability goal work provide quantitive answer question conduct comprehensive measurement study range real production anomaly prediction approach aim achieve advance anomaly prediction certain lead time intuition behind approach system often manifest gradual system metrics system escalate anomaly state monitor various system metrics call feature load free memory disk usage network traffic build feature value prediction model use chain scheme also induce statistical anomaly use naive tree augment naive tan learn integrate feature prediction anomaly classifier forecast system anomaly state future time paper conduct extensive comparative study quantify predictability system three production one failure data incorporate real host period widely use compute platform fourteen two smart disk failure data fifteen include measurement data disk among disk experience disk three system performance anomaly data report stream process cluster three extensive measurement study reveal follow key first real world system exhibit vary predictability anomaly prediction scheme achieve true positive rate less twenty false positive rate ping failure data second lead time true positive rate less ten false positive rate eighteen lead time smart disk failure data true positive rate less ten false positive rate two eighteen second lead time system performance anomaly data second use proper chain scheme achieve high prediction accuracy system metrics except metrics whose value present irregular change pattern large variation range however observe low prediction accuracy small number metrics significantly affect accuracy integrate anomaly prediction model third simple statistical naive tan model achieve high accuracy give sufficient train data normal abnormal state tan model outperform naive method case since relax strong independence assumption make naive method however also observe one exception smart disk failure tan worse performance naive reason tan model estimate conditional probability base class variable also metrics smart data set include metrics large variation range distribution result unreliable estimation conditional rest paper organize follow section present design anomaly prediction scheme section describe anomaly data collection experimental result discuss relate work section finally paper conclude section v system design section present design detail system anomaly prediction scheme first describe feature value prediction scheme follow statistical anomaly classification present integrate anomaly prediction model feature evolve pattern model use finite chain model evolve pattern various system feature consumption memory usage data rate example figure one show model metric range zero thirty three state build chain model metric x distinct state learn transition probability matrix matrix element row column j denote conditional probability make transition state state j derive train data set count number different state transition observe assume chain homogeneous derive feature value distribution x time future apply equation time probability distribution metric x two x zero denote probability distribution time initial probability distribution metric x respectively give current state want predict state future time need check matrix x row decide probable state ie state x five five three three three bin one five bin three five two bin two two two fig one feature evolve pattern prediction metric value range zero thirty partition value metric three state arc label state transition probability transition probability current state evolve time use need perform transform continuous feature value discrete state common include approach approach divide range feature value bin approach put number sample bin however find two approach incur high prediction error experimental study address problem propose hybrid approach first use approach create bin check number data sample fall bin bin extremely small number data sample less ten second bin accept otherwise apply approach use bin merge bin neighbor iteration merge bin contain number data sample proceed total number bin reduce target number merit hybrid approach preserve original continuous attribute distribution eliminate negative effect balance number data sample allocate different bin experimental section show impact different approach accuracy feature value prediction also possible apply prediction filter predict feature value future time choose work since provide possible value feature future time thus easily integrate feature value prediction result statistical anomaly compute anomaly probability future time detail integrate anomaly prediction model describe section b statistical anomaly classification goal anomaly classifier decide whether system currently run normal abnormal state let denote measurement sample vector system metric value time let denote system state time take one two state abnormal one normal zero input classifier train data set contain time series record h omit subindex context clear c c x three x one x two x three x four x two x four naive classifier b tan classifier fig two statistical anomaly classifier one class variable c four feature note classifier train process supervise since depend anomaly detector sixteen anomaly predicate ten provide proper class label train sample ideally classifier able produce posterior ie p c p c give measurement x compare posterior abnormal normal class decide classification result system abnormal follow inequality hold log p abnormal x log p normal x one otherwise system consider normal state mean classification confidence since likeliness one class overwhelmingly greater class typical value either zero prior difference likelihood derive train data however compute posterior probability challenge need evaluate p c every possible x multidimensional feature space dimensionality high computation costly leverage bay rule transform posterior probability p c conditional probability p c apply naive classifier seventeen naive tan network eighteen work naive classifier assumption naive classifier metric independent give class label illustrate figure two compute p c apply bay rule transform posterior probability conditional probability p c p c p c c p x two q neglect denominator p x depend c focus numerator fraction apply naive independence assumption transform p c n p c naive tan network tan model extend naive model consider among metrics constraint metric one parent network class variable structure tan model tree root class variable c contain conditional tree node illustrate figure two b posterior probability p exactly equal still proportional multiplication conditional individual metric however different naive classifier metrics independent apply exist scheme nineteen learn tan model example derive follow proportional tan model show figure two b p c p c p c p c p c posterior probability p c proportional probability c assign abnormal normal use odds ratio twenty denote x assign class label sample vector x ie system abnormal follow inequality hold p c one p c p c one p c x three threshold tunable parameter use control classification confidence typical value one c integrate anomaly prediction achieve advance anomaly prediction scheme integrate feature value prediction statistical anomaly classification feature evolve pattern model predict value metric future time anomaly classifier use perform classification future predict metric value word computation conditional naive tan classifier replace metric value equation two equation three predict metric value form prediction model naive classifier need replace deterministic discrete value xi possible discrete value xi take denote p xi probability xi take value future time give current value xi therefore p c become p xi p xi c c since build prediction model separately collect metric aggregate metrics x get predict posterior p c use equation one get anomaly prediction result p tan classifier compute predict posterior probability similar way naive model except metrics whose conditional depend metrics figure two b example metric depend metric want evaluate p c future time need sum metric metric specific use p p denote probability take value future time give current value respectively compute p c p p c c aggregate metrics x get predict posterior probability p c use odds ratio equation three get anomaly prediction result p p p system evaluation section evaluate anomaly prediction scheme perform comprehensive measurement study three first describe evaluation methodology next present analyze experimental result evaluation methodology implement anomaly prediction system deploy several real world compute fourteen virtual compute lab two system stream process cluster three one big challenge measurement study collect real system anomaly data deploy production although previous research project collect various failure data lack continuous measurement data require anomaly prediction system one exception smart disk failure data fifteen include measurement study collect real world system anomaly data develop scalable continuous monitor system deploy system collect set real system anomaly data monitor extend period time collect metrics use train feature value predictor anomaly classifier describe anomaly trace data use paper anomaly data collect measurement data widely use open compute platform monitor nod distribute world system collect host metrics load virtual memory state disk usage network traffic detail description metrics find either monitor site monitor site metric sample period ten second start data collection since use set experiment collect monitor infrastructure capable capture three type node one ping failure host responsive successive five ping initiate management node two failure node access command three monitor sensor failure monitor sensor program run node crash restart detect failure record failure log node name system store monitor metric data receive different nod separate log file correlate failure log monitor metric log use node name failure start time label record right failure occurrence abnormal record normal smart disk failure data second anomaly smart self monitor report technology data collection disk fifteen contain time series smart attribute collect smart incorporate modern hard disk drive totally distinct disk label good remain label fail disk sample smart attribute value sample collect interval two good disk approximately sample number sample fail disk range ten fail disk collect data may get corrupt even lose failure smart one sample originally consist attribute remove attribute obviously useful prediction serial number frame system anomaly data collect third anomaly trace system three data stream process system run commercial cluster consist blade run complicate multimodal stream analysis reference application collect system metrics sample interval two second system include bottleneck anomaly throughput anomaly process time anomaly cause various reason memory leak starvation buffer management error evaluation metrics evaluate anomaly prediction three first evaluate feature value prediction accuracy use mean prediction error measure deviation true value predict value collect metric xi time know current discrete value st derive future discrete value lead time use algorithm describe section transform predict discrete value predict metric value x use average value data sample inside bin represent discrete value calculate mean prediction error metric xi whole test data set follow p xi x xi four second evaluate performance classifier use receiver operate characteristic roc curve roc curve often use show true positive rate false positive rate classification algorithm draw roc curve change value threshold equation one naive classifier value threshold equation three tan classifier generate series true positive rate false positive rate pair third evaluate performance integrate anomaly prediction algorithm use standard true positive rate false positive rate p metrics give lead time anomaly prediction model infer class label c time future record hand annotate true label c compare predict label c true label c calculate true correspond number abnormal sample correctly predict true negative correspond number normal sample correctly predict false p correspond number normal sample mistakenly predict abnormal false negative n correspond number abnormal sample mistakenly predict normal thus calculate true positive rate false e r e v p e r one nine eight seven six five four three two one zero zero c r c c one nine eight seven six five four three two one zero one e r e v p e r one nine eight seven six five four three two one zero zero c r c c one nine eight seven six five four three two one zero hybrid five ten thirty r r r e n c e r p n e twenty fifteen ten five zero r r r e n c e r p n e twenty fifteen ten five zero ten forty seventy lead time ninety ten forty seventy lead time ninety quantization scheme b quantization granularity b tan fig three prediction error data fig four classification roc curve data four two eight false positive rate six four two eight false positive rate six one positive rate p standard way follow p n p p five b result analysis present anomaly prediction result examine system first show mean prediction error predictor different evaluate naive classifier tan classifier use roc curve finally show integrate anomaly prediction accuracy different lead time also report overhead anomaly prediction system one anomaly prediction first examine failure data collect focus host ping since find sensor program rare host ping occur frequently various different host observe ping nearly nod average number one node fifteen average duration ping six host use first half data train second half test figure three show achieve feature value prediction model use different approach generally increase lead time become observe predictor achieve reasonable prediction accuracy case result show hybrid approach consistently achieve lower prediction error approach figure three b show feature value prediction model use hybrid approach different number bin among three value observe predictor achieve best prediction accuracy ten small number bin five scheme tend group large range data sample one bin result representative value one discrete bin may longer representative even though prediction term bin identifier correct difference metric true value representative value bin equation four large hand large number bin thirty bin assign less train data train large enough chain get insufficiently train thus predictor may make true positive rate false positive rate true positive rate false positive rate zero ten twenty thirty forty fifty sixty seventy eighty ninety zero ten twenty thirty forty fifty sixty seventy eighty ninety lead time lead time b tan fig five advance anomaly prediction accuracy data mistake predict bin identifier also incur feature value prediction error evaluate performance naive classifier tan classifier use classifier isolation mean whether current system state exhibit abnormal behavior figure four figure four b show roc curve two host optimal performance top leave figure high true positive rate low false positive rate observe good furthermore tan model perform slightly better naive model evaluate performance advance anomaly prediction scheme show figure five figure five b average result among five host show standard error bar true false positive rat several one system still achieve reasonably good prediction accuracy future system state two prediction accuracy drop lead time become indicate predict distant future challenge three tan classifier predictive power naive classifier robust increase lead time four stable small standard error bar imply anomaly prediction robust different node two smart anomaly prediction present anomaly prediction result smart split original smart six contain fail normal disk therefore conduct sixfold relate experiment first show impact different prediction accuracy predictor figure six figure six b observe hybrid approach r r r e n c e r p n e forty thirty twenty fifteen ten five zero e r e v p e r one nine eight seven six five four three two one zero zero r r r e n c e r p n e seventy sixty fifty forty thirty twenty ten zero e r e v p e r one nine eight seven six five four three two one zero zero hybrid five ten thirty one nine eight seven six five four three two one c r c c one nine eight seven six five four three two one c r c c true positive rate false positive rate true positive rate false positive rate two eight fourteen eighteen lead time two eight fourteen eighteen lead time zero zero two six four lead time eight ten twelve fourteen sixteen eighteen zero zero two six four lead time eight ten twelve fourteen sixteen eighteen quantization scheme b quantization granularity b tan fig six prediction error smart data fig eight advance anomaly prediction accuracy smart data worst subset average best subset worst subset average best subset four two eight false positive rate six one four two eight false positive rate six one b tan fig seven classification roc curve smart data consistently perform better two approach particularly yield much higher prediction error two approach smart reason smart metrics wide range value tend make range bin big therefore one specific data sample may numerically far away representative value bin especially bin contain small number train sample similarly prediction accuracy highest neither small big similar reason scheme prediction accuracy bin number equal five much worse two case figure seven figure seven b show roc curve naive classifier tan classifier show best worst data well average result smart low false positive rate favor since costly replace good hard drive incorrectly predict crash soon observe naive classifier tan classifier achieve reasonable detection rate keep false alarm rate low roc curve also imply adjust threshold true false positive rat however different previous set experiment observe tan classifier perform worse naive classifier time reason conditional metrics tan model depend class label also metrics smart metrics large value range distribution different bin thus estimation conditional become unreliable metric bin contain train sample problem acute case naive classifier since assess conditional probability base class variable value class adequately represent smart figure eight figure eight b show performance integrate anomaly prediction use naive classifier tan classifier respectively since tan model worse classification accuracy naive model prediction accuracy also exhibit trend prediction model use naive classifier achieve true positive rate false positive rate lead time eighteen three system anomaly prediction present advance prediction result system different previous two set experiment focus performance prolong process time low throughput cause various fault insufficient program bug collect data six host use sixfold experiment figure nine nine b show feature value prediction accuracy different scheme quantization granularity respectively observe hybrid scheme use ten discrete bin achieve best prediction accuracy figure ten figure ten b show accuracy naive classifier tan classifier detect performance anomaly cause memory leak bug fault set service level advance label collect metric violation compliance observe achieve nearly perfect performance figure eleven eleven b show accuracy two integrate anomaly prediction model predict system performance observe prediction model achieve good prediction accuracy system performance anomaly evaluate overhead anomaly prediction model table show average train time prediction time two prediction model train time include time build model induce anomaly symptom classifier prediction time include time retrieve state transition calculate posterior synthesize classification result singe data record statistics collect different experiment run observe total train time r r r e n c e r p n e thirty twenty fifteen ten five zero e r e v p e r one nine eight seven six five four three two one zero zero r r r e n c e r p n e twenty fifteen ten five zero e r e v p e r one nine eight seven six five four three two one zero zero hybrid five ten thirty c r c c one nine eight seven six five four three two one zero zero c r c c one nine eight seven six five four three two one zero zero true positive rate false positive rate true positive rate false positive rate two eight fourteen eighteen lead time two eight fourteen eighteen lead time two four six eight ten twelve fourteen sixteen eighteen two four six eight ten twelve fourteen sixteen eighteen lead time lead time quantization scheme b quantization granularity b tan fig nine prediction error system data fig eleven advance anomaly prediction accuracy system data worst subset average best subset worst subset average best subset two four eight false positive rate six one five one fifteen two three false positive rate b tan fig ten classification roc curve system data within several prediction require less notice naive classifier faster tan classifier train prediction overhead show approach practical perform prediction system several factor may affect performance anomaly prediction scheme first prediction accuracy depend amount quality train data ie prediction model ideally train large enough cover second prediction accuracy improve provide adaptability dynamic execution plan refine anomaly prediction model along future work relate work system anomaly prediction recently receive much research attention previous work three approach learn recur failure pattern historical data approach evaluate periodic system memory consumption input number process thirty directly analyze time series error different previous work research focus failure prediction combine feature value prediction statistical anomaly classification work closely relate system also propose failure prediction solution distribute however one major difference first apply anomaly detection individual metrics generate vector feature time scheme train time prediction time fifteen one us tan two two us table anomaly prediction system cost use cluster method predict thus accuracy failure prediction depend accurate anomaly generate correct anomaly contrast approach require feature anomaly combine feature value prediction whole system classification use anomaly predicate recently statistical learn show promise autonomic failure management al propose apply tan model correlate metrics system state six capture essential characteristic call signature system state sixteen al explore decision tree learn approach diagnose several machine learn use correlate disk smart fifteen comparison focus explore learn future system state considerable research conduct system log analysis lin study log identify transient intermittent error process thirty al evaluate classification network failure prediction cluster liang al collect ras event log propose three prediction scheme base failure al propose console log mine algorithm detect file system comparison work focus characterization black box system use performance resource metrics al present several statistical analysis predict host availability forty power al investigate predictive power different statistical scheme learn approach al study failure statistics compute system al conduct comprehensive statistical study failure trend large disk drive population al discover statistical model host availability distribute system home different work work focus quantify predictability system v paper present comprehensive measurement study quantify predictability various system host ping smart disk system performance develop integrate anomaly prediction scheme combine efficient feature value prediction statistical classification best knowledge work make first attempt quantify prediction accuracy prediction lead time use real world system experimental result show real world system exhibit predictability anomaly predictor achieve high prediction accuracy lead time work sponsor part grant grant army research office grant manage secure open initiative exploratory stream analytics award faculty award express paper author necessarily reflect view government author would like thank anonymous insightful comment reference one elastic compute cloud two virtual compute lab three b h p spade system declarative stream process engine four e fox detect service neural network five j c j c adaptive anomaly detector worm detection six kelly j j chase correlate instrumentation data system state build block diagnosis control seven c triage diagnose production run user site eight g g fox technique cheap recovery nine k r e harper w k analysis implementation rejuvenation cluster ten g w king p detect past present predicate eleven l k n mi j e anomaly application change change towards detection application performance anomaly change twelve j r blake computer bottleneck detection belief net san ca morgan thirteen x h wang anomaly prediction robust cluster fourteen l culler blueprint introduce disruptive technology new jersey fifteen j f g f k machine learn predict hard drive application journal machine learn research vol six sixteen j kelly fox capture index cluster retrieve system history seventeen p w iba k analysis eighteen n network machine learn vol nineteen c chow c approximate discrete probability dependence tree information theory twenty w f measure association table journal royal statistical society series general computer failure data repository tan z gong x predictive information track production june distribute monitor system al challenge experience multimodal stream analytic monitor application system tan x h wang adaptive system anomaly prediction host r c v j l predictive management computer journal r singer k g r king nuclear power plant monitor fault detection theoretical v k k methodology detection estimation age reliability engineer international symposium thirty lin error log analysis statistical model heuristic trend analysis reliability vol four f predict computer case study telecommunication system b x x l failure prediction model fault tolerance within storage f use hide model effective failure prediction w p failure prediction distribute x j jordan e brewer failure diagnosis use decision tree g c approach failure prediction disk drive r k al critical event prediction manage computer cluster liang r failure analysis prediction model w l fox jordan detect system mine console log forty j w b noble exploit availability prediction distribute r power short term performance forecast enterprise b g study compute e weber l failure trend large disk drive population fast seven b vincent mine statistical model availability distribute empirical study home sept