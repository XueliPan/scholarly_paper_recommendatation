volley data placement cloud service agarwal alec research university abstract cloud service grow span globally distribute increasingly urgent need place application data across placement must deal business wan cost capacity limit also minimize latency task placement complicate issue share data data application change user mobility document challenge analyze trace live messenger live mesh two commercial cloud service present volley system address challenge cloud service make use volley submit log request volley analyze log use iterative optimization algorithm base data access pattern client output migration back cloud service scale data cloud service log volley design work scope five scalable platform allow volley perform worth computation less day evaluate volley live mesh trace find compare heuristic place data primary address access volley simultaneously reduce capacity skew two reduce traffic eighteen reduce percentile thirty one introduction cloud service continue grow rapidly ever functionality ever around globe growth major cloud service use geographically disperse continue build ten major unmet challenge leverage automatically place user data dynamic application data single cloud application serve best user first glance problem may sound simple determine user location migrate user data simple however tic ignore two major source cost wan capacity tolerate highly skew utilization paper show sophisticate approach dramatically reduce cost still reduce user latency sophisticate approach motivate follow trend modern cloud service share data communication collaboration increasingly important modern trend evident new business productivity sixteen office well social network twelve twitter common many read write make share data user wall user experience degrade update share data quickly reflect read write make group need collaborate may scatter make challenge place migrate data good performance data task place share data make significantly harder data example update wall user may trigger update data hold feed multiple data form communication graph represent increasingly rich however fundamentally transform problem mathematics addition data communication graph data motivate operate general graph structure application change cloud service want release new ever greater frequency new application feature significantly change pattern data share data release instant message feature reach capacity limit rush industry build additional motivate part reach capacity individual new add ten turn require automatic rapidly migrate application data new take advantage capacity user mobility travel ever today fifteen provide rapid response regardless user location cloud service quickly migrate data migration cost sufficiently inexpensive paper present volley system automatic data placement across volley incorporate iterative optimization algorithm base weight spherical mean handle share data data volley rerun sufficient speed handle application change reach capacity limit user mobility make use volley submit request log similar pinpoint seven fourteen distribute storage system request log include client address identify data access client request structure request call tree client request update wall one trigger request data two three handle user feed volley continuously analyze request log determine application data migrate scale data set volley design work scope five system similar eleven leverage scope volley perform machine worth computation less day migration find volley trigger data migration prior work study place static content across volley first research system address placement user data dynamic application data across geographically distribute service make use volley specify three input first define cost capacity model cost maximum amount data per second choose desire migration cost ongoing better performance ongoing performance include minimize latency reduce cost communication third specify data replication level three three different locate within allow use volley respect external factor contractual legislation rest paper first quantify prevalence trend user mobility modern cloud service analyze trace live mesh live messenger two commercial service present design implementation volley system compute data placement across next evaluate volley analytically use live mesh trace evaluate volley live consist twenty locate twelve commercial distribute around world preview result find compare heuristic volley reduce skew load two decrease traffic eighteen reduce percentile latency thirty finally survey relate work conclude two analysis commercial trace begin analyze trace collect two large live mesh live messenger live mesh provide number communication collaboration feature file share synchronization well remote access run live mesh client live messenger instant message application presentation also use source due ubiquity live mesh live messenger trace collect june cover access service entire month live mesh trace contain log entry every modification hard state change file live mesh synchronization service soft state device connectivity information store pool one live messenger trace contain login conversation total number message conversation live messenger trace specify sender size individual message simplicity model participant conversation equal likelihood send message divide total message conversation equally among message prior measurement study describe many user behavior live messenger system trace identify unique estimate client location use standard commercial prior work figure one simplify data leave live mesh right update wall request arrive wall data item data item send request fee data item send client live mesh publish new request arrive device connectivity data item forward data item send queue data item finally send client piece data may different communication data incur expensive traffic figure two two four data communication simplify example data placement require appropriately map four data simultaneously achieve low traffic low capacity skew low latency snapshot june end trace period use trace study three trend motivate volley share data data user mobility motivate trend volley rapid application change reach capacity limit document data source describe build cloud service often release update one provide background data arise commercial cloud service figure one show simplify live mesh example client one update wall publish client two allow learn live mesh example client one publish new address figure three distribution mesh trace figure four distribution messenger trace rout client two enable client two connect directly client one live mesh refer notification session enable efficient file share remote device access figure caption provide additional detail one case client involve multiple traffic minimize latency particular request minimize place data close possible two figure two attempt convey intuition data share make data placement challenge figure show web two simplify example determine whether map data achieve low traffic low capacity skew low latency actual cloud service face problem millions client may access many data data may need communicate deliver result furthermore may access data variety different lead large complicate graph order understand potential kind interconnection occur quite distant begin characterize geographic diversity trace client geographic diversity first study trace understand geographic diversity service client figure three four show distribution two trace map world figure show trace contain ure five show distance access data place accord centroid data share access distance zero data share whose address map geographic location give amount collaboration across within perhaps surprise large amount share happen distant data suggest even static benefit place data use heavily rather place close particular client access data data proceed study trace understand prevalence data analysis focus live mesh data live messenger document detail prior work figure six show number queue object subscribe receive object subscription create data interdependency object send message queue object see object send single queue object long tail popular object presence data motivate need incorporate volley client mobility finally study trace understand amount client mobility service client figure seven show characterize client mobility month trace compute first compute location client point time contact live mesh live messenger application use previously describe methodology compute client centroid next compute maximum distance client centroid expect observe move however fraction move messenger trace mesh trace quite dramatic comparison purpose antipodal point earth slightly apart trace characterize reason movement example could travel could connect remote office cause connection public suddenly emerge dramatically different location volley goal reduce client latency need distinguish different cause even though client physically move case client latency still minimize move data closer location client new connection public long tail client mobility suggest fraction ideal data placement change significantly month figure five share data geographically distribute messenger mesh trace large amount share occur distant figure six data live mesh object queue object user update hard state data item document store live mesh update message generate object document queue object subscribe receive copy message user device share document unique queue many object subscribe single queue long tail popular object subscribe many queue figure seven mobility messenger mesh trace travel however fraction travel quite far diverse set thus service performance may significantly benefit intelligent data placement geographically distant data share next study trace understand whether data share among distant particular data item compute centroid centroid sphere compute use weight spherical mean methodology describe detail section three fig device share centroid messenger mesh notification unique queue distance centroid mesh messenger live mesh live messenger service analyze section two already log data volley incorporate simple filter extract relevant subset log live mesh live messenger commercial cloud service data generate volley log much less data process user request example record volley log request live messenger service millions require per day lead average demand though reveal exact consumption live mesh live messenger service due confidentiality concern state small fraction total demand service base calculation centralize log single allow volley run log multiple time part compute recommend set additional input addition request log volley require four input change time scale change time scale noticeably contribute require volley additional input one ram disk per transaction type data handle volley wall two capacity cost model three model latency four optionally additional data placement legal volley also require current location every data item order know whether compute placement keep item place require migration steady state simply remember previous volley analyze thus far administrator need estimate average ram disk per data item administrator rely statistical smooth data consume average resource estimate look performance counter calculate average resource usage piece application data host give server capacity cost model specify ram disk provision service available network egress ingress charge model service use network energy usage cost figure eight application use volley data leave open possibility fraction observe correspond actual user ie modify drive program current analysis filter service use performance measurement various prior work look identify automatically volley might benefit leverage three system design implementation overall flow data system show figure eight make use volley log data cosmos five distribute storage system administrator must also supply input cost capacity model volley system frequently run new analysis job log compute migration job fee migration data migration describe step greater detail log request utilize volley log information request process log must enable correlate request call tree capture logical flow control across pinpoint seven fourteen source destination request movable ie data item control cloud service log identifier rather address address use movable volley location user request come volley responsible place data name already know current steady state sometimes possible source destination request refer would happen example figure one would refer client one wall client two fee exact field volley request log show table one total record require substantial prior work modify log kind information many request log record format field like either address mean time second request receive source another data item address client request use group relate request table one use volley application log record field every request mean size field also show migration proposal record format field entity change egress ingress per day mean name entity name new entity average change latency per request object onetime require migrate table two volley construct set propose describe use record volley select final set accord performance cost incorporate fix cost per server factor long server provision although may charge base peak usage individual peer link give service contribution peak lead charge service base total usage two accordingly volley help service minimize total usage expect capacity cost model stable migration fluid provision model additional capacity add dynamically need service volley trivially modify ignore provision capacity limit volley need latency model make placement reduce user perceive latency allow different static dynamic model plug volley migrate state large measure days hence use latency model stable base large body work demonstrate effectiveness network design volley treat distance space specify model purpose evaluation paper rely static latency model stable large model base linear regression distance geographic develop prior work compare measure round trip time across millions show reasonably accurate latency model require translate client address geographic purpose rely mention section two update every two work focus improve latency incorporate would require specify desire latency model arbitrary point data placement come many form may reflect legal data host certain jurisdiction may reflect operational require two physically locate distant volley model two distinct data may large amount communication along constraint locate different although commercial cloud service speak emphasize need accommodate commercial study paper currently face form although volley incorporate explore evaluation volley algorithm data cosmos volley periodically analyze migration perform analysis volley rely scope five distribute execution infrastructure high level resemble eleven query language current implementation volley take approximately fourteen run one month worth log file analyze demand volley place scope detail section volley scope job structure three phase search solution happen phase two prior work demonstrate start search good location improve convergence time hence recursive step wi xi n wi wi xi n one base case w c c cos cos b sin sin b cos b sin b sin sin b cos cos cos b sin b sin sin cos cos cos b c cos cos b sin sin b cos c b figure nine weight spherical mean calculation weight spherical mean define weight interpolation pair point wi weight assign xi xi node consist latitudinal distance node north pole longitude node new interpolate node c consist w part node one w part node b current distance b angle north pole b stay move angle b north pole new location use compute result simplicity presentation omit describe special case antipodal nod phase one compute reasonable initial placement data base client address phase two iteratively improve placement data move freely surface phase require bulk computational time algorithm code phase three need fix map data satisfy capacity output job set potential migration action format describe table two many adaptive must incorporate explicit prevent volley incorporate explicit mechanism oscillation damp would occur user behavior change response volley migration way volley need move user state back previous location phase one compute initial placement first map client set geographic use commercial mention map may update volley job update within single volley job map data item directly access client weight average geographic client access do use weight spherical mean calculation show figure nine weight give amount communication client nod data item whose initial location calculate weight spherical mean calculation think draw arc earth two point find point arc interpolate two initial point proportion weight operation repeat average additional point recursive definition weight spherical mean figure nine conceptually similar define familiar weight mean three two one xi two one xi three six three six compare weight mean weight spherical mean subtlety rule average two individual point use spherical figure ten show example calculation use data live mesh trace five different access single share object total eight different address device access share object far lead weight spherical mean label centroid figure place close device finally data item never access directly data item live mesh example figure one map weight spherical mean data communicate use position already assign phase two iteratively move data reduce latency volley iteratively move data closer data communicate iterative update step incorporate two weight spring model nine spherical spherical define data way conducive incorporate latency model geographic latency distance two nod amount communication increase spring force pull together however unlike network system nod figure ten example share object place weight spherical mean label centroid figure particular object access access draw live mesh trace device responsible almost access weight spherical mean placement object close device location w one one lab w b figure eleven update rule apply iteratively move nod communication closer together w fractional weight determine much node move towards node b lab amount communication two nod distance nod b current lob node b location update algorithmic constant volley experience contract force factor prevent collapse single location fix nature client yield update rule show figure eleven current implementation simply run fix number update rule show section four suffice good convergence intuitively volley spring model attempt bring data closer data communicate regularly thus plausible volley spring model simultaneously reduce latency reduce traffic show section four indeed case commercial cloud service study phase three iteratively collapse data compute nearly ideal placement data surface earth modify placement data locate set satisfy capacity like phase two do iteratively initially every data item map capacity volley identify experience access move next may still exceed total capacity due new volley repeat process capacity assume system enough capacity successfully host algorithm always terminate many system data item move volley output migration proposal contain new location new value latency ongoing onetime require migration straightforward calculation use old data new data input supply service administrator cost model latency model migration consume migration migration volley design usable many different cloud service volley compute recommend placement requirement impose cloud device share device device n v x service log request data describe table one give request log input volley output set migration describe table two leave actual migration data cloud service cloud service also provide initial location data migration proposal include require migrate expect change latency migration volley decision leave migration migration allow volley easily apply diverse set example use migration follow pattern mark data storage system one location copy data new location update name service point new copy mark new copy writeable delete old copy maintain multiple different migration may simple require designate different replica primary independent migration mechanism might desire employ throttle migrate user state predictive model suggest user unlikely access state next hour volley attempt migrate data interfere migration technique application may wish employ four evaluation evaluation compare volley three place data show volley substantially outperform metrics capacity skew traffic latency focus exclusively live mesh trace conciseness volley first compute data placement use week data live mesh trace evaluate quality result placement follow three data four placement data appear evaluation window placement computation window place single locate unite state production new data handle next time placement methodology run place previously unseen data one penalize different equally data first heuristic consider place data close possible address commonly access second heuristic put data one strategy still take many company due simplicity third heuristic hash hash data optimize three represent reasonable approach optimize three different metrics hash optimize traffic capacity skew respectively reasonably sophisticate proposal optimize latency throughout evaluation use twelve commercial potential distribute across multiple exact confidential confidentiality concern also prevent us reveal exact amount consume service thus present traffic different use metric fraction message allow comparison different volley without reveal underlie consumption consumption centralize volley log need volley small compare traffic affect graph compare metric among configure volley capacity model one twelve host ten data reasonably balance use capacity compute analytically use latency model describe section three require use client address trace place geographic location live mesh application client request require send message first data item send second message second data item second data item send reply first data item send client reply data latency simply round trip time client data separate latency sum four delay client one one two two back one one back client latency leave potential protocol need initially establish connection authenticate protocol encounter practice would magnify importance latency incur latency multiple time clarity presentation consistently group ten millisecond bin graph graph present latency better placement achieve latency well almost request evaluation begin compare volley three metrics capacity skew traffic section next evaluate impact latency client request include evaluate volley con figure twelve capacity require three different placement volley figure fourteen client request latency three different placement volley impact latency client request compare volley three metric latency figure fourteen show result hash high latency mediocre latency best latency among three although perform better hash volley perform better still particularly tail experience high latency even placement strategy compare volley reduce percentile latency thirty multiple previously evaluate impact placement latency analytically use latency model describe section three section evaluate volley latency impact live system use prototype cloud service use prototype cloud service emulate live mesh purpose replay subset live mesh trace deploy prototype cloud service across twenty virtual machine spread across twelve geographically distribute use one node sit act system prototype cloud service consist four document service service message queue service run every every service run every prototype map directly actual live mesh component service run production ways production component service provide feature live mesh service describe detail elsewhere one provide brief overview prototype cloud service expose simple accept client request rout appropriate component either another way client connect directly request require additional step update item send update forward appropriately design figure thirteen traffic three different placement volley text simple hypothetical example understand impact detail section evaluate incremental benefit volley function number volley section next evaluate resource demand run volley scope distribute execution infrastructure section finally evaluate impact run volley frequently less frequently section impact capacity skew traffic compare volley three place data show volley substantially outperform metrics capacity skew traffic figure twelve thirteen show result hash perfectly balance use capacity high traffic zero traffic ideal extremely unbalance use capacity modest amount traffic capacity skew one support twice load average volley able meet reasonably balance use capacity keep traffic small fraction total number message particular compare volley reduce skew two reduce traffic eighteen twelve message fraction one one two two five five p p p p b b b b b b b b one two two one one one two two three three four four table three hypothetical application log example one locate geographic two data p p volley phase one volley phase two table four volley compute use table three assume every point earth ignore capacity traffic one two three four distance zero zero latency volley phase two distance latency table five distance traverse user request table three use volley phase two table four note latency model include access penalty communication involve client latency model rely connectivity occasional high load nod lead high slice schedule delay due sample request trace live experiment impact capacity skew traffic two placement thus volley offer improvement every metric simultaneously biggest benefit come reduce traffic reduce capacity skew detail examination latency impact examine detail placement impact experience user request consider simple example table three list four hypothetical live mesh involve four data object behind two address purpose simple example assume every point earth infinite capacity traffic cost pick geographic figure fifteen compare volley heuristic live system span twelve geographically distribute access figure use random sample live mesh trace see volley provide moderately better latency heuristic allow cache location best connect give operation request still succeed client request arrive wrong due cache staleness walk example two rendezvous use document message queue service document service store arbitrary data case first client store current address second client read address document service contact first client directly service use send message data document service change example second client subscribe update first client address update send second client instead second client poll document service see change finally message queue service buffer message service client go connect queue service message evaluate volley heuristic latency live system use data compute first week live mesh trace actual live mesh service require twenty randomly sample request trace replay also map client trace subset node replay client request nod figure fifteen show measure latency sample live mesh trace recall group ten millisecond bin clarity presentation see volley consistently provide better latency placement latency benefit visible despite relatively large number external source noise difference actual client typical client connectivity volley fraction figure sixteen average distance travel object successive volley phase two average incorporate object travel quite far many travel little ease examine far object placement client address table four show calculate volley phase one two phase one volley calculate weight spherical mean geographic client access q object hence place roughly along segment one two place one phase one similarly calculate placement object use q object phase two iteratively refine consider latency impact set user request table three table five show user request physical distance traverse correspond latency round trip q q optimize client frequently use thereby drive latency minimum user request expense volley consider client calculate drive worst case amount drive common case lead overall better latency distribution note practice user request change time placement make evaluation use later set user request evaluate base request impact volley iteration count show volley converge small number allow us establish section volley run quickly ie less day thus rerun frequently figure sixteen seventeen eighteen nineteen show performance volley number vary figure sixteen show distance volley move data significantly decrease volley iteration show volley relatively quickly converge ideal placement data figure seventeen eighteen nineteen break change figure seventeen traffic volley iteration figure eighteen capacity volley iteration figure nineteen client request latency volley iteration volley performance iteration figure seventeen show traffic reasonably good initial placement phase one quite similar heuristic contrast recall hash heuristic lead almost eighty message cross traffic decrease factor two first five phase two decrease small amount next five phase two finally go back slightly volley phase three balance across course point avoid kind capacity skew see heuristic regard small increase traffic acceptable turn capacity see volley placement quite skew approximately constant amount phase three smooth load accord configure capacity change placement message twelve fraction volley phase one two three elapse time ten scope stag scope vertices sixteen seven table six volley demand scope infrastructure analyze one week worth trace model ie one twelve host ten data turn finally latency figure nineteen show latency reach minimum five phase two contrast impact traffic almost latency penalty phase three data movement satisfy capacity volley resource demand establish volley converge small number analyze resource many allow us conclude volley complete quickly rerun frequently scope cluster use consist well table six show volley demand scope infrastructure break volley different phase elapse time scope stag scope vertices cumulative phase phase one one iteration compute initial placement phase two ten improve placement phase three twelve balance usage twelve scope stage table six correspond approximately single map reduce step eleven stag overall lead lot data shuffle one reason total elapse time simply divide degree possible parallelism every scope vertex table six correspond node computation graph run single machine thus divide total number vertices total number stag yield average degree parallelism within volley average stage parallelize machine run substantially scope cluster dedicate volley rather cluster use several task operational cost use cluster sixteen every week small compare operational save consumption due improve data placement data analyze volley measure reveal exact amount could use infer confidential request since every volley log record impact rapid volley recomputation establish volley rerun frequently show volley provide substantially figure twenty client request latency stale volley figure traffic stale volley figure previously unseen object time better performance rerun frequently experiment use trace live mesh service extend begin june way begin figure twenty show impact rapidly volley compute data placement use trace first week june evaluate performance placement trace immediately follow week week immediately follow week week start month later week start three volley compute data placement better performance placement immediately follow week demonstrate benefit run volley frequently respect latency traffic figure twenty show run volley even every two noticeably worse run volley latency penalty keep increase volley placement fraction one one three one one three message week one one three object original week distribute compute describe prior work focus place static content compare prior work volley first research system address placement dynamic application data across geographically distribute finally describe prior work theoretical approach determine optimal data placement placement emerald twenty globe legion focus provide program migration move data computation examine distribute execution rewrite code leave placement policy user developer contrast volley focus placement policy mechanism prior work incorporate placement mechanism policy coign eighteen characterize volley placement policy next subsection placement distribute compute prior work automatic data placement broadly group distribute compute environment target place data lan tackle coign eighteen cage seventeen abacus three system al spectra thirteen slingshot forty wishbone explore data placement wireless context either mobile powerful ad sensor network thirty explore split data web web neither assume multiple geographic could host web server volley differ prior several ways first scale data volley must process significantly greater require design volley algorithm work scalable data analysis framework scope five eleven second volley must place data across large number widely vary aspect problem address prior work third volley must continuously update client though prior approach use profile approach figure fraction object move compare first week become increasingly stale figure show similar progressively increase penalty traffic run volley frequently result traffic save figure provide insight run volley frequently helpful number previously unseen object increase rapidly time run frequently volley detect access object sooner note inability intelligently place previously unseen object share heuristic separately evaluate rate degrade performance addition new object create access previously place object may experience significantly different access pattern time run volley periodically provide add benefit migrate object better serve new access pattern figure compare volley placement calculate first week june placement calculate second week first week third week finally first week fourth week ten object week undergo either direct result access pattern change due important object displace majority object retain placement compare first week run volley periodically third minor advantage client request come address present object access solely place volley additional trace include access address present volley place object base new access five relate work problem automatic placement application data resurface every new distribute compute environment local area network mobile compute sensor network single cluster web sit characterize relate work first focus develop zero twenty forty sixty eighty object object object placement static data data placement content delivery network explore many piece prior work nineteen focus static data cache header honor elaborate synchronization need easily employ decentralize individual server small set independently make data cache contrast volley need deal dynamic data would make decentralize approach challenge volley instead opt collect request data single leverage scope distribute execution framework analyze request log within single optimization abstractly volley seek map object minimize cost function although know approximation general problem theory community develop approximation numerous specialize cut four various flavor facility location six eight best knowledge problem volley map previously study example problem volley differ facility location cost associate place two object different cost object motivate volley choice use heuristic approach experimentally validate quality result data placement although volley offer improvement heuristic yet know close come optimal placement determine optimal placement challenge standard commercial optimization package simply scale data size large cloud service leave open tantalize possibility possible beyond volley six conclusion cloud service continue grow span large number make increasingly urgent develop place application data across base analysis trace two commercial cloud service live messenger live mesh build volley system perform automatic data placement across geographically distribute scale large data cloud service log volley design work scope five scalable data analysis framework evaluate volley analytically live system consist prototype cloud service run geographically distribute twelve evaluation use one trace show compare heuristic volley simultaneously reduce capacity skew two reduce traffic eighteen reduce percentile latency thirty show potential volley simultaneously improve user experience significantly reduce cost paper focus use volley optimize data placement exist service could also use volley explore future sit would improve performance include candidate volley input operator identify combination additional sit improve latency modest cost greater traffic hope explore future work greatly appreciate support team donate usage support live mesh live messenger team share data us thank shepherd anonymous detail feedback help improve paper reference one j centrifuge integrate lease management partition cloud service two web service three k g ganger g dynamic function placement cluster compute annual technical conference four expander flow gein graph partition five r b p b weaver j scope easy efficient parallel process massive data set six improve combinatorial facility location seven e e fox e brewer pinpoint problem determination large dynamic eight f improve approximation capacitate facility location mathematical program two nine f r cox f r morris sig decentralize network system ten data center global expansion trend eleven j dean simplify data rapid release cycle process large cluster twelve thirteen j park balance performance energy quality pervasive compute fourteen r g porter r pervasive network trace framework fifteen global air travel trend global sixteen seventeen g j graphics employ satellite cage computer graphics nine one agarwal j matchmaking game l ruffin operate system assessment compute steen p globe distribute system concurrency page c k j yin component placement service distribute five ten one one forty j slingshot deploy stateful service eighteen g hunt coign automatic distribute wireless k translator distribute execution legacy page e automatic application partition page twitter f yang j j language f q e large scale detection partition system nineteen c constrain mirror placement twenty e h levy n black mobility emerald system computer six one need replica placement content delivery network international workshop web content cache distribution v b h dynamic application partition generator version thirty lecture note computer science vol page n r r reliable efficient program wireless sensor network j e view network lewis core legion object model h k walsh r e design implementation single system image operate system ad network live mesh live messenger thirty b e code split web twenty j van dam experience distribute process graphics system computer graphics ten two office r newton l h madden wishbone partition