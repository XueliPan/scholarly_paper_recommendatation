use machine learn focus iterative optimization f e g j school university abstract iterative compiler optimization show outperform static approach however cost large number program paper develop new methodology reduce number hence speed iterative optimization use predictive model domain machine learn automatically focus search likely give performance approach independent search algorithm search space compiler infrastructure scale gracefully compiler optimization space size train set program iteratively evaluate shape space program feature model model learn use focus iterative optimization new program evaluate two learn model independent model evaluate worth two embed instrument show learn model speed iterative search large space order magnitude translate average ti two one introduction use iterative search basis compiler optimization widely demonstrate give superior performance static scheme one three eleven main drawback scheme amount search time need achieve performance give point search recompilation execution program although multiple acceptable embed code persistent long cycle restrict space search scale barrier adoption general purpose compilation number paper focus ing cost iterative optimization single evaluation consist compilation plus execution program two recent paper investigate reduce cost individual compilation execution twelve seven one six radical approach use reduce total number cooper al six examine structure search space particular distribution local minima relative global minima devise new search base outperform generic search alternative approach develop space compiler examine best perform small tree compiler compile new program tree search compile execute best path tree long best sequence categorize small tree prove highly effective technique paper develop new methodology speed iterative optimization automatically focus search likely give performance methodology base machine learn independent search algorithm search space compiler infrastructure scale gracefully compiler optimization space size use program feature correlate program optimize previous knowledge order focus search train set program iteratively evaluate shape space program feature record data scheme automatically learn model predict part optimization space likely give good performance different class program new program encounter appropriate predictive model select base program feature bias search certain area space use technique able speed search order magnitude large space paper structure follow section two provide motivate example demonstrate learn search significantly reduce number need find good performance proceed international symposium code generation optimization six l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero random focus b one ten figure one point correspond transformation sequence whose performance within five optimum ti contour predict area good b close best performance random focus search achieve program evaluation random algorithm achieve maximum improvement ten focus search follow section three description experimental setup analysis optimization space encounter examination two standard search random genetic perform follow section four description two predictive model demonstration use speed search section five describe standard machine learn principal analysis nearest neighbor use learn predictive model section six learn model test medium size exhaustively enumerate space large space show improve search performance order magnitude section seven describe relate work follow section eight brief two motivation example paper focus embed performance critical consequently large body work aim improve performance optimize fifteen work focus improve architecture specific compiler phase code generation register allocation schedule however investment ever sophisticate produce diminish return iterative approach base consequently give relatively small five paper consider twenty eight embed approach definition highly portable one processor next provide additional benefit manufacturer highly tune compiler however portability come cost example eight al require achieve reasonable performance search space reason excessive search time determine best high level sequence particular program consider diagram figure one show behavior program instrument diagram attempt plot good perform point within five optimum space length five select set fourteen therefore cover space size difficult represent large five dimensional space graphically good perform transformation sequence plot position denote prefix length two position axis denote suffice length three strike feature minima scatter throughout space find best difficult task prior knowledge good point likely could focus search allow minimal point find faster alternatively give fix number expect improve performance know good search within proceed international symposium code generation optimization six focus search paper develop technique learn ahead time predictive model iterative program predictive model define good space search figure one contour line enclose technique predict good point use prediction able reduce number search achieve performance rapidly reduce cost iterative search see figure one b compare random search average twenty statistically meaningful without predictive model focus denote logarithmic scale number perform search denote best performance achieve far search zero represent original code performance maximum performance achievable immediately apparent predictive model rapidly search instance ten random search achieve potential improvement available focus search achieve see figure one b large improvement would require eighty use random search justify investigation predictive model three optimization space paper develop machine learn improve search performance iterative optimization section briefly describe use program make optimization space embed evaluate space present two standard search later use show learn predictive model dramatically speed search experimental setup fourteen eighteen suite design evaluate quality code generate language c compiler target digital signal processor fourteen set contain small well compose complex size program range line code usually one second however program represent widely regard important use indefinitely label f n k h c transformation loop unroll loop flatten loop normalization nest loop conversion break load constant common elimination dead code elimination hoist loop hoist move copy propagation table one label use exhaustive enumeration space correspond loop unroll factor compiler one applicable c program available within compiler one ten purpose paper select eleven describe label table one arbitrarily consider four loop unroll factor increase number consider fourteen exhaustively evaluate sequence length five select fourteen allow us evaluate relative performance propose later evaluation section see section seven also consider search non exhaustively much space experiment perform two distinct demonstrate technique generic ti instrument high end float point wide cluster processor internal memory program compile use ti code composer studio tool version compiler highest optimization level flag generate large memory model code alchemy processor embed soc processor use core run instruction cache nonblocking data cache program compile compile flag accord manufacturer give best performance better later hence use experiment characterize space paper consider source source many also appear within phase native order characterize optimization space exhaustively enumerate transformation sequence table two summarize performance avail proceed international symposium code generation optimization six prog fir mult compress edge histogram spectral average ti four zero three zero three four ism four table two summary optimization space ti use exhaustive search able two three refer ti four five refer respectively time execution improve label two four show maximum reduction execution time obtain ti within exhaustively enumerate space eight twelve instrument eleven twelve achieve improvement best execution time reduction ti average reduction achieve ti translate average platform specific optimize compiler best perform sequence label three five table two contain best perform sequence machine individual letter within entry refer label table one hoist show complexity type good transformation sequence program dependent fir edge detect ti fir mult histogram reach best performance single ti obtain minimum execution time four sequence respectively similarly yield good performance appear best sequence program example sequence ism make run minimum execution time however none three individual present best perform sequence compress critically best perform sequence one program never best another therefore technique try simply apply best sequence find program unlikely succeed search section describe two common use search transformation space blind random search rand genetic algorithm ga random search generate random string transformation equally likely choose perform surprisingly well experience configure ga manner best ga six initial randomly select population fifty exhaustively enumerate space similar performance see figure two plot best performance achieve far algorithm many program perform plot average program either algorithm easily achieve ti due much greater number sequence give similar overall performance ga perform well early part search however random search perform better large number ga appear likely stick local minima case however large number need gain significant performance next section investigate predictive model speed search four model focus search order speed search algorithm wish focus attention profitable optimization space wish build model transformation sequence program obtain good performance hope learn use later program could simply record best sequence achieve program hope improve current program however number flaw firstly result table two show best transformation one program never best secondly know best sequence another program provide one single option guide subsequent search within space alternatively build intricate model characterize performance transformation sequence problem easily overfit model data generalize program proceed international symposium code generation optimization six l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero eighty sixty forty twenty l e b l v n e e v r p x f n e c r e p zero one one ten ten random ga ti rand ga b figure two performance respect random rand genetic ga search ti b denote logarithmic scale number perform search denote best performance achieve far search zero represent original code performance maximum performance achievable result average furthermore complex model require extensive train data may costly gather unrealistic section consider two different model try summarize optimization space without excessive consider simple independent distribution model complex model require relatively small amount train data construct easy learn see section five independent model identically distribute make sense start approach first model program independent know assumption hold general might sufficient better focus search consider set n let sequence length l element si choose independent model assume probability sequence good simply product individual sequence good ie p p si one l p probability transformation occur good sequence choose set good sequence sequence improvement performance least maximum possible improvement calculate p simply count number time occur good sequence p one normalize distribution ie record within vector probability n fourteen n build probability vector distribution refer oracle sense know value exhaustively enumerate space unrealistic goal able predict oracle use machine learn base train set program order improve search however necessary prove first oracle distribution indeed lead better search model describe probability distribution function assume mutually independent neglect effect among restrictive particularly enable applicability yield good performance apply therefore include technique make possible construction model ideally improve bias search obtain good performance order keep number sample need build probability density function low include proceed international symposium code generation optimization six l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero random ti random l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero ga b ti ga one ten one ten figure three ti random ga b search versus oracle result average among take one step distribution use chain chain transformation sequence define follow p p p l equation state probability transformation apply sequence depend upon apply main assumption model change along sequence ie position sequence therefore model often refer stationary chain oversimplification prevent number model increase length sequence consider thus model probability first position sequence p transition matrix p one l learn data count n p si one p one n must satisfy section model learn sequence improvement performance least maximum possible improvement use model give fourteen x fourteen matrix speed search evaluate potential model test potential scheme compare search algorithm algorithm use predictive model random algorithm instead uniform probability transformation select model bias certain case ga initial population select base model ga allow evolve usual construct model use result obtain search particular program space test search algorithm call two learn model form performance expect achieve later try learn model evaluate whether model improve search clearly best model oracle achieve worth expend effort try learn figure three depict average performance random algorithm random search bias two ti similarly figure three b depict performance ga algorithm versus use two generate initial population figure see significantly speed find good solution example evaluation ten random achieve less maximum available contrast random achieve seventy available performance random achieve around performance figure four depict similar picture architecture architecture two significantly improve performance algorithm random search algorithm achieve available performance ten contrast random achieve forty available performance twice better base random achieve avail proceed international symposium code generation optimization six eighty sixty forty twenty l e b l v n e e v r p x f n e c r e p zero one eighty sixty forty twenty l e b l v n e e v r p x f n e c r e p zero one rand ga ten ten random b ga figure four random ga b search versus result average able performance average algorithm need achieve performance oracle achieve ten see figure model potential dramatically improve performance search next section describe learn model previous run build predictive model five learn model biggest difficulty apply knowledge learn novel input consider exactly portion knowledge relevant new program show case many program successfully represent program feature use gauge similarity thus applicability previously learn knowledge obviously selection program feature critical success method employ well know statistical technique principal component analysis two assist selection initially identify feature think might describe program well use input process show table three tell us instance due redundancy covariance feature value feature combine way reduce five feature whilst retain variance data output process feature vector contain five condense feature value nearest neighbor use nearest neighbor classifier two select previously analyze program new program similar learn use nearest neighbor simply matter map feature vector train program onto feature space classification novel program compile first put feature extractor feature process result feature vector map onto feature space distance every point space calculate point consider nearest neighbor thus program associate point similar new program apply process twelve use disallow use train data feature vector associate program currently evaluate otherwise program would always select nearest select neighbor previously learn probability distribution select neighbor use model new program iteratively optimize evaluate learn useful know close learn distribution oracle distribution model average across learn distribution achieve approximately eighty performance per evaluation ti achieve similar result approximately performance proceed international symposium code generation optimization six feature loop simple loop nest loop perfectly nest loop constant lower bind loop constant upper bind loop constant stride loop unit stride number loop loop step within loop loop nest depth array reference within loop loop load loop store loop compare loop branch loop divide loop call loop generic loop array loop memory copy loop loop float loop loop float use loop loop contain loop contain statement loop array index loop indices array access nonlinear manner loop stride lead array dimension loop call loop branch loop regular control flow table three feature use show improve performance able achieve percentage improvement suggest learn model give performance improvement exist scheme evaluate next section six evaluation section evaluate focus search approach two optimization space first space exhaustively enumerate space describe throughout paper second much space size ie transformation sequence length twenty transformation select one possible available one ten achieve use standard leave one scheme ie learn model base train data program except one optimize test proceed international symposium code generation optimization six evaluation exhaustively space initially run random ga search program record time ti run time use two learn model achieve use standard leave one scheme ie learn model base train data program except one optimize test result ti show figure five six respectively ti learn base model achieve approximately twice potential performance either algorithm ten sixty learn model even better achieve available number would need forty achieve performance improvement performance less dramatic yet learn base achieve twice performance ten evaluation large space experiment within exhaustively enumerate space useful performance search algorithm evaluate relative absolute minima however wish search across large range infeasible run exhaustive experiment instead run random search program space train data time wish focus performance achieve early part iterative optimization run random search algorithm learn model fifty genetic algorithm random search behaviour first fifty ga separately evaluate two five ten fifty ti show figure seven due time nonnegligible exhaustively enumerate space evaluate learn model deliver good performance random learn model achieve average two furthermore random learn model achieve greater average performance five random algorithm fifty surprisingly learn model achieve better performance learn model fifty contrast result exhaustively enumerate space see figure five six rea random ga one ten one ten ti random b ti ga figure five ti random ga b search versus result average l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero eighty sixty forty twenty l e b l v n e e v r p x f n e c r e p zero one sixty l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero l e b l v n e e v r p x f n e c r e p ninety eighty seventy sixty fifty forty thirty twenty ten zero seventeen rand ga ten one ten random b ga figure six random ga b search versus result average son model need greater number train model model space accurately build model similarly show two five ten fifty figure eight learn model significantly outperform random algorithm fact random learn model achieve greater average performance five random fifty therefore achieve level performance order magnitude faster also true ti random unexpectedly outperform random fifty thus two find average almost three time performance algorithm finally single sequence give best performance average small space give average significantly less achieve random two ti exist single sequence give performance improvement average discussion predictor perform less well large space due reduce amount train data suggest model initially use new platform relatively small amount train data available sufficient new data accrue iterative optimization use second stage learn use model proceed international symposium code generation optimization six ti fir two five r r ten r fifty r figure seven achieve random search r random learn model random learn model two five ten fifty ti processor random learn model achieve greater average performance five random fifty seven relate work tune heuristic iterative optimization well work al one al describe introduction number relate project partially approach select sequence embed describe eleven approach combine user guide performance information genetic algorithm select local global sequence author nine five explore ways search program command line enable disable specific various eight iterative high level apply several embed use two probabilistic good obtain expense large number finally seventeen show carefully hand generate model approach performance iterative machine learn machine learn predictive model recently use base compiler attempt learn good optimization heuristic use instead compiler writer method al nineteen use genetic program tune heuristic priority function three compiler within impact compiler two achieve however two well implement turn data completely preferable reduce many gain third optimization register allocation able achieve average two increase manually al four describe use supervise learn control whether apply instruction schedule absolute performance report however finally al sixteen use classifier base decision tree learn determine loop unroll look performance compile program spec suite use two different learn scheme show modest improvement eight conclusion future work paper develop new methodology speed iterative compilation automatically focus search likely give performance use predictive model program feature learn profitable optimization space search experiment demonstrate approach highly effective speed iterative optimization currently phase build model apply new program obvious next step continuously update learn model new program iteratively optimize similar spirit lifelong compilation thirteen future work investigate different predictive model new space improve performance search base optimization reference one l cooper j w reeve l waterman find effective compilation sequence proceed international symposium code generation optimization six fir lat two five ten r fifty r r r figure eight achieve random search r random learn model random learn model two five ten fifty processor random learn model achieve greater average performance five random fifty two c bishop neural network pattern recognition fourteen c lee suite three f e iterative compilation nonlinear space workshop direct pact four j j moss induce decide whether schedule may five k chow selection char compiler six k cooper reeve l waterman search compilation sequence rice technical report seven k cooper reeve l waterman acme adaptive compilation make efficient eight b j g probabilistic embed program nine holler automatic recommendation compiler ten hall l b murphy e lam maximize performance compiler computer twelve eleven p kulkarni w h moon k cho j bailey park k find effective optimization phase sequence twelve p kulkarni j j fast search effective optimization phase sequence may thirteen compilation framework lifelong program analysis transformation fifteen k wang optimization embed sixteen machine learn approach automatic production compiler international conference intelligence methodology seventeen k g p comparison empirical optimization eighteen p chow c lee comparison traditional architecture compile case nineteen martin meta optimization improve compiler machine learn twenty b j wang loop optimization code generation proceed international conference acoustic speech signal process volume four page phoenix n august compiler exploration march proceed international symposium code generation optimization six