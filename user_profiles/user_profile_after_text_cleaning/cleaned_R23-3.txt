spatiotemporal university seidel figure one comparison different scheme fully dynamic scene complex shade indirect light ambient occlusion abstract process become increasingly expensive due complexity today however shade result spatially temporally coherent allow sparse sample reuse neighbor value paper propose simple framework spatiotemporal modern contrast previous work focus either temporal spatial process exploit coherence algorithm combine adaptive filter time image space robust respect temporal change achieve substantial performance limit number sample per frame time increase quality spatial recover miss information previous frame temporal strategy also allow us ensure image converge higher quality result one introduction shader substantial element modern graphics card lead visual despite tendency towards general process shade receive constantly increase much visual detail today shadow ambient occlusion procedural attribute process faster execution often lead direct performance increase current trend towards enhance image resolution modern high definition forthcoming super high definition image one observe neighbor spatial temporal become similar exploit spatiotemporal coherence frame copyright association compute machinery permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute commercial advantage copy bear notice full citation first page copyright work own must honor abstract credit permit copy otherwise republish post redistribute list require prior specific permission fee request one nineteen reduce render cost suppress pop become attractive method drive observation high quality important static thus accept loss strong occur show good assumption recently exploit shadow al achieve goal rely vary sample pattern produce image keep several sample time idea integrate sample unify manner heart method filter strategy combine sample space time time spatial kernel adapt accord sample coherence static time window choose large produce frame drastic change occur method automatically favor consistent spatial sample result lose visual accuracy maintain temporal consistency property algorithm locality mean good filter strategy choose accord actual image content differ recent yang al although method overhead small achieve higher quality approach run entirely leave idle purpose important game two previous work several ways reduce possible reduce amount shade use shade visibility test al shader cull paper exploit coherence reuse value space time temporal accelerate render update certain amount per frame bishop al susceptible arise change view geometry improvement achieve adaptively sample frame content dayal al efficient context suggest warp accelerate display global illumination mark al walter al refer al complete list reference lead sample density derive frame better quality obtain apply per object radiance guarantee error bound al reduce sample spatiotemporal coherence involvement ray trace although step direction exist make less cache al al al supplementary buffer encode fragment contrast image analysis geometry relatively cheap obtain displacement information evaluation vertex shader storage give current fragment one easily verify presence previous frame possible reuse value recover information necessarily final color intermediate shader result underlie assumption fix surface point value remain constant time assumption give rise idea integrate sample time static scene al static also exclude illumination change introduce concurrent work yang al yang al extend idea propose adaptive method cache profound error analysis adapt exponential smooth factor determine decay previously compute sample time temporal change shade blur due filter cache similar method temporally interleave frame virtually increase spatial resolution target thus use two two buffer sufficient purpose contrast method use propose approach depend rely important context allow spatial support propose efficient recovery concern supplementary information exploit filter process technique allow us handle miss therefore need resort render deal silhouette recover higher resolution image whereas yang al yang al exploit possibility propose way adapt filter kernel depend confidence spatial temporal data use different filter scheme temporal estimate gradient vary shade detect almost constant shader one use learn stage particular object al require long time setup exploit coherence might arise application shader dependent light stationary execution use change sample pattern enable detection inconsistent nevertheless method would still benefit good shader decomposition see orthogonal goal yang al yang al deal dynamic change reduce shade produce low resolution frame produce complete frame downside solution detail might capture low resolution frame hence always possible deduce information need current frame deal problem attempt add new recover image content analysis edge preserve interpolation solution work low resolution information ensure higher efficiency recover better high frequency estimate temporal strategy involve sample previous frame compensate motion perform spatiotemporal filter exploit temporal coherence filter commonly use video restoration successful suppress ray trace temporal coherence use advantage number global illumination discuss survey paper al al many present even require knowledge subsequent unacceptable interactive render purpose approach exploit temporal coherence low level single photon coherence usually give flexibility enable exchange information many frame however difficult efficiently exploit current solution rely relate interleave sample al al roughly similar incarnation three section explain strategy inspire previous work first review spatial section spatial section also refer cache step step describe present spatiotemporal solution section spatial yang al assume expensive shader spatially slowly vary reconstruct sparse sample follow interpolation true many light computation author apply filter al perform image al filter weight steer geometric similarity encode geometry buffer mean sample close world space similar surface orientation better interpolation simplicity use indices j follow give geometry buffer shade result l h compute h one j l j one n neighborhood around j index nearest image j spatial weight define j n zero one ni two two n two z k j two weight consist geometric weight function involve orientation n linear depth image space filter k simple spatial k choose arbitrarily linear hat function yang al term whereas keep n two z depend scene throughout paper use three difference near far frustum plane higher efficiency choose n cover four nearest image l one choose n freely long favor similarity fall quickly method yang al use filter relatively expensive use simpler yet similar function n g x one x three represent filter width control choose three correspond kernel g two three plot function various show figure four leave finite support clamp small epsilon avoid zero weight point correspond one ie visible previous frame fetch previous frame h one usually identify compare warp depth value depth value previous frame al compare depth value may miss certain locate contact point see fig three clear ambiguity also compare material store anyway geometry pass defer renderer take figure two leave regularly sample shade image produce frame output fuse previous frame spatial increase final image quality one also look back time instead interpolate within current frame miss resurrect past frame beneficial frame correspond differ otherwise static case new information gain time accurate convergence become impossible random pattern propose al cost efficiency imply supplementary render pass fill miss information slightly accelerate via termination method want avoid computation extra sample order ensure relatively constant cost per frame like yang al make update efficient use spatially regular pattern show figure two render sample set apply post perspective space encode projection matrix come supplementary render cost regularity also helpful spatiotemporal filter section concentrate window rest section discuss size section four process illustrate figure two simply reuse previous frame visible likely appear camera movement scene change result ghost trail follow object one compensate effect compute frame refer motion flow motion flow inexpensive necessary information available al improve quality cheap compute motion flow texture always consider two successive frame brevity refer time q ie standard one keep update set final output let search previous frame h one h one one l four h high resolution image current index time compose currently compute image l nearest index previous image h one one motion compensate position one special care take one point outside screen figure three deal temporal base comparison may fail contact point leave additional criteria material help reduce right previous compute current frame binary weight determine give whether fetch current previous frame set one compute current frame time zero respectively spatiotemporal previously describe scheme always well suit construct image spatially efficient prone blur sharp image feature hand temporal cache al al sensitive temporal change converge scene nearly static consequently would like combine two approach spatiotemporal framework h one q j q j q l j q five q temporal kernel favor compute recently one good choice exponential q improve upon section term explain one four indicate usually sixteen ie four four amount need cover sample frame intuitively follow sample back time time step ensure consider compute time contribution influence weight measure geometric difference penalize age filter k compute choose carefully precisely define k j g x x j r x position screen r diagonal length zero filter k constant result approach spatial k filter k j one j zero otherwise hence equivalent consequently want use function k blend two depend temporal coherence see fuse frame x sixteen frame n x n one two three four five six seven eight nine ten eleven twelve thirteen fourteen fifteen sixteen figure four leave geometric weight function n kernel right image space filter function k temporal weight function history buffer update next frame store h one one one choose exponential five seven equivalent note zero one reduce performance penalty respect yang al single texture algebraic furthermore possible longer need sixteen low resolution one history buffer one low resolution frame enough time dependence vanish general particular function previous section see efficient way involve longer temporal history nevertheless case might want fast change induce shadow would profit use spatial instead temporal hand improve quality shade output necessary integrate sample previous frame extent dynamically adapt temporal weight image space filter k locally precisely want address follow point one temporal flicker due low resolution sample high frequency spatial signal two temporal ghost due fast temporal change three convergence static choose k appropriately examine variance temporal signal rely temporal gradient weak gradient imply confidence grant evaluation time consequently large k reduce image blur give weight actually compute history buffer contrarily large indicate change occur history longer reliable accordingly fall faster k favor spatial introduce image blur achieve scale exponential filter function k define section confidence value maximum four good choice use experiment estimate temporal assume h one dimensional otherwise one could either compute norm consider separate rely finite define gradient address case value domain unknown realize usually make sense compute relative particular color definition tend capture contrast reduce color luminance h h h one one h h one one general definition accord time need previous section reduce time dependence single frame define two one h eight steer sensitivity spatial usually keep one experiment square equation eight suppress aggressively large temporal small one may notice depend h result currently want figure five leave dynamic shade result middle sum weight brightness represent confidence yellow insufficient spatial weight blue temporal weight red right image figure four right better convergence time achieve lower value improve temporal response present temporal steer section one assume moment three figure five middle visualize spatial weight four four mark blue consequently take previous frame yellow indicate small geometric weight current frame thus likely previous frame use red neither spatial temporal confidence make recomputation general sparse filter mechanism ensure plausible value attribute make possible avoid recomputation exponential history buffer filter equation five lead better result spatial temporal filter alone beyond question expensive need perform many dependent texture repeatedly produce one improve performance observe coherent time thus possible cache chain previous frame lead idea exponential history buffer store previous result previous spatiotemporal weight ignore temporal component equation five obtain standard bilateral one j j l j six weight give history buffer compute actual output h via blend h one one one one one seven zero two four six eight zero two weight twelve three g three g three g three zero two four six eight zero five filter x one five g x one ten g x one twenty g x one thirty compute therefore approximate h base spatially result compute make use history buffer spatial h may suffer temporal flicker finite potentially always noisy decide use filter time space simple spatial filter use would option since detect spatial might result however spatial correspond periodic temporal signal greatly reduce sum consecutive frame therefore address issue make use current three previous finite store vector h three three filter gradient h temporally compute absolute weight sum four three two one sum well current two previous store single texture finite relevant next frame use control though filter time value still fluctuate spatially filter want use kernel slightly distance sample thus slightly four four practice find filter deliver good quality value choose level lead improve estimate particular presence see figure seven temporally spatially filter value use equation eight care take special case previous frame compute temporal gradient impossible simply ignore may lead visible transition successfully order suppress set relative temporal gradient maximum consequence temporal gradient spread neighbor spatial filter lead gradually diminish gradient hence smooth transition spatial see fig six figure six crop run horse along motion leave smooth set maximum relative gradient right since spread neighbor spatial filter point whenever gradient falsely assume vary method break instead fall back spatial filter adaptation improve quality result even though algorithm ensure converge actual solution increase temporal window improve quality significantly illustrate figure seven leave accompany video alternatively temporal could obtain via spatial know temporal base newly compute value practice result expensive qualitatively less convince result solution filter space time little cost better handle investigate special case like zero motion find quality remain similar make supplementary memory load store motion unjustified figure seven temporal important detect change illumination figure show static freeze scene top row frame fully dynamic scene bottom row red negative green positive simple finite center prone noise filter right regularize gradient estimation static scene gradient almost zero top right eliminate flicker achieve high quality bottom right might lose almost invisible dynamic context result show leave demonstration purpose show sign spatial smooth rely absolute value four implementation detail overview far consider size four four strong approximation sixteen frame need produce accurate result static scene although convergence often faster fluctuate make sense decrease window size algorithm easily extend various size two two eight eight find screen resolution two two vary value better address simple even spatial bilateral need bigger take much time converge high quality result nevertheless even higher might change complex often consist several independent shade term low frequency high computational complexity fact direct light shadow expensive could efficiently compute every hence follow al split shader individual enable even higher gain illustrate effectiveness approach refrain result spatiotemporal integrate defer shade approach initial pass necessary geometry material information well motion write next pass expensive shade perform low resolution frustum coherent sample pattern see figure two correspond different subset next current shade result high resolution take account motion flow solely previous result dynamic converge scene jeep horse horse elephant shade sixteen two nine temporal ten spatial eleven eleven sixteen eighteen sixteen fifteen thirty ref seven table one final average standard deviation render frame spatial fill spatiotemporal reference ref image resolution four four window cost input shade time spend give thank section temporal temporal gradient filter assume spatially coherent need compute high resolution instead compute intermediate resolution two two spatiotemporal spirit yang al common way defer shade compute result higher resolution merge obtain average color scheme nicely fit propose need compute geometry material buffer intermediate buffer higher resolution display buffer result display resolution extent follow compute shade value lower resolution nevertheless hardware involve previous frame compatible defer shade result overhead quality depend shader spatial frequency five result comparison implement simple describe section hole fill al spatial yang al use perform test various challenge resolution time give table one visual result statistical error measure show figure eight initial geometry pass defer renderer deviate slightly throughout different explicitly show table one overhead compute motion always less one experiment first scene jeep little geometry move light source challenge texture filter reeve al six six kernel figure eight top second scene contain animate horse figure eight bottom static camera apply ambient occlusion eight eight randomize horizon sample different scenario figure one add instant global illumination evaluate large number virtual point light without visibility generate reflective shadow map setup camera move indirect light change quickly approach even suppress flicker due temporal noise sample please refer also video material provide paper finally last scene show run elephant large animate body render fix frame rate thirty sample spotlight directional occlusion al direct light sample sample environment map scene challenge viewpoint change quickly reveal large surface make difficult old sample furthermore shade accurately reproduce neither method favor spatial set seven scene completely fail scenario whereas method similar spatial still produce decent result result generally benefit spatial horse scene show static converge nicely whereas dynamic near run horse value take current spatial response quality jeep texture even separate faithfully converge shadow show minor hide motion show many ghost spatial converge solution visible near geometric detail background cathedral geometric become smaller emerge moreover flicker appear camera move detail assure constant supplementary render fill hole differ cost approach similar performance spatial illustrate table one maintain good image quality overall make solution good choice dynamic static six conclusion although spatiotemporal process explore different receive less attention term render fact inherently exploit spatial coherence structure massively parallel process pipeline however modern benefit little temporal coherence work propose relatively simple framework spatiotemporal render efficiency quality compare spatial algorithm produce higher quality introduce small performance overhead keep memory demand small dynamic algorithm robust temporal cache combine benefit demonstrate relatively complex technique reduce shade cost solution well suit increase screen beneficial various global illumination soft shadow procedural seven discussion future work although algorithm produce generally better robust result previous yang al may also fail first limitation cache solely base fast computable geometric flow might differ optical flow worst case scenario imagine fast move object camera attach move speed shadow cast object static floor completely position temporal help case mainly spatial influence final color temporal become large figure eight comparison spatial spatiotemporal first two row show difference image four time scale simple shade static geometry dynamic light difficult case method perform better amortize temporal obtain smoother difference image spatial geometric better handle lead visually please result third row show result expensive shader dynamic scene static camera background exhibit high quality achieve temporal convergence reflect positive influence method bottom row show dynamic scene shade result show figure one algorithm rely assumption temporal change shade smooth spatially coherent therefore filter quickly vary signal due noise otherwise could reliably estimate temporal weight coefficient trade spatial would flicker hence fine detail shade also quickly change time hard detect fortunately fast temporal change also hard track human visual system may appear blurry due integration eye effect modern display second minor shortcoming influence apparent motion blur arise avoid would like filter input signal shade instead shade result however way would interfere shader algorithm want treat flow accumulate history frame even though motion compute high resolution blur still appear example move camera small center accumulate several frame see fig nine simple remedy also propose yang al increase resolution exponential history buffer accuracy hand spatiotemporal reduce temporal influence old shorten leverage spatial coherence even shade static always small influence spatial neighborhood work rely temporal solely adapt temporal filter weight ideally would want extrapolate information base proof robust enough due accumulate algorithm produce better result increase incorrect quickly refresh newly compute eight jeep direct light seven elephant jeep four x difference j cull unit seven v virtual efficient intermediate representation workshop render j f joint bilateral graphics three mark w l bishop g symposium interactive render warp graphics sander p v j n j r accelerate shade reverse cache graphics hardware g r h k digital photography flash image pair graphics proceed conference three reeve w h cook r l renin sig shadow depth map graph seidel approximate dynamic global illumination screen space symposium interactive graphics game shadow map temporal shadow test confidence render b j c r b bidirectional instant render spatial animation sequence spatiotemporal filter proceed p j yang l sander p v improve shade cache modern graphics hardware p j yang l sander p v xi j shader optimization eight digital video process prentice hall c p interactive global illumination use fast ray trace render walter b g parker interactive render use render cache proceed workshop render yang l sander p v j geometry aware level detail render figure nine precision loss temporal top nearest neighbor result correct continuous motion flow green approximate red point different bottom bilinear texture filter trade blur since neighborhood influence final result downside temporal pattern least screen clearly recognizable deterministic temporal sample pattern however sophisticate adaptive would easily annihilate gain dynamic change sample pattern could help hide behind noise believe complex weight might better choice keep future work reference j l f generate exact animation frame computer graphics fifteen three k j teller interactive scene edit use ray segment tree proceed workshop render l ambient occlusion talk program e p l video enhancement use virtual graphics three bishop g h l e j frameless render double buffer consider harmful proceed induce image image process international conference three c reflective five proceed symposium shadow map interactive graphics game c k k state art global illumination interactive computer graphics forum one march e f flash photography enhancement via intrinsic graphics proceed conference press vol dayal c b p adaptive frameless render render yang l sander p v p j h amortize nine