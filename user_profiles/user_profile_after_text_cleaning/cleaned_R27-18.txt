impact document level rank focus retrieval one archive information study faculty university two faculty science university abstract document retrieval prove competitive evaluation focus retrieval although focus approach element retrieval passage retrieval allow locate relevant text within document use context whole document often lead superior document level rank paper investigate impact use document retrieval rank two use ad book track relatively short document collection much longer book book track collection experiment several combine document element retrieval approach find one get best improve upon individual retrieval retain document rank document retrieval approach replace document retrieve element retrieval approach two use document level rank positive impact focus retrieval impact much longer book book track collection one introduction paper investigate impact document rank focus retrieval compare standard document retrieval element retrieval approach evaluation focus retrieval study document retrieval prove competitive compare level retrieval three although focus approach element retrieval passage retrieval allow locate relevant text within document use context whole document often lead better document rank seven aim investigate relative effectiveness approach experiment combine two approach get best want exploit better document rank performance document retrieval higher precision element retrieval strategy study impact use document retrieval rank perform experiment two use ad book track relatively short document collection much longer book book track collection paper structure follow first section two report result ad track section three present retrieval approach book track finally section four discuss find draw two ad track ad track investigate several combine article retrieval element retrieval approach first describe index approach run combination adopt retrieval framework finally per task present discuss result document collection ad track base fourteen collection convert format one collection document use different tag name however tag occur occur ten time entire collection average document almost eighty average depth retrieval model index retrieval system base engine number five nine ad track use language model score element e give query q calculate p p e p one p view query generation chance query derive p e element prior provide elegant way incorporate query independent evidence four estimate p use smooth whole collection ie collection element e query q p one p p te two p te e e p e e p finally assign prior probability element e relative length follow manner p e e e e three e size element e parameter introduce length bias proportional element length one default set thorough description retrieval approach refer twelve comprehensive experiment data see ten index approach base work two six element index main index contain retrievable index textual content element include textual content result traditional overlap element index way do previous eleven article index also build index contain article ie page standard index remove morphological normalization stem apply query process similar document use either query query remove query present query query combine article element retrieval experiment combine run use two base run article run use article index element run use element index run use default language model fifteen ten show al seven article retrieval lead better document rank whereas element retrieval fare better retrieve relevant text within document ad focus task retrieve different document maybe interleave rank would expect element retrieval achieve high early precision document retrieval give return whole document often relevant entirety lower early precision hand expect document retrieval approach relatively little difficulty identify long article large fraction text highlight relevant therefore return top rank first return document thus contain relatively large fraction highlight text good precision result fairly slow drop precision across first recall relevant context task retrieve group document introduce document rank score retrieval score expect document retrieval approach rank document better perfect recall due retrieve text document reasonable score element retrieval expect precision better document retrieval approach less recall worse document rank therefore assume combine approach use document rank article level run within document element rank element level run outperform run context task experiment three combine article element result one retain article rank replace article retrieve element run retrieve use full article two multiplication multiply element score article score article belong element correspond article retrieve top result article run use element score three retrieval score divide highest score result list add article score element score article top result topic element score use thus get boost full article retrieve top result article run focus relevant context base follow base thorough run table one result ad track focus task run emphatic official zero one five ten run article element multiplication element multiplication submit art el art comb sum el multiplication art x el also make thorough run use filter method last year two pool target topic set filter run remove element type pool target official run three task base thorough run lengthy name run increase clarity consistency presentation denote official run use instead official run name use submission focus task ensure focus run overlap straightforward removal strategy traverse list simply remove element ancestor descendant element see list example first result article article include element article case run first apply filter remove overlap way around would first remove possibly relevant target overlap receive higher score table one show result focus task somewhat surprisingly article run outperform element run official focus measure one although element run fare much better precision level zero thus already one recall document retrieval higher precision element retrieval possible explanation give encyclopedic nature collection many ad entry almost entirely relevant form one total relevant text mention seem plausible document retrieval approach find page relatively easy one recall often achieve first one two result thus reasonable precision multiplication attain higher score zero latter keep higher precision recall level multiplication method lose much precision two compare run article table two result ad track relevant context task run emphatic official five ten fifty run article element multiplication element multiplication element combination lead substantial one multiplication method perform slightly worse article run however standard article run clearly outperform run look overall precision look run see small lead highest one score filter method lead overall score go compare non negative effect early precision zero one score go except multiplication run one score go also version multiplication run improve upon article run precision ten recall relevant context task relevant context task use focus run cluster belong article together order article cluster highest score element table two show result relevant context task article run better element across rank expect give result report seven superior article rank compare element run saw previous section even outperform element run official measure focus task however time combination multiplication better article run report measure except multiplication run five since use article rank article run higher precision score multiplication show retrieve element run improve precision article run method far behind fail improve upon article run early precision level five ten weight combination article element score article rank somewhat different article rank article run multiplication run filter method lead element run outperform standard article run combination show higher precision score non rank time method benefit filter whereas well behind per table three result ad track best context task run emphatic official five ten fifty run element article article offset multiplication element multiplication compare two combination version highest score ten fifty perhaps surprisingly element run even par combine run focus task element run score well combine run later rank group article later cutoff level small fact element run highest score filter could effect document rank element run best context task aim best context task return single result per article give best access relevant experiment three select best entry point highest score element highest score element return ar use combine run offset zero start return article offset median distance start article best entry point table three show result best context task article run far superior element run best context task rank fact article run outperform combine run run combine run better pure article run offset note two run article rank standard article run highest score element thus better estimation median offset large number however use start element clearly outperform run three run combination get better score early precision level five ten overtake multiplication method cutoff level three outperform element run article run fix offset run improve upon non show filter method robust task retrieval approach combination non give best early precision multiplication get better precision later cutoff level combination consistently improve upon element retrieval approach far behind standard article run mean focus retrieval fail improve upon article retrieval approach come select best point start read document closer look distribution might explain big difference standard article run run median offset fourteen first character show choose start article case result much better document score offset document find sum combination seem effective improve early precision official focus measure one lead article run element run method give best result official measure although element run score slightly better zero combination show good trade good overall precision article run good early precision element run combine filter improve overall precision hurt early precision relevant context task three improve upon article element run method show improvement across cutoff level multiplication method lead highest score three filter improve effectiveness although small method combine run show best good article rank article run precise retrieval relevant text within article element run best context task three combination score better early precision two better later cutoff level however focus retrieval method come close effectiveness pure article run close start article seem little need focus access collection result might explain nature collection collection contain many short article entire article easily fit computer screen focus specific text short article relevant usually make sense start read begin article finally filter method show robust task focus retrieval use lead consistent substantial upon non filter three book track book track investigate effectiveness use book level evidence page level retrieval experiment use rich resource topical knowledge find book mediate user query book book track collection use indri thirteen retrieval experiment default make one index book page level use stemmer removal create two base run one book level one page level book track collection contain book book average page word average page word important difference collection apart document length difference structural information form markup article markup base layout contain markup section paragraph table list figure book contain minimal markup base individually scan page layer section page level book level although information start section attribute marker provide information section end make use information retrieval would require either substantial change index approach step adjust markup introduce actual chapter section analyse impact book level rank retrieval individual page discuss various book level run submit book retrieval task book retrieval task al eight use intermediary search query book book collection experiment use link distance call query page title exactly match query book book collection associate one page base document external evidence improve retrieval performance adopt approach aim investigate effectiveness query exact match page obtain query page send query version choose first return result query exactly match page automatically return page otherwise return result list pick top result idea search dedicate page seventy collection find dedicate page query book page obtain take top term book whole collection query indri index next compute link distance query page book page apply random walk model link graph obtain measure closeness page book associate page closer link graph query page higher probability relevant eight combine closeness score retrieval score indri run probability go node j step query node node k compute j four one base dump twelve march table four result book retrieval task closeness order run official submission map p zero p one run book closeness closeness closeness order number link node j node k total number link node j j probability node j step experimentally use book track data find best closeness score book obtain simply add closeness score top eight page retrieve book submit follow run book book level indri run submit six b clean closeness run use closeness score submit six book forward closeness combination indri closeness score compute indri q b two closeness q b book b topic q submit six b square time table four show result submit run base first release relevance contain number per topic vary greatly one two judge book judge book careful draw result standard run perform best measure official run base closeness score alone perform poorly base simple error result per topic allow submit generate run closeness score first score topic use however closeness score order first highest score therefore add result unofficial run closeness order base highest closeness score per topic although still well run clearly much better erroneous official run run clearly best run page context run submit book track derive use book level run follow section page context ad track section two experiment page level run use rank book level run indri score always negative log probability ie range zero combine score lead unwanted effect page score book score lower page score alone therefore transform score back take score experiment follow three one add page score book score book retrieve use page score submit six plus two multiplication multiply page book score book discard page submit six time three retain book rank replace book page retrieve p age run page retrieve use whole book official evaluation measure result page context yet release relevance available allow direct comparison ad book track evaluate page context run use focus relevant context measure ad track transform book track format follow way first compute number page book length actual text average page length give page book average length compute page offset judge page retrieve page multiply average page length one page number book page one million character average page length character thus page book length start offset one two zero zero focus task rank individual page score without group per book relevant context evaluation require result document group use officially submit page context run book rank base highest score page book result page context run evaluate use ad measure focus task see section show table five see overall precision book run low precision score compare book retrieval task retrieve whole book instead relevant page however focus page level run even lower precision score except precision score run somewhat surprise result explain fact original p age run contain small portion relevant page early precision comparable book run rapidly drop reason low precision score five recall run contain retrieve page enough reach even five recall among page level run run clearly outperform standard p age run show book level rank help boost page highly rank book lead substantial precision across rank apart retain whole book individual page retrieve big impact recall especially result list book run find relevant book find p age run run also improve upon book run zero show focus indeed locate relevant text within book big difference p age run well low precision p age run show page level evidence limit use without context whole book result page context run evaluate use ad measure relevant context task see section show table six see similar pattern focus task result book run receive low score table five result book track page context task use focus measure table six result book track page context task use relevant context measure run zero one five ten book page thirty seventeen multiplication thirty fifteen five ten fifty run book page ninety multiplication fifteen retrieve lot irrelevant text focus able achieve much better precision run compete book run improve upon early overall precision fact run lower precision book run rank show lower rank whole book better individually retrieve page book although might partly cause low number page retrieve low precision score focus evaluation show content individual page effective locate relevant information book contain page four discussion ad track investigate effectiveness combine article element retrieval find method article run determine article rank element run determine part text return give best result focus task relevant context task multiplication method slightly better run filter pool target base entire topic set method give best performance overall combination effective best context task standard article retrieval run far superior focus retrieval run many short article collection focus specific make sense start read begin article make hard focus retrieval improve upon traditional document retrieval pool filter method effective three task well show consistent improvement upon non measure book track experiment run combination ad track ad track use collection see book track document retrieval approach however long document book track collection individual page form small part much context impact document level rank focus retrieval much bigger short document collection use page level evidence precision low indicate content individual page seem effective locate relevant text spread multiple page book use rank book level run replace whole content book individual page book retrieve combination improve upon standard document level retrieval support organization scientific research grant support grant bibliography one l p corpus forum two k n j j use detect link proceed volume page springer three n j malik overview ad track n page four use language model information retrieval thesis center information technology university extension search engine five six j b filter cluster retrieval result comparative evaluation information retrieval volume page springer seven j locate relevant text within document proceed page press new york eight g n page entry point book search proceed second international conference web search data mine press new york nine search engine ten b focus information access use element retrieval dis series university eleven b j de approach retrieval workshop proceed page twelve b j de mixture model overlap structural hint element advance information retrieval volume page thirteen h turtle w b croft indri base search engine complex query proceed international conference intelligent analysis fourteen free encyclopedia