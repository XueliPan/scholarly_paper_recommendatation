load balance stateful cluster web g b w department computer science federal de brazil abstract one main challenge wide use ability handle increase demand stateful comprise even difficult since necessary keep transaction data across request user one common strategy achieve employ cluster load distribute among various however consequence need maintain data coherent among compose cluster load imbalance arise among reduce efficiency server whole paper propose evaluate strategy load balance stateful cluster strategy base control theory allow gain employ load balance strategy reduce response time fifty increase throughput sixteen one introduction growth recent past widely link growth world wide web lot growth credit expansion electronic commerce service definitely one drive force behind expansion network increase number company use daily basis general sit particular success measure number access site ability site satisfy request promptly mean store successful must able get attention large number keep satisfy problem increase success directly relate increase number concurrent therefore increase demand company server able continue success popular site must able accommodate increase load gracefully become major concern every site nowadays however improve capacity individual server always effective give technological relate memory speed among factor fifteen distribution request group strategy achieve limit individual machine limit lot work direction static content define different distribution identify main performance bottleneck good survey work area distribute web compile al four one challenge face distribute however increase performance due increase number linear distribution request number impose new process demand guarantee consistency information among example two access different try purchase certain product two must guarantee sell item twice extra overhead may grow point add may fact make overall performance even worse design implement scalable efficient distribute service quite complex task specially consider architecture system organize multiple layer service distribution bring new dimension problem extensively address literature far work area performance analysis do context individual one five another source overhead besides consistency prob proceed symposium computer architecture high performance compute three management distribution request presence session state stateless protocol request page independent may direct host distribute server cluster hand sit interaction client site create certain amount state information add shop cart user identification example case request distribution must consider information also add complexity distribute server may result load imbalance among responsible handle request devise implement evaluate load balance subject paper divide load balance problem two one load migration two balance order solve first subproblem define work exchange among second subproblem demand design load balance also include definition imbalance metrics paper propose evaluate experimentally load balance strategy transaction cluster strategy evaluate actual realist rest paper organize follow section two introduce architecture major stateful web follow discussion issue face balance load section three four section five discuss common stateful server architecture section six characterize submit section seven present major result section eight conclude final future work two stateful cluster web order understand detail stateful server must understand various involve architecture server site whole section address issue without loss generality may discuss detail stateful analyze typical architecture basically three main consider service sessions first entity represent commercialize basically two type data static dynamic static data comprise information affect service provide server description book dynamic data hand contain piece information affect perform provide service number book stock address buyer second entity represent server record static dynamic data case information name address static content shop cart dynamic identification static dynamic crucial distribution service static data easily replicate among server cluster dynamic piece data must properly identify access must properly control avoid third entity relation first two represent interaction interaction usually represent user session build server response user request session combine reference static well dynamic data client group case number distinguish three also type data usually handle data first type data divide data two dynamic static dynamic data comprise information may change consequence perform inventory static data usually attribute good service market description manufacturer second type data data may also divide static dynamic data last type almost always dynamic although data may store better maintain even data application server order improve response time server distribute static data may view cache problem server limit amount storage space manage overall storage space take account factor communication cost reference locality storage cost server consider factor several cache management may employ storage cheap totally replicate cache may reduce access time overall since host local copy cache data hand storage expensive mutually exclusive cache make best use since every cache object occupy space one server cache however solution may handle lot communication case request reach hold copy require data many intermediary also possible level replication allow handle popular reduce communication case sixteen proceed symposium computer architecture high performance compute three distribute dynamic data quite complicate sense coherence become issue piece dynamic data store two must way guarantee either server notify change perform one problem novel distribute work address efficiently time however interest notice service impose involve static data thirteen due access information product image example kind data replicate cache certainly improve response time nine may distinguish essential scenario interaction client server site user request receive parse determine session refer need session data must retrieve well customer data case perform right context operation involve common case product data must also retrieve information need available request must process may affect dynamic data request result must save session state update finally response page must build base request result site presentation rule send back user browser presentation require different perform may fact execute different process server next two section discuss migrate data thus associate load decide migrate define load balance strategy three load migration become necessary cluster migrate load among machine example order improve load balance achieve move data two transfer associate process demand consider type represent service likely sessions since concentrate dynamic demand process sessions best migration since concentrate process due representation application logic access usually simple include process session request therefore work use sessions migrate load one server another use like switch four session migration may do way transparent commercial cluster rely stable storage manage server example maintain session data consistent mi grate among obviously introduce considerable overhead since session data persistent nature usually limit duration session reduce overhead include cache scheme take advantage locality access ten work present solution session data keep solely memory migration handle application avoid stable storage cache consistency use central session directory keep track assignment sessions cluster directory communicate switch control maintain rout table sessions whenever new session identify switch directory notify assign server switch program appropriate rout association assign server initialize session data upon receipt first request follow request rout server switch notify behave otherwise directory session must migrate server currently process original server newly assign server receive server notify session information transfer original server keep track migration pending request may receive session move receive server transparently receive server internal structure upon receipt migrate session notify directory operation complete directory record new location session notify cluster update table communication belong migrate session direct receive server start process request soon transfer session state complete clear process migrate session mention request alter product dynamic data example process relate product data entity besides session choose distribute product information evenly statically among however discuss verify experiment discuss later load due product manipulation low compare session relate process cost vast majority load migrate session four load balance problem load balance distribute discuss literature specially consider increase may provide two three propose consider integration data replication service parallelization however proceed symposium computer architecture high performance compute three work consider make propose approach realistic discuss previously interaction server base sessions whose duration process demand predict beforehand since process service distribution must take sessions consideration assign request discuss later section six sessions vary widely term number request duration generate load static allocation sessions would lead serious load imbalance mean dynamic must rely dynamic load balance scheme improve nowadays rely sticky load balance certain client assign temporarily server first time see cluster switch assignment do use hash function base connection address port number example client rout select server time time switch clear entry session table compute new association new request arrive commercial like cisco six network dispatcher eleven offer solution sticky load balance session migration always present since periodically cluster may decide route traffic specific session different server however decision migrate sessions take consideration load due session cost migration consider simply server overall load reason behind approach give large number sessions periodic redistribution data bind reduce load imbalance time although possibly cost extra migration overhead solution propose load balance scheme might implement separate load balancer process decide implement session directory describe section three consider role process describe one server keep track much load cause sessions assign periodically every ten second implementation report total load session directory two directory compute measure overall imbalance cluster would ideal balance load three directory compute much server deviate ideal load match overload facilitate load transfer match use greedy algorithm try minimize number exchange necessary four base information directory overload server select demand sessions set would account excess load migrate sessions server specify keep track load per session basis server keep track ratio time session duration lower bind one minute avoid peak begin session total load compute aggregate time sessions match overload perform direct pair instantaneous load could lead eighteen solution consider server cluster close loop controller illustrate figure one mean developer determine performance level acceptable system term controller take care find right load distribution pattern honor level behavior close loop controller follow user define expect behavior system term measurable quantity set point example maximum acceptable latency controller measure actual measure value variable process variable give error error troller must compute actuation value controller output input system minimize error bring value define e controller target system figure one controller close loop controller approach use control theory relation measurable process variable clear straightforward relation input variable case controller internal behavior responsible adjust input dynamically base feedback loop desire value achieve traditional form achieve goal implement call controller seventeen case controller output measure error relate equation proceed symposium computer architecture high performance compute three define weight three error must define tune process server directory implement controller server base information overall load controller set point define iteration average load compute directory process variable server actual load report server therefore controller error measure much server load deviate average error feed controller since controller try cancel error compute much load transfer server order bring closer load average five case study section discuss popular stateful server architecture consider perform different type information must handle structure server usually divide three major server transaction server nineteen twelve organization illustrate figure two request service web server transaction server data figure two server architecture server responsible service presentation receive user request parse do server must manage request static data serve directly request involve dynamic data forward next level transaction server also responsibility server deliver page compose transaction server result dynamic request transaction server also know application server virtual store heart service component must implement logic business handle client search present complete sale must keep track user sessions control shop cart provide site personalization example receive command certain service server must implement logic operation may include access server complete request build response page handle back server information relate store operation must keep consistent across sessions stable storage guarantee proper operation time responsibility management system third element server hold product client information number available data receive command transaction server return data result centralize sit three may implement monolithic application performance reason however case service implement use separate process three first approach improve performance distribution case simply use separate machine three although simple implement limit gain give intrinsically limit nature really scalable must distribute number machine require replicate process distribute request properly paper analyze propose solution load balance problem common approach employ many replicate cache static data dynamic data although restrictive approach simple term implementation impose severe coherence management system although replicate cache simple implement since demand cache efficiency tend smaller increase number distribute give decrease term efficiency come result smaller number request server receive thus amount information embed system result may number request cause impact overall performance server hand replicate dynamic data may result load imbalance consequence problem arise session data migrate among give server start answer request session keep session end last argument one main paper six characterization section present characterization behavior use store understand associate important allow us estimate amount work perform also impact distribution may load server base log sessions comprise request actual frequent proceed symposium computer architecture high performance compute three frequency distribution session size think time histogram e q e r f r e b n e e e c r p l fifty zero one eight six four two zero zero c n e q e r f ten one l r p p ten one one ten twenty thirty forty fifty sixty seventy ten twenty thirty forty fifty sixty seventy eighty ninety session size request think time figure three frequency distribution session size figure five think time probability distribution seven experimental result search term popularity load server one load balance server one server two server three server four ten term figure four search term popularity request select search follow home browse add pay two frequency distribution request per session present figure three also characterize popularity type request figure four present frequency distribution search request query term case type request seven clearly see concentrate term account indicate replication perform well another evidence high variability arrival process request may visualize probability distribution think time time consecutive request user probability distribution show figure five confirm high variability fifty time sec figure six load without load balance experimental setup section describe experimental setup use evaluate propose load balance strategy distinguish four integrate transaction server one web server apache eight two parallelize application server implement author three management system session directory describe section three submit fourteen modify parse server redirect request associate give session migrate specific server basis load migration proceed symposium computer architecture high performance compute three load server one load balance imbalance factor server one server two server three server four server without balance server balance fifty three four five six seven eight nine one time sec imbalance factor figure seven load load balance figure nine throughput cluster without load balance cluster load balance response time imbalance cluster without load balance cluster load balance c e e q e r p h g r h e e n p e r fifty forty thirty two six five four three two fifteen two e e e c r p l g n c n b l e g r e v one eight six four two zero zero fourteen twelve one eight six four two zero zero fifty time sec figure eight average imbalance three four five six seven eight nine one imbalance factor figure ten response time result gather cluster run six ram four ram machine communicate fast switch cluster organize follow four machine run one machine run directory remain four machine run server application server put web application server together justify fact load web server usually low since page generate dynamically application server placement two machine reduce communication latency implementation application comprise two set thread slave responsible answer request submit answer request worker may query server another application server slave responsible han data request may also query server whenever necessary generate client base show section six sessions equally distribute among note distribute sessions equally among guarantee load since among load impose session term request complexity term number request arrival process order evaluate effectiveness load balance propose generate deliberately fraction request parameter may reach submit single server metrics section discuss metrics use evaluate load balance strategy may divide meet proceed symposium computer architecture high performance compute three two group overall performance metrics metrics overall performance metrics response time throughput response time server response time individual request time elapse request arrive correspond response send completely throughput number request complete within period time metrics allow us evaluate well server handle request metrics quantify operation condition server also distinguish two metrics server load average imbalance server load metric quantify amount process perform per elapse time quantify processor usage average imbalance average server server imbalance define absolute value difference respective server load average server load metrics allow us quantify effectiveness load balance strategy result section present experimental result gather experimental setup describe test employ four generate start point mention configuration completely ie one server receive whole load balance strategy employ figure six show load server experiment last second see clearly load server one significantly higher load although load latter negligible associate slave thread activity remarkable impact variation load since case thirty within second perform experiment employ load balance mechanism describe section three four result show figure seven see load balance strategy able divide load among effectively consistently even load peak peak around experiment time strategy show robust handle burst make load equal confirm evaluation check average imbalance across time experiment show figure eight see average imbalance decrease consistently across time although result quite variation evaluate effectiveness load balance function degree imbalance impose call imbalance factor four imbalance factor range one fraction load direct single server case server one instance imbalance factor seven would direct seventy sessions server one remain would receive ten sessions figure nine ten show throughput response time various imbalance factor graph show effectiveness load balance strategy instance imbalance factor one throughput configuration employ load balance sixteen higher response time less half gain reduce imbalance decrease till point imbalance load balance configuration get slightly worse configuration consequence load balance overhead eight future work paper present evaluate strategy load balance stateful cluster strategy base migrate user sessions among accord controller define sessions migrate consider overall server load load associate sessions strategy validate use application show propose strategy allow performance fifty response time sixteen throughput emphasize effectiveness propose approach even present high variability term user behavior term request load see several future work pursue evaluate propose solution first one devise new load balance improve responsiveness another area research also intend evaluate problem power management stateful cluster would also demand product data migration since individual would turn reference one c e cox r j marguerite k w bottleneck characterization dynamic web site third conference two l load balance cluster web use distribute packet rewrite technical report six proceed symposium computer architecture high performance compute three three j martin distribute packet rewrite application scalable server proceed international conference network four v e p state art locally distribute compute survey two five e j marguerite w comparison technical report rice university series visit june six six cisco cisco seven b g r pinto w assess impact distribution service first seminar advance research electronic business rio de eight foundation nine j chase web cache content distribution view interior computer two ten p build site apache proceed ca eleven g h hunt g r p king r network dispatcher connection router scalable service computer network thirty seventeen twelve standard business architecture journal one thirteen w v r scheme proceed second international workshop advance issue information zero page june fourteen tool measure web first workshop server server performance performance page june fifteen e performance issue network ton ten one sixteen g van steen differentiate replicate web document proceed international web cache content delivery workshop seventeen w j linear system theory prentice hall second edition edition eighteen e sontag notion input output stability nineteen c design criteria electronic market electronic market seven four proceed symposium computer architecture high performance compute three