batch process exploration c wang computer science university burn computer science university malik center university abstract comb vast amount data gain importance consist needle haystack query long run data intensive query throughput limit performance maximize throughput query put forth query process system batch query overlap data rather schedule query arrival order execute query concurrently order data maximize data share among query decrease io increase cache utility however batch process increase query response time starve interactive address starvation use inspire head schedule disk drive depend upon saturation queue time system adaptively process query arrival order batch process evaluate federation astronomy reveal twofold improvement query throughput one introduction gray nine document data avalanche problem physical instrument better data lead exponential growth data size astronomy example panoramic survey telescope rapid response system produce daily ten explore result massive amount data immense c value c scale data become large store single machine various c discipline turn cluster order facilitate data exploration cluster data typically partition spatially temporally across multiple nod include cluster two astronomy survey ten turbulence cluster thirteen simulation cluster alternatively build manage data accumulate multiple geographically distribute data source include sixteen eleven five article publish creative commons license agreement may copy distribute display perform work make derivative work make commercial use work must attribute work author biennial conference innovative data research cluster achieve high degree parallelism aggregate throughput partition data across multiple nod allow make explore complex scale within cluster federate compute environment new class c emerge strain io execute join query mine data extract feature distribute across multiple nod require send nod scan large portion data node solution design compute environment node concurrent query access share data execute batch server however approach suitable partition spatially temporally query subdivide work correspond partition group base partition access reorder base change data access pattern batch process motivate es federation dozen data source distribute across three face crisis term ever expand data size number sit use conduct query compute spatial join across distribute data source nineteen many query long execution time several entire day navigate entire sky perform full scan query also transfer large amount data network also receive many query lead poor performance current query schedule query second focus small region sky highly selective send query query processor arrival order allow con number generally concurrent query execute time send query query processor order result starvation query queue await completion query query schedule need ensure high performance c cluster end provide relax schedule achieve large query throughput accomplish exploit contention query share data query identify data access read disk large sequential high contention process query overlap data region one batch query access data eliminate random redundant disk access choose name goal life raft rescue many important people possible rescue do fairly order complete analogy process many concurrent query possible contentious data realize starvation resistance dynamically shift complete query arrival order low response time batch process high throughput base saturation queue time employ age throughput metric schedule prefer data high contention query queue long time bias parameter weigh relative importance contention age set parameter zero select contentious data regardless age set one complete query order receive note even evaluate query order system bene data share among query thus saturate system throughput remain high even though queue time go age dominate contention balance contention age bias parameter resemble seek time versus age r disk drive seven instrument schedule starvation resistance double query throughput query owe higher throughput schedule also reduce response time treatment include study response time versus throughput demonstrate system ability adapt differ saturation two relate work query batch paradigm study large tertiary storage order minimize io cost seventeen explore paradise system reorder query data store magnetic tape reorder achieve sequential io collect data phase without physically perform io reorder tape request execute query concurrently one batch however query participate join midway must wait entire batch limit sequential data process al provide process partition data fragment physically contiguous tertiary device schedule concurrent query per fragment basis although work leverage describe work also explore additional metrics high query throughput namely amount data contention query starvation process spatial join query receive considerable attention six fourteen fifteen twenty patel twenty describe io algorithm join without spatial index use step partition data base minimum bound box follow step apply computational geometry join pair partition memory al six improve algorithm uniform object partition prevent ow memory constrain al fifteen propose parallel spatial join whereas ne approach improve io performance single spatial join query ensure high query throughput multiple query combine ne approach batch schedule allow concurrent query execution share data additionally operate point data rely space curve rather index partition four attractive paradigm parallel computation query astronomy could bene immensely parallel execution paradigm yang al extend paradigm support relational join add merge phase process heterogeneous simultaneously moreover al eighteen combine procedural style declarative construct parallel program paradigm recently al one incorporate batch process environment es share among map task job scan maximize throughput work complement result however differ cache memory crucial query schedule revisit section six also highlight current approach use achieve high throughput nineteen system avoid starvation short query scan query job submission system query class assign different throughput long run query improve partition data evaluate query parallel across multiple however distinction long short query decide arbitrarily short query interfere short queue long query experience starvation work use ad distinguish long short run query rely multiple process query data query size support single system three query process approach query process focus data query instead arrival order order query process access secondary storage accomplish partition relational data table number object bucket incoming query determine list satisfy follow property operate single bucket process order result original query obtain combine result finally bucket read disk one time query whose list overlap bucket process concurrently incur additional io step apply batch process query discuss ongoing work generalize paradigm arbitrary join query section six query probabilistic spatial join perform astronomy record celestial object probabilistic imprecision physical instrument lead error exact location object spatial specify area sky exploration produce serial join plan query join large fact table archive serially intermediate join result ship archive operation within extensively discuss malik al sixteen section describe batch schedule query permit io share maximize throughput partition request currently query evaluate exclusively use spatial indices always bene introduce random io con gray al eight show query cover large spatial region io cost repeat index access much higher large sequential scan application coarse propose solution partition data homogeneous bucket large amor id ten ten eleven zero one zero one figure one de bucket contain equal amount use hierarchical triangular mesh disk seek time partition preserve spatial proximity object join process localize within bucket coarse apply query assign object bucket overlap potential join object join via sequential pass correspond bucket object may overlap multiple bucket bucket join separately duplicate elimination necessary since spatial join perform point data work employ similar solution allow io share batch process multiple query employ hierarchical triangular mesh partition data table twelve method index object spherical surface regular decomposition surface currently use support spatial query compute object intersection containment moreover space curve employ latter property enforce linear order object allow us partition data bucket preserve spatial proximity astronomical observation currently assign unique integer denote id fourteenth level hierarchy number preserve spatial locality object close space also close along curve use derive object partition sky disjoint bucket bucket cover set contiguous range start end id value bucket result uniform io cost access bucket figure one illustrate sample decomposition partition space two bucket three object triangle label id two use denote triangle position level bucket zero contain object second bucket contain remain object object multiple query map bucket batch together join single sequential pass recall astronomy archive receive query list object include object mean range id value serve bound box cover potential cross match let denote list bucket denote list query w j represent set object overlap bucket ie object bucket id range overlap j w two j w queue bucket consist union w one j thus request multiple query interleave queue join one pass thereby minimize random redundant evaluate join manner batch together match object belong queue single bucket time object bucket correspond queue sort join perform simultaneously scan merge object bucket queue similar plane sweep technique use partition base join twenty object sort along one axis merge object multiple query interleave queue query c predicate apply output succeed spatial join throughput metric schedule maximize query throughput bias toward bucket contention term pending request longer queue mean cost read bucket disk amortize query bucket de ne throughput metric w j ut w j one w j denote size queue estimate time cost read bucket disk cost match single object memory respectively cost derive finally function one n zero one zero memory one otherwise bucket evaluate greedily order decrease throughput capture rate object consume queue rationale similar selection form high throughput link measure number packet per second wireless network environment order achieve better performance three greedy policy lead high query throughput may starve request note schedule throughput favor bucket memory avoid cost read disk bucket select order decrease queue length result pick frequently access bucket guarantee particular bucket query receive service thus balance approach schedule need maximize throughput resist starvation adaptive schedule describe starvation resistant adapt saturation query arrival rate make response time query throughput account greedy maximize rate object queue consume bene overall query throughput especially highly saturate downside indefinite starvation request increase query response time change less saturate bene query throughput greedy reduce solution inspire starvation resistant schedule modern disk drive mechanical nature disk drive mean locate piece data incur high position overhead measure seek time rotational delay order maximize throughput attempt minimize movement disk head accomplish account n c e x e n n n r f p e e p ten one one three one one one one ratio size queue bucket figure two use scan spatial index cal media service data block physically close current head position favor request large sequentially data block starve request disk counter account position time service request wait time request wait time use ensure request service arrival order similar disk drive combine starvation resistance process query arrival order throughput optimize employ age throughput metric account query wait time starvation arise bucket low throughput small queue access infrequently increase query response time introduce last mile bottleneck namely query every object remain bucket low throughput schedule prevent inde starvation account age request bucket bucket de ne age throughput metric ut one two ut denote throughput bucket real value zero one es strongly bias toward process request arrival order parameter completion order concurrent query specify age criteria bucket even set one data share occur among query adaptively tune base saturation explore section five hybrid join strategy selective application index join yield performance bene presence heterogeneous distribution size queue bucket vary widely due query selectivity differ spatial archive indices available join attribute small queue use index join cost random io access low relative scan entire bucket performance margin gain lose depend seek time data transfer rate disk employ hybrid strategy determine join plan either index join sequential scan bucket depend queue size predetermine threshold use determine appropriate join strategy figure two demonstrate performance bene scan relative index join function queue size give bucket size observe twenty fold performance gap depend join strategy employ break even point occur size queue roughly three size bucket four architecture query implement top server support query figure three incoming query present query take input list object join query base spatial attribute object assign correspond queue queue keep sort order base age throughput metric manager manager also maintain state information map pending query queue age query queue incoming query assign queue batch object queue highest age throughput metric send result join join select appropriate hybrid join strategy request data bucket cache bucket cache either read exist bucket memory execute range query ask bucket server use simple least recently use policy cache replacement finally join separate object succeed spatial join parent query apply query c predicate ship result next site show figure three adaptive aspect age throughput metric discuss technique revisit parameter selection respect detail section five parameter selection base query throughput versus response time curve illustrate effect adjust give saturation condition two curve show figure four low one query per second high five query per second saturation condition sample performance normalize maximum throughput average response time value currently determine curve manually vary saturation use representative component user tolerance threshold indicate much degradation query throughput permit figure four show ten low high saturation respectively average response time minimize without twenty maximum achievable throughput client query query queue object manager schedule work bucket cache batch query bucket join result figure three architecture four six eight one response time normalize maximum query number figure four performance curve saturation figure five top ten bucket reuse x e n e k c b ten eight six four two zero eighty sixty forty twenty l k r w f c n e q e r f e v c l zero zero low saturation high saturation ten fifty bias zero threshold fifty ten x e z l r n p h g r h one nine eight seven six five five experiment implement query federation instrument performance use derive web log user query evaluate range adjust age bias age throughput metric measure bene batch process compare evaluate query independently io share arrival order also compare round robin batch process solution propose perform sequential batch process service bucket id order oblivious length queue age request fair request receive attention regardless bucket join compare exist approach evaluate query exclusively spatial indices approach seven time even evaluate sloan digital sky survey six archive experiment perform server server memory data table strip across fifteen set mirror disk partition primary fact table perform object bucket result nearly bucket size also ush server buffer bucket read cache bucket manage independently server cache size twenty bucket experiment finally derive use compute throughput twelve second thirteen respectively current con employ query trace consist long run query include terminate prematurely due time limit impose system focus data intensive long run query allow us conduct forward look study remain faithful science query may join two archive vast majority occur archive measure performance intermediate result list object query allow us replay query work perform assume ow memory large accommodate bucket index figure six cumulative bucket result query resolve ow write queue disk leave future work figure five illustrate suitability batch process schedule top ten bucket reuse frequently access query moreover query overlap data access close temporally bene cache another perspective show figure six term total size measure number object bucket namely two bucket capture fifty remain bucket make tail susceptible starvation result compare query throughput response time various schedule vary value age throughput metric age bias zero denote greedy approach schedule bucket order maximize query throughput bias one schedule bucket arrival order base age request figure seven show twofold improvement throughput greedy approach increase performance drop less pronounce much bene derive batch process query permit io share performance similar one neither approach account contention measure size queue figure seven b show average query response time variance across various exhibit worst response time even compare starvation prone greedy twenty fifteen ten five ten nine eight seven six five four n c e e r e q p h g r h e r h n e z l r n e e n p e r bias zero fifty ten bias zero fifty ten n c e e r e q p h g r h n c e e e n p e r g v four three two one ten fifty zero one thirteen seventeen five saturation throughput schedule algorithm vary age bias throughput response time variance ten fifty zero one thirteen seventeen five schedule algorithm vary age bias b response time saturation b response time figure seven performance schedule algorithm figure eight parameter selection base saturation zero io overhead evaluate query independently lead higher queue time response time greedy approach nearly twice purely query every object since object may overlap bucket small queue query may linger inde bucket schedule bias toward age lead incremental response time expense query throughput moreover exhibit relatively high average response time recall schedule bucket increase id order rather age request thus query access data close recently schedule bucket respect id sequence service prior query arrive away id sequence translate high delay certain query worst case force query wait entire rotation figure eight explore performance query throughput response time saturation change vary age bias performance gap throughput figure eight widen considerably saturation change lead throughput ignore arrival order decrease age bias however response time performance gap figure eight b remain fairly insensitive change saturation due hybrid join strategy namely strategy query suffer higher wait time saturation increase offset query throughput performance strategy exhibit lower throughput schedule query access less contentious data may present cache offset io cost cache miss query evaluate use spatial indices avoid scan entire bucket thus rely spatial indices higher reduce overhead schedule maintain low wait time practice low saturation condition increase attractive accept small drop query throughput lead large query response time vice curve figure eight help guide selection consider saturation five query per second current zero increase lead twenty drop throughput twenty reduction response time attractive however increase saturation become attractive twenty reduction response time seven throughput fact increase become progressively attractive less saturation one saturation reduction response time achieve seven drop throughput increase zero one depend user make less aggressive use tolerance threshold section four six discussion describe batch service query batch process paradigm implement evaluate astronomy query query exhibit highest degree data share goal maximize query throughput balance throughput orient approach need low query response time interactive use age throughput metric metric allow tune batch process base saturation user several open future work generalize improve currently assume queue memory future plan address ow query need store disk fetch memory process query determine queue join bucket migrate match pair queue bucket memory evaluation note query may quite large include intermediate result sit need join current site also plan extend age throughput metric provide completion order guarantee ideally interactive query quickly risk starvation prior query thus want provide robust guarantee depreciate age bias longer query regardless arrival order better support interactive batch environment plan provide theoretical treatment batch process adapt recent work one formalize problem data share among map task group job batch base access sequential scan large share among many simultaneous job possible solution also include age policy prevent starvation however direct application query schedule cult several reason example model sensitive job arrival rate correspond stationary process solution poorly suit steady state problematic serve continuous stream query representative available nonetheless incorporate arrival rat avenue plan explore use different schedule policy batch job system share scan al one rely least sharable policy job bene future job execute contrast contentious data policy expect perform better c one reason unlike buffer queue intermediate join result require amount storage give many query already io bind accumulate large amount intermediate result memory write disk allow batch size later undesirable throughput metric address problem service contentious region reduce buffer cache also bene contention base environment share large memory one scan time analogous cache size single bucket however keep multiple bucket memory mean future query reference contentious data bene reuse incur additional io surprisingly compare zero policy purely one find forty seven request service cache respectively may evict contentious data maintain completion order plan con advantage cache less buffer future work finally integrate batch process distribute query process environment present additional challenge solution allow individual sit cluster federation batch query independently clear whether schedule across multiple sit bene latter require every site aware data access query query visit join sit advantage different sit query execution order maximize batch size sit amortize io cost query set least sharable data policy make sense site delay process bucket anticipate pending another site access bucket applicability beyond astronomy c bene batch process large obvious millions query process month measure query throughput crucial performance metric argument apply many evolve data set spatiotemporal thirteen query subdivide work operate static nonoverlapping data partition however regardless application batch process must mindful diverse user batch starve interactive query author wish thank contribute substantially vision technical detail work also wish thank ani tamas rest sloan digital sky survey team university assistance astronomy data work support part award seven reference one p c schedule share scan large data file two r fay schedule c work high performance compute cluster three j j r morris path metric wireless rout four j dean data process large cluster five web service six r c spatial hash join algorithm suit small buffer size seven r continuum disk schedule computer five one eight j gray zone algorithm find spatial technical report research nine j gray rubber meet sky bridge gap science data engineer bulletin four three eleven ten n kaiser h b burke h k chamber chun j k b hunt r r g e p pickle p h j j wick large synoptic survey telescope array eleven f v de scalable optimization exploratory query federate c twelve p index science archive thirteen li e wan yang c r burn g public turbulence cluster study evolution velocity turbulence journal turbulence nine one fourteen lo c v spatial record two fifteen g j f c j nonblocking parallel spatial join algorithm sixteen malik r web service approach federate seventeen j relational join data tertiary storage eighteen c b reed r pig language data process nineteen w n li batch back serve data web twenty j patel j partition base join query process tertiary memory sloan digital sky survey sterling j becker j e c v packer parallel c computation j gray p malik j c j public access sloan digital sky server data b l g r ganger n schedule modern disk drive h c yang parker relational data process large cluster j query batch paradise approach process query raster image