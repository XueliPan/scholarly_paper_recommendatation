adaptive cache allocation distribute storage department computer science engineer state university university park abstract increase complexity continuous increase data set size combine slow disk access result io become performance bottleneck several ways improve io access one promise approach use different layer io subsystem cache recently frequently use data number io request access disk reduce different layer cache across storage hierarchy introduce need efficient cache management scheme derive maximum performance benefit several storage cache management scheme focus optimize aggregate hit rate overall io latency agnostic service level also exist work focus different cache replacement manage storage cache discuss different exclusive cache context cache hierarchy however orthogonal problem storage cache space allocation multiple hierarchy storage cache multiple storage remain open research problem work use combination latency model linear program model proportion storage cache dynamically among multiple across different level storage hierarchy across multiple provide isolation satisfy application level algorithm improve overall system performance significantly subject operate storage management work support part grant permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee ten june japan copyright general term management design performance experimentation storage cache io one introduction improve io performance critical maximize performance parallel emerge storage compute typically organize cluster nod equivalent file server server context enterprise class request data cluster storage connect network issue stream io request underlie io turn request data multiple storage significantly enhance availability reduce operation cost general storage architecture although commonly use typical storage compute domain enterprise storage domain show figure one case compute domain execute compute nod issue io request forward io io accommodate first level storage cache forward request underlie storage storage accommodate second level storage cache typically io storage share among concurrently execute similarly enterprise domain forward io request issue execute web underlie storage server cache first level storage server cache second level share among problem manage share compute domain isomorphic one enterprise interference among compete resultant unpredictable system behavior critical issue need address share across different layer hierarchy exist manage storage cache fifteen fourteen consider however many storage compute compute execute concurrently compute nod web execute web io request forward io io first level cache cache commodity network second level cache io server io server io server io server storage storage server storage storage server storage storage server storage storage server e c p e e e g g g r r r l l l c c c g g g l l l n n f f v v p p r r e e v v r r e e e e g g r r n n n h h h b b b n n n network io request forward forward file first level first level cache second level cache storage storage figure one architecture storage architecture leave represent typical storage one right represent typical enterprise storage multiple storage show figure one propose recent literature consider data block access one storage server cache use application hint partition cache presence multiple achieve io response time similarly recent work nine focus maximize io performance scheme oblivious provide certain io performance guarantee however utility compute service orient service provider may set different different encapsulate guarantee io performance reliability manageability metrics compute domain like weather prediction demand performance guarantee io subsystem environment would require storage system able allocate share proportionally cater level performance guarantee demand application develop many replacement manage storage cache four six twenty twelve ten arc eighteen replacement design single server recent work fifteen storage cache management use replacement base access pattern propose distribute io cache however problem storage cache space allocation orthogonal replacement policy use manage block within allocate space propose storage cache allocation algorithm call address problem cache partition distribute storage involve cache io first level multiple share storage server cache second level allocate partition storage cache space among dynamically let us underlie replacement policy manage individual block within allocate space figure two show spectrum allocation replacement different allocation rep resent figure range uncontrolled storage cache space share among without explicit partition dynamically partition cache space multiple level among include fair share equally partition share cache multiple level among similarly spectrum replacement may include previously propose replacement policy range least recently use scheme work inclusive storage cache hierarchy replacement work well exclusive storage cache like demote least recently frequently use scheme point space valid represent combination allocation policy replacement policy manage storage cache paper make follow first build io latency model level storage cache predict storage cache space require compete meet specify io latency requirement use latency model predict cache space allocate application first level io server cache total cache space allocate application across storage form second level cache specify constraint satisfy use linear program determine cache space individual storage second level regular algorithm record observe io latency current cache size allocation application able repeat process refit io latency model account new observation cache account new value thereby capture dynamic phase change exhibit present experimental result obtain use set demonstrate storage cache partition strategy accomplish performance insulation among multiple compete well improve effective utilization multiple level share storage cache space thereby improve overall io performance continuously provide service level demote n n e e e e c c p p e e r r l l c c l l p p uncontrolled uncontrolled demote demote demote fair share fair share fair share uncontrolled allocation policy figure two two dimensional space cache replacement cache space allocation guarantee two background motivation system model role multiple level storage cache critical target emerge number io nod disk representation io stack enterprise compute give figure one assume io server serve multiple use paper target system two level cache io host first level storage host second level cache io storage connect network connectivity could complete io server access storage partial io server access subset available storage general scheme work connectivity io storage storage connect physical storage system like disk array hold data manage io stack io server cache storage server cache disk cache network disk dynamically share among various lead possible destructive among important note io call application level go general across multiple layer stack finally reach disk addition io call originate different compete share stack therefore proper management share across io stack important give io stack share reside potentially layer behavior achieve service level difficult problem cache management scheme enable resource management across different determine minimum amount level achieve require application distribute additional cache space proportion project gain maximize value global interapplication metric partition scheme envision incorporate part server dynamically receive information compute best allocation storage cache space application level also calculate best possible distribution cache space across multiple storage server provide hint storage server system compute cache partition size important note approach general extend share resource application metric specify service level variety approach use past specify al propose use specification call parameter value range zero one cache absorption rate hit rate achieve application within share available storage server cache al propose alternate mechanism service provider first execute application isolation entire infrastructure execute share available infrastructure among order determine possible best utilize service provider maximize work indicative maximum degradation tolerable term average io access respect average io fair share aggregate cache space level ie equal partition storage cache space level instance application average io latency ten hundred io access fair share case specify five maximum tolerable degradation service level guarantee provide application term mean io latency would maximum hundred io access note specify term fair share cache space guarantee service level always meet irrespective load system although one may argue specification trivially adopt static fair partition ensure always guarantee scheme would optimize global performance also believe minimal performance guarantee necessary performance optimization scheme purely performance orient scheme target global performance metric may harm application performance beyond tolerable limit therefore objective maximize global performance metric without affect performance single application beyond tolerate specify requirement alternatively one think specify absolute value performance maximum tolerable average latency however order guarantee absolute minimum performance need admission control policy scheme extend admission control policy estimate amount remain satisfy application compute information motivate example present motivate example highlight need storage cache partition experiment four detail well detail description experimental platform give later section four experiment two io first level four independent uncontrolled c n e l e z l r n figure three normalize io observe different scheme execution storage second level two share first io server two share second io server storage second level share four conduct experiment follow four different scheme independent uncontrolled independent scheme application execute alone entire system hence share available interference application uncontrolled scheme four execute entire system time without enforce partition share storage cache space scheme partition first second level storage cache use miss ratio curve describe respectively level share figure three present result io latency normalize respect fair share cache allocation level cache see io latency achieve independent scheme best possible value system provide individual specification maximum tolerable degradation five average io latency fair share cache allocation level cache use experiment see result uncontrolled scheme scheme always violate specification scheme meet specification case violate specification remain manage second level lead improve io compare manage first level uncontrolled scheme general except cost miss second level disk access latency much higher cost miss first level ie access storage however case storage cache hit rate io first level high management first level overcome benefit manage second level hence case manage first level give better result compare uncontrolled second level scheme though still meet specify result motivate need alternate scheme manage two level storage cache space rest paper present evaluate scheme partition level storage cache fashion service level agreement step eleven application characterization step build latency model use build latency model use statistical regression step twelve fulfillment step determine step twelve fulfillment step determine minimal two level cache necessary satisfy step thirteen infeasible partition filter step eliminate overrule available cache space step fourteen fair optimization step allocate remain cache space maximize fair metric linear program module distribute cache allocation second level among multiple storage multiple storage l l l v v v r r r e e e n n n n n n e e e e e e c c c r r r f f f n n n e e e r r r e e e v v v e e e n n n k k k c c c b b b e e e e e e f f f c c c r r r c c c c c c n n n c c c e e e r r r p p p e e e v v v r r r p p p one one p p e e e e e g g g r r r l l l e e e v v v e e e l l l l g g n n n n r r p p e e h h c c c c two p e e e g g r r r r e e v v r r e e l l g g g n n n n n n r r r p p p e e e h h h c c c c c c figure four high level operation scheme issue request io server turn service storage three storage cache partition overview storage cache partition scheme consist two main step high level show figure four first step consider partition allocate storage cache space two level cache io storage second step partition allocation application across available storage cache show figure four step one divide four application characterization fulfillment infeasible partition filter fair optimization describe step detail follow section cache partition size determine application io server cache storage server cache enforce interval time call enforcement interval every enforcement interval algorithm record observe io latency current cache size allocation application give feedback able repartition cache thereby capture dynamic phase change exhibit storage partially connect application service subset k different storage st one st two st k fully connect application service k step one cache partition cache partition scheme use divide four step first step call application characterization step build io latency model function storage cache use statistical regression second step call fulfillment step determine minimal two level cache necessary satisfy infeasible partition filter step eliminate multiple overrule figure five application characterization model use fulfillment step io latency model maintain every application model update new cache level cache correspond io latency value every enforcement interval available storage cache share multiple fourth final step fair optimization allocate remain cache space application way maximize system performance measure fair metric step eleven application characterization approach employ prediction module help us decide minimum amount cache space io storage satisfy application specifically use statistical regression build prediction model model io access latency application function total cache space require level statistical regression nineteen establish tool find best curve fit set measure value use method least square find regression curve minimize sum square prediction important property regression best fit curve compute set measure value value accurate prediction however start predict value necessary learn module build io latency model use least square method use certain number sample point whole process partition determine end fair optimization step enforce newly measure io latency value enforce cache use update model way algorithm iteratively update application latency model every enforcement interval order experimentally gather sample point increase accuracy prediction figure five give sample io latency surface particular enforcement interval build application use curve one predict set io server cache storage server cache value satisfy application note since curve update use recently observe io latency value ie capture dynamic phase change consequently make better step twelve fulfillment every enforcement interval io latency model build application characterization step service level objective application use calculate assure io latency io application recall indicative maximum degradation tolerable average io respect io la b point intersection plane perpendicular latency axis latency io model represent point fulfill application fair share cache space io first level storage second level io air io latency application allocate fair share cache level storage cache assure io latency even presence io application would io io air use surface model calculate io obtain several point lie curve intersect imaginary plane perpendicular io latency axis value io ie cache level storage cache hierarchy satisfy specify depict figure five b cache allocation point form fulfillment set application remain point interest point either satisfy io io belong large set point select point set may yield fair global cache allocation multiple execute system therefore fulfillment set application contain point intersect curve value io step thirteen infeasible partition filter theoretically cache fulfillment set application satisfy requirement application however practice consider manner share storage cache io storage derive available cache space set possible available cache space consider share among predict satisfy filter satisfy available cache space call remain set feasibility set example two share io server cache feasibility set contain entry meet sum io server cache exceed available cache space eliminate step step fourteen fair optimization although point feasibility set choose determine cache first second level criteria use select point many feasible important determine free cache space remain level satisfy specify thereby determine opportunity optimize global performance metric fair cache capacity require satisfy allocate two one meet cache spar two meet cache spar second case need distribute remain cache space among allocation feasibility set compute distribution remain cache space level remain cache space level either equally distribute among distribute among proportion project gain application exhibit term reduce io latency allocation cache level use second approach since objective improve system performance satisfy metric five metric use quantify io latency multiple use system metric relative base scheme define harmonic mean per application io latency improvement respect base scheme fair share f scheme n n number note fair metric indicator overall improvement io across another key property fair metric increase application io latency improve without hurt possible achieve io latency lower cache allocation definition base scheme fair one higher value fair metric indicate better improvement io latency well better fairness among therefore obtain possible partition cache multiple level entry feasibility set utilize available cache apart guarantee meet compute predict fair achieve set io latency model choose partition derive highest fair ensure improve fair achieve best possible extent utilize available cache space level scheme base algorithm one detail different step partition storage cache size determine io server storage server satisfy application give respectively unused cache space remain satisfy distribute among proportion project gain application determine total cache space allocate application io server storage server storage cache hierarchy enforce determine cache size io server application directly assume system model application cache data one io server first level however distribute application among multiple storage second level next subsection describe cache partition detail algorithm one level partition st scap number number io cache capacity io number storage st scap cache capacity storage specification application goal maximize fair maintain latency application bound within application application characterization step onetime one initialize st bootstrap bootstrap st enforcement interval one application characterization iterative measure io st fulfillment step air st air st io air get latency surf air st air io io air f set point lie plane intercept surf eight infeasible partition filter step filter infeasible partition possible fulfillment set application eliminate require available aggregate cache either level get feasibility set fair optimization step st application feasibility set j p distribute accord project gain among j p p p st st scap j p distribute accord marginal gain among st scap j p st predict fair partition select overall partition achieve maximum fair p p eight eight step two cache partition second step partition scheme see figure four involve cache partition total cache space require application second level st st st obtain first step algorithm distribute across available storage server cache use linear program base model formulate problem system linear follow manner suppose server st server j total storage cache capacity st partition server cache st server j cache allocation st application distribute across k follow st share application table one important experimental parameter value number io number storage number io server cache size storage server cache size disk capacity disk disk seek time enforcement interval cache block size replacement policy io server cache replacement policy storage server cache service level objective two four four one one five thirty sec sixteen five cache st server j j range one k also total cache use concurrently run server st server j less equal total available cache st ie st solver determine every share application cache st server j use mention enforce determine cache partition size every enforcement interval cater storage cache important note solver distribute cache application available server cache uniformly possible single server overload four measurement analysis experimental setup build storage cache simulator support multiple storage storage cache thirty accurate disk simulator simulate disk model possible measure individual cache hit rat io access latency io server cache storage server cache interface linear program module integrate setup three solver interior point linear program package simulator use application trace collect use modify version trace record information io access type time file identifier io size execute four compute nod use four large scale trace follow domain parallel io version block base code use implicit algorithm solve compressible perform large read write use basic io perform file use class b version output data flexible io develop scalable io project perform interleave random read write single file application operate single share file maximum write maximum read io use tool non contiguous io performance two allow user specify variety noncontiguous io access pattern verify output finally application test performance noncontiguous access also use four large scale trace follow enterprise domain transaction process application trace involve mix five different concurrent sixteen collect trace decision support exercise different query concurrently modify query involve huge volume io read write request business report decision support similar additional base advance knowledge query consist suite business orient query concurrent data glimpse stand global implicit search provide index query scheme file use search text string directory seventeen scale operate data set range choose cover large spectrum data intensiveness exhibit vary data pattern storage cache locality application specific average io latency requirement specify default configuration platform consist two io four storage execute four storage cache io give aggregate share cache capacity first level storage cache storage give aggregate share capacity second level configuration two share io first level four share storage second level system time cache allocation make enforce interval enforcement interval default value thirty sec use sixteen cache block experiment study behavior warm cache execution time set five table one list default value major simulation base scheme independent scheme entire infrastructure available application execute independently hence share io latency scheme provide upper bind scheme achieve fair share scheme aggregate storage cache divide equally amongst compete application use assign allocation thereby provide isolation note static allocation scheme change cater vary resource demand time determine reference either independent scheme fair share scheme use fair share scheme guideline specify experiment scheme server cache share among amount storage cache use application bind aggregate cache capacity uncontrolled partition independent uncontrolled independent uncontrolled c c c c c n n n n n e e e e e l l l l l e e e e e z z z z z l l l l l r r r r r n n n n n twelve eleven eleven one nine nine eight seven six six five four four thirteen twelve twelve eleven one nine nine c c c c c n n n n n e e e e e l l l l l e e e e e z z z z z l l l l l eight r r r r r n n n n six six c c c c c n n n n n e e e e e l l l l l e e e e e z z z z z l l l l l r r r r r n n n n n twelve eleven eleven one one nine eight seven seven six six c c c c c n n n n n e e e e e l l l l l e e e e e z z z z z l l l l l r r r r r n n n n n eleven one nine eight eight seven seven six six glimpse glimpse comparison various scheme scheme term io b comparison various scheme scheme term io enterprise normalize performance complete connectivity io b normalize io enterprise execute complete connectivity figure six io latency different comparison different base scheme storage system system enforce partition share storage cache level although simple scheme flexible accommodate traffic encourage share buffer data often plague problem interapplication lead unpredictable application behavior lead lack performance guarantee first level scheme learn model io latency allocation storage cache io storage cache second level ie storage share second level scheme learn model io latency allocation storage cache storage storage cache io ie first level share access note last two scheme special case involve cache partition step compare period enforcement interval roughly twenty every enforcement interval thirty second correspond overhead seven overhead cache partition come linear program step also small since linear program problem relatively simple specifically cost ninety every enforcement interval average three overhead note simulate entire framework result present section include performance analysis perform experiment compare scheme respect base scheme describe figure six plot io latency normalize respect fair share case assume five degradation respective fair share storage cache space present result enterprise domain see base scheme general violate specification case uncontrolled partition scheme almost figure seven normalize io different replacement bar graph represent notation x allocation strategy replacement policy never satisfy specify however case glimpse result obtain uncontrolled partition scheme satisfy mostly data set size glimpse small enough fit two level storage cache use experiment hence io latency value sensitive different scheme use scheme meet specification case glimpse violate specification general manage second level lead improve io compare manage first level uncontrolled scheme probably miss second level storage cache higher penalty term access latency compare miss first level cache however case storage cache hit rate io high management first level overcome benefit manage second level scheme combine advantage scheme perform significantly better term average io latency application also satisfy specify constraint apart objective metric ie fair metric also use overall io latency metric define sum average data access access system quantify achieve scheme achieve better average io latency four compare specify service level objective average overall io latency metric io latency value achieve scheme close independent execution individual possible addition compare fair share case see improvement fair metric case improvement case enterprise scheme storage cache space allocation scheme orthogonal replacement policy use manage storage cache cache space allocation also work presence order measure sensitivity scheme replacement policy na table two connectivity matrix storage glimpse hierarchy measure scheme two base scheme fair share uncontrolled least recently use replacement algorithm inclusive cache level demote scheme use exclusive cache level first level least recently frequently use replacement algorithm second level result give figure seven obtain system model storage server service request see figure seven demote scheme perform better level inclusive hierarchy general true allocation scheme use whether static fair share scheme dynamic scheme also observe scheme outperform fair share uncontrolled partition scheme replacement scheme however choice good replacement policy exclusive cache crucial observe fair share scheme exclusive cache outperform scheme inclusive cache although better policy overall outperform fair share uncontrolled partition base scheme respectively demonstrate scheme apply generic system architecture figure eight present result compare scheme respect base scheme service subset storage second level connectivity storage show table two result also indicate scheme work well partial connectivity well ie satisfy achieve improvement fair metric compare fair share scheme enterprise respectively sensitivity analysis sensitivity cache size impact change io server first level cache size performance scheme study result present figure nine see figure scheme satisfy application irrespective io server cache size per server figure nine enterprise figure nine b notice increase io server cache size generally lead better performance due higher amount cache remain satisfy note specification relative therefore equal five tolerable degradation fair share give amount total io server cache overall io latency scheme fair share case one io server cache glimpse normalize performance partial connectivity io b normalize io enterprise execute partial connectivity figure eight normalize io different replacement bar graph represent notation x allocation strategy replacement policy c n e l e z l r n twelve eleven one nine eight seven six five four c n e l e z l r n one nine eight seven six c n e l e z l r n twelve eleven one nine eight seven six five four one one nine nine eight c c c c c n n n n n e e e e e l l l l l e e e e e z z z z z l l l l l seven r r r r r n n n n six six glimpse sensitivity scheme respect io server level one cache size storage b sensitivity scheme respect io server level one cache size enterprise storage figure nine sensitivity different change cache size io server case respectively case enterprise also experiment change storage server second level cache size performance scheme present result due lack space summary result show scheme satisfy application wide range storage server cache size improve overall io latency significantly overall io latency scheme fair share case respect cache size one two respectively case case enterprise sensitivity specification figure ten show sensitivity scheme specify requirement note specify higher tolerable degradation performance fair share case fair optimization step become dominant factor decision final partition choose would many feasibility set end previous step infeasible partition filter step observe huge improvement performance derive maximum benefit one five ten one five ten c n e l e z l r n one nine eight seven six c c c c c n n n n n e e e e e l l l l l e e e e e z z z z z l l l l l r r r r r n n n n n one nine eight seven seven six six glimpse sensitivity scheme respect different specification storage b sensitivity scheme respect different specification enterprise storage figure ten sensitivity different different additional cache figure ten ten b cost performance albeit bound specification cache insensitive figure ten ten b hand stringent specification one tolerable degradation almost achieve similar benefit order study effectiveness track different different also experiment two share single io server two storage specification set maximum tolerable degradation two set eight io latency time scheme two show figure eleven observe individual always respect ie normalize io latency always less always less sensitivity enforcement interval experiment use default value enforcement interval thirty second enforcement interval important design parameter since decide often scheme run adapt dynamic behavior however highly application specific select smaller phase change require dynamic response also enforcement interval small lead repeat result incur high order study parameter quantitatively conduct sensitivity experiment scheme vary enforcement interval detail experiment notice significantly broad range value enforcement interval twenty second seventy second lead comparable benefit five relate work share cache management storage recently many explore share cache partition design attempt avoid conflict among multiple eleven example eleven follow dynamic partition principle ie server buffer dynamically allocate accordance work set size argon cache partition algorithm use simulator predict cache absorption rate c n e l e z l r n eleven one nine eight seven six five four three two one zero zero ten twenty thirty forty fifty sixty seventy eighty ninety execution progress figure eleven io latency time application specify different specification thirteen seven partition share hypothetical cache size file system cache multiple process detect access pattern common characteristic special treatment block access belong one server cache service level guarantee share server cache eight fourteen describe architecture share storage proxy cache provide hit rate compete class use feedback control one describe performance management scalable file system transform io guarantee component data path client server exist provide performance guarantee storage throttle data traffic single storage node thirty many propose manage server cache presence multiple propose manage multiple level storage cache use different replacement base access pattern use application hint partition cache achieve io response time multiple however discuss data share multiple also provide guarantee service level system comparison propose cache partition scheme determine best partition size storage architecture approach also guarantee service level term application specify io latency problem base cache partition distribute storage involve multiple level share cache address six distribute io environment storage cache generally organize cache reside multiple typically share multiple may destructively interfere scenario storage cache allocation involve proportion storage cache among dynamically across different level hierarchy across multiple concurrently execute satisfy fair metric maximize work provide algorithm partition aggregate storage cache space among seventeen glimpse tool search entire file eighteen n arc low overhead replacement cache fast nineteen w second course statistics regression analysis prentice hall twenty e j p e g page replacement algorithm disk buffer management data h al use analyze io performance tech report national energy research scientific compute center g al dynamic partition cache hierarchy share data center g al dynamic resource allocation run virtual storage fast g e l new memory monitor scheme schedule partition e g r ganger argon performance insulation share storage fast wang merchant schedule distribute storage fast p wong parallel io version tech report computer corporation advance division research center wong j cache make storage exclusive b g r ganger n simulation environment university michigan technical report thirty j provide quality service support file system g factor k li multiple cache g factor karma replacement cache fast p v j dynamic track page miss ratio curve memory management j f replacement algorithm second level buffer cache compete distribute application cache allocation across application service goal maximize global performance metric without affect performance single application beyond tolerate specify requirement future work plan evaluate design change number dynamically certain measure effect performance seven reference one al performance management scalable distribute storage data storage workshop two ching al evaluate io store structure scientific data three j al linear program four dan approximate analysis fifo buffer replacement scheme five l k al find single number indicate overall performance suite news six lee al existence spectrum subsume least recently use least frequently use seven c r butt c program counter base pattern classification buffer cache eight p r provide storage system cache nine k buffer cache management consistent access locality quantification ten x efficient low recency set replacement policy improve buffer cache performance eleven x file block placement replacement protocol effectively exploit hierarchical locality buffer cache twelve low overhead high performance buffer management replacement algorithm thirteen j kim al unify buffer management scheme exploit sequential loop reference fourteen b ko k lee k scalable service differentiation share storage cache fifteen x li al cache management use write hint fast sixteen r implementation global performance measurement computer