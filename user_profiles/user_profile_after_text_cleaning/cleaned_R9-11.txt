seventh international conference data mine seventh international conference data mine seventh international conference data mine seventh international conference data mine seventh international conference data mine detect fracture classifier performance department computer science engineer university dame v abstract fundamental tenet assume many classification presumption train test sample draw distribution data stationary distribution assumption entail past strongly indicative future however real world many factor may alter one true model responsible generate data distribution significantly subtly violate stationary distribution assumption traditional validation scheme holdout become poor performance classifier thus become critical discover fracture point classifier performance discover divergence paper implement comprehensive evaluation framework identify bias enable selection correct classifier give sample bias thoroughly evaluate performance within bias consider follow three miss completely random akin stationary miss random miss random latter reflect canonical sample selection bias problem one introduction consider fundamental task data mine give train sample data formulate model optimize measurement criteria typically accuracy model apply yet unseen set test depend nature data practitioner might select model generate decision tree calculate nearest neighbor support vector machine typically empirical validation approach use tenfold validation train set structural risk minimization might use dimension model space know nineteen assume expression one true model data within set machine possible express classifier proper class occurrence rate map correctly unseen example three suggest reasonable performance metric optimize one true model model yield better performance unfortunately task make several fundamental namely stationary distribution assumption machine learn literature distribution assumption data mine community definition one stationary distribution assumption state every train set instance test set instance identically independently draw common distribution q x previous work four five six already introduce instance violate assumption injection bias data case even one true model may become irrelevant apply future instance data distribution change substantially unpredictably however identify two issue within context problem first identify change performance attributable bias second detect presence degree bias two data generally try determine generalization error base train set set order determine generally perform best however theoretical empirical limit presence distributional structural risk minimization bind establish function dimension make critical stationary distribution assumption thus imply bound may hold contain distribution drift five empirical comprise tenfold bootstrap generate empirical measure generalization performance classifier obvious measure limit generate validation set derive similar distribution train set measure mean reflect effective generalization presence change test set present challenge establish feature space information practitioner become aware bias data equip make inform classifier take additional bias correct step use four different nine different assess utility framework thus key question address paper detect fracture predictive test set b detect feature responsible introduction bias test set would also like point framework use construct sensitivity index different train one simulate different bias validation observe variation performance bias accordingly generalizable classifier choose demand application domain remainder paper divide follow section two define bias treatment paper section three describe use paper section four present case study performance presence bias section five identify bias may detect data sample also provide thorough description statistical use work section six draw work present paper two bias data sample selection bias four five nine provide primary vehicle establish violation stationary distribution assumption suppose consider x draw independently distribution domain x x feature space class label space binary space variable indicate example train one train set zero operate environment follow case emerge regard dependency x nine fifteen definition two miss completely random sample selection bias occur independent x thus state p p one thus sample bias depend factor totally independent feature vector x class label imply train test set derive distribution stationary distribution assumption theoretically hold include paper completeness definition three sample bias miss random mar depend x conditional x independent thus may state p p therefore sample feature dependent sample figure one propose bias identification response framework landscape performance across different data assumption thus paper focus follow critical relevant application knowledge discovery data mine process detection deviation predictive estimate test set compare validation set b identification cause drift distribution feature responsible test population change believe issue pervasive deployment evaluation data mine contribution paper outline statistical framework depict figure one identify fracture predictive bias feature space consider change data distribution inject sample selection bias approach problem two stag stage one detect whether statistically shift predictive propose use test seven isolate bias distribution generate learn algorithm note test unsupervised aware actual test set class thus compare posterior probability validation set test set test indicate indeed shift predictive distribution practitioner may use series unsupervised statistical measure base test eleven twenty distance two indicate presence absence bias feature three estate oil page phoneme segment twenty twelve six ten sixteen five nineteen table one use study column indicate number give train validation test vary accord feature vector x independent class label situation occur test set one know feature definition four miss random bias occur independence assumption x scenario essentially introduce sample selection bias distributional shift may unknown one may access feature lead censor may state tautology p p thus particular feature x distribution observe train set different observe test set p one p zero establish bias follow use remove fifty test set remove uniformly random also use mar remove top fifty value along one feature first sort base one particular feature remove top top fifty condition particular feature case remain select feature mask unknown incorporate bias substantial portion distribution remove mask feature unknown miss able inject latent bias generate separate mar bias test feature within report result within paper aggregate indicate average case bias introduction fairness equivalent number sample generate thus result similarly aggregate paper use several common sixteen summarize table one vary extensively size distribution offer many different page phoneme segment come machine learn repository sixteen oil contain set oil slick image base live data twelve represent real world finance data may contain natural bias train test sample come different come study medical domain estate consist state series compound national cancer institute yeast anticancer drug screen eight experiment conduct use decision tree naive bay neighbor k five support vector machine classifier form probability estimate model decision tree train probability estimation tree pet seventeen neighbor form predictive proportion class set nearest neighbor one use default form probabilistic naive bay naturally form restrain default establish even four effect bias classification various factor responsible introduce distributional test set feature space could bias number cause classifier generate inappropriate predictive case bias occur result collect separate govern independent feature class probability density function within single distribution example measure one species bird find two independent tropical temporal distance may also incorporate bias rule govern data may change slightly drastically time bias occur various market credit score target population change time present case study across different demonstrate effect bias test set use test statistically validate whether test set start significantly differ validation set bias introduce discuss test present result l e v p n e r f one eight six four two zero tree bay base figure two test across represent average test test statistical test develop economist fourteen test use analysis variance rank test assume data come continuous distribution apart possibly different due column row effect mutually independent example test evaluation n use k weld torch ensue weld rat quality one torch produce better weld x matrix place sample store across row r rank within block ie within row average rank per sample calculate r k one k number sample n represent number sample rank calculate follow two twelve k one k j k one two two associate null hypothesis column essentially low indicate likely case null hypothesis void apply begin first randomly partition fifty train twenty validation thirty test classifier learn correspond train set apply natural validation test sample result probabilistic set form base result stationary distribution assumption validation test set derive distribution introduce three bias mar follow consider feature data set time inject correspond amount bias discuss previous section result many test set number feature bias combination allow us avoid dominance result one feature particular apply learn train set generate bias test set result probabilistic form bootstrap validation test set probabilistic calculate test use test null hypothesis statistically difference validation test set figure two show result give amount bias average application particular bias feature thus reflect summarize give bias classifier convention figure domain show different test bias include base stationary distribution bias cluster four line represent different show range across classifier decrease hypothesis strongly reject figure two show compel trend run along observe range drop go towards heavily bias test set confirm premise suffer nonstationary among decision tree neighbor seem less sensitive distributional bias compare naive bay since reflect range observe lead complete failure predictive estimate approximately zero nevertheless within confidence fail strong demonstration fragility change hence form main motivation work l e v p l l l w k r k one nine eight seven six five four three two one zero tree bay base figure three test across represent average note one directly use framework generate bias validation process result immediate evaluation sensitivity different population drift condition nature application one choose classifier consistent perhaps cost accuracy stationary distribution five detect identify bias goal work apply unsupervised detect bias unsupervised require class test data presume unknown time evaluation follow provide test find bias three separate test test section two test nominal feature section test continuous feature section distance section together provide statistical framework show figure one split original data fifty twenty thirty train validation test proportion respectively describe introduce mar onto feature independently form separate test sample generate number test sample result section represent average value find across bias feature reflect average case feature become bias particular analysis generate probability estimate analysis variance rank method test equality population among group seven unlike assumption regard normal distribution make since test also assumption population compare group three four test calculate follow statistic k n one g ni two ni two g number group g overall rank observation j group g n total number average rank within group g average rank calculate two k null hypothesis sample draw population different distribution therefore useful test determine set draw different apply comparison estimate validation set natural test distribution six bias figure three observe calculate set generate compare set validation test set form quite similar expect similarity validation sample test completely randomly bias test sample however substantive difference mar bias set sophisticate bias distribution probability estimate differ significantly drastic change estimate follow fairly substantial change classifier performance also note value capture quite correlate find supervise determine accuracy require know class test figure two information feasible useful practitioner initially train model predict validation test data sample use practitioner may determine whether set come different wise use test section attempt determine bias type isolate bias feature two test two statistical test use compare observe nominal data useful determine whether distribution within categorical data dissimilar two p v ni j n five p v value v represent count value v population p count within population p n p note compare two p two determine test freedom also consider p p one v one six base find value two table use determine test may determine appropriate nominal feature test test often call test determine divergence two underlie probability whether underlie probability distribution differ hypothesize distribution either case base finite sample eleven twenty test particularly useful general method compare two sample detect divergence location shape observe distribution function advantage statistical make assumption distribution data student make however may sensitive distributional meet quite simply make use plot cumulative fraction function suppose two fifteen seventeen fifty seventy ten b fifteen seventeen fifty nine thirty nineteen test begin sort set value independently single plot generate contain value distribution point x calculate percentage instance strictly smaller x hence cumulative fraction data smaller x f n c r f e v l c one nine eight six five four three two one zero three test comparison cumulative fraction plot seven distribution distribution b two x two one zero one three four five six seven figure four example test plot significantly divergent five x figure four contain plot b use test calculate maximum vertical deviation two b figure four indicate case maximum vertical deviation five would like state whether value represent distance calculate two seven number two sample use two two calculation resultant suggest whether difference two may compare desire confidence level within context may use test determine distributional difference train test continuous feature feature nominal two test instead apply determine must iterate feature wise basis tabulate number fail feature use probability better first step table two represent proportion feature fail test bias base result observe page segment contain degree natural bias train test least surprise train test data come two independent set financial information cover separate sequential two year three note actually reduce fail estate oil page phoneme segment base fifty mar mar fifty fifty zero zero zero zero zero zero zero four four zero zero seven five zero zero table two proportion feature fail test confidence estate oil page phoneme segment three zero zero zero zero one zero zero zero zero zero zero zero two zero four zero zero zero zero four zero fourteen six zero zero zero zero nine one three zero zero four three sixteen one three seventeen sixteen zero zero two twenty zero zero eleven thirteen zero zero three one one fourteen seven zero zero three thirteen fourteen zero six table three average correlation feature failure ure proportion somewhat likely unusual value create large maximum random bias remove value reduce separation hence drop feature failure rate remain minimally increase feature failure rate observe systematic bias mar increase feature failure rate substantially indicate test may use simply quite effectively detect bias incorporate two data addition understand degree bias cause feature failure test seek study interaction particular feature fail feature restate feature tend fail independently concomitantly end failure correlation matrix f construct fi j represent count feature j fail concomitantly base count within f correlation calculate pairwise set feature fi j fi fi fi j fi j j fi j eight strong measure two di discount effect sample size average correlation per pairwise comparison report table three value zero three consider little three seven seven strong average correlation quite low zero comparison thus little correlation failure feature failure occur mar introduce spike correlation expect result degree covariance among measure feature thus bias one feature degree incorporate bias relate feature exception trend report zero correlation categorically within test either none feature fail test except failure occur totally random thus demonstrate test may use identify proportion feature significantly different within two data sample difficult bias usually cause greater proportion feature fail addition combine correlation determine feature fail independently concomitantly different bias bias suspect test e n l e b r e v e e r c n n e c r e p e c n r e g n l l e h zero estate oil page phoneme segment figure five distance detect bias leave right set bar indicate relative change distance test sample set predict test operate quick method check existence bias see fairly high proportion feature fail test case thirty feature failure appear reasonable point presume bias observe table two table three report correlation test capable determine group feature tend fail together suppose high correlation failure two feature case one fail one may assume reasonable correlation two feature omit fail feature model train confident succeed feature account much information contain within fail one see table two test struggle isolate individual bias feature thus good method confirm find acutely determine degree feature bias turn distance distance dependent data x x contain p bin bin contain count logical measure x distance x calculate x p two x nine suppose exist two p p occurrence count value b c within population tabulate report table four p p seven zero b zero ten c zero two distance two also refer distance ten measure distributional divergence thirteen conclude linear ordination distance offer better compromise linearity resolution compare similar metrics two metric two distance distance use effectively within ecological domain recommend cluster ordination species abundance data eighteen measure also use mean locate statistical fraud detection insurance apply measure density presume two table four example population data use nine p p two happen maximum possible distance expect p p completely divergent overlap value b c distance apply simply feature individually case nominal feature feature value form separate bin measure difference count value continuous feature treat similarly thirty bin average per feature fifty mar mar fifty fifty estate oil page phoneme segment eight two ten sixty one table five skew average distance per feature distance calculate observe relative change distance calculate base test distribution summarize figure five calculate distance tend relatively low base train test test generate substantial increase distance mar play thus apply distance quite effective differentiate relative level bias sophistication additional interest skew distance produce fact table five demonstrate typically substantial negative skew set distance calculate mean tail value mean indicative data mean would expect normal distribution high distance shift mean upwards cause lower distance value mean normal population note oil violate trend likely due extremely small size general distance enable isolation feature along bias occur experiment note able corroborate find complement differentiation determination bias test useful determine maximal point separation distance refine isolate bias since method compare relative two range march expect order sample random fairly closely resemble train set mar produce highest change feature generate bias observe distributional change reflect distance expect produce result mar since feature bias along hide also reasonable expect level correlation observe feature recommend couple usage test distance isolate bias feature six data mine present challenge drift data distribution train test sample basic assumption past reasonable predictor future may hold different certainly hinder performance learn also demonstrate work thus become critical identify react change data distribution end implement framework comprise family statistical measure show possible detect fracture classifier performance test suite comprise variety data set different base make follow use validation test useful first step practitioner determine difference possible proceed per typical otherwise practitioner use follow test isolate bias feature test ably detect independent feature failure correlation analysis also determine feature quite strong sophisticate bias distance also quite useful readily identify differentiate level bias even factor bias unmeasured bias know high skew distance indicative capable isolate feature generate bias sample believe single statistical measure use isolation rather family measure use conjunction remain confident detect fracture classifier one support vector machine light reference fifteen r little statistical analysis miss ing data new york sixteen c blake c repository machine learn seventeen f provost p rank three tree induction machine learn eighteen c review canonical alternative analysis use distance nineteen j p r framework structural risk proceed annual conference computational learn theory twenty n estimation discrepancy empirical curve distribution two independent sample bulletin university v nature statistical learn springer new york k c doss k bowyer j c w p comparative evaluation pattern recognition detection seven six k j g j p unsupervised outlier detection use finite discount learn knowledge discovery data mine page b learn evaluate sample proceed selection bias conference machine learn two r minimum distance estimation approach use distance handbook statistics volume fifteen page three r data mine metric space empirical analysis learn performance criteria proceed tenth international conference knowledge discovery data mine four page four n v g learn label unlabeled data empirical study across five w fan efficient framework select amongst sample selection bias proceed six w fan b p improve categorization classifier sensitivity international sample selection bias conference data mine seven j statistical inference edition eight l hall b l kier state structure information atomic level molecular graph journal chemical information computer science nine j j sample selection bias error one ten divergence measure signal selection action fifteen one eleven n empirical distribution function dell twelve r machine learn detection oil spill satellite radar image machine learn thirteen p e ecologically meaningful ordination species data fourteen h r analysis variance complex experimental design w h freeman san