international symposium computer architecture high performance compute system computer science federal de brazil state university fireman hawk abstract development high level program distribute become crucial effort computer science several propose expose simplify program useful broad class implement efficiently distribute one system anthill base program model decompose set independent filter communicate via stream anthill achieve high performance allow filter transparently replicate across several compute nod paper present global state manager anthill export simple abstraction manipulate state application filter state distribute transparently among instance filter manager design allow data migration one filter instance another enable anthill dynamically execution time evaluate system use two well know data mine result show framework incur low overhead eighteen average result system effectively make use new make available execution time average minimum expect time scenario one introduction development high level program distribute become work partially support crucial effort computer science one hand current computer often compose multiple independent process connect fast communication channel architectural trend true level grid compute multicore hand become increasingly pervasive many science engineer many application domain necessarily expert result program efficient parallel heterogeneous remain complex problem simplify implementation still achieve high performance current many program propose introduce simple flexible model could use broad class allow efficient anthill six framework take advantage parallelism loosely couple heterogeneous anthill allow parallelization several dimension partition set filter communicate use stream model filter distribute allow multiple create transparently previous result show efficient scalable several use anthill range complex parallel image process fourteen seven parallel data mine six fifteen paper present global state manager anthill create simple abstraction programmer manipulate filter state allow state distribute transparently across many nod one main system maintain high level programmer isolate filter implementation transparent copy mechanism within anthill allocate use provide distribute transparently across multiple instance filter moreover manager allow data migration one filter instance another enable anthill dynamically adjust number filter instance application least three reason mechanism useful adapt dynamic environment adapt dynamic application fault tolerance evaluate system use two well know data mine result show global state manager incur low overhead execution time average less eighteen experiment show result near minimum possible execution time theoretical case overhead add due result show best case minimum execution time average application mean manager allow anthill application make effective use extra soon become available execution time paper organize follow section two briefly describe anthill framework section three present work describe propose global state manager well dynamic mechanism section four present experimental evaluation present relate work section five conclusion future work section six two anthill anthill framework base program model implement four model use approach decompose set process refer filter also provide abstraction call stream allow data buffer transfer across filter application decomposition process lead possibility task parallelism become set connect filter like direct graph transparent copy mechanism allow vertex graph replicate many nod data go filter may partition among copy create data par allelism transparent copy refer filter instance remain paper several natural decomposition cyclic graph execution consist multiple filter pipeline application start data represent initial set possible process pipeline new candidate create process subsequent experience develop anthill notice behavior also lead asynchronous sense several candidate possibly different process simultaneously essence application loop parallelize data independent automatically detect execute concurrently anthill therefore try exploit maximum parallelism use three discuss task parallelism data parallelism loop parallelism divide computation multiple pipeline stag one replicate multiple time parallelism since happen execution mostly bottleneck free granularity parallelization select maintain balance computation communication application thus hide effect latency major difficulty anthill parallelization scheme relate state filter ideally state filter transparently partition across instance filter anthill utilize label stream concept partition message flow input stream appropriate instance filter label associate message send stream anthill apply programmer provide hash function label base result message deliver specific filter instance approach guarantee message associate label consequently state always deliver filter instance paper abstract transparent copy state partition application describe system layer provide programmer standard memory management interface manipulate state framework take care partition allocate memory efficiently across instance filter moreover system allow state migrate one instance another provide anthill capability dynamically best exploit available three global state manager section go address issue relate anthill dynamic enable global state manager mention framework may decide application either due application execution platform may different compute pattern load balance different filter change time may make sense anthill vary number filter instance available filter throughout execution environment may also change execution demand may vary time cause change resource availability also particularly true opportunistic grid become available go away constantly system may also decide due fault compute node become unavailable execution load node automatically distribute nod even migrate new one new copy filter defer issue future work additional require particular redundancy become necessary store state prevent become unaccessible memory management one main global state manager provide application higher level program abstraction particular implement filter programmer filter single sequential program towards goal implement standard base use manipulate state function interface framework create global address space across transparent copy filter allocate local portion entire state global state manager also design allow state migrate one filter instance another one reason functionality initial partition state function map input data filter initial placement particular variable match destination select hash function variable migrate automatically instance access also functionality add flexibility anthill allow framework dynamically respond change application demand execution environment also feature important fault tolerance distribute share memory three thirteen many require global state manager provide abstraction single share memory single address space use physical memory interconnect mean provide share memory parallelism general despite good result show literature three feature really necessary anthill case may lead high particular general purpose provide access serialization enforce semantics also integrate cache important due performance reason incur demand coherence transparent copy anthill filter however specific access pattern high locality reference since state partition one filter instance update state variable give time eliminate need cache synchronization reason decide trim version system use global state manager filter implementation simply allocate space entire state divide among transparent copy initial partition space arbitrarily define implementation access state do global state manager provide two function purpose whenever filter instance access state variable global manager verify available locally operation perform local memory otherwise manager trigger variable migration mechanism find state variable move local memory access instance one copy state variable give time distribute memory variable available locally access accordingly optimistic approach show work well anthill experiment describe section four model execution configuration simply configuration mean number instance filter time dynamically anthill application basically mean change number instance application filter word change configuration filter without state straightforward data execution status could easily filter state hand need data migration capability provide memory management system anthill could many asynchronous concurrent data flow run independently follow inconsistent situation could achieve message may queue within stream message send application different configuration one solution problem synchronize instance take place approach may incur overhead amount global barrier filter consume old message without produce new approach base synchronization distribute nine introduce global logical clock get update every time take place system keep application configuration every global clock message send stream automatically global time filter instance local time get update base receive message throughout execution framework behave accordance configuration system instance local time eventually filter instance synchronize global clock implementation detail global state manager implement three first directory contain indices state per application second multiple copy daemon actually store data third component library function provide access data remote access data assume indication bad placement decision trigger data migration mention client use update information directory keep track state implementation also support state allocation multiple simultaneous anthill implement anthill monitor responsible collect information summarize send central repository anthill monitor two main local central monitor local monitor responsible collect data machine send central monitor example local monitor collect number process run swap memory load local node base data central monitor global view environment example know machine use execution overload finally add anthill capability filter instance fly application run one important piece still miss decide base upon information anthill monitor good idea application new configuration leave future investigation direction four experimental evaluation use two different data mine evaluate performance impact propose paper select previously build efficient anthill adapt use global state manager propose paper cluster eleven popular cluster algorithm base concept group object iteration object assign group centroid update end iteration algorithm repeat object change group maximum number reach figure one show anthill implementation use three filter assigner centroid calculator final assigner filter set object application try cluster receive input set object compute distance assign local centroid label stream c e n r c l c l r global centroid broadcast g n e r final f n l figure one filter object nearest one centroid calculator compute new base object currently assign assigner filter call new compute object reassign termination algorithm finally send final filter print user readable version result modify algorithm assigner filter store object global state identify filter major bottleneck application consequently good candidate modification multiple instance assigner filter create one access local partition entire data define instance rank define anthill happen rank use along total number filter way instance read local data whatever portion proper location migrate transparently association analysis association analysis consist determine association rule causality among frequent fifteen first step compute consist determine set appear frequently give threshold traditional algorithm two partial occurrence c n e r v e r f e r candidate frequent c n e g e n e r r figure two apriori filter original anthill implementation em figure two base principle order set k frequent need also frequent algorithm start initial set frequent include size one every new candidate counter filter compute actual frequency value pass verifier filter check whether frequency threshold send information candidate generator filter generate new algorithm end counter filter transaction maintain global storage allow multiple instance filter count frequency local portion entire local portion change dynamically base application configuration state verifier filter consist global counter candidate counter allocate global state manager well allow number instance filter change dynamically execution experimental setup use synthetic conin point cluster point fifty dimension dimension could represent example group also use synthetic consist compose seventy attribute generate use procedure describe fifteen mimic retail environment use original modify two original implementation compare new implementation order evaluate overhead incur global state manager case happen experiment design follow set experiment consider case nod become available execution choose three application completion trigger fifty milestone run experiment vary initial execution configuration eight execution point reach number available double particular reason option felt scheme would give us enough insight performance system different experiment could do execution time number machine apriori use apriori use use use well experiment run cluster twenty connect fast node processor two main memory run result figure three show new still close linear show addition global state manager introduce bottleneck parallelization n c e e n c e x e zero one two four eight sixteen number machine figure four execution time different three fifty work do gain except eight sixteen machine milestone discuss next discussion situation half way computation number available nod go n best possible time application could run would average execution time n general case best possible execution time would weight average execution time several weight percentage execution time configuration show close minimum execution time experiment present table one number present ratio observe execution time estimate minimum execution time application different experiment table show highest overhead observe go eight sixteen work do less eight experiment incur overhead go one two computation do less two result show cost drop execution time include machine sooner application observe go eight sixteen machine work do yield increase performance intend study reason fact measure throughput algorithm linear apriori twenty fifteen ten five e v l one two four eight sixteen number machine figure three new figure four show difference execution time original new application see incur global state manager actually negligible algorithm average difference execution time original new implementation around fifteen eighteen look carefully see performance penalty due additional functionality figure five show execution time implementation different without fifty different one two four eight see gain three also sooner happen benefit mean system make effective use additional soon become available figure five b present experiment algorithm experiment occur n c e e n c e x e n c e e n c e x e zero zero number machine execution time normal execution experiment fifty experiment throughput execution time throughput p h g r h ninety eighty seventy sixty fifty forty thirty twenty ten one two four eight sixteen number machine number machine execution time normal execution experiment fifty experiment zero time second figure six throughput experiment two four machine work finish one two four eight sixteen five relate work number machine b apriori enough task leave execute would take advantage additional available several work develop migrate use stop start model one ten five although efficient expensive large state due tool adopt different approach like process eight split merge process twelve adapt application execution environment process approach eight achieve application malleability create number virtual normally much number physical p processor use abstraction allow flexible efficient load balance process migration support approach interest especially due fact programmer limit number physical express program term nature parallel problem however generate unacceptable overhead turn big problem become scarce large number process twelve al show effective resource utilization could attain use adaptation implement monitor per figure five evaluation different nod slowdown fifty one two four eight table one measure minimum execution time execution throughput base rate new verify frequent figure six show throughput two four machine milestone experiment show throughput increase dramatically reduction occur last twenty execution normal run application also verify throughput last twenty execution one quarter average throughput smaller number task process end execution intrinsic characteristic application explain gain perform eight sixteen machine milestone form split merge migration iterative io intensive run computational experimental evaluation show good result could achieve use strategy restrict regular communication process pattern target system support fit model could assume six future work paper present global state manager increase level abstraction application add transparent capability anthill experimental result show system achieve good performance two classic data mine due store data global state manager exceed eighteen average experiment show execution time average minimum possible execution time hypothetic case overhead add due future work go incorporate redundancy current global state manager would provide transparent fault tolerance anthill ongoing work proposal validation base environment information trigger filter instance reference one r starfish dynamic program cluster proceed international symposium high performance distribute compute page computer society two r r fast mine association rule large page chile june three c l cox p h r w w share memory compute network computer two eighteen four r j h filter large scientific archival storage symposium mass storage page five j j framework develop malleable parallel distribute parallel process letter june six r w l b g r anthill scalable g environment data mine symposium computer architecture compute seven hastings pan k r j support distribute execution scientific three eight c g l evaluation adaptive six proceed eleventh symposium practice parallel program page new york nine l time clock order distribute system seven ten condor idle proceed international conference distribute compute june eleven j b classification analysis proceed fifth symposium statistics probability page twelve k e b k c dynamic malleability iterative proceed seventh international symposium cluster compute grid rio de brazil page computer society may best paper award nominee thirteen wood efficient distribute space implementation network l bouge p volume page berlin fourteen g r w pan j support efficient execution scientific distribute symposium computer architecture high performance compute brazil fifteen j r g asynchronous anticipatory base parallel algorithm frequent mine four proceed conference practice knowledge discovery page new york new york