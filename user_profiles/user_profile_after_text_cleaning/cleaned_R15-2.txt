scalable earthquake simulation one two four panda h jordan one k lee j five three one one three j p small two g three three two day p san state university two san center university southern state university four five one three abstract need understand rupture wave dynamics shake require engineer safe structure one toward goal develop highly scalable parallel application achieve full dynamical simulation earthquake southern san fault two calculate use uniform mesh billion cub represent crustal structure southern area home twenty million people production run produce sec wave propagation sustain jaguar use core earthquake simulation open new territory earthquake science model seismic hazard goal reduce potential loss life property computational seismology earthquake grind motion parallel extreme io introduction earthquake system science seek provide society better earthquake cause effect toward goal southern earthquake center conduct collaborative research program within community model environment make extensive use numerical model earthquake phenomena incite capability compute demand facilitate development highly scalable application call paper describe first time design focus optimization allow code run efficiently development scalable application community platform exemplify collaborative research possible use particular personal use material permit however permission material advertise promotional purpose create new collective work resale redistribution list reuse copyright component work work must obtain new provide capability simulate anticipate san fault system high shake one require understand seismic risk scientific goal apply new tool mitigate life property could cause future elsewhere demonstrate simulate earthquake rupture entire southern central sea near total fault length scenario hereafter refer require computation grind motion throughout large simulation volume complex geologic structure vast region derive community velocity model represent uniform mesh resolution comprise total billion cubic fig one source calculate use fully dynamic model show produce grind motion level close agreement grind motion prediction fig one topographic location map rectangle depict model area dash line long stretch rupture shade show depth velocity knowledge earthquake simulation ever conduct present tremendous computational io challenge require collaboration thirty computational execute production run core jaguar national center computational currently rank first among top section two paper outline numerical method behind section three detail implementation section four introduce key tune use performance optimization section five demonstrate parallel efficiency summarize sustain performance achieve section six review milestone capability base finally section seven present scientific result simulation jaguar system algorithm description variety numerical available model model earthquake motion include finite difference finite element spectral element finite volume computational capable model wave propagation method provide best term accuracy computational efficiency ease implementation massively parallel abbreviation wave propagation day base code originally develop kim university code solve wave explicit scheme scheme accurate space accurate time code undergo many transform personal research code community model platform capability key code include dynamic model vertical planar fault lead day well simulation wave propagation lead k overall integration capability lead govern solve couple system partial let denote particle velocity vector x z symmetric stress tensor govern two write one e e e g e e r velocity vector x r stress tensor seismic wave suffer earth attenuation must include realistic wave propagation attenuation quantify quality factor wave p wave early attenuation model include maxwell standard linear solid model six day seventeen day eighteen significantly improve accuracy stress relaxation scheme use implementation memory efficient technique implement method closely approximate q incorporate large number relaxation time eight relaxation function without sacrifice computational memory efficiency b finite difference nine govern scalar approximate finite stagger grid time space time approximate follow central difference two two two spatial let denote generic velocity stress component h equidistant mesh size approximation x grid point j k two j k three two j k three two j k one one two j k three xi j k four j k h equation use approximate spatial derivative velocity stress component c algorithm dynamic fault rupture model highly scalable dynamic fault rupture boundary condition integrate day base accurate verify stagger grid scheme fourteen method fault divide computational domain two see fig two denote side fault plane set three govern differential split nod introduce fault plane order account velocity stress three external boundary condition truncation model domain computational mesh inevitably generate undesirable absorb boundary condition design reduce level numerical noise include two different type efficient perfectly match layer scheme originally introduce model electromagnetic wave two three later adapt wave stagger grid thirty formulate simple procedure equation split perpendicular parallel damp term add perpendicular component example wave propagation start split normal tangential x x velocity vector stress tensor similarly decompose normal tangential x x x x follow partial differential obtain x one one x x x x x x x damp apply perpendicular boundary via damp function x result update x x x one x x x x x since introduce develop multiaxial add efficiency apply damp separately propagate parallel perpendicular boundary implement side bottom grid approximate central space time efficient memory usage computation time moreover preserve interaction associate method make suitable implementation massively parallel single instruction multiple data computer although efficient know numerically unstable presence strong media inside thirty case implement second kind base simple sponge layer nine apply damp term full unsplit inside sponge layer unconditionally stable however ability sponge layer absorb fig two geometry illustrate grid adjacent fault scheme fault plane grid point split plus minus side finite difference motion partition form separate elastic restore force r act two halve two halve split velocity node interact shear node point fourteen velocity stress measure split node label accord fault side reside essence method calculate traction interact two surface fault solve equation motion govern side surface scheme accommodate quite general friction fault geometry though currently limit simulation rupture planar fault use friction law whereas time method remain center accurate approximation spatial depend proximity fault plane match accurate stagger grid point least two spatial fault plane point less two grid point fault plane accuracy reduce split nod introduce certain stress velocity assume fault plane locate follow use arbitrary velocity stress component two k one k three k k three two k one k one two k h three two k one two k one k k h h fault plane spatial velocity shear stress compute conform traction continuity condition four fig three shakeout simulation scenario use three independent cod top middle bottom result compute model smaller use two study simulation successfully use width ten grid point e free surface boundary condition top model apply boundary condition simulate flat free surface earth use free surface boundary condition define vertical level stress f verification successfully verify compare dynamic rupture wave propagation result numerical example fig three show nearly identical peak grind three different cod one simulation earthquake shakeout southern five verification crucial optimization code update implementation integration package design modular fashion aim provide efficient dynamic rupture wave propagation computational level implementation develop scalable mesh generation partition mind applicable diverse although development efficient code key challenge input output process tool turn equally important application final package compose tool mesh generator mesh partitioner dynamic source generator dynamic source partitioner dynamic fault rupture solver wave propagation model script validation aval derive ingestion tool io particularly critical generate mesh source deliver nod develop package effectively consolidate distinct contain variety tool streamline dynamic utilization multiple fig four scheme design structure grid system communication code perform message pass interface incorporate domain decomposition data parallelism efficient mechanism parallel finite difference cod processor responsible perform stress velocity within simulation volume allocate external edge volume must also process absorb boundary condition ghost occupy pad layer manage recently update exchange edge neighbor see fig five illustrate integration illustrate fig six begin update velocity vector interior boundary processor share locally update velocity physically adjacent stress tensor update similar way since information along ax arrange large number small noncontiguous chunk intermediate stag buffer introduce accumulate disseminate information source fig four fig five leave decomposition simulation region long wide deep right communication neighbor fig six flow diagram show separation dynamic rupture model path mode well wave propagation path wave mode destination respectively b parallel mesh generator package contain variety mesh generation tool develop small support interpolation approach static three scalable parallel algorithm extract material mesh require grid space program partition mesh region set slice along illustrate fig seven slice assign individual core extraction underlie scheme achieve effective parallelization partition extraction process core interact indirectly file system slice merge final mesh file core contribute slice final mesh compute offset location slice within mesh file use efficient file seek location write slice parallel version reduce extraction time fig seven mesh region partition slice along slice assign core job core query underlie point slice five fig eight leave serial approach mesh partition right parallel approach mesh partition c mesh partitioner create single global mesh file entire computational domain scalable efficient mesh partition technique one critical challenge prepare seismic particular deal highly fragment io data mesh partition aggregate regular highly fragment chunk data write back local contiguous file send dedicate partition consequently implement two io model deal issue one serial io input two partition fig eight serial io model require input partition prior simulation although many partition small file generate model provide efficient data locality guarantee extensive use system io unfortunately file approach may encounter issue incur excessive file system contention model hand allow process issue parallel io access library general library provide good input request well organize accord system topology tool theoretically work flawlessly however deal file highly fragment scatter access multiple unexpected io issue file consequently try minimize fragmentation scatter request io scheme first portion read highly contiguous big chunk mesh data maximize io throughput second retrieve data redistribute communication destination core see fig nine essential minimize average physical communication distance model current implementation plane read parallel base topology distribute associate require layer build full local cube find communication overhead highly tolerable use approach io performance significantly enhance resolve potential six part standard specify syntax semantics parallel io however implementation architecture dependent ago one incorporate experience provide opportunity help compiler system resolve multiple relate reduce io overhead set environment control frequency io level consequently require velocity result aggregate memory buffer much possible flush scheme work effectively practice case reduce io overhead less two io aggregation one critical feature code particularly beneficial many involve separate generation volume surface velocity output convenience data analysis visualization track verify integrity simulation data generate parallel processor mesh parallelize approach substantially decrease time need generate several data f seismic simulation take complete case application level tolerance various system critical deal provide simulation state consist internal state processor periodically save reliable storage processor responsible write update data use library incorporate application assist library call application synchronize task write state disk need approach help restart case unexpected termination current approach essential component program may introduce significant amount overhead file advance feature thus develop eleven fault tolerance framework different sense survive application process automatically abort small number application process fail instead process continue run program environment adapt previous g adaptation support different careful require handle system distinct include memory file interconnect experience fig nine leave cub center plan contiguous burst read efficient data distribute right high performance io data redistribution cause excessive memory requirement reader easily exceed amount usable memory core single plane subdivide along factor n approach allow n time participate read subpartitioned contiguous chunk data fig nine many experiment perform test performance file direct io model good strong tolerance advance model work best provide highly scalable collective file access kinematic source generator partitioner require kinematic source description formulate moment rate time finite number point moment rate time store file generate kinematic source generator tool file create source partitioner distribute source description associate incorporate approach similar parallel mesh partition special consideration must take irregular distribution source information general source highly cluster source concentrate give grid area result source data assign single core fit large data processor memory decompose spatially partition source file time scheme temporal spatial locality significantly reduce system memory e parallel output store simulation result significant bottleneck use allow velocity output concurrently write single file obtain efficient performance define new index data type stage represent segment output block set logical file view individual participate file io instead use individual file handle associate offset use explicit perform data access specific participate twelve avoid use file save io seven indicate application performance significantly affect determination fundamental system attribute thirteen consequently special implement adapt different unique feature facilitate simulation configuration able determine handle maximize solver io performance configuration specify memory buffer allocation buffer aggregation adjust depend memory usage io interconnect architectural alternative also include selection cache block size communication model overlap selection spatial temporal decimation output serial parallel io inclusion parallel collection performance asynchronous h verification aval code continuously update new improve efficiency new platform require acceptance test update therefore mandatory develop process configure reference problem run simulation compare result reference solution test use simple norm fit new simulation correct result reference solution archival digital library use high performance data transfer sit require human intervention execution distribute across several machine control remotely fig ten depict use remotely spawn multiple parallel process generation data file place destination machine task complete verification perform parallel parallel implementation significantly reduce transfer time average transfer rate event file transfer transaction record maintain allow automatic recovery retransfer digital collection twenty manage integrate rule orient data system use ingest data digital library aggregate transfer rate ten time faster direct use single allow modeler access file register data grid associate integrity replica information enhance incorporation derive data analysis advance vector visualization performance tune typical seismic use core require input produce output large fraction output must transfer archival storage utilize intensive analysis task challenge compute storage require develop execute simulation undergo extensive past six result address previous section io especially highlight recent performance section use model production run computer location processor interconnect peak table one ranger sun intrepid kraken jaguar core use custom fat tree fat tree torus torus torus torus barcelona table one summarize key machine use study jaguar system powerful list jaguar compute node contain two memory two router peak connect torus fig ten illustration data partition kraken solver simulation jaguar data archival kraken eight provide interconnect high low latency good interconnect communication partition simulation volume smaller total number match number use simulation partition space wave propagation information must share among neighbor scheme require pad outside correctly propagate wave number propagate number surround neighbor determine amount communication propagate wave one end computational domain long linear communication link form cause severe communication latency generally communication latency core highly dependent physical interconnect distance node topology nonuniform memory architecture link among core node may also asymmetrical cause latency ranger jaguar intrepid incorporate architecture main loop compose many computational communication io ensure consistency insert however local nature computation io within make many unnecessary global synchronization create redundant adopt originally synchronous communication model model communication path cascade multiple call pair latency accumulate along path make accrue latency core highly dependent number core communication path synchronous communication model particular issue base torus find however number access torus network tend increase communication latency example observe drop parallel efficiency forty core deal architecture issue redesign communication model asynchronous communication change effectively reduce communication overhead cause unnecessary interdependence among communication nod use asynchronous communication call mechanism need synchronize overall communication flow former synchronous code directly convert asynchronous code unique tag avoid ambiguity new model allow arrival unique tag maintain data integrity fig eleven scheme significantly reduce latency cause fine grain order control redundant synchronization mechanism extreme communication overhead inherent synchronous model cause critical performance degradation code asynchronous communication model effectively remove interdependency among nod show temporal dependence result highly balance low latency communication optimize communication code run ranger core reduce total time thirteen consume synchronous version code parallel efficiency increase addition asynchronous communication improvement remove redundant communication communication six stress tensor three velocity v w need update time step consider follow code j k j k j k j k j k j k j k k k k j k j j j stress tensor component j k j k j k j k need calculate update j k imply need update x direction rather three send two plane face information leave neighbor one plane right neighbor x direction reduce message communication achieve additional fifteen wall clock time jaguar execution b optimization use performance tool analyze single performance find hot spot execution time spend profile result show seven account forty total application execution time initially focus reduce expensive division frequently use lame parameter array mu lam compute remain un fig eleven communication latency asynchronous model nine change entire simulation array mu lam use form mu j k j k reciprocal form use frequently invoke reason store mu lam rather array throughout solver critical share three structure node execute loop processor local mesh achieve good memory access behavior however cache utilization rate low primarily due requirement assess value multiple array vary second third indices one value access whole cache line contain value fetch cache since number inner loop large cache line usually evict cache right reference improve cache utilization need access many value per cache line load possible cache block technique provide better cache utilization difference algorithm extremely limit memory number must fetch memory relatively high give computation perform require cache effectiveness cache reuse difference code low since amount data computation entire plane exceed size cache consider follow code calculate harmonic mean lame parameter lam k j nye lam j k lam j k lam k lam k lam j lam j lam lam reasonably size grid line contain plan locate cache difference equation perform next plane grid subdivide smaller plan may still cache computation progress accomplish form memory block k j loop describe follow code nye twenty k min twenty j min nye lam j k lam j k lam k lam k lam j lam j lam lam value choose guarantee subsequent plan still cache plan compute grid point access eight time cache block perfect variable fetch memory seven fetch cache value dependent upon number access within loop typical loop length optimal solution find variation different around three also use explicit loop unroll improve cache utilization even though automatically incorporate form optimization since number register processor limit could deteriorate loop performance empirical study prove unroll two give best performance implement additional manual major computational automatically example eliminate function innermost compute loop replace three value alternate one two removal enable compiler arithmetic loop summary benefit proper computational intensive significant jaguar instance obtain performance gain forty full system scale arithmetic optimization two loop unroll seven cache block c communication computation overlap communication nearest neighbor make performance heavily dependent system interconnect panda team state university develop nonblocking computation communication overlap improve parallel efficiency velocity stress exchange account time application velocity stress compose large amount small noncontiguous chunk memory enhance overall communication throughput process accumulate chunk contiguous stag buffer correspond neighbor disseminate receive data different velocity vector stress tensor independent oneanother hence divide computation communication per component interleave example velocity computation exchange split three part base v w value v compute exchange perform simultaneously provide efficient ten overlap similarly exchange v overlap computation w component nonblocking call use initiate exchange velocity component wait completion transfer use call end exchange w initiate similar process employ stress tensor overlap implementation obtain elapse time performance gain eleven core respectively however performance limit skew create load imbalance boundary interior full machine scale reason combine cache block technique overlap get consistent performance gain independent processor count largely due efficient computation result reduction skew group use semantics finer grain overlap achieve additional performance gain ranger unfortunately current library support thus take advantage optimization load balance exploit hybrid analyze performance tool able reduce load imbalance full machine scale achieve incorporate hybrid approach approach effectively resolve load balance issue reduce memory traffic independent architecture hybrid method multiple thread spawn single process directly access share memory space within node architecture hybrid synchronize memory request instead reduce memory latency data movement within node thread data collocation hybrid also eliminate domain decomposition produce hybrid implementation exploit performance gain pure implementation hybrid approach reduce load imbalance introduce significant idle thread overhead processor count approach arithmetic limit decomposition overhead may offset entire performance gain especially run communication synchronization overhead dominate simulation time pure code still perform better hybrid code continue investigate issue thread support evolve e io optimization large core count serial io performance hinder collection file system contention example simultaneous read mesh core fail due minimize impact issue implement simple io approach constrain number synchronously open file control number concurrent request hit approach also apply scheme improve performance file velocity data large core count method avoid system contention also improve io rate observe significant enhancement aggregate io throughput twenty jaguar file strip within file system also improve io performance file use command distribute give file content across maximally available object storage target enable concurrent provide overall superior io rate place different class file different easy set distinct strip stripe count set manageable size single large source mesh file locate input directory access simultaneous read multiple stripe size set unity serial access input file simulation output use large strip count depend actual output v exploit parallelism various ways various level granularity code evolve table two summarize evolution table two evolution optimization tune io tune partition mesh asynchronous single opt overlap cache block reduce year code sion ten twenty thirty forty fifty sixty seventy parallel efficiency sustain four execution time time step decompose five computation communication synchronization source output generation seven expression denote total execution time pure computational time denote synchronization communication time eleven respectively output time refer time due temporal partition dynamic source indicate io operation rate divide fix number choose simulation since perform infrequently significantly smaller term due extremely fast local read source allow safely omit run aggregate output buffer write output every time step result minimal io time per iteration reduction total execution time aggressive computation synchronization communication optimization positively impact overall performance provide useful estimate communication cost apply obtain formula define follow two factor average latency denote average denote one notation cost send single message k data represent k since grid contain n grid point topology consist p redefine n p c n p four three eight eight c n eight eight factor c account number float point stencil fact nine output update six stress tensor three velocity vector see section two stand machine computation time per flop example jaguar follow value estimate calculation combine machine application code performance demonstrate parallel efficiency jaguar core production scale display ideal consistent theoretical parallel efficiency fig twelve breakdown execution time compute communication synchronization io time jaguar execution time per step use leave v sixty right v cache block reduce communication fig thirteen reduction per time step achieve new version jaguar discuss differentiate parallel performance current version v previous version v sixty lack cache block reduce communication collect time information communication synchronization phase fig twelve detail spend fragment core io time six two total time heavily dependent local demonstrate due efficient cache utilization problem size per processor reduce core data set sufficiently cache memory access time subsequently decrease report indicate cache block optimization directly contribute reduction reduce communication optimization cause simultaneous decrease include time spend call since pure communication time two total execution time mostly compose single call per iteration regard weak scale use synchronous communication scheme demonstrate ideal scale core jaguar measure ninety parallel efficiency weak scale processor core primary factor responsible degradation performance load imbalance cause variability boundary interior computational load increase ratio diverse significantly improve parallel efficiency jaguar full system scale optimization improve code performance forty reduce division unroll two cache block seven overlap eleven include v reduce communication fifteen see fig thirteen two outstanding include incorporation asynchronous communication model achieve reduction wall clock time jaguar core reduction io time original less two wall clock time finally simultaneous read input processor core significantly reduce time fig fourteen detail twelve fig fourteen strong scale doe incite progressive follow milestone eighteen billion version wo io tune billion grid point shakeout v intrepid wo optimization v sixty ranger v kraken wo communication billion grid point v jaguar wo cache block reduce solid line scale square dot line denote scale optimization dash line ideal case occur jaguar b sustain performance present two sustain performance estimate base jaguar core first estimate scenario dimension spatial resolution meter maximum frequency two fourteen trillion mesh point make preparation project blue water plan slightly simulation second estimate simulation run produce remarkable result document call record run sustain rat respectively average float point per second base report divide measure time emphasize sustain performance base production simulation input output run performance result particularly remarkable consider stencil typically achieve low fraction theoretical peak performance milestone capability use section review significant milestone simulation carry recent base application see table three table show sustain performance increase computer grow past five first important computational milestone obtain hereafter refer model effect earthquake stretch southern five area southern use grid point model generate volume data scientific analysis breakthrough computational seismology time identify critical role sedimentary along southern border san san channel seismic energy heavily populate san basin rupture southern se contrast rupture stretch generate smaller peak motion fig fifteen thirteen base name maximum frequency source description year conduct table three w core core pacific northwest core shakeout ranger core kraken core jaguar core description kinematic source base event dynamic source base initial stress condition long period grind motion new community velocity model subduction zone sok kinematic source base geological sod dynamic source full tomography use full physics wave propagation source combine source space billion mesh point source new record use kinematic source description base earthquake rupture scale magnitude source relatively smooth slip distribution rupture owe resolution limit de fig fifteen maximum rupture superimpose leave right downtown long beach b modify al fig sixteen slip rate dynamic top kinematic bottom rupture sec initiation modify al source inversion impose kinematic see fig sixteen kinematic source often strong earthquake rupture process usually constrain physical fault earthquake rupture friction stress condition order examine effect use complex source execute use dynamic rupture dynamic rupture generate derive spontaneous rupture model heterogeneity base earthquake fig sixteen source model show average slip rupture velocity slip duration nearly correspond value source grind motion two source type significantly different particular increase complexity source decrease peak grind motion associate wave guide deep basin amplification factor general reduction overall grind motion attribute less coherent radiate source another notable characteristic feature grind motion star burst pattern increase radiate fault ray elevate grind motion generate fault dynamic rupture pulse change abruptly speed direction shape fig seventeen reason burst elevate grind motion also correlate pocket large slip rat fault pattern absent owe limit variation rupture speed constant shape source time function dynamic source expensive produce add important physical source usually miss kinematic follow shakeout great southern shakeout earthquake preparedness exercise mount many improve public readiness catastrophic earthquake along southern success exercise involve five million people ever hold unite state attributable part physical realism fourteen grid space lead us simulation motivate need understand seismic hazard southern accumulate significant slip deficit since recent large rupture dangerous fault southernmost segment southern creek beach participate major earthquake since circa imply slip deficit meter north southern recent large event estimate recurrence major southern study recently reduce less time since earthquake indicate entire southern san lock load sixteen consensus study rupture extend sea event ever happen current uniform earthquake rupture forecast probability rupture modest three however record consistent event late grind motion type earthquake need investigate use mode fig six generate dynamic rupture model since mode apply planar fault method employ first step simulate spontaneous rupture planar vertical fault long beach sixteen deep source time obtain dynamic simulation transfer onto segment approximation southern source solve surface topography include rupture wave propagation model source description simulate spontaneous rupture fault embed seismic geologic model represent average density along friction model follow law static dynamic friction five respectively distance three top two fault emulate velocity strengthen force linear transition two three cause stress drop region negative additionally increase one free surface use cosine taper top three initial shear stress fault derive assumption normal stress fifteen initial compressive normal stress n increase depth consequence increase overburden frictional strength f generally fig seventeen simulation white line depict fault trace county line dot line depict part san fault rupture modify al fig eighteen slip four seven source white contour contour label depict rupture time modify al lation use drive exercise shakeout scenario base geological data cumulative strain estimate record scenario rupture initiate southern terminus near sea propagate unilaterally toward northwest western desert seven dynamic source use fig eighteen assess uncertainty peak motion shakeout project increase upper frequency limit one addition large southern use several important model project conduct collaboration one project produce five large earthquake pacific northwest study demonstrate strong basin amplification grind motion five metropolitan forty another prominent project io intensive tomography iteratively improve southern use calculate sensitivity account full physics wave propagation generate update velocity model substantial better fit data compare start model ten finally preliminary car fifteen fig nineteen source model obtain spontaneous rupture simulation leave right se final slip b horizontal peak slip rate c rupture velocity normalize local velocity c yellow dominate rupture red blue patch indicate rupture propagate speed black contour show rupture time one second stress drop increase well also include cohesion one fault define initial shear stress zero fault first generate random stress field use van function lateral vertical correlation fifty ten respectively random stress field accommodate frictional strength profile way minimum shear stress represent reload residual shear stress last earthquake maximum shear stress reach failure stress fifteen initial shear stress zero generally increase depth despite random component shear stress taper linearly zero surface depth two rupture initiate add small stress increment circular area near nucleation patch locate twenty northern end fault use spatial temporal extent rupture model include zone fault absorb side bottom rupture model adequate good numerical resolution demonstrate previous work fourteen fig twenty perspective view x x model domain central southern northern sedimentary reveal cutaway material velocity less define four depth surface indicate color scale size computational domain eighty forty two billion nod dynamic rupture generate kraken use core simulate second rupture moment rate time define time step source partition spatially separate addition spatial locality enable temporal locality split source loop responsible time step reduce memory final slip fig reach fault surface average slip total seismic moment ten eighty value general agreement magnitude eight peak slip rat generally depth exceed ten two patch fig rupture propagate speed reach opposite end fault second fig large patch rupture velocity locate thirty smaller patch near b wave propagation source insert onto approximation southern apply temporal interpolation filter cutoff frequency two source imbed volume extract four see fig twenty use universal transversal projection volume billion cub use minimum velocity density value store mesh quality factor specify attenuation calculate approximate empirical relationship fifty sixteen fig derive superimpose regional topography component add select peak list along trace mesh file jaguar use alternative procedure case hardware file system failure use direct contiguous imbed solver directly read single mesh file redistribute partition process solver time final production run use first approach read mesh file four avoid file contention limit number synchronous file open request maximum jaguar result achieve aggregate read performance twenty simulation second wave propagation take jaguar use core sustain produce surface synthetic consume thirty time computational require see section six activate production simulation avoid additional potential stress file system write file time step save grind velocity vector every time step eighty eighty grid output aggregate write every time step minimize io overhead total consume memory per core solver buffer aggregation output earth model seventeen source lower memory high water mark segment temporal partition c scientific advance several important scientific advance gain primarily relate increase include two vast computational domain complex source description simulation fig show horizontal peak grind calculate root sum square horizontal along synthetic select sit show pattern agreement result previous include large value strong directivity effect radiate fault due complexity spontaneous rupture propagation although experience significant order four downtown excite amplification extent earthquake southern rupture rupture direction largely transverse avoid intense focus effect observe shakeout rupture large grind motion expect due strong directivity effect generally obtain long peak occur immediately top fault trace isolate exceed ten extreme reduce correct nonlinear soil response yet incorporate result occur fig component velocity snapshot illustrate wave propagation cone enter big bend section connection patch rupture distance thirty northern end fault fig nineteen previous analyse rupture propagation grind motion focus constant rupture simple homogeneous layer media one four nineteen study show wave generate rupture obtain fig carry intense grind motion much distance fault case rupture furthermore component grind motion tend display similar amplitude compare component usually contain peak rupture propagation due directivity show similar extend analysis complex heterogeneous rupture model media particular along fault tend occur rupture speed increase rapidly rupture speed rapid increase rupture speed likely contribute exceptionally large grind motion velocity time associate large fault generally characterize single simple pulse significant amount energy one two case large shake may occur associate longer example san see fig reach six spectral analysis show peak correspond san like build top relatively deep sedimentary basin san basin two deep combination location within strong directivity rupture appear cause large grind motion san valley another sedimentary basin locate along fault experience intense shake whether large peak motion prevail real require study nonlinear soil response alternative friction model rupture study currently underway order rank grind motion level relative expect frequency occurrence generic site event magnitude make simulate predict recent next generation attenuation attenuation empirical regression estimate attempt quantify statistical distribution grind motion include propose eight seven note use geometric mean since measure use eight seven geometric mean generate typically time smaller eighteen value calculate root sum square measure use fig since calculate grind motion two expect significantly bias simulation fig show comparison horizontal rock sit distance fault value predict eight seven rock sit define surface depth eight distance fault median ar agree well median one standard deviation close ar sixteen probability poe level respectively good agreement provide independent evidence fault area therefore average stress drop use consistent moment magnitude eight event comparison figure show sit propagation effect relatively unimportant match remarkably closely grind motion statistics encode empirical course empirical nature ie since base empirical fit data predict effect associate southern geological model capture mainly sedimentary grind motion predict high amplitude ie low poe relative correspond generic see fig basin fault two poe seven basin fault thirteen poe seven particular large peak grind motion simulate fall well one poe level seven illustrate fig comparison calculate eight c eight b seven rock sit rock sit define surface depth eight poe stand probability distance ten fault however extreme grind motion cause complex source propagation basin amplification effect expect capture replicate geographically specific effect summary outlook develop highly scalable parallel application target earthquake hazard combine dynamic rupture seismic wave propagation three dimension integral part community model environment widely use community apply scientific research recent performance gain make possible simulate great earthquake scenario produce two grind motion region within southern use structure community velocity model sustain approximately ten peak performance nearly ideal scale entire jaguar system core value demonstrate unprecedented performance explicit solver breakthrough seismology term computational size detail grind motion simulation large scenario earthquake thus far perform important new scientific insight gain grind motion level expect great earthquake particular large population center within model area example generate large amplification peak grind exceed basin large amplification expect rupture due channel seismic energy fault however show directivity effect great earthquake initiate near propagate se may generate similar level amplification basin despite wave field enter almost perpendicularly wave guide hand peak motion la basin reach forty downtown san appear area hit due directivity effect couple basin amplification proximity fault also provide new insight effect rupture propagation particular suggest exceptionally large grind motion generate along fault trace earthquake rupture transition speed addition reduce attenuation wave generate rupture big nineteen bend may contribute factor large peak motion obtain area additional rupture plan within include source generally rupture speed test whether grind motion characterize less extreme directivity effect associate coherent wave field extreme grind motion addition different ie rupture propagation bilateral rupture several different carry obtain estimate grind motion uncertainty relate great event increase complexity multicore push burden obtain good performance application level paper address critical technical issue regard earthquake careful design efficient adaptive package optimization message pass effective particular understand underlie parallel file system build highly parallel io extreme scale plan near future include development highly scalable fault tolerance technique base work al eleven add feature allow change io external configuration file facilitate extremely large volume data analysis use vector visualization technique finally continue port increasingly compute upcoming blue water compute resource allocation award sponsor program path successful completion milestone recent prominent example demonstrate optimization enhancement major application cod essential use large ie number number data produce also show multiple type need large namely execution analysis data collection management development lead create community code use community perform earthquake future validate grind motion use realistic structural model provide better estimate strong grind motion interest engineer emergency management seismological author acknowledge office science department energy doe provide contribute research result report within paper innovative novel computational impact theory experiment incite program allocation award perform jaguar part oak ridge leadership facility oak ridge national laboratory support doe contract research use leadership compute facility national laboratory support office science department energy contract research support allocation advance compute provide national science foundation perform kraken national institute computational data management perform san center data system use advance compute center university provide contribute research result report within paper work describe paper support university southern center compute state university communication research support research receive technical user support advance support asta program research support southern earthquake center fund agreement award contribution number paper reference two one th grind motion sustain supersonic fault rupture bull soc vol j perfectly match layer absorption electromagnetic wave j vol two j perfectly match layer absorption electromagnetic wave j vol two three five four p shear wave characterization kinematic fault rupture model constant rupture velocity j l vol two j r grave r l day g th jordan p j g shakeout earthquake scenario verification three simulation set j l vol one jo blanch model constant q methodology algorithm efficient six twenty inexpensive technique geophysics vol sixty one seven prediction average horizontal component five damp spectral one earthquake spectra vol eight grind motion model geometric mean horizontal component five damp spectral one earthquake spectra vol nine c r boundary condition direct acoustic elastic wave geophysics vol fifty four ten p l th jordan full tomography crustal structure region bull soc vol four k lee p th jordan application compute nine poster k lee kaiser p th jordan io application earthquake compute nine poster simulation visualization p e implement acceptance test scientific press thirty c implementation perfectly match layer scheme j vol eleven z fault tolerance parallel distribute vol nineteen twelve e b minster j visualize seismic vector field twelve r p b minster day j th jordan enable scale earthquake parallel machine l science lecture note computer science series vol thirteen r p h jordan computational platform earthquake advance lecture note earth vol fourteen la day method spontaneous rupture simulation j vol fifteen la load dynamic rupture process union fall meet sixteen te will summary geologic data rupture model san fault appendix f open file report seventeen day efficient simulation constant q use memory bull soc vol four eighteen day simulation wave propagation bull soc vol three nineteen em bhat attenuation radiate grind motion stress rupture j vol twenty r j b minister p manage large scale data earthquake j grid vol five three eh field te ad v th jordan stein will uniform earthquake rupture forecast version two two bull soc vol four e accuracy explicit planar boundary condition implement scheme bull soc vol three grave simulate seismic wave propagation elastic media use finite bull soc vol four data grid digital persistent archive real time data th jordan p community model environment information infrastructure earthquake science letter vol one nonconventional perfectly match layer wave propagation isotropic anisotropic elastic media stability analysis bull soc vol four se spatial parallelism finite difference elastic wave propagation code j vol one jaguar h k lee single optimization annual meet poster simulation wave propagation salt lake basin doctoral dissertation p day estimation q two wave basin bull soc vol two day minster r p th jordan strong shake expect southern san earthquake letter vol day minster p th jordan spontaneous rupture southern san fault bull seism soc vol three forty w j crustal structure grind motion earthquake pacific northwest region j seism vol twelve two la day j j p th jordan grind motion estimate use ensemble large southern san fault spontaneous rupture propagation letter vol p lai k sur k w barth panda quantify performance benefit overlap use seismic model application proceed l conference j coppersmith fault behaviour characteristic san fault j vol r k g earthquake cycle long recurrence record tell us fault work soc vol fourteen nine j guest high performance data transfer ingestion optimization ten vol one