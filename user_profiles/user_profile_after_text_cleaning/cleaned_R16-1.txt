web search use mobile core quantify mitigate price efficiency janapa university benjamin c lee university research corporation abstract hardware data center scale growth demand greater power efficiency sustain traditional enterprise typically memory io bind well serve chip comprise small core recent advance mobile compute lead modern small core capable deliver even better power efficiency core deliver efficiency data center small core impact application robustness flexibility increasingly invoke intensive challenge constitute price efficiency quantify efficiency web search engine production evaluate search server use atom subject computer organization computer organization performance study reliability availability serviceability general term measurement experimentation performance one introduction service experience paradigm shift computation data migrate cloud distribute locate data center hardware data center scale growth demand greater power efficiency sustain advance chip comprise small core provide power efficiency piranha propose integrate permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee ten june copyright simple core lower design effort improve throughput respectively one seven nine smaller core deliver throughput better power efficiency compare recent advance mobile compute provide small core even greater power efficiency traditional enterprise transaction process amenable execution small core typically memory io bind consequently platform overall system design rather design determine whether application service meet emerge data center increasingly invoke intensive small core may weaken service guarantee relative traditional sort comprise intensive latency part service level agreement sla design small core increasingly determine whether service satisfy emerge although small core advantageous power efficiency throughput compute less capable handle increase computational intensity might jeopardize application latency challenge constitute price efficiency small core quantify price power efficiency web search bing unlike traditional enterprise version web search rely machine learn core significantly increase computation index serve nod way contravene conventional wisdom regard small core enterprise demonstrate computational intensity search engine respect figure eleven search engine experience significantly instruction level parallelism figure one exhibit greater one surpass prior search experience similar traditional enterprise two three demand indicate need performance typically provide simple core consequently strategy small core greater power efficiency deep explore make follow configure per operate typical load condition run natively processor table one ten eight six four two zero c p e z l r n web apache file exchange search mail figure one computational need search engine exceed traditional noticeably greater one search evaluate web search engine operate enterprise environment use machine learn index serve nod service user query section two efficiency compare power efficiency atom search rely hardware counter data power search five efficient atom section three price efficiency search efficiency atom come expense robustness flexibility guarantee become less robust per query latency increase become variable computational intensity increase bottleneck impact search computation section four mitigate price efficiency address price efficiency effective system design greater integration enhance also address total cost ownership data center level due platform level translate lower performance per dollar collectively result paper contravene conventional wisdom respect small core data center web search industry offer choice two achieve scale necessary evolve one start big high performance core improve efficiency two start small low power core improve performance compare two favor latter search two search search representative broad class data center perform distribute expensive computation require service query strict performance flexibility reliability guarantee single query might require processor cycle access data three traditionally parallel index afford substantial improvement performance however search continue evolve machine learn become integral per core performance become important incoming query aggregator cache manager manager manager ranker stream index content index serve node figure two overview specific search paper target darken subset within index serve node structure figure two outline structure search engine search query enter system aggregator aggregator satisfy query set frequently ask query ie cache distribute query index serve nod operate distribute manner examine subset document index node use neural network identify return top n relevant page dynamic rank responsible rank page well generate relevant page user five upon receive query manager invoke ranker local subset index ranker parse query invoke stream use query feature identify match list page query feature ranker use statistical inference compute relevance score page match list use score ranker identify top n result pass result aggregation layer turn decide upon set result return aggregate sort relevance score aggregator request caption caption comprise title context caption generate base content distribute particular caption top n result across return user response query robustness search performance quantify combination throughput latency application define metric minimum percentage query handle successfully example metric percent require minimum successful query every query might due long expensive query feature might drop due fully occupy queue give target constraint might consider platform sustainable throughput quantify maximum number query per second arrive node without cause node violate constraint exceed sustainable throughput degrade query process must also observe latency average response time query must fall within certain number additional percentile query latency directly impact relevance ie document correspond specific query affect number iterative make search result give latency constraint ranker check remain time example check next tier tiered index lower query process allow additional improve relevance flexibility absolute load search engine operate highly distribute system variety load activity pattern must system scalable must also flexible change activity example activity pattern often periodic correlate time day moreover even modest spike complex query may generate sudden activity spike measure absolute term complex query break simpler query redistribution across multiple nod every must handle incoming complex query load therefore underlie architecture must robust enough tolerate absolute spike ideally would exhibit gradual rather sharp load increase exhibit gradual rather sharp load increase absolute term would provide greater flexibility less disruption reliability relative load hardware expect within data center ensure reliability robustness presence must operate spare capacity bear additional load fraction index serve nod fail since work dynamically across remain nod node experience fractional increase fail node sustainable throughput activity spike measure relative term exhibit gradual minimal load increase relative term would provide greater reliability less disruption three efficiency search exercise use inference neural net service query therefore traditionally run use server section seek understand use design explain experimental infrastructure compare search run versus atom quantify power cost efficiency across design term deliver search application performance experimental setup methodology consider spectrum commodity observe one end end table one summarize consider representative modern consider processor comprise core eight fourteen processor implement several power implement use dielectric metal gate process technology reduce leakage power switch power thirty percent moreover cache organize slice allow cache resize power reduction dynamic voltage frequency scale support power mitigation finally consider particularly part operate choice core process frequency pipeline depth width execution reorder buffer buffer data cache cache per die atom one four fourteen stag four issue one two sixteen sixteen stag two issue na na unavailable unavailable table one evaluate search eight fourteen ten fourteen represent spectrum commodity provide optimistic favor atom representative modern consider ten fourteen core design operate range core implement pipeline power efficient instruction decode schedule also narrower issue two per cycle furthermore atom design avoid specialize execution favor logic provide multiple functionality example integer multiplier float point divider use execute would normally execute separate dedicate scalar ten intend reduce power also may performance describe section four setup search distribute activity across several nod paper specifically target activity within use application currently production drive real query user activity search illustrate figure two specifically examine darken subset rank page return sort result aggregator quality search relevance page depend upon performance activity range sixty seventy percent indicate usually heavy load consequently performance depend underlie motivate evaluation within search neglect aggregator well caption hereon loosely refer term search engine part investigate compute page rank forty thousand query input query obtain production run query arrival rate parameter within experiment sweep rate identify maximum architecture sustain without violate target query compute overall rank page match query one production index subset global index distribute across several nod index fit memory eliminate page fault minimize disk activity effect consider first tier tiered index reside memory subsequent require access disk organize resource stall rat stall stall float point fourteen store load store instruction retirement miss branch b branch c load figure three synopsis search execution versus stall time b breakdown stall activity c instruction mix search source cache access extremely rare practice therefore determine application performance configuration additionally ensure fair comparison atom total number application thread service query match number hardware available specifically simultaneous enable atom result normalize single socket unless state otherwise system application server os also configure setup representative typical deployment strategy allow comparison power analyze performance use detail collect via thirteen toolbox provide us interface hardware counter atom counter provide detail insight activity various part search engine execute relate activity energy consumption quantify power dissipate processor voltage regulator module identify line enter regulator apply clamp ammeter collect power use digital let x sustainable throughput give search application quality service target figure three illustrate search execute x query per second show figure three percent execution time spend stall either register alias table rat front end cache memory stall suggest fully utilize percent execution time spend retire due structural conflict front end fetch decode long latency memory block instruction retirement figure three b break stall activity stall instruction fetch arise branch instruction cache effect illustrate figure three c substantial branch activity branch per make branch predictor bottleneck moreover see seven cycle penalty number speculative branch exceed capacity branch predictor branch history table thirteen furthermore instruction fetch often stall cache activity percent cache access attribute instruction cache miss figure three resource stall may attribute memory x twelve n e x e v l e r eight four zero e e n c p l l h c e f c p n c e r p h c n r b r n c e r p h c n r b n z l b e r r b b n z l b z l b k c b e r w r e v e r b l c p b l r b l e r e h c c one l e r e h c c one l c p e h c c one l p c e r n c v e two l e r e h c c two l figure four atom respect accord figure three c total percent either load store data lead pressure cache hierarchy consequently figure three show load store account percent cache access cache activity often translate memory request percent bus activity attribute memory show application activity atom demonstrate similar behavior relative atom implement simpler pipeline figure four demonstrate effect aggravate atom data correspond atom atom sustainable throughput target high frequency branch atom pipeline depth lead ten increase performance branch atom divide time greater performance effect may arise decision favor generality specialization execution specifically use specialize execution minimize example integer multiplier float point divider use execute would normally require dedicate scalar integer multiplier integer divider respectively ten moreover per core basis atom implement much smaller cache hierarchy accord table one atom data cache percent smaller per core smaller cache hierarchy translate fifteen eighty number data cache miss collectively effect lead three increase cycle per instruction table two compare throughput search target let x sustainable throughput atom query per second sustain throughput sustain atom x per core basis eighty sixty forty twenty zero w r e w p atom five four three two one r e w p sixty time figure five consume atom consume average four core sustain twenty throughput sustain two atom core sustainable throughput differ absolute process waste fail query therefore throughput gain less gain power figure five illustrate power time series atom search run operate idle power component substantial idle power dissipate particularly problematic give processor stall percent cycle exhibit dynamic power range percent difference idle peak power contrast atom low idle power component percent difference idle peak power atom get drastic power reduction relative atom low idle power large dynamic range particularly attractive pursuit energy proportional compute four performance per core basis atom five efficient compute performance power efficiency sustainable per watt table two compare atom variety metrics power per processor per core dominate performance per processor nineteen per core large power cost justify relatively modest increase sustainable throughput although paper focus primarily power efficiency also mention area price efficiency comparison area efficiency comparable two indicate area dynamic instruction schedule execution produce linear improvement throughput search however price efficiency atom price efficiency price atom price sustain number query per second note consider price see data center cost see processor may target higher profit moreover analysis consider equipment price total cost ownership peripheral network interface card also impact analysis section five assess sensitivity effect four price efficiency understand role data center continue emerge evolve must identify understand price exploit small core efficiency search find become less robust small core less capable absorb even modest increase query load greater variance per query latency distribution indicate query experience higher limit time available perform additional computation improve search result relevance rank latency effect depend part shift computational intensity resource bottleneck use small core robustness give quality service target atom sustain throughput x respectively consider guarantee robust target meet despite temporary increase query load robust guarantee critical application requirement search data center robustness also determine extent one node utilize index server nod absorb activity spike little degradation operate closer peak sustainable throughput give increase query load figure six indicate robustness trend horizontal axis quantify normalize sustainable throughput x vertical axis quantify term percentage successfully process query process additional query robustly modest gradual atom unable absorb large number additional query quickly violate latency increase query load degrade success rate metric also increase latency service deliver search algorithm use multiple refine search result query latency yet exceed cutoff latency figure seven illustrate latency trend normalize cutoff latency use logarithmic vertical axis figure indicate increase mean latency query load increase atom respective sustainable atom latency nearly three greater versus relevance latency direct impact search query relevance refer user utility set search result search often multiple refine result however load cutoff latency determine room refinement tiered index page index first tier always rank indices subsequent may rank exceed lower per query allow multiple iterative search result improve page relevance moreover lower provide search algorithm explore since average latency atom higher x see figure seven search atom unable refine page manner equivalent figure eight show page relevance atom compare x load increase vertical axis compare match page return search atom define relevance search result example percent mean percent atom query return search result perfectly match study atom beyond sustainable throughput characterize robustness assume sustainable operation load performance power w power efficiency ten six area ten area area efficiency price price efficiency ten two two two two ten two per processor per core atom fifty twenty ninety na na na atom na na na twenty na na na table two search versus atom performance quantify sustainable throughput maximum number query arrive per second service successfully target report relative atom performance average power use compute efficiency area report per processor price report per unit purchase order one thousand x x eighty sixty forty twenty zero e r e q l f e c c f ten one one one c l e z l r n c n e l q x g n h c e g p f zero four three two one n five ten fifteen twenty normalize x five ten fifteen twenty normalize x five ten fifteen twenty normalize q figure six atom normalize x figure seven latency atom normalize x figure eight bottleneck atom limit quality page hit search percent vertical axis indicate two percent atom query produce different result relative query result match perfectly across top n result match magnitude difference quantify one two three four n reduce subset n result match worst case none result match measure relevance highly conservative since assume define best relevance result mismatch degrade user perceive relevance however metric facilitate relevance analysis quantify search result even consider case load absolute minimum atom approximately one percent query produce different result atom query latency atom minimum load ten query per second still higher latency x see figure seven consequently page refine third time complete work lead different search result fifteen percent query produce different result number differ query increase three percent load approach flexibility search engine frequently experience activity spike measure absolute term therefore underlie must capable adapt rapid shift search activity especially case presence complex query complex query consist multiple simpler query break distribute across multiple nod index serve node must process complex query even modest spike complex query cause absolute activity spike within therefore nod sensitive activity spike must operate sustainable throughput provide safety margin understand sensitivity evaluate query latency eighty sixty forty twenty zero n b r e v l c eighty sixty forty twenty zero n b r e v l c x x x two x three two three five ten fifteen twenty latency normalize five ten fifteen twenty latency normalize b atom figure nine query latency distribution experiment allow query exceed track frequency order understand two handle sudden burst activity spike distribution change load increase presence different type query explain behavior effect cutoff figure nine illustrate latency distribution normalize cutoff latency experiment allow query exceed track frequency understand two handle sudden burst activity spike process query x percent query satisfy less percent query satisfy cutoff latency less ten percent query require moreover trend modestly sensitive activity spike quantify use increase load x three percent query still satisfy less atom per query latency exhibit much greater variation sensitivity activity spike figure nine b process query atom percent query satisfy less percent number query complete atom comparable however nearly thirty percent query x x two x three e r n c p l l h c e f c p n c e r p h c n r b c e r p h c n r b n z l b e r r b b n z l b z l b k c b e r w n e e e r b l c p b l r b l e v e r e h c c one l r e h c c one l c p e h c c one l p c e r n c v e two l e r e h c c two l two three x n e x e v l e r sixteen fourteen twelve ten eight six e v e r l sixteen fourteen twelve ten eight six c p l l h c e f e r n c e r p h c n r b c p n c e r p h c n r b n z l b e r r b b n z l b z l b k c b e r w n e r e v e r b l c p b l r b l e r e h c c one l e r e h c c one l c p e h c c one l p c e r n e r e h c c two l c v e two l b atom figure ten activity beyond sustainable query load require thus compare latency observe much spread atom minimum maximum per query furthermore atom latency highly sensitive activity spike increase load three percent query satisfy less figure ten examine activity provide insight flexibility processor inflexibility atom processor load data normalize respect activity processor sustainable throughput increase query load minimally impact next add bus activity see noticeable change figure ten however query load increase two three beyond atom degrade performance percent respectively performance arise primarily increase contention cache hierarchy small one cache become constraint miss rate increase percent eviction rate increase percent increase eviction rate result much higher bus utilization increase linearly additional query load memory subsystem become bottleneck pipeline often stall wait data divider utilization fall eight percent extra load three query complexity atom processor susceptibility absolute load spike function query complexity query latency atom take hit throughput rat higher certain type query require computation search criteria language specification conditional like determine query complexity long take e r e q l f e c c f ninety query type query type b query type c e r e q l f e c c f ninety query type query type b query type c b atom x x x two x three two three figure eleven degradation query complexity query type search query type b c increase amount complexity require process capability process query complex query break simpler multiple individual query within effective query load higher complex query demonstrate query complexity affect processor behavior sustainable throughput isolate query different search criteria pool mix query use evaluation label query type b c figure eleven query type complex search criteria therefore fast process query type b c impose search criteria query type c contain many type b thus require even process atom able sustain equivalent query type even high activity spike query simplicity processor unable stay competitive query type b c load increase beyond percentage successful query ninety percent stream type c query arrive back back query take longer process consequently search queue begin fill new incoming query drop search complete pending query exceed cutoff contrast figure eleven show suffer problem regardless query complexity able absorb activity spike smoothly reliability hardware often data center therefore must understand homogeneous deployment comprise atom perform load accommodate load redistribution due node lead fractional relative increase sustainable throughput give processor instance processor experience relative load twelve hypothetical rack consist five experience one system failure since absolute load evenly distribute across many atom compare data center full find basis atom achieve higher sustainable throughput compare atom reliable deploy search compare degrade due fractional load increase across atom present data system normalize sustainable throughput figure twelve load slightly beyond sustainable throughput ten normalize axis latency trend line increase sharply atom atom degrade percent degrade per ninety eighty seventy sixty fifty e r e q l f e c c f q q ten one one one c l e z l r n c n e l q x q ten five fifteen twenty ten five fifteen twenty figure twelve compare normalize system sustainable throughput figure thirteen compare latency normalize system sustainable throughput cent degrade gradually fractional increase load twelve atom correspond smaller increase absolute number query unable handle load increase robustly latency compare latency versus atom respect machine sustainable throughput figure thirteen latency increase gradually atom query exceed beyond mean even though processor eventually locate page correspond query result invalid aggregator terminate assume produce require page comparison latency atom still tolerable thus result still valid unable scale higher load saturate beyond figure fourteen show effect across atom relative load increase twelve fourteen sixteen eighteen two beyond sustainable throughput processor event activity onwards branch rat bus utilization activity cache activity reach maximum level therefore increase cap system saturate atom room additional load indicate increase additional activity relative load overall find indicate capable sustain higher throughput must run significantly peak capacity handle thus lower top already high power cost load per atom server smaller load distribute data center comprise higher capacity search reliable however platform effect addition flexibility sensitivity impact transition five mitigate price efficiency necessary mitigate price efficiency use small core web search section propose holistic well individual core enhance robustness flexibility reliability guarantee improve despite activity spike might overprovision atom find atom node x q x n e x e v e r l sixteen fourteen twelve ten eight six e v l e r sixteen fourteen twelve ten eight six e n n z l b e r r b b n z l b z l b k c b e r w e v c p b l e r b l e r b l e p c r n c v e two l e r e h c c one l e r e h c c two l e r e h c c one l c p e h c c one l c p l l h c e f c p n c e r p h c n r b r n c e r p h c n r b e n n z l b e r r b b n z l b z l b k c b e r w e v c p b l e r b l e r b l e p c r n c v e two l e r e h c c one l e r e h c c two l e r e h c c one l c p e h c c one l c p l l h c e f c p n c e r p h c n r b r n c e r p h c n r b b atom figure fourteen activity load redistribution tolerate increase robust manner simply utilize node one percent reduce throughput power difference atom still favor mobile however incur power total cost ownership break server cost average power consumption associate infrastructure cool power distribution provide insight cost also assess sensitivity atom efficiency advantage cost platform although atom core typically dissipate anywhere fifteen run search peripheral contribute another twenty platform power successful integration necessary help reduce system engineer atom deliver better since integration amortize peripheral number base peripheral component analysis table three exhibit four cost power efficiency although atom processor much system engineer optimization require reduce peripheral network interface card memory storage reduce platform amortization strategy need integrate atom core single processor atom hypothetical cost power w cost power w cost power w processor network interface memory storage total server cost normalize efficiency zero ten thirty five eight ten ten eighty zero four thirty five eight ten four zero ten thirty five eight ten table three peripheral component cost cost power quote twelve atom quote six memory data report micron power sixteen storage data report data sheet nineteen processor cost hypothetical atom base power correspond die compute cost build two socket system consist evaluate number atom core fit area budget processor four fit area single socket processor fifty hypothetical scenario base industry trend towards multiple core twenty assume processor cost atom equivalent platform manufacture cost drive die area number core give die size assume processor cost similarly socket compatibility assume cost system memory storage cost independent processor therefore equivalent across three test benefit integration compare cost platform platform representative current experimental platform representative project integration integrate eight core single chip build system two amortization highlight atom efficiency per compute cost table three integrate would competitive cost power efficiency advantage summary analysis prompt us towards better system integration enable successful achieve much better approximately efficiency sensitivity depend upon application robustness flexibility reliability platform certain degree necessary however degrade efficiency reduce operational load processor therefore table three report efficiency maximum sustainable load cost power efficiency require careful consideration present analysis search figure fifteen peak throughput utilization zero percent integrate ten cost efficient power efficient see figure fifteen figure fifteen b respectively however consider flexibility efficiency improve example search require tolerance eight six four two zero p q c n e c f f e atom atom hypothetical atom atom hypothetical eighty forty zero w p q c n e c f f e zero twenty forty sixty eighty zero twenty forty sixty eighty b figure fifteen efficiency sensitivity robustness flexibility reliability service activity spike require percent whereas every core within hypothetical atom require percent margin consequently cost power efficiency respect hypothetical atom improve percent twelve percent respectively base sensitivity analysis figure fifteen invite identify target utilization level best fit robustness flexibility reliability capital operational cost study cost manage versus scale entire data center quantify term aggregate sustainable dollar assume search run either atom evaluate use publicly available cost model estimate data center capital operational cost eleven model assume facility cost base critical power data center power usage efficiency seventeen model amortize power distribution cool infrastructure cost fifteen purchase cost three total cost operate manage data center present monthly basis model categorize follow power electricity bill run purchase cost cool power distribution data center infrastructure power cost miscellaneous cost maintain focus platform power efficiency constrain analysis omit discussion network license personnel cost assume uniform across figure sixteen proportionally illustrate cost associate use atom instead go figure sixteen figure sixteen b suffer percent loss spend manage data center despite spend amount money purchase percent versus percent get lower aggregate throughput loss efficiency mainly power limit number atom per data center fix critical power budget data center house far possible within power envelope generate percent throughput match throughput data center require far exceed data center critical power budget factor three better system integration however data center achieve approximately fifteen dollar figure sixteen c illustrate better improvement sheer increase pie size respect notice improvement data contrast difference negligible see table three advantage data arise issue like power cool distribution instance atom consume approximately three less power therefore cool lower benefit data center density system integration achieve better value per dollar spend manage data center consider distribution change slice correspond figure sixteen figure sixteen c hypothetical atom server purchase cost portion monthly increase percent percent despite increase use opportune two reason first aggregate throughput use increase second consider critical power envelope data center able accommodate many deliver higher aggregate throughput better integration void need expand build data center higher power budget since capable exploit exist infrastructure effectively moreover compare purchase cost additional overall operational management cost increase sixty percent relative trend combine lower power cool infrastructure indicate investment value improve transition small core address robustness concern system level achieve lower latency per query still essential atom especially flexibility presence complex query load otherwise quality search result deteriorate explain figure eight effectively achieve lower latency require atom core section three find atom experience particular stress divider branch predictor cache hierarchy enhance atom core base find imply design small core use unconventional example light manager n e x e l r n p c thirty twenty ten zero ranker stream manager ranker stream b figure seventeen search execution activity execution time distribution across search phase b normalize across different phase search computation atom weight pair disproportionately large cache hierarchy least like search subtle likely power efficient transition understand atom bottleneck root cause design must breakdown analyze different part search isolation figure seventeen illustrate execution time fairly distribute across phase search computation distribution gather identical search atom additionally figure seventeen b suggest important function exist throughout phase computation four major search engine experience latency increase fifteen relative performance atom performance degradation broadly distribute attribute one function phase computation bottleneck limit function within phase search computation observe overlap within top twenty function across atom indicate function importance depend application less architecture give twenty important function knowledge computation phase identify representative function phase manager ranker stream figure eighteen illustrate affect performance four representative function illustrate broad range performance adopt small atom core single function single phase computation account atom performance single event identify performance constraint function represent different phase search exercise different part atom constrain particular stress exert divider branch predictor cache hierarchy neural network stress divider cache function exhibit increase division time seem arise design decision regard versus scalar scalar division perform execution unit ten atom small cache lead fourteen increase cache miss net effect increase contrast part ranker stress branch predictor data cache performance impact branch increase low may arise ranker algorithmic apply different depend query cutoff power power distribution cool infrastructure power power distribution cool infrastructure power distribution cool infrastructure power b atom c atom hypothetical figure sixteen total cost operation dollar chart illustrate breakdown capital operational expense associate sustainable throughput per monthly dollar pie chart b c proportionally illustrate return value per dollar spend manage data center use either propose integrate top function manager ranker stream q x n e x e v l e r e r n c p l l h c e f c p n c e r p h c n r b c e r p h c n r b n z l b e r r b b n z l b z l b k c b e r w n e e v e r b l c p b l r b l e r e h c c one l e r e h c c one l c p e h c c one l p c e r n e r e h c c two l c v e two l figure eighteen identify bottleneck across phase search use representative function impact data cache miss increase low net effect increase also stress branch predictor stream manipulate data structure contain indices match word within query find particular element within require control flow exercise branch predictor penalty relative therefore increase lastly manager movement index file memory smaller cache limit exploit locality produce fourteen increase miss smaller cache also increase memory subsystem activity twenty thus cause increase overall although observe comparable performance representative function across four major phase computation search bottleneck differ significantly despite ideal efficient seem closer end spectrum instance reflect back effect show activity spike figure ten observe significantly since activity spike noticeable effect branch predictor divider cache hierarchy migrate simpler core logic area overhead redirect towards proposal traditionally disproportional structure like large cache bus mobile core reduce latency towards heterogeneous core accelerate look beyond heterogeneous might provide mitigate computational bottleneck prior make combine large small core single chip section six however consider division manager ranker stream across big small core analysis indicate solution inefficient version web search search single function phase computation carve execute efficiently large core consider four phase computation manager ranker stream potential performance gain figure eighteen furthermore pessimistically assume atom operate measure peak optimistically assume operate measure idle thus derive minimum power increase perform computation versus atom power increase always practice even optimistic scenario power differential dominate performance differential speed manager ranker stream core heterogeneous would lead seventeen eighteen atom efficiency indicate difficulty efficient acceleration heterogeneous comprise may possible extract parallelism granularity finer computational phase require production web search complicate costly task might also feasible direct complex query instead atom since handle internal absolute load spike gracefully atom see section however cost efficiency high future efficient acceleration may arise target computational neural network may incur low power cost recover performance lose six relate work landscape data center change discuss change mix usage pattern motivate need integrate analysis efficiency application survey enterprise information technology trend seventeen complement prior work examine role power efficiency small core analysis relate application robustness flexibility reliability power efficient data center design active area research al make case energy proportional compute data center utilize energy proportional amount computation three al propose power management scheme across ensemble mitigate cost associate power heat eighteen efficient integral understand effect work piranha make case small core improve design efficiency throughput memory io bind transaction process one seven nine contrast quantify small core specifically mobile intensive data center web search lim al take system view propose unify transition mobile embed fifteen similarly al propose use fast array nod fawn achieve energy data intensive compute emphasize embed performance query per second power efficiency use system power measure electrical socket contrast take view server measure addition system power core power track current activity voltage regulator make case chip quantify economic price compare smaller core two small core reduce economic price increase application perceive price efficiency quantify term robustness flexibility reliability emerge data center exercise data path extensively application perceive price efficiency raise case small core data center understand system better navigate inherent performance power efficiency seven conclusion emerge data center exercise processor significantly traditional enterprise transaction process thus deeply examine role small core specifically mobile web search particular study challenge respect robustness flexibility reliability search price efficiency system design implementation deployment example future reduce platform power associate peripheral essential longer term heterogeneous mitigate bottleneck may instrumental reduce price small core power efficiency eight extremely grateful several people help us research undertake include would like specifically thank mark shaw brook dan smith also grateful national science foundation grant compute research association project find express material author necessarily reflect view national science foundation compute research association nine reference one l k r b smith r stet b piranha scalable architecture base zero two l price performance economic case chip queue three l j dean web search planet cluster architecture micro four l case compute computer five brin l page anatomy web search engine six corporation technical product specification board seven j j k maximize throughput mediocre core pact five eight v c tong k v sarkar p singh next generation core two processor seven nine l sun big splash chip spectrum five ten g b b f merchant b patel h processor mobile metal gate eight eleven j cost power data center twelve corporation design guide series memory controller hub thirteen corporation core two duo processor performance analyzer help fourteen corporation volume one basic architecture manual fifteen k lim p j chang c patel understand design new server emerge eight sixteen micron technical note calculate memory system power seventeen p n enterprise trend architecture research eighteen p p leech j chase power management dense blade six nineteen barracuda data sheet twenty l e sprangle abrash p lake j r r e p architecture visual compute graph r core architecture dive v j franklin l tan cluster