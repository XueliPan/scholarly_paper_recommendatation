persistent code cache exploit code reuse across janapa university corporation smith smith university dan university colorado abstract compilation challenge task translate program instruction stream maintain low overhead manage code cache utilize amortize translation cost ineffective program short run time large amount cold code program prevalent compute range graphical user interface program management persistent code cache address issue describe evaluate dynamic binary instrumentation system pin propose approach improve model code reuse store reuse across thereby achieve persistence dynamically link program leverage interapplication persistence use persistent library code generate program new discover across automatically accumulate persistent code cache thereby improve performance time persistence improve performance nearly ninety interapplication persistence achieve improvement specialize use suite experience improvement dynamic binary instrumentation finally achieve translate oracle regression test environment one introduction compilation alter dynamic instruction stream application execution function independently allow provide variety powerful service operate exist unmodified dynamic optimization one four six ten recognize optimization apply run time dynamic binary two nine twelve facilitate execution compile one instruction set architecture different dynamic instrumentation enable study without recompilation new employ security eleven eighteen fault tolerance three also implement use compilation open many excite full potential govern strict increase program overhead virtual machine overhead arise spend time within infrastructure either emulate system function translate new application code latter significantly addition translate code overhead serve execute dynamically compile application code even absence provide new service performance translate code incur execution overhead alter dynamic instruction stream maintain control program execution paper focus reduce overhead specifically cost associate translate application code compilation effective minimize overhead execute code overhead remain infrequently execute cold code cold code context compiler code whose translation cost amortizable repeat execution program lifetime exhibit cold code behavior prevalent everyday compute range program graphical user interface pin dynamic instrumentation system cause large even prior inject instrumentation code many small well large program large like oracle incur several order slowdown directly due overhead associate compile cold code performance degradation effect cold code important compilation provide translation security instrumentation service service run program completely system control require every instruction dynamically thus must overcome cold code unlike dynamic resort original program execution presence cold code one twenty furthermore apply towards provide service instrumentation increase overhead associate cold code overcome translation cost compilation manage code cache avoid repeat code effective frequently execute code benefit small cold code due limit reuse exist compilation resort interpretation four less aggressive translation two attempt reduce cold code translation approach discuss paper base observation cold code within execution often hot code across multiple compilation exploit persistence generate persistent code cache use across subsequent program high code share benefit improve execution time reuse single persistent cache performance low code share improve time accumulate new code discover across persistent code cache propose model code reuse leverage interapplication persistence exist form common library program ie library code generate one application another application persistent code cache evaluate pin experimental result discuss across different type suite oracle overall persistence improve performance nearly ninety interapplication persistence improve performance dynamic instrumentation performance suite improve finally exploit execution model oracle yield improvement regression test set paper structure follow section two introduce evaluation framework discuss overhead identify overhead detrimental performance section three explain exploitation persistent application improve performance present work system section four evaluate benefit persis tent cache pin section five address prior work section six summarize paper two compilation infrastructure compiler design vary base upon system nevertheless certain fundamental section present background discuss associate overhead context pin evaluation framework pin overview pin dynamic binary instrumentation engine support arm operate pin illustrate figure one pin export instrumentation interface client support write pin tool client core internal emulation unit compilation unit dispatcher compilation unit application code code call trace trace pin context linear sequence fetch start address fix instruction count reach unconditional branch instruction encounter execution always enter trace via first instruction allow fetch instruction layout trace alter perform pin attempt original program optimization pin optimize instrumentation code generate trace compile without instrumentation place code cache translation map update translation map maintain information pertain code within cache example give original instruction address map return code cache address update map translate branch target correspond compile trace link together hence subsequent code require retranslation control remain code cache control transfer back code need generate emulation system call require emulation unit handle latter ensure proper program execution motivation overhead time spend within virtual machine translate application code emulate system function former dominate time spend within rest paper overhead measure cost dynamically generate application code current compilation implement code cache tackle overhead un figure one pin compilation framework persistence shade discuss section effectiveness figure two show behavior pin without instrumentation first reference input use program multiple input vertical line graph represent translation request rightmost vertical line indicate end program execution white space black line indicate translate application execution within code cache accord figure two translation request occur frequently program new code discover much translate code begin execution correspond program typically cold code loader frequently execute code generate number translation request drop time spend execute translate application code except fit profile outlier footprint capture even towards program completion sixty execution time substantial number vertical line graph spend generate code reuse enough amortize overhead issue application footprint present code cache mostly prevalent begin program execution observe suite often relative overall execution time however everyday prove challenge illustrate present table one discuss minimum wait time pin program ie button user interaction show figure two b time without pin large due design implementation pin result cold code execution program time spend execute translate application code behavior use reference input pin b overhead breakdown figure two behavior performance pin assume unbounded code cache pin translate code performance much smaller time spend generate trace pin overhead program except replace operate system signal require pin intercept emulate signal program behalf signal emulation expensive mechanism thereby result poor translate code performance upon completion phase overhead drop substantially show thereafter user interaction tolerable program program behavior begin resemble figure two overhead arise program concern apply instrumentation regression test regression test short run instance program exercise localize code characteristic allow test specific program feature instrumentation enable task like code coverage characterization memory error detection aid translation cost amortize due short execution time test consider gnu compiler whose test case several hundred source code file across many test compiler perform identical task analysis optimization persistence description code application file transfer client graphical text editor diagram creation tool file roller archive manager image manager eighty table one use evaluate performance code amount library code execute code generation verify output ie program binary result prior discussion identify sixty compiler time spend translate code unacceptable presence many test much like test utilize development verification oracle large number test demonstrate severe challenge employ instrumentation service validation nevertheless overhead substantially reduce store reuse across thereby enable test service even three persistent code cache present compilation discard code cache end execution subsequent program start empty code cache generate require possibly retranslate code already translate previous run persistent code cache eliminate redundant thereby reduce overhead persistent compilation system extend code cache model store reuse code cache across exploit code reuse reuse code across multiple application include application library code persistence figure three show example code reuse across two input original program control flow show leave illustrate program pin input one wo persistent code cache illustrate request generate code execute first time input one use persistent code cache show improve execution time store reuse across input invoke even though code execute first time already exist within persistent code cache persis figure three example translation reuse across input via persistent code cache figure four code coverage percentage phase within oracle reference input yield overhead save new generate real compute possible encounter input persistent nonexistent persistent compiler option either start empty code cache use persistent cache generate another input first option suffer cost retranslate code however latter common code need retranslate show figure three input two use input one persistent code cache illustrate translation reuse e across input c require translation overhead save may match persistence use another input cache viable approach complete retranslation use persistent cache across input persistence effectiveness persistence dependent upon amount code coverage input corroborate data section figure four show scale average code coverage oracle set multiple reference input cluster close indicate input exercise identical code scale indicate lower code coverage oracle application experience little code coverage different process average code file roller file roller table two number common process separate invocation program binary serve specific need execution since process perform highly specialize task little code coverage amongst propose model code reuse via interapplication persistence leverage library usage dynamically link table two expose library share average least third use application also use discuss table two execute code share table one time reducible reuse library generate one program another persistent compilation system persistent code cache implement pin framework pin support multiple work evaluate environment platform system support well interapplication persistence multithreaded require persist dynamically generate persistent cache manager persistent cache illustrate figure one manager perform fundamental task generate persistent cache verify possible reuse store follow paragraph persistent cache present description generation usage follow initially present context persistent system follow discussion change require facilitate interapplication persistence persistent code cache persistent code cache file store disk contain trace associate data structure data structure contain information trace link translation map data structure persist facilitate new code discover across persistent cache generate assume application remain unaltered however possible modify static compiler modify become invalid reuse result erroneous execution also invalid persistent system change code data structure specific version system utilize across prevent use persistent cache contain information pertain executable present memory time creation information contain key key hash base address map size binary path program header modification number key generate vary base number present memory point persistent cache creation minimum key generate application pin pin tool specify instrumentation application key ensure original program modify pin key ensure reuse across persistent system pin tool key ensure instrumentation semantics consistent across key create code dynamically generate application code thus persistent cache contain trace back file disk trace invalidate remove information translation map persistent code cache generation information write persistent code cache whenever code cache become full last thread execution perform exit system call particular program persistence manager allocate two large linear memory application virtual address space persistent memory pool together form persistent cache pool unavailable persistence abandon execution continue normally ie persistent cache generate point execution one persistent pool dedicate contain trace akin pin code cache contain data structure associate persist trace pin data structure c program object allocate application heap destroy upon program termination manager persist object overload object default memory ie new free custom manage memory request persistent data structure pool persistent memory pool data structure trace maintain separately performance reason intermix code data structure result poor performance data structure frequently access application footprint still capture code cache thereafter control remain mostly code cache little need separate code data allow code tightly compact otherwise data intermix code result increase cache page fault translation buffer miss persistent code cache reuse persistent cache manager facilitate persistent code cache reuse invoke cache function begin execution function attempt locate persistent cache utilize key compute application run pin pin tool find cache load memory persistent cache load via two system call file disk one map code cache load data structure since kernel employ page disk io occur base access pattern execute code library load occur via system call may load different address across result change program behavior host environment persistent system must ensure validity cache ensure proper execution library load intercept key compute load binary compute key match key contain within persistent cache valid otherwise conflict occur implementation leverage pin exist mechanism handle conflict occur even code cache model even absence conflict load different address across problematic absolute address embed persist incorrect execution example compiler may translate call instruction push pair push instruction place return address top stack instruction transfer control trace contain translate call translation perform maintain transparency ensure proper execution reuse translation cause program failure library contain call instruction relocate different address subsequent run literal persist push instruction become invalid describe implementation use persist library vary across however compiler adapt generate position independent capable cop library relocation thus far system discuss context persistence enable interapplication persistence require minor change application key use persistent cache function ignore thereby allow function return cache correspond application instrument identically check verify usability persist application mandatory ensure execution proper program check fail persist application correspond run program hence require invalidation invalidation consequently trigger current binary execution execution proceed persistent library common program reuse identical load address across program otherwise invalidate retranslate four result section discuss benefit persistent code cache first foremost persistence evaluate illustrate benefit persist reuse without require new code generation follow evaluation benefit persistent cache across input lastly code reuse across program present methodology performance evaluate suite oracle express edition suite compile use gnu compiler level optimization omit source code compile experimental environment program evaluate phase time take graphic interface ie button ready user interaction reproducible interactive behavior achieve use gnu package experimental data gather r r four machine memory run distribution oracle discuss context regression test setup representative production test every regression test comprise five phase phase new instance program perform highly specialize task start phase identifiable via process creation treat separate execution addition phase treat unique input exercise significantly different code sequence phase follow instance preparation start instance association mount enable open execution work deactivation close evaluate perform sixty ie ten table oracle evaluate r clock memory run enterprise three run unmodified pin application address space tunable parameter reserve pin use memory equally divide code cache support data structure reserve memory exhaust pin reclaim space flush code cache code cache flush discard translate code data structure course experiment discuss section none trigger code cache flush persistence persistence demonstrate peak potential system figure five present peak potential show relative run base pin figure five b discuss benefit instrumentation service train reference input substantially different run time execution six longer reference input use expect longer run limit benefit use persistent code cache application footprint capture code cache fix overhead become smaller percentage execution time specifically case exercise little new code time figure two result performance gain better train input overhead reference input experience fifty save train input large benefit ten see reference input exception thirty ten variability performance train reference input indicate cold code exist program amount cold code dependent upon input dismiss rare occurrence persistent system discuss paper reduce overhead cold code exist without penalize performance cold code figure five b show breakdown overhead performance translate code leftmost bar cluster original program execution time bar middle cluster show execution time pin perform binary translation bar split lower section represent time spend execute trace upper section represent overhead similar breakdown present last bar basic block instrumentation add translation two suite overhead remain incur negligible primarily due poor performance translate code little gain use persistently cache consistently execute new code throughout lifetime cost relative figure two use persistent cache two eliminate overhead completely show figure five additional service like instrumentation add long run program possible disproportionally increase overhead worsen translate code performance illustrate last bar within cluster figure five b detail basic block profile increase overhead much increase substantial absence instrumentation incur two overhead program highlight interest aspect persistence code program remain consistent across different input substantial part program input user interaction mouse activity button click user input present program process program unless complete code ie cold code consistently execute across hence cache cold code program extremely beneficial figure five show average improvement ninety execution time highly desirable interactive nature slow time tolerable lastly performance oracle show single phase sequence without pin take approximately eighty second run test pin take nearly second without instrumentation use persistence reduce execution time second improvement performance benefit instrumentation even instrument memory reference without persistence extend execution second persistence take slightly second four overhead sensitive amount instrumentation add analysis perform within instrumentation instrumentation increase overhead due additional code generation complex time consume analysis diminish relative significance overhead avoid potential bias instrumentation result discuss remainder paper performance compare minimum overhead pin must overcome apply instrumentation cost dynamically application code persistence persistent cache capable improve performance input use create performance improvement train reference input oracle b reference input without instrumentation figure five evaluation persistence input well persistent cache usage model desirable persistent cache unavailable evaluate two illustrate figure four discuss detail case study criteria choose amount overhead amount code coverage input two interest worth investigate detail oracle experience large exhibit different code coverage suffer overhead tight code coverage ninety input oracle experience slowdown due overhead average code coverage compare figure four interest due low code coverage respective input figure four incur low two eight figure five reference input per improve execution time relative run pin without persistence substantial headroom overhead reduction small observe table three show code coverage across different reference input leftmost column indicate run percentage code cover input list follow row code coverage amount static code correspond input also execute input example input five code also execute input two code coverage correspond persistence table show fluctuation code coverage input four show least code coverage input suggest lower benefit likely compare use input persistent cache table three b show similar code coverage table input one input two input three input four input five input one input two input three input four input five ninety ninety ninety ninety start mount open work close close start mount open work eighteen eighteen b oracle table three code coverage percentage oracle data indicate fluctuation coverage across phase range eighteen work coverage start close coverage open persistent cache create use start phase least likely help phase due low code coverage eighteen persistent cache open phase likely help phase since encompass large amount code correspond input benefit persistence show figure six within cluster leftmost bar indicate performance input execute without persistent cache rest bar correspond prim code cache persistent cache generate use input correspond legend example persistent cache input two refer persistent cache generate use input two analyze performance persistence insight sizable performance achieve run pin without persistence performance tie amount code coverage input similar result compilation best result achieve persistence coverage execution input five use persistent cache input four result higher execution time coverage second execution time use persistent cache input two coverage ninety second execution time performance oracle phase persistence show figure six b even though oracle lower percentage code coverage input phase benefit use persistent code cache range seven start phase persistent cache b oracle figure six time save persistence mount mount phase persistent cache open unlike input oracle phase behave substantially different base upon cache utilize consider execution time close phase use persistent cache start persistent cache open sixty difference execution time correspondingly large difference seventy exist coverage close phase open start phase input benefit least even persistence start phase relative phase start cover least phase result persistence improve performance seven overall persistent cache useful even input run infrequently improve performance input addition persistent cache degrade performance ineffective persistence improve current code cache model persistent cache accumulation use persistent cache create one input limit benefit amount code coverage accumulate cache persistent code cache accumulate ascend input order skip cache correspond input evaluate example consider input two set one cluster contain persistent cache generate use input one set two contain accumulation persistent cache generate use input one input three input two set two skip correspond input evaluate set three make input one input two input four set four comprise input one input two input three input five across input accumulate persistent cache outperform pin without persistence closely match performance persistence benefit accumulate two persistent cache due large amount code coverage input therefore additional add large amount new code persistent cache contrast accumulation largely benefit oracle trace input accumulate increase set number performance improve exception start phase gain limit experience least code coverage phase across mount work close phase set three yield improvement performance contain code accumulate start mount open phase open phase complex execute large amount new code present start mount phase result accumulation contribute number trace persistent cache result improve execution time set four addition close phase set three contribute much improvement close phase relatively small additionally set three already contain much code close exercise due open phase cover close code footprint table three b overall persistent cache accumulation effective like exhibit high code share accumulation maintain persistent code use later without decrease performance like oracle experience lower amount code share persistent cache accumulation greatly improve performance aggregate trace different phase single persistent cache narrow performance within persistence interapplication persistence time real world diminishable leverage library share amongst program table four show amount application library code find persistent cache example library code find persistent b oracle figure seven time save persistent cache accumulation input oracle experience low code coverage input ie phase performance differ significantly depend persistent code cache use instance persistent cache start yield least improvement performance across remain phase average execute code exercise input table three new code discover across input change opportunity improve performance persistent cache time code coverage persistent cache increase repeatedly use across different input add newly discover addition new persistent code cache persistent cache accumulation effect apply persistent cache accumulation show figure seven cluster show execution time accumulate persistent cache use input leftmost bar cluster performance base pin run without persistence last bar every cluster performance persistence exist compare effectiveness persistent cache accumulation bar indicate per file roller file roller table four library code coverage percentage figure nine persistent cache size coverage data table four average seventy coverage exhibit code share implementation inherent trace correspond identical load different address across program use system generate translate code instead system fall back retranslation hence potential benefit lose persistent code cache size input code coverage ie code footprint determine size persistent cache small code result cache less size due large code footprint persistent cache per figure nine oracle discuss paper even persistent cache stack bar figure nine illustrate memory consume persistent trace ie code cache persistent data structure interestingly data structure correspond trace consume memory trace suite exhibit characteristic data structure memory consumption trace management require large amount information link register liven analysis register bind memory management important aspect compilation prior work focus reduce memory footprint translate code fourteen fifteen assume code cache consumer memory however data figure nine indicate room reduce memory footprint target data structure figure application persistence time eight save inter cache data refinement table two present code share coarse granularity entire account actual code coverage execution time interapplication persistence ie use one application persistent code cache another show figure eight leftmost bar reflect time application pin without persistence average twenty second persistence second bar cluster previously discuss section provide basis evaluate time save interapplication persistence every cluster legend correspond ie persistent library cache legend entry bar isolate maximum benefit achievable use library code form persistence without trace correspond primary application across program bar within second two persistence indicate indeed execute code claim table one persist translate library code offer large performance time remain bar within cluster show time save interapplication persistence performance average around across correspond closely code five relate work persistence explore domain binary translation mean reduce overhead static seven seventeen support translation usage however static pretranslation prove infeasible production due extensive code expansion even add small amount instrumentation field experiment show ten increase code size expansion impractical large like oracle static size statically require use dynamic system persistently cache execute code experiment use implementation discuss paper yield manageable cache size persistence dynamic binary briefly touch upon author strata thirty neither focus entirely persistence demonstrate benefit use paper potential persistence explore thoroughly across different class well correspond input hazelwood smith sixteen characterize code share context dynamic optimization system suite work motivate initial study build upon three important ways first compilation overhead break overhead reducible via persistent cache explain second code coverage significance persistent cache discuss across set contrast suite program oracle lastly performance result use real system present li al nineteen improve code cache model binary translator discard unload memory rather invalid cache separately code cache attempt reuse module later reload execution persistence investigate paper go extend model code reuse across well conte al eight use persistence improve dynamic reschedule use across machine dynamically reschedule machine native counterpart store disk use across hence reduce number reschedule request lifetime binary incompatible machine evaluate benefit profile information prior work five thirteen explore effectiveness train input predict code coverage future program behavior new input considerable work profile drive optimization leverage information present work investigate benefit persistence system pin affect code coverage control flow memory usage persistence evaluate pin fundamental approach leverage code reuse across exploitable dynamic compilation well engage complex analysis prior engage complex task must overcome cold code therefore persistence exploit mean overcome performance bottleneck six conclusion paper propose extend model code reuse employ present compilation interapplication leverage common library generate cache persistently disk reuse across run important contribution paper persistent useful several important application class particular persistence benefit program severe cost large code oracle performance even specialize use compilation dynamic binary instrumentation persistent code cache implement pin persistent system support well interapplication persistence multithreaded performance benefit evident result experience average improvement instrumentation phase benefit nearly ninety furthermore achieve translate oracle regression test environment aside performance system degrade performance persistence ineffective seven thank kyle anonymous detail comment improve quality paper also extremely thankful pin team grant us access pin source code work fund corporation reference one v e dynamo transparent dynamic optimization system program language design implementation two l wang execution layer international symposium three e c wang g transparent comprehensive error detection international symposium code generation optimization computer society four garnett infrastructure adaptive dynamic optimization three international symposium code generation optimization five b predictability branch digital technical report june six r mojo dynamic optimization system workshop dynamic optimization seven r w p g optimize alpha spike digital technical journal nine four eight conte w dynamic reschedule technique object code compatibility annual international symposium nine j c b grant j p ban r j code morph international symposium code generation optimization ten g n e p j fisher new control point annual international symposium eleven twelve k e r daisy dynamic architectural compatibility international symposium computer architecture june thirteen p feller value profile memory master thesis university san fourteen k hazelwood l reduce exit stub memory consumption code cache international embed fifteen k hazelwood code cache management dynamic optimization thesis university may sixteen k hazelwood smith characterize interapplication optimization persistence workshop explore trace space dynamic optimization san ca seventeen r j digital combine emulation binary translation digital technical journal nine one august eighteen v p secure execution via program shepherd security symposium page nineteen j li p international conference virtual execution twenty j h r fu b yew performance data cache dynamic optimization international symposium r r muth h g v j k hazelwood pin build program analysis tool dynamic instrumentation program language design implementation june n j program supervision framework workshop verification oracle make oracle pax web site j p h j kelly field harder dynamic instrumentation tool kernel international model tool computer communication system performance evaluation tool two c young compare combine profile volume two k j k dynamic translation technical report university serrano r quicksilver compiler international program b r compact code compression dynamic translator conference design test thirty j p p dynamic translator workshop binary instrumentation b p miller dynamic instrumentation commodity operate system operate design implementation project w wall predict program behavior use real estimate profile program language design implementation g site c c transparent execution recompilation computer three