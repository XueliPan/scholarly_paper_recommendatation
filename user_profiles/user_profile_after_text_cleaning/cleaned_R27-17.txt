overview ad track alan one university two university technology three university new abstract paper give overview ad track main ad track twofold first goal investigate value internal document structure provide markup retrieve relevant information continuation reason retrieval result liberalize arbitrary measure choose fairly compare retrieve range arbitrary second goal compare focus retrieval article retrieval directly reason standard document retrieval rank derive run evaluate standard measure addition set query target derive proxy log run also evaluate click page ad track feature three task focus task nonoverlapping result need relevant context task nonoverlapping result return group article come best context task single start point element start tag passage start article need discuss result three task examine relative effectiveness element passage retrieval examine context content search well content structure structure search finally look ability focus retrieval rank article use standard document retrieval judge well query click proxy log one introduction paper give overview ad track two main research question underlie ad track first main research question value internal document structure markup retrieve relevant information document structure help identify relevant information within document question first study attract lot attention recent one eleven argue since relevance bind element retrieval also bind element implicit assumption system return least effective system return assumption base observation lower granularity describe reverse however true describe al four implement fix window passage retrieval system show comparable element retrieval rank derive similar study five show although rank base comparable direct estimation relevance superior finally six study relation highlight structure collection directly show reasonable correspondence document structure relevant information element passage retrieval approach could compare map may significantly affect comparison since map course turn passage retrieval approach effectively element retrieval approach study value document structure direct comparison element passage retrieval approach retrieval result liberalize arbitrary every element course also passage text simple passage retrieval format introduce use allow standard passage retrieval work collection offset length calculate text article ignore markup evaluation measure base directly highlight arbitrary point identify result possible fairly compare retrieve range arbitrary change address request liberalize retrieval format range two later request liberalize arbitrary text eleven second main question compare focus retrieval directly traditional article retrieval throughout history participate group find article system retrieve whole article default result fairly competitive performance seven ten note every focus retrieval system also generate underlie article rank simply order result different article rank clear relevant context best context task article rank explicit part task description study importance underlie article rank quality derive article level treat every article highlight text relevant derive article rank every submission basis evaluate standard measure also would light value element passage level evidence document retrieval one addition also include query derive proxy log topic set derive later click proxy log treat click article relevant query two hand also evaluate click page give insight test collection search ad track feature three task one focus task nonoverlapping result must return evaluate early precision relative highlight believe relevant text retrieve two relevant context task nonoverlapping result must return group document evaluate mean average generalize precision generalize score per article base retrieve highlight text three best context task single start point element start tag passage offset per article must return also evaluate mean average generalize precision generalize score per article base distance assessor point discuss result three task give result top ten participate group discuss best score approach detail also examine relative effectiveness element passage run content query content structure query rest paper organize follow first section two describe ad retrieval task measure section three detail collection ad track section four report result focus task section relevant context task section best context task section section five detail particular type run versus element versus passage particular query section six look article retrieval term judge treat article highlight text relevant term click page query derive proxy log finally section seven discuss find draw two ad retrieval track section briefly summarize ad retrieval task submission format especially identify also summarize measure use evaluation task focus task scenario underlie focus task return user rank list topic request focus task require find focus result satisfy information need without return overlap shorter prefer case equally relevant since longer three always relevant greater lesser extent challenge choose correct granularity task number display result present user result view result relevant context task scenario underlie relevant context task return rank list article within article relevant information capture set nonoverlapping relevant article likely contain relevant information could spread across different task require find set result correspond well relevant information relevant article task number display result group per article original document order access provide navigational mean document table content consider article natural retrieval unit prefer overview relevance within context best context task scenario underlie best context task return rank list article identification user start read article order satisfy information need even article completely devote topic request one best start point read even begin article task number display single result per article consider article natural unit retrieval prefer guide best point start read relevant content submission format since retrieval approach may return arbitrary result within document way identify nod need allow submission three type result range text element result element result identify mean file name element node path specification file name collection unique extension remove next example identify target document collection file file four element give fully specify allow next example identify first article element within first body element first section element finally within first p element path article one body one section one p one path importantly count one count element type example section title two paragraph would title one p one p two result element identify unambiguously use combination file name element path show next example result result file file path article one body one section one p one path range support range elemental give passage need start end element give separately follow example equivalent element result example since start end element boundary result file file passage start article one body one section one p one end article one body one section one p one result note format convenient specify range follow example retrieve first three section result file file passage start article one body one section one end article one body one section three result passage result give format offset length calculate character respect textual content ignore tag file special version one extend format allow optional use allow start end middle element format supersede clean passage format five collection provide facilitate use passage retrieval file offset start count zero zero follow example effectively equivalent example element result result file file offset length result paragraph start character character beyond first character length character evaluation measure briefly summarize main measure use ad track since allow retrieval arbitrary text match judge ability regard passage text relevant unfortunately simple change necessitate deprecation metrics use prior campaign natural retrieval unit longer element use basis measure note properly evaluate effectiveness remain ongoing research question measure solely base retrieval highlight text simplify task highlight text retrieval assume return highlight text compare character text retrieve search engine number location character text identify relevant assessor best context use distance best entry point run identify assessor focus task recall measure fraction highlight text retrieve precision measure fraction retrieve text highlight notion rank relatively fluid use interpolate precision measure calculate interpolate precision score select recall level since interest happen first retrieve result official measure interpolate precision one recall one also present interpolate precision early recall point mean average interpolate precision standard recall point zero one two overall measure relevant context task evaluation relevant context task base measure generalize precision recall nine per document score reflect well retrieve text match relevant text document specifically per document score harmonic mean precision recall term fraction retrieve highlight text six document use f score fourteen make precision four time important recall use interest overall main measure mean average generalize precision also present generalize precision score early rank five ten fifty best context task evaluation best context task base measure generalize precision recall per document score reflect well retrieve entry point match best entry point document specifically per document score linear discount function distance measure character n x b n n zero otherwise use n roughly number character correspond visible part document screen n one zero use interest overall performance main measure mean average generalize precision also show generalize precision score early rank five ten fifty three ad test collection section discuss corpus relevance use ad track corpus document collection corpus base early three collection contain article average article contain nod average depth node tree document original syntax convert use general tag layout structure like article section paragraph title list item typographical tag like bold emphatic frequently occur detail see three ad create follow precise candidate contain short query optional structure query one line description search request narrative detail topic request task context information need arise figure one present example ad topic base submit candidate select use ad track topic number seven topic id six title mean life title article philosophy section mean life description mean life description narrative get bore life start wonder mean life element relevant discuss mean life different long serious example discuss mean life relevant something like mean life cheese comedy irrelevant element must self contain list link consider irrelevant sense know context link give element narrative topic fig one ad track topic addition query derive use ad track topic number well candidate without field default add base assess follow precise use new assessment system assist highlight relevant text topic ask mark relevant text pool document assess article relevance separate best entry point decision make assessor focus relevant context task evaluate text highlight whereas best context task evaluate relevance freeze time seventy fully assess moreover eleven judge two separate without knowledge result paper refer seventy first assign assessor typically topic author seventy assess addition click page available proxy log eight table one statistics judge relevant article per topic judge article article relevance highlight highlight character unique article click total click article total per topic number min two three seventy seventy seventy seventy fifteen median mean eighteen ten one one one three zero one two three four five eight seven six number per article nine ten eleven twelve fourteen fifteen sixteen nineteen twenty fig two distribution article click article number table one present statistics number judge relevant article total article judge relevant find article mean number relevant article per topic distribution skew median highlight mean median per table one also include statistics number click article proxy log total click article unique per topic total mean eighteen median one click article per topic filter log query issue multiple also count total number click see total click article mean median three click per topic clear click article log different character ad two recall focus task main effectiveness measure precision one recall give average topic relevant article one recall roughly correspond relevant passage many accomplish first first result nine table two statistics best entry point best entry point offset first relevant character offset fraction highlight text number min median mean fourteen twenty one one five seventy seventy seventy zero zero best entry point offset fig three distribution best entry point offset figure two present number article give number vast majority relevant article single highlight passage number quickly taper request provide separate best entry point judgment every article highlight relevant text table two present statistics best entry point offset first highlight relevant character fraction highlight text relevant article first look mean well within article distribution skew median offset fourteen figure three show distribution character offset best entry point clear overwhelm majority begin article statistics first highlight relevant character table two give similar number offset mean offset first relevant character median offset twenty suggest relation offset offset figure four show scatter plot offset two present first clear diagonal position exactly first highlight character article second also vertical line offset zero indicate tendency put start article even relevant text appear later finally statistics fraction highlight text table two show amount relevant text vary almost nothing almost everything mean fraction median indicate typically half article relevant give majority relevant article contain large fraction relevant text plausibly explain frequently position near start article ten e f f r e c r h c n v e e r r f l zero fig four scatter plot best entry point offset versus first relevant character zero best entry point offset table three candidate topic questionnaire familiar subject matter topic would search topic query differ would type web search engine look specific information interest read lot relevant information topic could topic satisfy combine information different part topic base see relevant part document information equal relevance topic find several document approximately many article whole collection expect contain document relevant information collection approximately many relevant document part expect whole could relevant result check apply single sentence single para graph single sub section whole article topic completely satisfy single relevant result additional value read several relevant result additional value know relevant result would prefer see best result relevant result know would prefer see isolate document part article context know assume perfect knowledge assume structure least one relevant result know assume reference document structure vague imprecise comment optional candidate topic author ask complete questionnaire design capture context topic author topic request candidate topic questionnaire show table three feature twenty question capture contextual data search request eleven table four post assessment questionnaire submit topic familiar subject matter topic hard decide whether information relevant obvious source look information topic highlight passage check apply single sentence single paragraph single sub section whole article single highlight passage enough answer topic highlight still informative present context often relevant information occur article something else well total length highlight text correspond usefulness article follow two closer actual highlight locate useful article highlight best nothing highlight text relevant accord narrative even mean highlight entire article best entry point check apply start highlight passage section structure contain highlight text start article best entry point correspond best passage best entry point correspond first passage comment optional questionnaire show table four feature fourteen question capture contextual data search request way topic judge question add end show considerable variation topic author term topic familiarity type information request expect result interpretation structural information search request mean highlight passage mean best entry point need analysis contextual data relation result ad track four ad retrieval result section discuss three ad task result participation total run submit participate group table five list number run submit also break task focus relevant context best context use query use result type element passage unfortunately less run turn invalid evaluate respect article retrieval value section six allow submit three element run per task three passage run per task three task twelve table five ad track x e n c n n v e l e r x e n c n e b e c f l e r n e e l e l e r e g p l e r l f n r l v r e q c r e q c n r e b six six three nine three zero six zero six zero zero nine zero eighteen eighteen six six six fifteen three six thirteen zero two fifteen fifteen six six three zero three three zero zero zero zero five zero three one one zero zero nine zero three three three zero zero three zero two zero one zero zero nine seven one three three zero zero zero nine two zero zero zero two four two three zero one zero zero three zero three zero zero zero zero six three six zero zero zero zero six one zero zero two zero zero two three two zero zero zero zero five zero three two zero zero zero three one zero zero one zero zero nine three three three three zero zero nine zero three zero zero zero zero zero two zero zero zero zero zero two zero two zero zero zero zero zero zero two two two zero six three three four ten zero two zero ten thirteen five five five fifteen zero fifteen zero zero fifteen fifteen forty fourteen four nine three five nine three zero two two three three one zero five zero six three zero two six three five nine three seven zero four three six two two five one nine three zero two six eight three five nine three seven two four three six two two five one nine three zero two six id participant four university five university technology six university nine university ten twelve university granada fourteen university sixteen university university china statistical institute forty university university corporation sixty saint university de university curie university university university total run total eighteen run per spread well ad retrieval task focus forty relevant context best context focus task discuss result focus task nonoverlapping result require official measure task mean interpolate precision one recall one table six show best run top ten participate group first column give three turn two group submit run allow university submit six extra element run university submit four extra element run moment decide mention footnote thirteen table six top ten ad track focus task zero one five ten participant participant see table five full name group second fifth column give interpolate precision zero one five ten recall sixth column give mean average interpolate precision standard recall level zero one briefly summarize currently know experiment conduct top five group base official measure task one university element retrieval run use query description run use okapi model score section paragraph use okapi addition score boost double value first ten word element element retrieval run use query description system retrieve article use linear combination content score proximity score also take document structure element retrieval run use query description base language model use smooth equally weight element score context score context score base university manual element retrieval run use query description use indri search engine lemur manually expand query description narrative field run retrieve article saint university element retrieval run use query description probabilistic model use evaluate weight tag probability tag distinguish term relevant ie base fact tag contain relevant non relevant result tag weight incorporate run weight base information ten run use query fourth run use manually expand query use word description narrative fourteen table seven top ten ad track relevant context task five ten fifty participant field tenth run automatic run use title description field run use query title field run retrieve result rank second fourth tenth retrieve full article relevant context task discuss result relevant context task nonoverlapping result need return group article come task evaluate use generalize precision generalize score per article base retrieve highlight text official measure task mean average generalize precision table seven show top ten participate group best run per group show relevant context task first column list participant see table five full name group second fifth column list generalize precision five ten fifty retrieve article sixth column list mean average generalize precision briefly summarize information available experiment conduct top five group base university element retrieval run use query description run use okapi model score section paragraph use okapi group result article rank article best score element university technology element retrieval run use query description run use query serve nonoverlapping group per article article order best score element university manual element retrieval run use query description focus run fact literally article rank focus run recall run retrieve whole article fifteen table eight top ten ad track best context task five ten fifty participant element retrieval run use query description element retrieval run use new score function ie consider element document compute standard model select nonoverlapping base score group per article article rank highest score element university element retrieval run use query description use select rank top document whole document select passage run retrieve whole article base information run rank sixth ninth use query run rank third use manually expand query base description narrative run use query topic title field run retrieve result solid article rank seem prerequisite good overall performance third best run fifth best run ninth best run retrieve full article best context task discuss result best context task document rank topical relevance single best entry point document identify best context task evaluate use generalize precision generalize score per article base distance assessor point official measure task mean average generalize precision table eight show top ten participate group best run per group show best context task first column list participant see table five full name group second fifth column list generalize sixteen precision five ten fifty retrieve article sixth column list mean average generalize precision briefly summarize information available experiment conduct top five group base university element retrieval run use query description run use okapi model score section paragraph use okapi keep best score element per article university manual element retrieval run use query description focus relevant context run fact three run literally article rank run retrieve start whole article best entry point word article retrieval run university china element retrieval run use query description use language model compute leaf level combine aggregation retrieval time assume independence university technology run retrieve range use query run always return whole article set start article description run use query rank article best score element transform return complete article effectively article level run university run retrieve use query description language model local prior set always start article since offset always zero similar article retrieval run base information relevant context task see solid article rank important fact see run put start retrieve article rank two rank four rank five fourth rank run use range albeit degenerate case always full article select fifth run use albeit degenerate case always zero offset exception run rank nine ten use query best run per group use query significance test test whether higher rank significantly better lower rank system use table nine show task whether significantly better indicate lower rank run seventeen table nine statistical significance focus task one two three four five six seven eight nine ten b relevant context task c best context task one two three four five six seven eight nine ten one two three four five six seven eight nine ten example focus task see early precision one recall rather unstable measure none run significantly different hence careful draw base focus task result relevant context task see top run significantly better rank two four ten second best run better rank four six ten third rank system better rank six ten fourth fifth rank better rank eight ten best context task see top run significantly better rank four ten second third run significantly better rank five ten fourth rank system better rank five seven ten fifth rank system better rank nine ten five analysis run topic type section discuss relative effectiveness element passage retrieval approach relative effectiveness use structure query versus receive eighteen use range result total five participate group look relative effectiveness element passage run saw section four three task best score run use unit retrieval table ten show best run use range three ad task run use query turn best focus run use rank outside top score run table six best relevant context run use rank fifth among top score run table seven best best context run use rank fourth among top score run table eight outcome consistent result use element retrieval eighteen table ten ad track run range focus task zero one five ten participant b relevant context task participant five ten fifty c best context task participant five ten fifty passage retrieval approach show comparable superior behavior element retrieval approach four five however look run detail character often unlike one would expect passage retrieval run focus article retrieve run use range manual query run use relevant context article retrieve run use range best context article run use range article run use element retrieve run use range two run retrieve article hence sufficient evidence warrant conclusion effectiveness passage level result hope expect test collection passage run use research relative effectiveness element passage retrieval approach versus look relative effectiveness structure query saw section four one best run per group relevant context task two top ten run best context task use query query since artificial query form title add without title table eleven show distribution target total four note use trivial hence regard trivial query target table eleven non nineteen table eleven query target target element frequency thirty eleven three one section article p figure body number turn assess result present restrict table twelve list top ten measure use focus task relevant context task b best context task c focus task run score lower query run relevant context task best run would rank fifth among run best context task best run would rank seventh among run overall see team submit run type query higher score run participant six notable exception relevant context six analysis article retrieval section look detail effectiveness ad track article retrieval look first article rank term ad track every article contain highlight text relevant look article rank term click page derive proxy every click article relevant article retrieval relevance first look judge section use derive standard relevance regard article relevant part highlight assessor throughout section derive article retrieval run every submission use first serve map simply keep every first occurrence article retrieve indirectly element contain ignore result article use evaluate map run use mean average precision map main measure since run article retrieval run task disappear moreover run violate twenty table twelve ad track run side versus run side focus task zero one five ten participant b relevant context task five ten fifty participant c best context task five ten fifty participant participant zero one five ten participant five ten fifty participant five ten fifty task notably nonoverlapping result task scatter result article relevant also consider work run submit ad track table thirteen show best run top ten participate group first column give participant see table five full name group second table thirteen top ten ad track article retrieval map participant third column give precision rank five ten respectively fourth column give mean reciprocal rank fifth column give mean average precision sixth column give binary preference measure use top r judge document recall second rank run manual article retrieval run submit three task also run rank three run rank seven retrieve exclusively article relative effectiveness article retrieval run term article rank surprise furthermore see three ad task notably run best context task rank one two four six run focus task rank two three five seven eight nine run relevant context task rank two ten breakdown run original task show side table fourteen compare rank section four see run familiar table three focus run correspond table six five relevant context run correspond table seven seven best context run correspond table eight formally look two system rank correlate use tau focus task system rank correlation one map map relevant context system rank correlation map forty best context system rank correlation overall see reasonable correspondence rank ad task section four rank derive article retrieval measure correlation focus task run much lower relevant context best context task make sense since rank article important part two context task article retrieval click page addition create assess also include query derive proxy log also construct regard every click article relevant table fourteen top ten ad track article retrieval per task judge leave click page right focus task participant map map participant b relevant context task map participant map participant map participant c best context task map participant table fifteen show best run top ten participate group first column give participant see table five full name group second third column give precision rank five ten respectively fourth column give mean reciprocal rank fifth column give mean average precision sixth column give binary preference measure use top r judge document compare judge immediately see much lower score early precision measure precision table fifteen top ten ad track click article map participant five ten reciprocal rank time higher score overall measure map result low number relevant document eighteen average make impossible get grip recall run rank first fourth seventh retrieve exclusively full article great surprise run well task article retrieval result rank quite different article rank base judge ad table thirteen one run common although agree five ten look formally system rank two type article retrieval see follow system rank correlation focus task correlation relevant task correlation best context task correlation hence judge derive proxy log vary considerable large part explanation dramatic difference number relevant article average judge eighteen average proxy log seven discussion paper provide overview ad track contain three task focus task nonoverlapping result require relevant context task nonoverlapping result group article belong require best context task single start point element start tag passage offset per article require discuss result three task analyse relative effectiveness element passage run query structure query also look effectiveness term article retrieval use judge use query click derive proxy log examine relative effectiveness find task best score run use query contrast result show structural hint help promote initial precision eight part explanation may low number comparison number seventy judge query majority query make reference particular tag structural may diminish value query comparison give put fair comparison element passage retrieval approach number passage disappoint use range passage result whereas use element result addition many passage use exclusively full article result although receive run draw clear saw passage base approach competitive superior element base approach outcome consistent result use element retrieval four five saw article retrieval reasonably effective ad task three run among best run top ten group look article rank inherent ad track saw three best run top ten group term article rank across three task fact run also suggest evidence still valuable article retrieval compare system rank term article retrieval system rank term ad retrieval task exact topic set see reasonable correlation especially two context task best performance ad task also tend best article rank look different topic set derive proxy log shallow set click page rather test collection see notable give low number relevant article eighteen average compare ad average click page focus exclusively precision lead different system rank although still agreement best group two set require analysis finally ad track two main research question first main research question comparative analysis element passage retrieval approach hop would light value document structure provide markup find best perform system use predominantly element result although number retrieval run submit low draw definite second main research question compare focus retrieval directly traditional article retrieval find best score ad track also tend best article rank best article rank generate use evidence main research question hope expect result test collection prove value future use main aim initiative create evaluation structure retrieval approach support organization scientific research grant bibliography one j p evidence document retrieval proceed annual international conference research development information retrieval page new york two c l range result retrieval proceed workshop element retrieval methodology page three l p corpus forum four w r element retrieval use passage retrieval approach proceed document compute symposium page five k c l retrieval proceed workshop focus retrieval page university new six j relation relevant document structure proceed workshop focus retrieval page university new seven j de b importance proceed morphological normalization retrieval first workshop page eight j de b articulate information need query information nine j k use grade relevance evaluation journal society information science technology ten j j well best context reflect ad retrieval page eleven passage retrieval task proceed workshop element retrieval methodology page university new appendix full run name task query result note manual thirty group run label four four four five five five five five five five five five five five five five six six six six six six six six nine nine ten ten ten ten twelve twelve fourteen sixteen sixteen sixteen continue next page manual invalid manual invalid invalid invalid invalid group run label forty forty forty sixty sixty sixty sixty task query result note eleven invalid invalid manual manual manual