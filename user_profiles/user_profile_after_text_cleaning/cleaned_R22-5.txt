use continuous statistical machine learn enable performance prediction hybrid instruction set institute compute architecture school university forum ten street unite kingdom abstract functional instruction set perform simulation high instruction rat unlike however capable provide cycle count due higher level hardware abstraction paper present novel approach performance prediction base statistical machine learn utilize hybrid instruction simulator introduce concept continuous machine learn simulation whereby new train data point acquire demand use update performance model furthermore show statistical regression adapt reduce cost update simulation simulator model arc embed processor demonstrate approach highly accurate average error achieve fifty simulation subject performance model general term experimentation performance instruction set simulator performance prediction continuous statistical machine learn one introduction instruction set simulation frequently use method custom hardware instruction set allow design test hardware prior create prototype allow hardware much flexible approach design new device allow permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee nine copyright verification design large investment make allow performance device determine early process allow incremental design instruction set simulation provide flexible development platform test operation performance piece without access physical device also allow many concurrent program without need investment excessive quantity hardware due large vary use instruction set many different design exist range purely functional simulate operational output program underlie hardware completely take exact time model hardware provide precise performance metric simulation understandably design vary broadly speed information collect functional extremely fast due abstract away hardware detail collect various statistics much due much finer level detail simulate work drive vast difference speed instruction set relation underlie accuracy performance metrics example derive hardware typically operate per second compare million per second recent three nine ten greater one gip per second achieve purely functional performance gap several make functional attractive choice embed hardware however due abstraction away hardware provide statistical information full performance metrics desire recently hybrid emerge eleven combine functionality instruction single framework use hybrid simulator program execute either instruction mode user change instruction basic block typically feature use fast forward program mode region reach user decide collect detail local statistics use simulation mode eleven aim aim develop performance estimation methodology suitable integration hybrid retain much high speed simulation possible provide user detail accurate performance statistics entire application among paper development adaptive yet highly accurate performance estimation methodology enhance exist hybrid instruction set introduction continuous statistical machine learn incremental statistical regression feature selection instruction set simulation performance estimation evaluation simulator model commercial arc embed processor large range include industry standard twelve overview remainder paper structure follow section two introduce reader background hybrid regression base performance model introduce novel performance estimation methodology section three present result section four follow discussion large exist body relate work section five summarize conclude section six two background section present background material hybrid instruction set simulation technology statistical regression use performance estimation hybrid hybrid combine functionality single framework allow seamless transition simulation useful example mostly use fast simulation application development require occasional detail time specific work use simulator implement arc embed processor memory system six validate correspond hardware implementation simulator three main operation mode take instruction individually decode binary code compile hardware simulate decode instruction use update state processor attach ie cache memory cycle count provide mode similar previous mode execution implement additional time model take consideration pipeline memory effect cycle count provide mode execute block code time compile host machine execute natively hence result higher simulation rate cycle count provide addition different operation simulator sup port two hardware abstraction level behavioral structural behavioral mode simulate behavior instruction necessary update simulate register main memory simulate cache branch processor pipeline structural addition exact behavioral simulation instruction structural mode simulate detail state behavior processor pipeline cache branch predictor hardware abstraction level completely independent fact simulation require structural information whereas simulation operate behavioral structural mode simulation currently support behavioral mode simulation speed depend mode operation level hardware abstraction vary greatly simulation operate five million per second whereas simulation execute fifty behavioral structural mode respectively simulation reach highest simulation rat simulator change simulation mode time program execution work make use operation use structural information hence improvement simulation speed limit factor fifteen currently work performance estimation methodology suitable simulation however beyond scope paper statistical regression regression analysis statistical method examine relationship dependent variable n independent x relationship model function f f x function f choose depend considerably relationship input vector x output many different form regression analysis exist compute f include many linear nonlinear relationship x linear would choose linear regression model like zero n one zero n weight matrix calculation often choice independent input variable x subset total factor affect variable allow equation one approximation create predict value difference error prediction cause inadequate selection input potentially unrelated input minimize whenever possible error prediction call residual give train point n ym n extend original design matrix equation one consist equation system zero n n one ym zero n n zero three zero five six one twenty three four seven eight zero zero zero zero one twenty three four six seven eight zero c seven eight zero four zero five eighteen nine zero four three four c eighteen zero zero eight seven eight nine four four b four three four zero c zero eighteen zero seven eight e f g figure one sequential operation instruction set simulator continuous learn mode rewrite x vector regression weight matrix x model matrix process choose model must perform manner minimize regression function produce close actual value possible common method choose method minimize sum square prediction model observe data zero j two n two minimize compute value represent estimate regression thus calculation prediction point x involve application equation one theory linear least square simple calculate weight matrix follow x x three unfortunately expensive operation due calculation inverse variance matrix x x dependent upon size train data severely hinder performance especially weight matrix must update frequently due newly add train point incremental method prefer circumstance however exist research seven provide incremental linear learn describe section three calculation weight matrix also hinder easily variance matrix x x occur fairly easily instance train data contain large quantity zero value among circumstance either new train data must introduce feature select input matrix x must reduce three methodology novel method alternate phase fast detail simulation simulation phase performance model construct subsequently use performance estimation simulator operate mode employ continuous learn algorithm effort ensure accuracy make allow train data update confidence decrease prediction make use recent relevant train information also allow perform much smaller time slice ensure occur affect smaller section code previous work suffer statistical due large prediction block four combine learn prediction within simulation also assist train data current execution reduce error overview diagram figure one display operation simulator continuous learn mode show diagram simulator initially begin mode new train point add predictor enough point collect initial train matrix calculate simulation remain mode perform cycle count every time slice prediction accuracy confidence check prediction inaccurate confidence interval prediction high last time slice add train data prediction matrix update error confidence interval drop threshold simulation switch mode rely purely upon confidence interval prediction monitor every prediction become high simulator fall back mode one two describe next section simulator continue run mode update train data per time slice attempt error ratio confidence prediction drop simulator return mode continue number confident occur time slice make increase attempt gain performance gain confidence interval widen far time slice reduce allow train across finer grain describe section incremental linear regression standard linear regression algorithm well suit train data point add calculation weight matrix expensive operation involve inversion potentially large matrix calculate variance matrix train data occasion update train matrix necessary calculation involve recalculation weight matrix use entire train data set alternatively research perform incremental version calculate weight matrix seven alternative linear regression algorithm still require initial calculation weight matrix however optimize process add new data point update weight matrix initially calculate process one data involve initially update variance matrix x x include new train point variance matrix hereafter refer optimize two ways dependent upon number train point add one method single update matrix involve calculation inverse matrix another method multiple train point add train set single add train point update variance matrix calculate one one x one x four five six seven x correspond row newly add train point give already calculate initial fit weight matrix requirement recalculation allow optimization algorithm case multiple sample add train data add train point individually use equation four would result computation necessary hence alternative equation show use one one one x one x one one one method still calculate inverse matrix update variance matrix however size matrix invert one x one one much smaller less expensive perform across entire data set update variance matrix calculate weight matrix regression function update show one x x represent column vector output variable newly add train point future use update weight matrix equation one feature selection purpose feature selection determine subset relevant feature train data number possible feature selection available help choose feature affect cycle count continuous learn simulator necessary feature selector relevant feature likely different also help prevent issue singular matrix calculation weight matrix equation three calculation relevant feature perform every time train data update potentially require recalculation train matrix list relevant feature change new train point update matrix use standard incremental linear regression however change relevant feature require complete recalculation train matrix reason threshold decide feature relevant must set feature selection change infrequent ensure relevant feature keep addition stability choose feature set feature selection algorithm require efficient possible repeat execution contribute overall time simulation reason sum nonzero value within feature choose allow easily determine threshold use sum maintain train update remove need repeat pass data set deal less confident prediction less confident prediction occur threshold situation handle two distinct fast patch scheme conservative rollback replay scheme patch simulator accept less confident prediction fall back mode update train matrix base upon next time slice simulator accept less confident prediction simulation roll back previously know state ie last time slice begin rerun simulation mode update train matrix necessary first method simply use result less confident normal follow patch train data future whereby second method rely upon less confident prediction ensure accuracy time slice theoretically second method provide accurate result degrade performance roll back simulator performance degrade may prove expensive lack accuracy first method implementation scheme base exist facility simulator modify store simulation state memory rather external storage addition implement mechanism reduce overhead associate regular simulation state alter time slice length aid performance simulator possible make across differ time slice allow simulator train short time slice make higher time slice exploit feature simulator initially train short time slice perform number length time slice stay within confidence level time slice increase factor ten make much less frequent allow greater performance benefit make across number time slice confidence interval monitor allow time slice increase regular manner higher limit provide remain accurate confident enough exceed maximum confidence interval time slice decrease factor ten lower limit retrain commence core pipeline execution order branch prediction memory system cache cache simulation simulator io system call development tool compiler compiler arc interlock yes data none yes arc simulator default emulate suite description sweet small small automotive consumer digital entertainment network office cryptography audio process table four overview suit table one overview simulation target four empirical evaluation section discuss empirical evaluation start overview experimental setup methodology provide general overview result go discuss effect modify time slice length number make confidently time slice incremental linear regression prediction scheme next discuss simulation use patch scheme beyond statistical information collect individual simulation calculate several metrics determine approximate accuracy new methodology percentage mean absolute error mae maximum error total configuration experimental setup methodology simulator configuration use hybrid instruction set simulator ten arc embed processor table one detail processor simulate configuration simulator table two list counter maintain simulator provide predictor train prediction counter description instruction counter total total read total dirty miss total branch prediction table two counter maintain instruction set simulator simulation host system perform distribute across approximately eighty one per computer time table three list system simulation host machine core two quad processor cache cache main memory operate system scientific kernel eight share six table three simulation host table four list suit use evaluation performance estimation methodology suit total separate experimental methodology experiment perform sequence initial simulation follow new simulation method two modify inside simulator across initial length time slice number perform time slice prior increase length modify ten respectively increase factor ten perform patch total separate entire suit ensure accurate read execution time difference standard simulation new simulation method simulation perform simulation immediately follow new method method involve rerun simulation entirety however minimize noise stack computer result follow paragraph present result different initial simulation time slice number confident switch fast simulation follow result patch scheme show result highlight minimal overhead performance estimation scheme figure two illustrate accuracy expect statistical performance estimation scheme estimate cycle count time slice length compare actual observe cycle count set value plot scatter graph figure two program vary several order magnitude total execution time scheme highly accurate come close actual value see proximity data point near ideal straight line figure two b distribution estimation error show vast majority center closely around zero error mark virtually fall two interval correspond error margin less eleven new method train period initial bottleneck simulation fact shorter hinder performance easily render new simulation scheme benefit useless alter initial time slice length shorten train period allow train matrix fill finer grain data perform across three two two three n c l e c c e c e r p zero one e one eight zero e one six zero e one four zero e one n e zero zero one zero eight zero six zero four zero two zero three two one zero one two three observe cycle count error ratio estimate observe cycle count b distribution estimation error figure two accuracy estimate cycle count initial length block initially examine performance benefit method examine accuracy percentage useful display figure three relative show figure four graph display useful clear shorten original time slice desire effect allow begin early simulation process however also noticeable performance benefit cycle original time slice certain start perform worse inspection point imply make simulator either outside error margin low confidence solve alter however would increase error still cause performance degrade cycle original time slice provide best performance benefit general higher value less performance benefit apparent level clear performance simulator begin increase beyond cycle fifteen figure five show distribution error ratio modify original time slice length additional line show two three represent expect respectively line error distribution show majority lie five increase original time slice decrease average error mae start time slice however due performance issue introduce high start time slice mae maximum start time slice preferable instruction time slice mae still maximum error vary number confident time slice increase tweak performance simulator low quantity ten increase time slice predictor train accurately enough extra train point would normally add predictor lose confidence miss cause low number valid render new method useless shorter cycle find value confident increase time slice optimal feature selection greatly reduce number feature consider performance model example show final set select feature show table five alter number confident vary number confident increase tweak performance simulator figure seven display amount accurate confident vary quantity increase length show eight alter number confident dramatic effect performance simulator low quantity ten increase predictor train accurately enough extra train point would normally add predictor lose confidence miss cause low number valid render new method useless shorter cycle increase value simulator start receive performance increase cycle cache add sub min ex total count instruction cache read hit data cache read hit branch predictor branch prediction unit hit branch prediction unit miss table five select feature n c e r p l v f e g n e c r e p p e e p zero zero one zero eight zero six zero four zero two zero five one zero one five zero zero zero n c e r p l v f e g n e c r e p p e e p zero zero one zero eight zero six zero four zero two zero five one zero one five zero zero zero observe cycle count observe cycle count length b length figure three percentage useful different time slice observe cycle count observe cycle count length b length figure four impact time slice length relative n e n e zero zero one zero eight zero six zero four zero two zero zero zero one zero eight zero six zero four zero two zero three two two three three two two three three two one zero one two three two one zero one two error ratio error ratio length b length figure five impact time slice length distribution estimation three two two three three two two three n e n e zero zero one zero eight zero six zero four zero two zero zero zero one zero eight zero six zero four zero two zero three two one zero one two three two zero two error ratio patch scheme error ratio b scheme figure six error patch scheme n c e r p l v f e g n e c r e p zero zero one zero eight zero six zero four zero two zero n c e r p l v f e g n e c r e p zero zero one zero eight zero six zero four zero two zero observe cycle count ten observe cycle count b figure seven percentage useful alter number confident increase fifteen time longer beyond however detrimental performance smaller overall performance gain longer less confidently predict block mode accuracy predictor intend increase however prove see figure six less confident block little effect error predictor create slightly worse performance majority hand add overhead result noticeable performance penalty see figure four asymptotic fifty reach execute improvement close theoretical achieve simulation see section two small less benefit scheme spend entire execution train mode however critical size simulate within less even use available mode simulation sum nonzero value feature selection incremental linear regression low computational complexity suitable performance model fact profile extend simulator reveal overall execution time spend update performance model hence make contribution negligible performance improvement may achieve use faster behavioral simulation mode maintain state cache even use simulation maximum performance outside train however beyond scope paper part future work performance estimation scheme display fifty mae maximum error best prove shorter original time slice effective allow shorter receive performance benefit without adversely affect longer also prove variable prediction time slice pose additional performance benefit without severely affect error however increase quickly prevent predictor receive adequate train data negate performance benefit also little benefit rerun less confident prediction block mode ensure accuracy simulator gain adequate performance benefit compare prior work area comparable mae significantly better maximum error better four use comparable processor five relate work relevant simulation base performance estimation five smart eleven tool aim support processor architect explore processor design space make inform design contrast aim support fast instruction set equip accurate time model five choose simulation point use phase classification algorithm calculate phase pair use cluster choose single representative phase estimate remain perform detail program analysis simulation choose representative contrast method rely phase classification algorithm work perform addition entire application execute current input processor state inspect purpose point throughout simulation finally offer quantifiable confidence performance estimate smart eleven framework apply statistical sample accelerate simulation employ systematic sample measure small portion entire application simulate similar work smart p e e p five one zero one five zero zero zero p e e p five one zero one five zero zero zero observe cycle count ten observe cycle count b figure eight relative alter number confident increase simulator use two simulation detail functional sample systematically fix interval contrast employ adaptive scheme time slice variation time eliminate need repeat detail sample confidence high addition approach adaptive temporal change capable readjust underlie performance model use continuous statistical machine learn scheme one two eight four suggest machine learn performance estimation either lack comprehensive evaluation one two fail achieve acceptable level accuracy eight four six paper develop novel simulation base performance estimation methodology use continuous statistical machine learn build top exist hybrid simulator technology enable accurate cycle count program execute mostly fast nondetailed simulation mode hence achieve fifty simulation cost modest average estimation error future work include store prediction model would allow simulator start make start execution hence remove initial train period furthermore currently extend performance estimation methodology work faster even simulation mode offer simulator use paper seven reference one j r e w l performance estimation design tool proceed cod zero two g w data analysis method performance prediction proceed date two three j w construct portable compile approach proceed date six four b fast instruction set simulation proceed workshop embed eight five g e j b thirty faster flexible program analysis proceed workshop model simulation six n high speed simulation use dynamic binary translation proceed conference high performance embed seven j introduction radial basis function network technical report cognitive science university eight f f r accurate performance estimation use domain classification neural network proceed four nine p n hybrid compile simulation efficient technique architecture simulation embed compute eight three ten n high speed simulation use binary translation proceed annual workshop model simulation hold conjunction san eleven r e f b j c hoe smart accelerate simulation via rigorous statistical sample proceed annual international symposium computer architecture