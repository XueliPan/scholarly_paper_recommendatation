fabric construct resilient multicore amin advance computer architecture laboratory university michigan ann arbor mi shoe abstract scale feature size long source dramatic performance gain however reduction voltage level able match rate scale lead increase operate current give plague semiconductor highly dependent significantly higher failure rat project future technology consequently high reliability fault tolerance traditionally subject interest server market get emphasis embed space popular solution use redundancy coarse granularity modular redundancy work challenge practice redundancy identify inability scale high failure rate investigate advantage end paper present evaluate highly multicore architecture name design reliability first class design criteria rely network replicate processor pipeline stag maximize useful lifetime chip gracefully degrade performance towards end life result show propose architecture perform nearly fifty cumulative work compare traditional multicore one introduction technological trend regime lead increase current power rise result increase transient well permanent rat lead technology warn device reliability begin deteriorate node onward eight current indicate future compose many unusable manufacture time many degrade performance even fail expect lifetime processor ten effort assuage concern industry initiate shift towards multicore inspire design employ simpler core limit power thermal envelope chip however paradigm shift also lead towards core design little inherent redundancy therefore incapable perform possible big core thus near future must directly address reliability computer innovative source computer system widespread range transient fault due energetic particle strike electrical noise permanent cause phenomenon thirteen time dependent breakdown recent industry invest effort build resistant transient fault contrast much less attention pay problem permanent fault specifically transistor due degradation semiconductor time traditional deal transistor involve extra provision logic circuit know account expect performance degradation time however increase degradation rate project future technology imply traditional margining insufficient challenge tolerate permanent fault broadly divide three requisite task fault detection fault diagnosis system fault detection nine five use identify presence fault fault diagnosis fifteen twelve use determine source fault ie break component system recovery need leverage form spatial temporal redundancy keep faulty component isolate design example many computer provide ability repair faulty memory cache inclusion spare memory recently begin extend support spar additional branch eleven register granularity maintain determine number system tolerate focus work understand issue associate system recovery design fault tolerant architecture capable tolerate large number traditionally system recovery mission critical address use dual redundancy seven however approach costly therefore applicable embed recent popularity multicore traditional approach able leverage inherent redundancy present large chip one however historical design modern emphasis redundancy incur high hardware overhead tolerate small number defect increase defect rate semiconductor technology uncommon see rapid degradation throughput single device entire core decommission often time majority core still intact functional contrast paper argue case redundancy finer granularity end work present fabric highly adaptable multicore compute substrate multicore architecture design network pipeline stag rather isolate core network form replace direct pipeline stage boundary crossbar switch interconnection within architecture pipeline stag select pool available stag act logical process core logical core architecture refer easily isolate adaptively rout around faulty stag interconnection flexibility system allow salvage healthy stag adjacent core even make possible different scarce pipeline resource add flexibility system possess inherent redundancy borrow share pipeline stag therefore else equal capable maintain higher throughput duration system life compare conventional multicore design time fail system gracefully degrade performance maximize useful lifetime flexibility architecture cost associate introduction network switch heart processor pipeline inevitably lead poor performance due high communication low communication stag key create efficient design rethink organization basic processor pipeline effectively isolate operation individual stag specifically interstage communication must either remove namely break loop design volume data transmit must reduce paper start design efficient logical core attack reduce performance overhead network switch acceptable level present complete architecture stitch together multiple form highly architecture capable tolerate large number work take simple core design basis architecture motivate fact thermal power push design towards simpler core furthermore adopt design target massively multicore chip suitable high throughput time believe propose design methodology also effectively apply aggressive pipeline design primary paper include one design space exploration resilient two design evaluation network pipeline three design evaluation resilient multicore architecture compose use multiple two granularity tolerate permanent fault must ability refer variety range decommission noncritical processor structure swap cold spare architecture recovery entail isolate defective module incorporate spare structure need support achieve various grain ability replace individual logic gate design focus isolate entire processor core choice present complexity implementation potential lifetime enhancement section show experiment study draw upon result motivate design architecture overlay core area power clock frequency data cache size instruction cache size technology node eight eight b implementation detail figure one embed experimental setup order effectively model reliability different design model core use lifetime reliability experiment core conventional pipeline design representative commercially available embed core synthesize place rout use industry standard cad tool library characterize process final along several attribute design show figure one study impact granularity chip calculate individual module determine estimate effect common mechanism dielectric breakdown core run representative employ empirical model similar find equation one present formula use calculate temperature number generate use nineteen one v e x one v operate voltage temperature k constant b x z fit base granularity trade off granularity use describe unit within chip various order increase granularity discuss one gate level level system replace individual logic gate design fail unfortunately design typically impractical require precise fault diagnosis tremendous overhead due redundant wire rout area two module level scenario processor core replace break structure branch predictor design active research sixteen biggest downside level replacement replacement replacement f n e e r c n n e c r e p zero zero fifty percent area overhead figure two gain addition cold spar granularity pipeline stag processor core gain show cumulative spare add denote order expect fail maintain redundancy full coverage almost impractical additionally case simple core even exist isolation since almost unique design three stage level entire pipeline stag treat single monolithic replace level challenge one pipeline stag tightly couple performance loss two cold spar pipeline stag expensive area overhead four core level level entire processor core isolate system event failure core level also active area research one perspective system designer probably easiest technique implement however return term lifetime extension therefore might able keep increase defect rat multiple level granularity could figure two demonstrate effectiveness apply isolation include study figure show potential lifetime enhancement measure function much area designer will allocate cold spar redundant structure take n time base overall system take fail module design similar serial model failure use figure overlay three separate plot one level redundant spar allow add much area overhead data show figure two demonstrate go towards categorically beneficial far gain concern overlook design complexity aspect problem tend exacerbate hardware challenge support redundancy logic wire overhead circuit time management time coarse grain also ideal candidate since scale poorly area overhead therefore compromise solution desirable one manageable hardware better life expectancy stage level position good candidate system recovery scale well increase area available redundancy figure two logically stag convenient boundary pipeline divide work level stag fetch decode similarly term circuit implementation stag intuitive boundary data signal typically get latch end every pipeline stage factor helpful desire minimum impact performance however two major must overcome stage level practical one pipeline stag tightly couple therefore difficult two maintain spar pipeline stage granularity area intensive one ways allow stage level pipeline stag word remove direct communication stag replace switch base interconnection network figure eight call design processor core within design part high speed stage processor pipeline correspond node network horizontal slice architecture equivalent logical processor core call use switch allow complete flexibility pipeline stage depth n communicate stage depth even different architecture overcome major stage level pipeline stag hence faulty easily isolate furthermore need exclusively devote chip area cold spar architecture exploit inherent redundancy present multicore stag adjacent core nod stag eventually fail exhibit graceful degradation performance gradual decline throughput along benefit architecture certain area performance associate area overhead primarily arise switch interconnection network stag depend upon switch variable number cycle require transmit stag lead performance remainder paper investigate design practical architecture start single three overview basic build block architecture consist pipeline allow convenient granularity stag basis design simple embed processor core use consist five stag namely fetch decode issue three four see figure three although block sometimes separate multiple stag treat single stage work start basic pipeline design figure three go step transformation first step pipeline latch replace combination crossbar switch buffer graphical illustration result pipeline design show figure three b shade box inside pipeline stag discuss detail later section minimize performance loss interstage propose use full branch feedback forward register fetch h c l decode issue h c l h c l register file h c l gen branch predictor pipeline branch feedback register e l b r e f f b fetch gen branch predictor e l b r e f f b packer decode e l b r e f f b e l b r e f f b register file scoreboard issue e l b r e f f b e l b r e f f b bypass e l b r e f f b b pipeline stag interconnect use full crossbar switch shade portion highlight present regular pipeline figure three traditional pipeline design crossbar switch since allow nonblocking access input b small number input output prohibitively expensive full crossbar switch fix channel width result transfer instruction one stage next take variable number cycle however channel width crossbar vary performance area addition forward data path pipeline feedback loop also need go similar switch need context complete architecture different share stag thus require exchange branch result instance result say execute stage might need direct b issue stage due introduction crossbar switch three fundamental challenge overcome one global communication global pipeline signal fundamental functionality pipeline stall signal send stag case multicycle memory access hazard similarly flush signal necessary squash fetch along control stag global broadcast infeasible two forward data forward crucial technique use pipeline avoid frequent stall would otherwise occur data instruction stream data forward logic rely precisely time architectural sense communication execute later stag use combinational link variable amount delay switch presence intermediate buffer forward logic within feasible three performance lastly even two solve communication delay stag still expect result hefty performance penalty rest section discuss design overcome challenge section also propose recover expect loss performance section functional need stream identification pipeline lack global communication signal without global signal traditional approach flush upon branch applicable first addition basic pipeline stream identification register target problem design show figure three b certain shade order distinguish find traditional pipeline one additional stream identification register stag single bite register arbitrarily consistently across stag initialize zero one course program execution value change whenever branch take place every instruction carry stream id use stag distinguish correctly predict path incorrect path former process allow proceed latter squash single bite suffice pipeline model one resolve branch outstanding give time follow branch squash word stream id work cheap efficient mechanism replace global branch signal detail register value modify discuss basis fetch every new instruction stamp current value store register branch detect use branch update stage toggle register flush program counter point onwards fetch stamp update stream id decode register update stream incoming cycle old stream id store decode match stream id incoming instruction branch imply decode flush instruction buffer issue maintain register along additional register register update use stream id instruction perform register value update stream id last successfully issue instruction instruction reach issue stage stream id compare register value match eligible issue mismatch imply branch recent past knowledge require determine whether new incoming instruction correct path incorrect path register become important mismatch new instruction stream id indicate new instruction correct path execution hence eligible issue match imply otherwise new instruction squash complete significance make clear later section compare stream id incoming register event mismatch instruction squash branch instruction toggle stream id along register value store branch resolution information send back fetch stage initiate change register value branch instruction also update issue stage thus cycle update complete summarize normal operate condition ie go switch interconnection fabric get issue execute write back compute result occur use stream id mechanism incorrect execution path systematically squash time scoreboard second component require proper functionality scoreboard reside issue stage scoreboard essential design forward unit normally handle register value feasible often scoreboard already present pipeline issue stage hazard detection scenario minor need tailor conventional scoreboard need pipeline pipeline need scoreboard order keep track register result outstanding therefore invalid register file one input register invalid stall issue stage scoreboard table two see figure seven c first maintain valid bite register second store id last modify instruction case branch scoreboard need wipe clean since get pollute wrong path execution recognize issue stage maintain register store stream id last issue instruction whenever issue stage find new incoming instruction stream id differ know branch take place point scoreboard wait receive receive already branch instruction branch instruction easily identify bear stream id new incoming instruction finally wait period scoreboard clear new instruction issue network flow issue stall automatically handle maintain network back pressure switch interconnection crossbar forward value buffer subsequent stage stage stall similar way network queue handle stall implementation guarantee instruction never drop throw away buffer base system transfer latency variable double buffer standard technique use make transfer latency overlap job cycle producer consumer stag input output latch double buffer enable optimization performance enhancement discuss previous section bring design point functionally correct order compare performance basic design pipeline figure three conduct experiment use two four six eight e n r e z l r n six five four three two one zero three e g g seven two seven two one one e id c p c one r r w w r c four v b el e r el g e one eight one e q n g r e p w c v c f e r g e e c n c e e c embed figure four pipeline compare pipeline without bypass cache slowdown see issue stage stall reduce size bypass cache increase accurate simulator develop liberty simulation environment basic imply configure stream identification logic scoreboard double buffer interest find detail simulation setup section performance comparison show comparison first second bar figure four result normalize processor average slowdown observe price pay return flexibility however version design much leave table term performance performance lose stall due one absence forward two transmission delay switch bypass cache due lack forward logic frequent stall expect register alleviate performance loss add bypass cache stage see figure seven cache store value generate recently execute within stage follow use cache value need stall issue wait fact cache large enough result every instruction issue write back retain would completely eliminate stall arise register emulate forward logic fifo replacement policy use cache older less likely produce result incoming instruction scoreboard unit issue stage make aware bypass cache size system first configure whenever number outstanding register scoreboard become equal cache size instruction issue stall case instruction issue input guarantee present within bypass cache hence scoreboard accurately predict whether bypass cache vacancy store output current instruction furthermore issue stage perform selective register operand fetch value go available bypass cache issue stage reduce number need transfer stage evident experimental result figure four addition bypass cache result dramatic overall performance biggest improvement come configuration without bypass cache second bar one bypass cache size two third bar improvement diminish saturate beyond eight average slowdown hover around addition bypass cache still high crossbar width crossbar channel width number bite mop three mop four mop five mop six e n r e z l r n two fifteen one five zero e n r e z l r n sixteen fourteen twelve one eight six four two zero three g seven g seven e two two one one e id c p c one r r w w r c four v b el e r el g e one eight e q one n g r e p w c v c f e r g e three e g g seven two seven two one one e id c p c one r r w w r c four v b el e r el g e one eight one e q n g r e p w c v c f e r g e e c n c e e c embed e n c c e e c embed figure five pipeline variation transmission expect performance improve higher transmission figure six bypass cache capability handle mop compare pipeline second bar mop size fix one bar constraint number transfer crossbar single cycle context determine number cycle take transfer instruction stag result present far section crossbar channel width figure five illustrate impact vary width performance three data point present every channel width channel width infinite channel width large performance gain see go width width infinite essentially mean eliminate transfer latency stag result performance comparable crossbar switch average slowdown macro performance design suffer significantly overhead transfer stag since every instruction go switch network variable amount delay natural optimization would increase granularity communication bundle multiple mop two advantage one work multiple available stag work next mop transmit two eliminate temporary intermediate value generate within small sequence therefore give illusion data compression underlie interconnection fabric identify statically compile time dynamically hardware keep overall hardware overhead low form statically compiler approach involve select subset belong basic block bound two one number two number use simple greedy policy similar fourteen maximize number minimize number form mop long computation time stag bring closer transfer time interconnection win compiler embed mop internal data flow information program binary decode stage packer structure responsible identify assemble mop leverage hint embed program binary packer assign unique mop id mid every mop flow pipeline stag also slightly modify order work mop instead simple particularly true stage controller cycle across individual comprise mop execute sequence performance result show figure six bypass cache switch channel width mop various bar plot different mop selection algorithm result show beyond certain limit relax mop selection result performance improvement prior reach limit relax help form longer mop thereby balance transfer time computation time beyond limit relax result longer mop instead produce mop increase transfer time without actually increase number distinct encode best case result embed slowdown equivalent slowdown worst poor branch prediction rat fact performance find strongly correlate number per thousand expect use mop additional cycle spend data transfer stag cause behave like deep pipeline stage section go pipeline stag sum add fetch make restrict addition register small amount logic toggle upon branch figure seven decode decode stage figure seven b collect fetch buffer instruction buffer common structure find pipeline design add register incoming instruction different stream id register toggle instruction buffer flush decode stage also augment packer packer logic read buffer identify mop assign mid fill mop structure attribute length number register name issue issue stage figure seven c modify include scoreboard track register mop ready issue register file read populate issue stage also maintain two register order identify branch flush scoreboard appropriate time stage figure seven house bypass cache emulate job forward logic stage also first update register upon branch order handle mop execution controller modify walk mop one time one execution per cycle instruction buffer incoming branch resolution handler next predict next x update branch predictor fetch controller response request fetch mid packer logic outgo macro b decode branch resolution incoming macro macro latch incoming macro macro latch reg id valid last mid last zero one two sixty zero one one zero one one zero one seventeen seventeen register issue controller c issue scoreboard register file outgo macro counter ex mem controller functional unit reg id reg value outgo macro bypass response request figure seven pipeline stag gray block highlight add transform traditional pipeline time compute result save bypass cache later use switch rout table four multicore fabric present last section complete solution allow pipeline stage level maintain cold spar stag likely fail design achieve lifetime enhancement target project figure two however gain greatly amplify without cold spar cost use multiple build block architecture high level abstraction combination design form basis fabric figure eight final design highly multicore fabric capable arbitrarily use pipeline stag form logical two prominent hardware structure within architecture one interconnection switch role switch direct incoming mop correct destination stage task maintain static rout table address use thread id mop thread id uniquely determine destination stage current form allow thread use two stag type circumvent danger single point failure multiple switch maintain fabric two configuration manager give pool stage configuration manager divide logical logic configuration manager better suit implementation since one access infrequently two flexibility available experiment resource allocation configuration manager design module occur trap send interface initiate update event stage failure architecture initiate recovery combine live stag different slice ie salvage healthy form logical refer stage borrow section addition underlie stage design permit stag two distinct instance pair even one lose issue stage still run separate thread share single live issue stage refer stage share section stage borrow pipeline stage failure system call upon configuration manager determine maximum number full logical form use pool live stag full imply exclusive access exactly one stage type number form configuration manager determine stage live instance example figure eight top three minimum two stag alive type thus two logical form logical slice highlight use shade path indicate flow instruction stream noteworthy top three figure eight least one fail stage therefore multicore system similar situation would lose three hence ability efficiently borrow stag different slice give competitive edge traditional multicore stage share stage borrow good enough certain failure example first stage failure fabric reduce number logical one however stag multiple number logical maintain figure eight bottom two figure eight architecture form use five example scenario lightning bolt indicate break stag four operational extract show transparent share issue stage number logical share single stage tune implementation share beneficial thread involve present interleave execution therefore thread high per cycle expect derive lesser benefit compare low thread furthermore degree stage share increase benefit expect shrink since thread available stage order stag shareable certain hardware also require fetch need maintain separate program counter thread memory access instruction cache turn also share implicitly execute thread decode instruction buffer partition different thread issue scoreboard register file populate state value specific thread trivial share two ways handle share structure one compile thread register two use hardware structure register cache evaluation implement register cache hardware share across multiple thread bypass cache statically partition thread similarly data cache get share thread configuration manager invoke whenever stage resource develop defect system depend upon degree stage share determine number logical form configuration manager also configure stag need share partition accordingly thread work higher share configuration manager employ fairness policy resource allocation work thread get evenly divide among stag example five thread need share three live stag type fairness policy prefer configuration two thread stag one two remain one stage three configuration three thread stage one one stag two three detail regard resource allocation omit space reason five result discussion simulation setup evaluation infrastructure fabric consist three major one compilation framework two architectural simulator three monte simulator lifetime throughput total fourteen select embed application emphasis embed base embed core variety use include several encryption audio process process addition four also include order exhibit potential architecture use compilation system forty first component mop selection algorithm implement compiler pass intermediate code representation pass code augment mop miscellaneous attribute final code generate compiler use twenty architectural simulator evaluation develop use liberty simulation environment functional emulator also develop within system two flavor simulator implement sufficient detail provide cycle accurate result first simulator model simple five stage pipeline also experiment second simulator implement architecture propose table one list common attribute third component simulation setup monte engine employ lifetime throughput study iteration monte process simulate lifetime architecture configuration architecture specify table one various stag switch system calculate use equation eleven crossbar switch peak temperature take perform interconnection model raw multicore chip stage extract core ambient temperature normalize one use calculate use mean generate time failure module system iteration monte system get lifetime whenever failure introduce instantaneous throughput system compute new configuration use architectural simulator multiple random obtain system throughput lifetime nearly run conduct monte study base core base multicore branch unify memory pipeline double buffer crossbar switch five core five five redundant crossbar switch configuration manager global history predictor size sixteen one cycle hit latency five cycle hit latency forty cycle hit latency table one architectural attribute simulation result lifetime performance benefit simulation result gather separately embed figure nine show lifetime throughput result multicore compare various architecture run embed system start performance advantage architecture however accumulate time throughput overtake performance thereafter remain dominant instance year seven nearly shade portion figure depict cumulative distribution function combine instance plot show ten average twelve fail system similar throughput see figure nine c figure nine b show cumulative performance total work do various configuration compare end lifetime achieve much fifty improvement work do fabric forty achieve stage borrow additional ten benefit result stage share furthermore go share higher share yield negligible improvement expect result overlap diminish contention stage increase figure nine cumulative performance stand forty overall exhibit lesser benefit embed result follow trend see figure six area overhead area overhead arise additional structure add fetch stage qualify ten conservative estimate actual module level value available public source interconnection fabric compose crossbar switch area overhead show use core see section area number scoreboard bypass cache register cache estimate take similar structure core resize appropriately scoreboard area estimate base register file bypass cache register cache base area also associative structure finally area double buffer base maximum size store size structure do accordance configuration achieve best performance crossbar switch area base model total area overhead design fifteen design block synthesize place rout use industry standard cad tool library characterize process area overhead separate crossbar switch show figure ten total area overhead system compare multicore show figure ten b although investigate impact change circuit critical change primarily impact pipeline depth due additional buffer hence expect measurable influence cycle time compare design block scoreboard bypass cache register cache double buffer crossbar switch area percent overhead eighteen fourteen area crossbar switch configuration percent overhead without share share b total area overhead figure ten area overhead architecture six relate work concern reliability issue future technology spawn new wave research recent work address entire spectrum reliability fault detection diagnosis system repair recovery section focus relevant subset recent work propose tolerate adapt presence fault server design reliability design constraint around typically rely coarse grain replication provide high degree reliability seven tandem nonstop six seventeen two stratus six however dual triple modular redundant incur term area power furthermore still remain susceptible since tolerate high failure rate elastic slightly different architectural vision fault tolerance exploit circuit monitor health individual core author propose dynamic reliability management throttle even multicore without share share share share multicore without share share share share five ten fifteen twenty five ten fifteen twenty zero zero zero monte result embed time b cumulative performance result embed time multicore without share share share share multicore without share share share share thirty twenty fifteen ten five e h c w n e g e l f f r e b n thirty twenty fifteen ten five e h c w n e g e l f f r e b n two fifteen one five e c n r f r e p e v l c e z l r n two fifteen one five e c n r f r e p e v l c e z l r n c p p h g r h c p p h g r h fifteen three two one five zero zero fifteen three two one five zero zero five ten fifteen twenty five ten fifteen twenty zero zero zero c monte result time cumulative performance result time figure nine throughput cumulative performance result architecture plot c also show shade portion expect number fail point lifetime turn core age time elastic rely upon redundancy management core level similar isolation one within framework system must provision massive number redundant core face prospect rapidly decline process throughput single fault disable entire core much work also do redundancy maintenance bulletproof sixteen spar array structure eleven structure scheme typically rely inherent redundancy core also extremely hard achieve full coverage nevertheless approach leverage system additional benefit apply redundancy management finer granularity research focus build reliable future expect inherently processor grid design recursive system black box employ unique fault tolerance project boast amount defect tolerance come overhead term redundant structure differ dramatically previously propose goal minimize amount hardware use solely redundancy importantly enable granularity pipeline stage make possible single core tolerate multiple much lower cost work extension eighteen explore potential pipeline stage level context single parallel al thirty propose multicore architecture core cannibalization architecture also exploit stage level allow subset lend stag break thereby avoid full crossbar interconnection unlike maintain feedback link avoid major change although design reduce overall complexity exist compare seven conclusion technology continue evolve must employ counter effect ever demand reliability challenge fault detection diagnosis must leverage together form comprehensive solution problem unreliable silicon work contribute area recovery propose radical architectural shift processor design motivate need network pipeline stag identify effective cost reliability enhancement although performance suffer first result change basic pipeline able reclaim much lose ultimately fabric exchange modest amount area overhead fifteen return highly resilient multicore fabric yield fifty work lifetime traditional multicore process like use combat time upcoming technology high defect rat manufacture time beyond also employ yield finally distant future carbon likely need use conjunction combat high failure rat hence fabric well position withstand rapidly increase device failure rat expect future technology nod eight thank assistance liberty simulation environment help cadence encounter also gratitude go anonymous referee provide excellent feedback work research support arm national science foundation grant research center one five research center fund focus center research program semiconductor research corporation program nine reference one n p n p j e smith isolation build high availability commodity multicore annual international symposium computer architecture page enable compact energy efficient chip notice eleven k v recursive processor grid reliable system architecture unreliable international conference dependable network page june p k k multithreaded processor micro two w lee r frank j v sarkar schedule parallelism raw machine eighth international conference architectural support program operate page li p v diagnosis permanent hardware fault international conference dependable network june comprehensive error detection simple core micro one w dally delay model speculative architecture international symposium computer architecture page two r r j carter w b p g integrate custom compute international symposium custom compute machine page processor implement register cache international conference page three arm four arm five diva reliable substrate deep submicron design annual international symposium page six w l commercial fault tolerance tale two dependable secure compute one one seven b p r j j nonstop advance architecture international conference dependable network page june eight k scale tutorial presentation nine j detection annual international symposium page ten design reliable unreliable challenge transistor variability degradation micro six eleven f bower p g j tolerate hard fault array structure international conference dependable network page twelve f bower j mechanism diagnosis hard fault annual international symposium page thirteen electronic device degradation sons fourteen n clark scalable map acyclic computation international conference architecture synthesis embed page fifteen k v detection hardware defect architectural support evaluation annual international symposium page sixteen k plaza j b v bulletproof switch architecture international symposium computer architecture page seventeen w r r carter p g defect tolerance custom computer international symposium custom compute machine page eighteen j build block resilient international conference architecture synthesis embed nineteen w r k k compact thermal model method large scale integration fourteen five may twenty v b architecture specification version eleven technical report n r k use stack technology thirty b f j core cannibalization architecture improve lifetime chip performance multicore processor presence hard fault international conference parallel compilation l l n k network micro p c exploit redundancy defect tolerance international conference computer design page r reliable computer design evaluation edition ak j j kim j hoe b efficient resource share concurrent error detect annual international symposium page j c b gold b j c hoe reunion multicore redundancy annual international symposium page l parallel enterprise server fault tolerance historical perspective journal research development six j v p bose j case lifetime annual international symposium computer architecture page june j v p bose j exploit structural duplication lifetime reliability enhancement annual international symposium computer architecture page june sylvester e elastic adaptive architecture unpredictable silicon journal design test six forty infrastructure research n j malik august liberty simulation environment deliberate approach system model computer three j g h j singh v e c n processor international circuit conference page estimation likelihood capacitive couple noise design conference page c weaver fault tolerant approach design international conference dependable network page computer society stratus computer system resilient compute e j w lai e interplay voltage temperature acceleration oxide breakdown gate electronics j terrestrial cosmic ray journal research development one