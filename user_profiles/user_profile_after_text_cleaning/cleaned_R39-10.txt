armor cache high defect density amin advance computer architecture laboratory university michigan ann arbor mi shoe abstract aggressive technology scale introduce serious reliability challenge design large structure use cache particularly sensitive process variation due high density organization typically overprovision cache additional overcome however static allocation bind redundant result low utilization extra ultimately limit number defect tolerate work design process variation tolerant cache focus flexibility dynamic allow large number defect tolerate modest hardware overhead approach combine redundant data array permutation network provide higher degree freedom replacement graph color algorithm use configure network find proper map replacement perform extensive design space exploration cache identify several optimal yield analysis population chip study technology node design sixteen design eight area achieve yield respectively subject memory structure reliability test general term design reliability process variation cache manufacture yield one introduction technological trend regime lead increase vulnerability manufacture part process variation host factor lithography line edge permission make digital hard copy part work personal classroom use grant without fee provide copy make distribute profit commercial advantage copy bear notice full citation first page copy otherwise republish post redistribute list require prior specific permission fee micro nine new york copyright roughness random fluctuation result wide distribution transistor directly translate lower parametric yield seven divergence process nominal specification limit achievable frequency also significantly hurt leakage power modern high performance efficiency technology questionable face challenge current indicate future compose many unusable manufacture time many degrade performance even fail expect lifetime processor nine address reliability concern must armor design tolerate operate properly presence fault memory array high performance critical chip reliability seventy devote cache structure however particularly vulnerable process variation due sensitive differential circuit area efficient layout yield unprotected cache technology low imply necessity proper protection three four process variation single cell fail follow reason sort base frequency occurrence three access time failure write stability failure read stability failure hold failure illustrate reliability cache figure one present least one faulty cell consider different storage trend show wide range single cell failure assume uniform failure distribution failure probability increase graph granularity fault manifestation decrease size instance cache configuration demonstrate modest number thus redundancy solution would satisfactory fault tolerance case however cache certain contain least one faulty cell cache high chance fault cache block make use level redundancy impractical hence increase failure probability smaller granularity redundancy necessary guarantee robustness trend see cache favorably shift towards right due smaller block size cache comparison cache primary challenge scenario design cache architecture maintain utilize smaller level redundancy defect tolerance technology node cell expect standard deviation threshold voltage result high four thus real need devise reliability challenge amount literature target cache reliability concern transient fault manufacture defect process variation cache block size word size b cache block size word size figure one probability least one faulty cell different vary failure probability cell operation propose divide three major cod simple error detection cod parity apply detection fault cache single error correction double error detection widely use technique protect memory structure however rate situation practical strict bind number tolerable fault protect data chunk section five error correction cod scheme present fifteen use two set row data array result show scheme also appropriate rate like one address work overhead update column cod cache write high multiple bite error correct cod like ham cod capable tolerate high failure rat inefficient term cod delay area power cache fifteen summary cod best apply memory structure low transient fault main concern many propose employ dynamic scale improve cache reliability try identify vulnerable cell line scale access level guarantee proper operation two major scheme one mechanism need dynamically determine cell row two work condition cache must adjust cell result considerable performance penalty access latency dram cell substitute conventional cell improve reliability however cell retain value long period must refresh periodically moreover since dram normally use current add complexity effort another alternative size use different structure st eighteen unfortunately incur large area overhead section five mostly employ power reduction allow operation architectural dual modular redundancy scheme use many design provide memory structure reliability highly inefficient term overhead popular architectural solution use redundant row twenty see figure one b probability least one failure row close ten imply expect faulty start result poor utilization provision redundancy moreover since redundant row replacement base modification use fuse generally applicable ten extra row thirteen similar set base cache disable also suitable rate al suggest several layer merge multiple defective form single functional achieve operation presence fault method sacrifice half cache area method add three cycle latency cache access time result considerable performance work use table map faulty block onto another one fourteen impose high pressure communication bus increase miss rate substantially furthermore properly applicable cache three efficiently scale higher defect flexible solution necessary end introduce mean body armor rate tolerant solution cache adaptive dynamically solution tackle high defect rat future also provide wide range cache design base primary design concern delay power area overhead work architecture leverage tolerate process variation technology take advantage intelligent interlace usage multiple ways substantially cut protect cache knowledge capability achieve highest degree fault tolerance among previously propose approach give area budget current already equip protect cache substitute conventional protection provide level robustness considerably lower overhead section five believe scheme provide solid foundation cache take advantage higher clock frequency transistor density technology nod preserve correct functionality time design less overhead primary paper one flexible dynamically architecture leverage protect regular structure high defect density figure two two simple line swap preserve correct functionality cache resolve occur collision black box show faulty chunk data technology nod two minimize amount redundancy require protect cache model collision pattern cache well study graph color problem take advantage exist rich approximation three design space exploration show actual process fix architecture four derivation model manufacture yield evaluate propose method process variation condition two section architecture first describe adaptively absorb fail next effective algorithm configure underlie architecture present architecture key idea behind architecture use redundant multiple ways increase potential utilization partition complete cache array set equally size logical group logical group allocate one spare cache onwards use term line refer logical group form carefully shuffle together physical cache line order optimize utilization single spare cache line line divide equally size data chunk allow smaller spare substitution instance fourth data chunk second spare line use substitute fourth data chunk cache line case failure flexibility line shuffle provide add network cache allow swap cache line eliminate conflict conflict occur two line share spare line failure chunk cache line correspond spare chunk may sufficient redundancy conflict arise render cache illustrate issue figure two show two simple preserve correct functionality underlie cache possible conventional redundancy figure line contain five data every two consecutive line main cache form logical group logical group assign one line spare cache figure three architecture show figure extra add cache highlight note slice base address show use number one two three address format fault map array spare cache share avoid get activation signal main cache simplicity separate sense fault map spare cache show module commonly use fault diagnosis embed memory structure first line main cache failure place first line spare cache swap first fifth line main cache resolve collision swap second fifth row form first logical group utilize first row spare cache second conflict situation two line logical group swap fourth sixth line one possible way resolve conflict swap eliminate increase chance functional cache give area overhead budget architecture show figure three cache data array divide equal size group line within group share single spare line spare cache static spar access cache array high speed design spare cache fault map array also access parallel result fault map access determine whether spare data chunk rout output instead main cache content order tolerate many defect logical group form carefully shuffle together cache line use interconnection network figure two demonstrate functionality interconnection network swap line manner resolve exist configuration network compute save nonvolatile network configuration storage use static interconnection network overcome static bind maximize utilization spare remainder section provide detail description architectural spare cache row spare cache correspond logical group line main cache single row spare cache break smaller redundancy fix size redundancy spare cache keep valid content correspond corrupt element main cache exist order avoid high require use main cache row spare cache fault map array use separate share use top fault map array fault map array number row spare cache redundancy unit spare cache row fault map array store row number correspond logical group utilize redundancy example break data chunk row logical group replace correspond spare unit fault map save redundancy unit imply small granularity redundancy length fault map array significantly longer main cache access time fault map array comparable cache hence structure access parallel tag array access conversely cache access structure happen hit resolution tag side result reduction dynamic access energy contrast network configuration storage fill manufacture test time fault map get content directly self test module first boot system content save retrieve machine boot mechanism work properly fault map since rout already fix test operation effect line swap automatically account comparison stage stage compare least several set segment return content fault map array determine whether unit redundancy replace data chunk main cache level end access critical path base result comparison stage level determine redundant unit whether main cache spare cache data valid drive onto cache output cache divide equal redundancy size redundancy specify granularity hand since read write symmetric modification implementation would replace pass order guarantee proper operation cache assume main structure architecture ie main cache spare cache tag array fault map would affect process variation design main spare cache major area potential structure directly handle scheme order protect fault map tag array employ process variation tolerant cell area efficient simple transistor size eleven ten however note cell come around area overhead cost effective protect entire cache section five configuration proper configuration crucial achieve higher utilization spare first step toward determine map word logically group together cache line share single spare line model graph color problem solve manufacture test time solution color problem provide require configuration information save network configuration storage first boot machine module take advantage already configure find faulty fault map array populate module base location faulty cache order achieve effective line swap capability architecture two major algorithmic need address one effective group number depend number cache logical group figure four network show connect second row four consecutive logical group row main cache example single route also show n set segment memory address n base number row spare cache interconnection network order shuffle around cache line form logical group use interconnection network network place row main cache cache unidirectional network use provide nonblocking rout full permutation map input output figure four show consist two connect butterfly network main reason select work one full permutation nonblocking allow rout permutation input output fashion two logarithmic depth net minimize impose delay overhead interconnection network connect nod one stag require call n swap level three scale superior comparison interconnection network like omega network network consist multiple local local use connect relative position different group instance figure four four group line connect local many interleave local line single group set group connect single local call swap set size swap set swap level example show determine depth network give full permutation nonblocking choose interconnection network line relative position swap different logical group increase depth widen scope line swap however also impose higher underlie cache order minimize reach network higher depth employ efficient implementation present thirty memory also use alternative however since network critical path cache access employ provide inherent flexibility lower delay lower power consumption network configuration storage interconnection network configuration keep network configuration storage accord next section small fraction manufacture test time use solve configuration map network configuration storage use describe however since structure extremely small mostly less employ nonvolatile fuse negligible impact result figure five map graph color problem defect pattern cache solid edge stand intrinsic conflict dot edge correspond conflict due defect pattern number write spare indicate correspond cache spare assign correspondence number form content fault map array formation two network configuration effective group formation problem determine logical group share single spare line architecture model graph color problem figure five example illustrate process map defect cache graph cache array figure five black box stand faulty cell cache divide four logical group spare line assign logical group two local require proper shuffle line one two main cache form logical group utilize line spare cache first second line different logical group swap position use correspond local line one three five seven swap position graph leave hand side figure construct base defect pattern cache node graph represent line cache whereas edge represent conflict pair line ie two nod connect edge represent line logical group graph color algorithm apply graph find solution neighbor nod assign color thus color nod color guarantee edge imply correspond cache line conflict cache line color thereby form logical group graph edge represent conflict line broadly divide two intrinsic edge line spare cache dedicate single logical group main cache imply spare line logical group result four nod b c construct complete figure five moreover structure force line connect local different logical group example line one three five seven group consequently four also form complete defect edge defect pattern cache introduce edge graph defect edge connect pair line least one conflict data chunk instance defect edge nod three c second data chunk faulty graph color problem solvable graph g integer k zero nod g color k color edge exist color nod problem instance want show h logical group cache nod color h color would feasible configuration work properly since always complete problem graph h nod due intrinsic edge chromatic number least h hand problem constraint dictate use h color graph color problem hence graph color problem configuration solution exactly h color valid color assignment indicate collision line within logical group replacement defective data chunk properly handle graph color widely recognize thus solve use approximate algorithm call incomplete backtrack sequential color sixteen heavily optimize version full backtrack solution restrict branch factor level expedite process find approximate chromatic number average increase chromatic number graph considerably better theoretical upper bind use analysis section three complexity algorithm v four actual discuss next section furthermore algorithm easily convert exact solution eliminate branch heuristic especially useful case small graph computational devote solver graph color solution determine assignment line logical group line cache color form single logical group example line orange color bind orange spare row use correspond local figure five illustrate valid color assignment color assignment place logical group formation complete main cache next step solve configuration problem order make cache functional network configuration nonblocking also allow permutation input map output figure six leave cache figure six proper configuration two transform actual cache layout leave virtual one right give color assignment upper bottom connect first second row four logical group color get select bite one lighter color get select bite zero show physical cache layout solution graph color problem describe color line determine logical group line assign result position particular line line swap apparent instance figure six last cache row green color correspond first row spare cache denote last cache row map second row first logical group line order virtual cache layout right hand side obtain physical layout employ two deep local properly configure determine select signal within achieve reorder desirable permutation employ recursive method describe configure network since construct two identical n two input configuration compute three design space exploration process find suitable design point involve fix architectural high level architectural use exploration list table one addition three main specific design size spare cache b depth c granularity redundant data chunk section sweep wide range value study overhead design point number spare cache line take set zero one seven note length main spare cache depth select set one three five nineteen granularity select set zero one ten total consider cache point design space order prune design space number practical design consider instance design spare line study due significantly high overhead detail practical impact design space follow finally pick suitable one graph color solver time provide range cache line swap thereby improve defect tolerance however network also increase complexity graph color configuration two graph color problem far dominate factor figure seven depict relationship size problem time require solve use algorithm section run solver single core processor memory capacity clock rate plot logarithmic demonstrate fast growth solver increase problem size total manufacture test time processor consider functional structural wafer package test around nineteen use reference limit graph solver time use maximum ten second four cache structure two bank case cache one spare every k depth one total number nod graph color problem would k one accord figure seven base solver time budget use nine level deep connect logical group together instance logical group consist eight would eight one nod graph color problem numerous work twelve parallel graph color use decrease solver potentially increase allowable depth however scrutinize beyond scope paper side note order get feel size network look transistor count deep less cache much smaller less four chance solver find feasible color assignment due time budget inherent complexity collision pattern section four use longer time budget solver finer granularity spare cache reduce small chance nevertheless situation arise either resize cache simply reject disable also apply position faulty cell e l g n r c h p r g ten one one one one one p one p three p five p seven p nine zero number nod graph figure seven graph color solver different edge number nod graph figure p edge density define probability edge arbitrary pair nod random graph g n p preserve correct functionality note need resort rare two probability operation probability operation pop definitive metric reliable system calculate probability specific architecture properly operate give use result prune design space graph generate section represent instance defective cache sake study defective cache model random graph g n p since cell defect occur random random defect due major contribution random fluctuation process variation four n number nod p probability edge arbitrary pair nod next step estimate graph color solution graph calculate average upper bind chromatic number random graph challenge problem graph theory six use two different propose upper bound evaluate pop give number set input condition require upper bound derive one two eight propose upper bind b work better smaller value p bind mostly applicable value p thus use weight average two bound base p value pa one p b approximation use derive upper bound significantly table one target system configuration frequency cache cache register rob reorder buffer queue instruction fetch buffer issue width fu functional unit float point unit main memory branch predictor branch history table ras return address stack branch target buffer value four data instruction set associative two cycle hit latency block size two bank unify set associative twelve cycle hit latency block size integer float point four four one two memory system port four one cycle latency sixteen latency combine bimodal associative approximation factor compare algorithm use section edge probability factor p define ratio expect number edge graph number edge complete graph n nod expect number edge randomly construct graph calculate account intrinsic fault edge one one twelve two two two two one one two two number logical group number logical group swap set b granularity number redundancy n number swap set main cache spare cache one one pi b show probability least one failure b figure eight show pop spare granularity eight five level swap two fix third one get value original sweep set notice figure eight add first level line swap significantly increase robustness cache beyond three level add level diminish return since weight average two bound integer number employ function sigmoid function fit shift step function number logical group five map calculate chromatic number pop use function calculate chromatic number smaller number available logical group swap set graph colorable probability close one derive chromatic number one unit number logical group probability would close zero show three high base fact pick design point design space pop ninety three area power base limit factor propose size design space shrink start point point next factor eliminate point comparison give design point spare granularity deep another design point exclude first point design space inferior dimension equivalent remove dominate point space dimension step reduce design space eleven point eight point evaluate design use cacti sixty evaluate area leakage power dynamic energy structure employ evaluate area time leakage power dynamic energy part design evaluate figure nine show area leakage power dynamic energy overhead select point design space instance stand design point redundant row granularity eight depth three notable increase size spare cache always lead increase area fault map size reduce however due longer finer resolution require result relatively fault map array compare dynamic energy overhead zero level one level three level five level seven level nine level zero one one one one one one one one one probability defect bite probability defect bite probability defect bite effect change number swap level use spare granularity eight b effect change granularity use spare five level swap c effect change number redundant row use granularity eight five level swap figure eight pop different fix two allow third one vary zero one eight six four two n r e p f l b b r p one two four eight sixteen zero tag tag forty thirty twenty fifteen ten five zero fifty forty thirty twenty ten zero two l r f e h r e v e r f e g n e c r e p one l r f e h r e v g r e n e c n f e g n e c r e p one eight six four two n r e p f l b b r p one l r f e h r e v r e w p e g k e l f e g n e c r e p two l r f e h r e v g r e n e c n f e g n e c r e p thirty twenty fifteen ten five zero fifty forty thirty twenty ten zero tag tag l l l l l l l l l l l one three one three one three one six one six one six one six one one one one one one one one two one one two eight three two one four two one six five four one four three four six six three two five four seven two two two two eight three eight six eight one eight two two three four five two five eight seven six nine l l l l l l l l two three two six two six two six two one two one two one two one two one five four one three four two five four four seven two two two two eight two three eight four five eight eight seven eight one six nine l l l l l l l l l l l one three one three one three one six one six one six one six one one one one one one one one two one one two eight three two one four two one six five four one four three four six six three two five four seven two two two two eight three eight six eight one eight two two three four five two five eight seven six nine configuration cache configuration cache configuration cache percentage area overhead b percentage area overhead c percentage static power overhead one eight six four two n r e p f l b b r p forty thirty twenty fifteen ten five zero thirty twenty fifteen ten five zero one l r f e h r e v e r f e g n e c r e p two l r f e h r e v r e w p e g k e l f e g n e c r e p tag tag l l l l l l l l two three two six two six two six two one two one two one two one two one five four one three four two five four four seven two two two two eight two three eight four five eight eight seven eight one six nine l l l l l l l l l l l one three one three one three one six one six one six one six one one one one one one one one two one one two eight three two one four two one six five four one four three four six six three two five four seven two two two two eight three eight six eight one eight two two three four five two five eight seven six nine l l l l l l l l two three two six two six two six two one two one two one two one two one five four one three four two five four four seven two two two two eight two three eight four five eight eight seven eight one six nine configuration cache configuration cache configuration cache percentage static power overhead e percentage dynamic energy overhead f percentage dynamic energy overhead figure nine area power energy overhead potential state percentage mostly higher compare two reason behind one cache access fault cache parallel main cache two cache read entire set every access whereas cache able read right cache block tag data access sequentially four cache access latency increase depth also direct impact cache access time since cache essential performance modern assume slack available access time cache therefore minor modification base cache result least one extra cycle access penalty nonetheless case considerable slack available design narrow leverage avoid additional cycle latency design level critical path cache access base time analysis design figure nine design point depth less equal seven need one extra cycle latency cache access ie depth nine require two extra cycle section five evaluate performance due additional access latency consider design point figure nine select impose sixteen area nine static power nineteen dynamic energy overhead cache select impose eight area nine static power sixteen dynamic energy overhead compare cache two select represent good design however base particular optimization criteria another design point might work better instance static power main concern optimal design point switch four yield analysis section go process manufacture yield calculation population enable chip population chip generate select purpose account die die within die wid process variation leverage model systematic module level chip consider composition e f r e b n fifty zero e f r e b n fifty zero two seven one one two two three three four four five five six six seven seven eight eight nine nine five five two seven two seven two seven two seven two seven two seven two seven two seven two seven five five five five five five five five five five five five five five five five five five four one two two three four five six seven seven eight nine one one one one one one one one one two zero nine seven six four two one nine seven six zero one two two three four five six eight five nine two six zero four seven one five eight two four two one nine eight six four three five two nine six three zero seven four one eight five six nine three seven one four eight two two nine six three zero seven four one distribution generate chip base number faulty cache b distribution generate chip base number faulty cache number faulty number faulty figure ten distribution generate chip number faulty cache population chip generate consider cluster effect systematic parametric eight structure two bank correspond spare cache set project systematic variation technology four high level variation model place approach use derive number faulty array arbitrary chip population one take variation model four use model nominal value across module derive data provide base average shift module two cluster effect determine degree defect dispersal cache structure also model due high density structure cluster effect impact arrangement defect correspond array account employ cluster negative binomial model seventeen base negative binomial yield formula figure ten illustrate generate chip base number faulty cache instance figure ten show around chip faulty cache derive consistent three interest note case protection scheme cache yield technology could low manufacture yield define fraction fully functional chip total number manufacture value interpret probability operation particular chip manufacture process define express proper functionality manufacture chip existence faulty chip respectively follow total number manufacture chip ni number chip faulty total number base rule probability p r p r one p r ni since consider independence cache show fourteen yield chip write one result p r write cache separately equation one use calculate chip yield case p r probability functional cache give contain faulty write p r f c f p r p r f f p r c f equation cache array work properly similar previous event faulty tag array fault map tag array assume guarantee operation relatively small structure ie p r f f one p r one finally calculation last term discuss section three give population generate chip ni cache structure know use mention model yield cache bank calculate describe methodology derive yield bank respectively imply yield five comparison discussion demonstrate efficiency design compare conventional recently propose section architecture pick configuration sixteen area overhead yield configuration eight area overhead yield comparison conventional tech figure eleven demonstrate amount area overhead require protect cache use different protection scheme give probability failure start least possible overhead every mechanism gradually increase area overhead pop reach ninety infinity symbol top bar indicate achieve pop ninety possible correspond protection mechanism figure account amount redundancy require consider complete word hardware overhead consider x x e h r e v e r f e g n e c r e p eighty sixty forty twenty zero one e five five e five one e four five e four one e three one e five five e five one e four five e four one e three cache cache probability failure single bite figure eleven area overhead different protection tolerate give figure stand row redundancy protection scheme error correction scheme respectively similarly augmentation include area overhead protection method protect cache inefficient usage redundant nevertheless show thirteen ten extra row efficient due considerable increase row latency show figure area overhead significantly smaller compare even two bite error correction scheme power area overhead go beyond two bite correction use cod extremely expensive term code storage area power delay fifteen hand single bite correction even protect cache structure difference protection even noticeable longer cache size challenge protection term energy consumption impose around fifty respectively fifteen whereas select less twenty energy overhead section three hence clear conventional cache protection scheme deal high degree deep comparison recently propose recent target high defect density challenge impossible conventional scheme compare three recently propose cache reliability scheme target failure rat close purpose comparison measure performance system table one equip select section three performance loss expect due extra cycle latency add design use five simulator along average performance observe maximum minimum one agarwal four propose cache use cache block preserve correct functionality process variation figure one depict around cache block expect faulty technology method map faulty block neighbor functional block force access get value block method applicable cache efficiently apply show figure one around cache block faulty value block must retrieve main memory system configuration table one result effective access time cycle hurt performance drastically nevertheless consider achieve yield compare yield scheme al propose two cache protection scheme use several layer shift merge multiple defective line single functional line method originally design reduce operational voltage cache power save reduce operational voltage cache cause start fail try tolerate unwanted alternatively order improve stability cell chang al ten propose cell study compare detail manner eleven work show effective simple transistor improve stability cell robust read upset compare conventional cell due isolation read write eleven table two summarize comparison two scheme see method notably higher performance behavior due two reason three additional cycle latency access compare one cycle reduce fifty respectively provide spar fix report power thus best provide estimate table two ignore overhead due correction repair pattern shift layer along correspond method power overhead parallel access bank necessary cache parallel access occur high leakage power st use tag array lastly area overhead method modest slightly higher note area around time consequently area overhead protection scheme chip mostly determine area overhead cache cell provide superior performance either scheme cost area overhead power overhead cache also notably higher design overall tolerate high defect result modest amount performance loss provide competitive best six conclusion bring demand reliability challenge due high process variation particular structure highly vulnerable parametric alteration thus design large cache table two comparison recently propose cache protection scheme protection scheme eleven ten area fifteen sixteen cache disable fifty zero zero power area power norm sixteen fifteen seven eight twelve ten cache disable zero zero able efficient important problem work present flexible dynamically cache architecture efficiently protect cache high failure rate solution take advantage static row along add capability dynamic swap maximize utilization spare cache fault pattern map graph color problem configure architecture explore large design space come two suitable architecture minimize area power achieve desire level robustness sixteen eight area overhead achieve yield respectively finally compare scheme several conventional illustrate efficiency effectiveness seven gratitude go anonymous referee provide excellent feedback work research support arm national science foundation grant research center one five research center fund focus center research program semiconductor research corporation program eight reference one c chromatic number random regular graph international workshop randomization computation page two two possible value chromatic number random graph symposium theory compute page new york three agarwal b k process variation embed failure analysis variation aware architecture journal solid state circuit nine four agarwal b c h k cache architecture improve yield large scale integration thirteen one five e infrastructure computer system model two six b berger j better performance guarantee approximate graph color five three seven k process design international conference design page computer society eight b chromatic number random graph eight one nine design reliable unreliable challenge transistor variability degradation micro six ten l chang fry j j sleight r r l c k w stable cell design node beyond symposium technology page june eleven g sylvester n kim design international conference computer aid design page twelve h f parallel graph color use first workshop page thirteen redundancy annual international conference innovative silicon page fourteen l cache architecture proceed pacific rim international symposium dependable compute page computer society fifteen j kim n k b j c hoe error tolerant cache use error cod annual international symposium sixteen w graph color five university technology seventeen z incorporate yield enhancement process eighteen j p kulkarni k kim k fully differential robust trigger base international symposium low power electronics design page new york nineteen r trend manufacture test international test conference page computer society twenty j h lee j lee b kim redundancy methodology use build international conference four page x liang r canal brook replace data cache combat process variability micro one chromatic number random graph eleven one h k model failure probability statistical design array yield enhancement design integrate circuit page n r n p optimize wire large cache cacti sixty micro page self rout network annual international symposium computer architecture page new york g j h cache annual international symposium n choose error protection scheme data cache international conference computer design sarangi b r j j model process variation result time semiconductor manufacture page k ram journal solid state circuit thirty z shi r lee implementation complexity bite permutation signal page k h n k nine v operation flash memory embed logic symposium technology page r j application schedule power management chip annual international symposium computer architecture page june k test journal design test thirteen one n employ redundancy journal circuit one improve performance guarantee approximate graph color journal thirty four c h r z trade cache capacity reliability enable low voltage operation annual international symposium computer architecture x yang r b lee fast permutation base butterfly network media processor page