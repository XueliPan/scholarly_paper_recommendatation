scalable nonblocking approach transactional memory jar chi computer laboratory university abstract transactional memory provide promise simplify parallel program eliminate need lock associate deadlock priority inversion convoy adopt long term need deliver promise need scale high number date scalable relegate issue contention paper present first scalable implementation distribute share memory free without need intervention design scalable implementation optimistic concurrency control support parallel commit commit protocol use cache filter coherence message scalable design base transactional coherence consistency support continuous fault isolation performance evaluation design use scientific enterprise demonstrate design scale efficiently one introduction move parallel program domain high performance compute address need simpler parallel program model transactional memory develop promise good parallel performance parallel code seventeen sixteen fourteen unlike synchronization transactional memory allow nonblocking synchronization code deadlock freedom guarantee higher degree fault atomicity concurrent thread several study already show work well eight sixteen however give transistor large scale sixteen single board even single chip soon available process become available able use program model vary scale hence interest scale paper present first scalable nonblocking implementation tune continuous use within parallel program adopt continuous implement single coherence protocol provide nonblocking synchronization high fault isolation simple understand consistency model basis work implementation transactional coherence consistency model define coherence consistency share memory system transaction fifteen unlike scalable detect conflict transaction ready commit order guarantee without intervention contention also unique use lazy data allow transactional data system memory transaction commit provide higher degree fault isolation common case make scalable use implement three parallel commit protocol concurrent involve data separate b commit communicate address data nod c address data communication commit conflict detection occur may cache share data demonstrate allow scalable performance essentially work describe implement optimistic concurrency control scalable hardware use major propose scalable design system nonblocking improve tune continuous transactional execution describe directory implementation reduce commit conflict detection use commit scheme parallel commit cache directory also act conservative filter reduce commit conflict detection traffic across system demonstrate propose system scale efficiently distribute environment scientific commercial range eleven range sixteen commit interference concurrent bottleneck less five execution time overall paper show scale achieve performance expect parallel still provide desire feature make attractive rest paper organize follow section two give overview scalable protocol review optimistic concurrency control section three discuss protocol implementation section four present experimental methodology evaluation result section five discuss relate work section six conclude paper two protocol overview optimistic concurrency control lazy transactional memory achieve high performance optimistic concurrency control first propose use transaction run without acquire lock optimistically assume transaction operate concurrently data assumption true end execution transaction commit update share memory dependency check lazily commit time conflict detect violate local update roll back allow nonblocking operation perform well ample concurrency conflict rare common case transactional behavior scalable multithreaded program eight execution consist three phase execution phase transaction execute speculative buffer locally visible rest system validation phase system ensure transaction execute correctly serially valid consistent phase complete successfully transaction abort restart phase complete transaction violate commit phase transaction complete validation phase make visible rest system commit phase kung al outline three condition phase may overlap time maintain correct transactional execution validate transaction must serial order run system assume transaction give transaction id tid point validation phase transaction id j ti j one follow three condition must hold one ti complete commit phase start phase two read anything ti want validate ti finish commit phase start commit phase three read try validate anything ti want commit ti finish execution phase complete execution phase condition one execution overlap transaction start execute transaction finish commit yield concurrency whatsoever condition two execution overlap one transaction allow commit time original design fifteen example operate condition two transaction arbitrate token use order bus ensure commit finish transaction start commit sequential commit limit concurrency become serial bottleneck system high processor count condition three allow concurrency conflict completely overlap execution commit phase scalable operate condition three allow parallel commit however require complex implementation furthermore additional require accommodate distribute nature large scale parallel system specifically distribute memory unordered interconnection network protocol operation overview model buffer speculative data execution phase validation processor request commit token hold one processor time commit token acquire processor proceed flush commit data share nonspeculative cache via order bus scalable system organization node zero processor main memory ca directory node one node two node three k r w e n n c e n n c r e n b processor detail register processor address data violation commit store address fifo c c h e v tag data share vector write vector commit address snoop control fill control commit data commit control commit address commit data refill data commit data commit address communication assist ca figure one scalable hardware circle part processor indicate original scalable model work well within commit plentiful low however system perform poorly since commit serialize sum commit time place lower bind execution time commit broadcast message also excessive network traffic likely exhaust network system figure show organization scalable hardware similar many distribute share memory one scalable protocol leverage system overcome scale original implementation maintain execution model programmer point view allow several first even though directory allow single transaction commit time multiple commit parallel different thus increase number system provide higher degree concurrency parallel commit rely locality access within transaction second allow protocol move data nod true share cache finally allow filter commit traffic eliminate need broadcast invalidation message scalable cache slightly modify cache original proposal use track may speculatively read share data processor validation phase acquire tid proceed commit phase guarantee processor violate send commit address responsible data write transaction generate invalidation message message description load tid request skip message probe mark commit abort write back flush data request load cache line request transaction identifier instruct directory skip give tid probe service tid mark line intend commit instruct directory commit mark line instruct directory abort give tid write back commit cache line remove cache write back commit cache line leave cache instruct processor flush give cache line memory table one coherence message use scalable protocol mark read stale data receive invalidation message use track determine whether violate simply invalidate line protocol correct condition three two rule must enforce first conflict write address different serialize second transaction tid ti commit lower could violate alin word ti read word ready commit transaction lower tid may write ti must first wait transaction commit directory require send message order mean directory allow send message infer already communicate commit information particular directory directory track tid currently allow commit serve tid register transaction nothing send particular directory time ready commit inform directory send skip message include tid directory know wait particular transaction simple commit example figure two present simple example protocol transaction processor successfully commit one directory second transaction processor violate restart figure divide six part change state circle number show order mean number occur time event label occur label description make use table one list coherence message use implement protocol part load cache line subsequently mark directory zero b one c one directory zero x two two x tid x tid vendor two one l one directory one two x directory zero three tid one n one three n p r b e mark x two four n three one n one one two kip one e directory zero two one l x tid x load x one five x two x three tid tid vendor tid one four one x directory zero one n p r b e tid x one tid three tid vendor one tid probe n one k p one one directory one one directory zero x two c one two tid two two two directory one f request x two three b x w three n v l e one x four directory zero four l x one five x tid vendor tid vendor tid vendor three two directory one three directory one three directory one figure two execution scalable protocol directory one respectively write data track directory zero information communicate directory commit part b processor load another cache line directory zero start commit process send tid request message tid vendor respond tid one one processor record part c communicate directory zero directory want write order commit write first probe directory use probe message parallel send directory one skip message since directory one cause directory one increase two meanwhile also start commit process request tid also start probe directory zero probe require processor acquire tid receive tid two record internally part receive answer probe also send skip message directory one cause directory change three send message directory zero answer receive lower tid tid hand match directory zero thus send message directory note able serialize potentially conflict write data directory zero send mark message cause line x mark part commit transaction without use mark message transaction would complete validation phase send address want mark message allow precommit address subset ready service transaction complete commit need make sure lower tid violate must make sure every directory zero one do younger since currently service directory zero certain lower already service directory however need also probe directory one receive three answer one hence certain younger tid three already service directory one thus violate commit directory part e send commit message cause mark line become own mark line transition own generate send line except commit processor become new owner receive invalidation discard line violate current transaction read part f attempt load own line cause data request send owner owner write back cache line invalidate line cache finally directory forward data request processor mark list line one commit require transaction send single skip message set present either write transaction also communicate probe di skip one one two two x directory zero three n two n p r b e one tid vendor n one two one n p r b e one directory one one two kip b one one two x directory zero one r k x ark one directory one b two x directory zero two one r k x tid one n two ark one one e b r p n directory one two c two three x directory zero one c c three three one c directory one two four three x directory zero three bort two three one c four three directory one v n two figure three two involve pair attempt commit parallel top scenario successful bottom fail note two start generate message part first scenario mark sharer line directory one communication limit performance limit message cheap high interconnect amortize whole transaction furthermore show section four number touch per commit small common case even case use still result efficient system bear performance evaluation show protocol scale well practice parallel commit example point time directory single transaction commit since many system write overlap figure three illustrate two possible pair attempt commit parallel assume two already ask obtain one two respectively write data directory one write data directory zero part transaction send probe message correspond directory receive satisfactory necessary skip message already send processor part b c present successful parallel commit access data directory one access data directory zero part b send mark message appropriate directory additional probe message processor include single directory part c send commit message two process commit concurrently update owner affect cache line part b c present scenario parallel commit fail abort transaction read word directory one attempt commit part b probe directory one well include receive answer back one smaller tid two proceed receive higher equal word two commit serialize involve directory zero however commit never occur commit first part c since commit new value line speculatively read directory one send invalidation violate since already send mark message directory zero need send abort message cause directory clear mark note lower tid two commit would still serialize would violation would commit first commit afterward would receive invalidation would detect invalidation send transaction occur logically nonetheless invalidate target cache line three implementation detail processor state figure show detail processor speculative state store multiple level data cache use chip cache provide high capacity support fast associative search twelve twenty also allow speculative nonspeculative data dynamically share storage capacity available processor flexible way figure present data cache organization case speculative state track tag include valid word processor cache line eight type need per line bite indicate correspond word modify currently execute transaction similarly bite indicate word read current transaction speculative state track work similar manner require single valid bite per line approach easily expand multiple level private cache level track information may overflow limit speculative buffer hardware situation handle use like nine however recent study show large private cache track transactional state unlikely overflow occur common case eight simpler protocol state regular transient extend conventional coherence use orthogonal due nature large scale machine figure also use circle highlight additional necessary processor cache scalable protocol add dirty bite per cache line support protocol check dirty bite first speculative write transaction already set first write back line nonspeculative level cache hierarchy former nonspeculative cache require behavior without speculative cache would delay till next speculative access dirty line cache structure compare protocol inclusion share vector write vector include bite per directory system indicate transaction commit share vector track home speculative data read current transaction load infer directory number address set correspond bite vector similarly write vector track home speculative data write current transaction directory state figure four show directory organization scalable protocol directory track information cache line physical memory house local node first track nod speculatively read cache line list set nod send invalidate whenever line get commit second directory track owner cache line last node commit update line list mark ow tid optional directory controller zero skip vector ad figure four directory structure scalable write back physical memory eviction owner indicate set single bite list own bite mark bite set cache line involve ongoing commit directory finally include tid field allow us eliminate rare race condition unordered interconnect use discuss race elimination part section directory also register skip vector describe protocol operation skip vector control access contiguous region physical memory time single directory service one transaction whose tid store directory register example directory might serve mean send message memory region control directory nothing commit directory send skip message tid attach directory mark tid complete key point directory either service skip every transaction system two overlap concern directory serialize commit directory track skip message use skip vector skip vector allow directory buffer skip message send early higher one figure five show skip vector maintain directory zero busy process message receive process skip message time skip message tid x receive directory set bite location x n st id skip vector directory finish serve mark first bite skip vector proceed shift skip vector leave till first bite longer set increase number shift commit process transaction attempt commit probe write share vector receive equal higher tid repeat probe avoid directory respond require tid service directory satisfactory transaction send mark message correspond address assume cache skip message transaction twelve four receive zero zero one two three four five six seven eight nine zero commit wait skip zero zero one two three four five six seven eight nine arrive shift skip vector skip arrive three zero one two three four five six seven eight nine three commit shift right away eight zero one two three four five six seven eight nine figure five skip vector operation note bite zero correspond black mean bite set processor mark line sharer owner line note transaction send mark message one directory may still probe essential design wait may serve lower tid mark complete write vector transaction receive higher tid directory share vector transaction commit send commit message directory mark line own potentially generate commit processor line transaction violate send mark message need send abort message write allow mark processor attempt load mark line stall correspond directory could allow processor load value memory time mark sharer optimize common case assume commit attempt succeed thus best stall load processor avoid subsequently invalidate violation processor cache track speculatively read write data word level make accommodate fine granularity conflict detection mark line word flag send alongside mark message flag buffer directory send word flag include invalidate message processor clear list particular line commit line cause invalidation send word processor notify directory line replacement hint may generate extra validation message false processor use information track cache determine whether violation upon receive invalidation word speculatively read current transaction operation guarantee two process commit either write conflict true data transaction lower tid always succeed commit design directory guarantee behavior transaction higher tid able write directory lower tid either skip directory commit furthermore transaction commit sure speculatively load service potentially send invalidation yield protocol guarantee forward progress limit starvation possible starve transaction keep tid violation time thus time become tid system long retain tid age may decrease system performance programmer still guarantee correct execution moreover provide profile environment tape seven allow quickly detect occurrence rare event assign end execution phase maximize system throughput may increase probability starve mitigate allow request retain violate thus insure assign global tid vendor distribute time stamp thirty work implementation since produce sequence rather order set globally unique race elimination certain protocol race condition may occur require attention example whenever transaction give tid commit involve commit wait result acknowledge resolve situation transaction tid allow commit since receive answer probe receive invalidation transaction x x unordered network may introduce additional race example assume transaction zero commit line x write back line x transaction one run processor commit new value line x write back line x x x address different data possible highly congest network x arrive x flush owner may memory data race resolve feature description core cache line associative one cycle latency cache line associative sixteen cycle latency grid topology cycle link latency fourteen main memory directory cycle latency vector sharer list first touch allocate directory cache ten cycle latency table two simulate architecture unless indicate otherwise result assume default value parentheses attach tid own directory entry time commit get tag processor recent tid processor acquire previous example commit x process directory entry tag tid one flush x tid zero attach thus drop arrive order one final example data race occur follow processor send load request give directory directory satisfy load separate transaction commit generate invalidate invalidate arrive request processor load resolve could drop load arrive race condition present use unordered interconnect four methodology evaluation section evaluate scalable first discuss experimental methodology introduce use evaluate protocol finally present discuss result methodology evaluate scalable use simulator model except load store ten table two present main simulate architecture memory system model time cache interface communication assist directory cache contention queue access cache interconnect accurately model simple policy use map virtual page physical memory various nod evaluate scalable use suite parallel swim spec suite radix parallel suit execute use two virtual machine also include two suite five set new cognitive base probabilistic reason learn spec splash convert code barrier call discard lock unlock convert five unordered table three show key execute transaction size range thousand wide range transaction size provide good evaluation scalable system ninety size less ninety never exceed eighteen table three also present ratio per word high ratio imply transaction large amount computation per address hence may able better amortize commit latency ratio range two depend transaction size store locality exhibit application addition table three also give key use understand behavior cache coherence system number processor case show number touch per commit directory cache work set define number remote finally directory occupancy define number cycle directory busy service commit result indicate good directory performance work set fit comfortably directory cache directory occupancy typically fraction transaction execution time touch couple per commit result discussion section analyze performance quantify effectiveness scalable architecture also explore impact communication latency performance figure six show execution time breakdown run single processor execution time break five indicate spend time first component useful cycle represent cycle spend execute commit second component cache miss time spend stall cache miss third component idle time spend wait synchronization point fourth component commit time spend wait transaction commit finally fifth component refer time waste due conflict present case figure six commit time additional overhead processor around one percent average thus system one processor equivalent conventional application cluster ga five radix five swim input size set per word write set work per commit directory set occupancy cycle ref ref key ref ref ref ref one twelve fourteen sixteen one one three two two one two one one two table three scalable characteristic performance percentile transaction size transaction write size per word write also show number touch per commit percentile work set cache directory number directory occupancy cycle per commit e n c e x e e z l r n zero commit idle cache miss useful cluster g radix v wim w w figure six normalize execution time run one processor figure seven show execution time normalize single processor case scale number eight see figure seven overall performance scalable architecture good range eleven range sixteen suite commit time small fraction overall execution time look detail give us insight behavior scalable perform well system performance due fact execution time scale increase processor count particular even high processor count commit time remain small fraction overall execution time indicate scalable commit protocol behave well cluster ga genetics algorithm low processor count suffer evenly distribute across lead additional load high processor count roughly fix number cycle waste due evenly distribute across spec application limit parallelism lot communication result small avoid inherent communicate excessively even though small may reduce violation time lead increase commit time high processor count radix large per word write ratio one highest suite would indicate perform well system even though radix extremely high number touch per commit touch still perform well system large enough hide extra commit time scale linearly number due limit communication highest per word write ratio study thus ideal scalable best perform application due large large per word write ratio similar fashion scalable commit protocol behave well particular commit time nonexistent even high processor count swim little communication exhibit large generate large however require remote communication affect excessive number commit require communicate flag behavior yield low per word write ratio limit application increase commit time breakdown commit time show indicate majority time spend probe di useful cache miss idle commit five five nine five six zero one two zero one two eight one five seven two six eight one seven four two two eighteen sixteen fourteen twelve one eight six four two zero e n c e x e e z l r n eight six six one one zero two three three five five three seven one eight zero eight nine seven four seven seven six zero seven six seven six three one nine five two nine three four six five one zero zero three eight five one zero one three one seven five eight four one four zero three three five five zero four one eight four two one nine four nine one one five seven one three four two zero three one five seven one eight six two two four one six four two five nine three eight six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four eight six six one two three four six cluster g radix p e v wim w w figure seven performance scalable processor count vary eight execution time normalize single number top bar represent achieve single processor useful idle cache miss commit r n r e p e b fifteen one five zero overhead miss share e n c e x e e z l r n nine eight seven six five four three two one zero seven four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight seven two four one eight two cluster g radix v wim p e w w figure eight impact communication latency normalize single processor processor share vector lastly compare instructive number per word write algorithm inherently less communication synchronization thus scale better less commit time less violation time less synchronization time breakdown commit time show similar behavior figure eight show impact vary communication latency degree cluster g b arn es ake radix v wim w ared w figure nine remote traffic performance affect determine number remote load commit example amount remote load miss increase latency cycle per link increase execution time fifty likewise amount commit time see level degradation contrast swim remote load miss commit time suffer almost performance degradation increase communication latency finally figure nine show traffic produce consume average directory system report traffic term per instruction total traffic include data address control per range one per instruction execute two tal range swim within range commodity cluster interconnect eighteen additionally large high ratio per word write yield low overhead compare traffic figure nine radix water publish traffic number suggest number within publish range sometimes better sometimes worse minor account architectural cache size block size use versus conventional cache coherence five relate work number transactional memory expand early work knight nineteen seventeen stone show transactional execution provide good performance simple parallel code thirty fifteen three early transactional memory scheme hide perform conventional code thirty recent scheme propose program model fifteen three general use data version management conflict detection data version management policy specify handle new data become visible transaction commit old data retain transaction abort eager version management store new value place must restore old value transaction abort lazy version management buffer new value transaction commit conflict detection also handle eagerly detect potential overlap read write different occur lazily detect conflict transaction ready commit transactional memory use eager version management write memory directly improve performance commit frequent abort however may also incur additional incur lazy six provide lower fault isolation three event fault policy would leave memory inconsistent state moreover conflict detect eagerly execute load store three could lead solution propose problem employ contention manager force application deal issue run continuously execute code part transaction continuous provide uniform consistency model easy reason contrast use lazy conflict detection version management guarantee forward progress without application intervention keep speculative update store commit guarantee isolation even face hardware fault similar thirty three abort require invalidate buffer result low abort overhead postpone conflict detection transaction commit guarantee operation without intervention fifteen even though commit costly lazy version management conflict detection show still possible achieve excellent parallel performance heavily influence work speculation thirteen twenty eleven basic difference attempt optimistic concurrency within semantics sequential program communicate speculative state provide optimistic concurrency parallel communicate commit state nevertheless similar hardware support model fourteen transactional memory explore scalable modify exist coherence one four provide limit sequential program semantics ten scalable transactional memory system provide guarantee operation similar manner proposal token coherence make use limit broadcast small impact overall system excellent performance scalable token coherence demonstrate limit use broadcast incompatible six paper present scalable architecture distribute share memory base first scalable implementation hardware transactional memory system continuous transactional execution system require contention provide guarantee architecture base directory design provide support parallel commit cache coherence traffic filter simulation demonstrate propose design scale efficiently scientific enterprise range eleven range sixteen ability commit multiple parallel allow design avoid performance due commit serialization overall performance evaluation scalable architecture show possible retain parallel program benefit still provide scalable performance wide range find commit behavior work quite well scalable commit protocol seven effort sponsor national science foundation grant defense advance research project agency department interior national business center grant number view contain document author interpret represent official either express imply defense advance research project agency government reference one agarwal al alewife machine architecture annual computer architecture page two b virtual machine journal one three c al unbounded transactional memory computer architecture five san four l al piranha scalable architecture base annual chip computer architecture canada june five six l j tuck j c bulk speculative thread six computer architecture page seven h al tape transactional application profile environment five annual page june eight j al common case transactional behavior high program performance computer architecture nine j al transactional memory architectural support program operate ten j f j architectural support scalable speculative parallelization arch june eleven j al buffer memory state speculation three computer architecture page twelve j e smith g speculative cache fourth computer architecture thirteen l al data speculation support chip architecture support cessor program operate fourteen l al program transactional coherence consistency architectural support program operate page fifteen l al transactional memory coherence computer architecture page june sixteen k language support lightweight three annual program page seventeen j e b moss transactional memory architectural support data structure computer architecture page eighteen trade association nineteen knight architecture mostly functional lisp functional program page august twenty v j chip architecture speculative special issue multithreaded architecture h kung j optimistic concur control six two june j origin highly annual able server computer architecture page al dash computer three k martin hill wood token coherence performance correctness computer architecture page june j f j speculative synchronization apply speculation explicitly parallel architectural support program operate al characterization pact five parallel compilation k e j j hill wood transactional memory computer architecture al remove architectural bottleneck speculative parallelization computer architecture r j r goodman speculative lock elision enable highly concurrent multithreaded execution micro annual thirty r j r goodman transactional execution program architectural support program operate page r k lai transactional memory five annual computer architecture page june b al high performance transactional memory system multicore six eleventh practice parallel program march g e breach annual arch june standard performance evaluation corporation spec bench mark standard performance evaluation corporation j g al scalable approach speculation computer architecture june j g c potential use data speculation facilitate automatic parallelization arch j stone h stone p j multiple parallel dis update technology one four c woo al program characterization methodological computer architecture page june