Modeling Anisotropic Surface Reﬂectance
with Example-Based Microfacet Synthesis

Jiaping Wang∗

Shuang Zhao†

Xin Tong∗

John Snyder‡

Baining Guo∗

∗Microsoft Research Asia

†Shanghai Jiaotong University

‡Microsoft Research

Figure 1: Fabric SVBRDFs from our algorithm mapped onto a pillow: (a) yellow satin, (b) red satin with colorful needlework, (c) wallpaper, (d) velvet.

Abstract
We present a new technique for the visual modeling of spatially-
varying anisotropic reﬂectance using data captured from a single
view. Reﬂectance is represented using a microfacet-based BRDF
which tabulates the facets’ normal distribution (NDF) as a function
of surface location. Data from a single view provides a 2D slice
of the 4D BRDF at each surface point from which we ﬁt a partial
NDF. The ﬁtted NDF is partial because the single view direction
coupled with the set of light directions covers only a portion of the
“half-angle” hemisphere. We complete the NDF at each point by
applying a novel variant of texture synthesis using similar, overlap-
ping partial NDFs from other points. Our similarity measure al-
lows azimuthal rotation of partial NDFs, under the assumption that
reﬂectance is spatially redundant but the local frame may be arbi-
trarily oriented. Our system includes a simple acquisition device
that collects images over a 2D set of light directions by scanning a
linear array of LEDs over a ﬂat sample. Results demonstrate that
our approach preserves spatial and directional BRDF details and
generates a visually compelling match to measured materials.

Introduction

1
The physical world contains many complex materials whose re-
ﬂectance properties must be modeled or captured to produce re-
alistic CG imagery. Spatial variation and anisotropy are crucial and
particularly challenging to reproduce. Such effects can be repre-
sented by the six-dimensional Spatially Varying Bidirectional Re-
ﬂectance Distribution Function (SVBRDF) ρ(x, i, o) [Nicodemus
et al. 1977], describing how light is reﬂected at each surface point

∗Email:{jpwang,xtong,johnsny,bainguo}@microsoft.com
†Shuang Zhao was a visiting student at Microsoft Research Asia.

ACM Reference Format
Wang, J., Zhao, S., Tong, X., Snyder, J., Guo, B. 2008. Modeling Anisotropic Surface Reﬂ ectance with 
Example–Based Microfacet Synthesis. ACM Trans. Graph. 27, 3, Article 41 (August 2008), 9 pages. DOI = 
10.1145/1360612.1360640 http://doi.acm.org/10.1145/1360612.1360640.

Copyright Notice
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted 
without fee provided that copies are not made or distributed for proﬁ t or direct commercial advantage 
and that copies show this notice on the ﬁ rst page or initial screen of a display along with the full citation. 
Copyrights for components of this work owned by others than ACM must be honored. Abstracting with 
credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any 
component of this work in other works requires prior speciﬁ c permission and/or a fee. Permissions may be 
requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, fax +1 
(212) 869-0481, or permissions@acm.org.
© 2008 ACM 0730-0301/2008/03-ART41 $5.00 DOI 10.1145/1360612.1360640 
http://doi.acm.org/10.1145/1360612.1360640

x as the radiance ratio measured when viewed from direction o and
lit from direction i. Current techniques have proven inadequate for
obtaining visually compelling SVBRDFs.

The traditional approach represents the BRDF at each surface
point using parametric models [Cook and Torrance 1981; Ward
1992; Lafortune et al. 1997; Rusinkiewicz 1998]. It is difﬁcult to
create realistic appearance by building such models ab initio. Sim-
ple models lack power to capture real-world materials. More com-
plicated, multi-lobe models represent any BRDF to arbitrary accu-
racy but their many parameters are too hard to specify and control.
This has led to extensive research work in BRDF measurement.

A number of systems measure 6D SVBRDFs directly from sur-
face samples [Dana et al. 1999; McAllister et al. 2002; Lawrence
et al. 2006]. However, densely scanning over light and view di-
rections necessitates lengthy capture on expensive devices. It also
requires precise calibration of multiple or moving cameras, adding
to the cost and fragility of these systems. As a result, few mate-
rials have been measured in this way and little SVBRDF data is
available. Another measurement approach ﬁts parametric BRDF
models at each point, given data from a sparse set of views [Lensch
et al. 2003a; Gardner et al. 2003]. This simpliﬁes the acquisition
process, but fails to capture detailed, anisotropic reﬂectance. Sim-
ple parametric models do not capture details in the measured data,
while multi-lobe models overﬁt the sparse view data and generalize
poorly to uncaptured views.

We present a new technique for modeling SVBRDFs from im-
ages of a surface sample taken from a single view. Our approach
represents anisotropic specularity at each point with a general mi-
crofacet BRDF model [Ashikmin et al. 2000], and tabulates the mi-
crofacets’ 2D normal distribution function (NDF). The result is a
spatially-varying NDF (SVNDF). Data from a single view deter-
mines the NDF over only a partial region of the hemisphere. We
generate the full NDF at each surface point by iteratively grow-
ing these partial NDFs using partial NDFs from other points. Each
iteration searches candidates that overlap the current point’s par-
tial NDF and are similar within the overlapping region. Since this
procedure is similar to example-based texture synthesis [Efros and
Freeman 2001; Kwatra et al. 2003], we call our method Example-
Based Microfacet Synthesis.

Our basic assumption is that for any surface point we can ﬁnd
others having a similar but rotated microstructure (i.e., a different
local frame). A single view thus yields different slices of the BRDF
at points sharing similar reﬂectance, equivalent to partial NDFs de-

ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.ﬁned over different subregions of the hemisphere. By converting
slices of 4D BRDFs to 2D partial NDFs, we are able to detect which
surface points share rotated microstructure and merge them to com-
plete their NDFs. Although we do not produce the original sample’s
SVBRDF exactly, we do capture its statistical variation and rich ap-
pearance, as shown in Figure 1.

Our method represents a new application of ideas from texture
synthesis to SVBRDF acquisition in order to exploit spatial redun-
dancy. It is also the ﬁrst sparse-view (actually single-view) acquisi-
tion method that preserves spatial and angular details. The sparsity
of input data required by our method greatly simpliﬁes acquisition
and reduces processing costs. Results demonstrate good visual ac-
curacy using data acquired by a simple and inexpensive device.

2 Related Work
Anisotropic BRDF models were introduced by Kajiya[1985].
A number of empirical BRDF models have since been proposed,
including Gaussian [Ward 1992] and generalized Phong [Lafortune
et al. 1997; Ashikhmin and Shirley 2000]. While these models ap-
proximately capture anisotropic reﬂectance, they ignore the under-
lying microstructure and can miss details in many real-world mate-
rials [Ngan et al. 2005].

Another strategy is to explicitly model geometric microstructure.
Physically-based anisotropic BRDF models have been developed
for specialized materials such as ﬁnished wood [Marschner et al.
2005], hair [Marschner et al. 2003], and cloth [Yasuda et al. 1992;
Irawan and Marschner 2006], but it is difﬁcult to extend these mod-
els to other materials.

Models can also be developed to represent more general mi-
crostructure. Early work by Poulin et al.[1990] used a set of small
cylinders. Westin et al.[1992] computed a BRDF by simulating
the optical scattering of speciﬁed micro-geometry. Ashikhmin et
al.[2000] proposed a model based on an NDF for surface micro-
facets. Recently Ngan et al.[2005] showed that this microfacet-
based model captures real-world anisotropic materials better than
traditional parametric models. They developed a method to ﬁt the
NDF from captured 4D BRDF data.

We also model anisotropic BRDFs using tabulated normal distri-
bution functions as in [Ashikmin et al. 2000; Ngan et al. 2005]. But
we deal with the challenge of inferring spatially varying BRDFs
from sparse measured data.

Dense view acquisition using a spatial gonioreﬂectometer was
proposed by Dana et al.[1999] to directly measure SVBRDFs
and bi-directional texture functions (BTFs) of real world sur-
faces. Different systems have since been developed to capture
SVBRDFs [McAllister et al. 2002; Gu et al. 2006], BTFs [Dana
2001; Muller et al. 2005], and reﬂectance ﬁelds [Garg et al. 2006].
These methods all require a dense sampling of view and light direc-
tions over the hemisphere. This is achieved by moving any two of
the three components (camera, object, and light source) or by using
a dome containing multiple light sources and cameras. Although
several techniques have been proposed to simplify the capturing
work with special devices [Dana 2001; Han and Perlin 2003], or by
exploiting intrinsic properties of reﬂectance data [Garg et al. 2006;
Lensch et al. 2003b], acquisition still takes a long time or needs
an expensive hardware setup. Precise image registration is also re-
quired to detect surface correspondences, a difﬁcult task that leads
to blurring if not done carefully [Weyrich et al. 2007].

Sparse view acquisition has been employed by several re-
searchers to solve the camera calibration problem and make BRDF
acquisition cheaper and easier. In [Gardner et al. 2003], the sur-
face is scanned with a linear light source and captured from a ﬁxed
view. An isotropic Ward model is then ﬁt to the captured data at
each point. Lensch et al.[2003a] reconstructed SVBRDFs of a real
object of known geometry. BRDFs are grouped into a small set

each ﬁt using a Lafortune model basis, and reﬂectance at every
point is represented as a linear combination over this basis. Gold-
man et al.[2005] use the same linear combination idea but with an
isotropic Ward model as the BRDF basis, to reconstruct both an
object’s shape and its SVBRDF from sparse reﬂectance data. Al-
though these methods preserve detailed spatial variation of surface
reﬂectance, the simple parametric models on which they rely do not
accurately capture details or anisotropy of angular variation.

Debevec et al.[2000] apply a generalized microfacet model to
human skin. A face is acquired from a dense set of illumination
directions, at a single view from each side. Given speciﬁc assump-
tions about the skin’s BRDF (i.e., the refraction index is known
and spatially constant, and the shadowing is based on the V-shaped
groove model) the face can then be rendered under new viewing
and lighting conditions. We capture surface reﬂectance for arbi-
trary and unknown materials from a single view. We are also able
to reconstruct reﬂectance for view/light directions whose half-angle
was not actually acquired. We do this by explicitly inferring partial
NDFs and completing them by merging from other surface points.
Recently, Zickler et al.[2005] presented a method to infer a
BRDF at one point by exploiting data from neighboring surface
points. Their method models the SVBRDF using six-dimensional
radial basis functions which ﬁt sparse reﬂectance data in each lo-
cal region. Angular resolution is enhanced at the cost of spatial
resolution. Moreover, they assume that reﬂectance is isotropic in
direction and varies smoothly in space. Our representation makes
no assumptions about the material distribution over the surface – it
models the BRDF as a tabular microfacet normal distribution func-
tion that is spatially variant. By synthesizing the partial NDF ﬁtted
at different surface points, our approach captures angular variation
without decreasing spatial resolution.

3 Microfacet-based SVBRDF Model

Figure 2: Symbols used in BRDF deﬁnition.

Microfacet theory represents surface microstructure with a large
number of tiny mirror facets, each purely reﬂective and having
the same refraction index [Cook and Torrance 1981]. The BRDF
ρ(x, i, o) at a surface point x can be decomposed into two parts:

ρ(x, i, o) = ρd(x, i, o) + ks(x)ρs(x, i, o)

(1)

where ρs(x, i, o) is the specular part due to single-bounce reﬂec-
tions, ρd(x, i, o) is the diffuse part resulting from subsurface scatter-
ing and multiple-bounce reﬂections, and ks(x) controls the diffuse-
to-specular ratio. We model the diffuse part with the Lambertian
model ρd(x, i, o) = kd(x)/π.

Assuming the microfacets form a height ﬁeld, the specular term

is given by [Cook and Torrance 1981]:

ρs(x, o, i) =

D(x, h) G(x, o, i) F(x, o, i)

4 (i · n) (o · n)

(2)

where h = (o + i)/|o + i| is the half-angle vector (shown in Fig-
ure 2), and n is the upward surface normal at x. Note that for a ﬂat
sample, n = (0, 0, 1). The model consists of three spatially-varying

41:2       •       J. Wang et al.ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.components: the Fresnel term F, the microfacet Normal Distribu-
tion Function (NDF) D, and the shadowing-masking term G.

The Fresnel term F(x, o, i) affects the specular shape near graz-

ing angles. Following [Cook and Torrance 1981], it is given by

F(x, o, i) =

(g − c)2
2 (g + c)2

(c (g + c) − 1)2
(c (g − c) + 1)2

!

1 +

 

(3)

for unpolarized light. Here g2 = η(x)2 + c2 − 1 and c = |i · h|. η(x)
denotes the relative refraction index at surface location x.

The normal distribution function (NDF) D(x, h) describes the
distribution of microfacet orientations on the surface. It satisﬁes
D(x, h) ≥ 0 and
(n · h) D(x, h) dωh = 1 where the integration is
done in half-angle space over the hemisphere

Ω+

R

Ω+ = Ω+(n) =

h

h · n > 0

.

n

(cid:12)
(cid:12)
(cid:12)

o

High-frequency characteristics of surface reﬂectance such as glossi-
ness and anisotropy are dominated by D(x, h), so we make no as-
sumptions about it and represent it in tabular form.

G(x, o, i) represents the shadowing and masking effects of micro-
facets on both incoming and outgoing light. It can be approximately
decomposed into the product of two directional shadowing terms S
as in [Beckmann 1965; Smith 1967; Ashikmin et al. 2000]:

G(x, o, i) = S(x, i) S(x, o).

(4)

We follow the derivation in [Ashikmin et al. 2000] to compute
the shadowing term S(x, k) for a given direction k from the NDF
D(x, h) via

S(x, k) =

Ω+(k)

Ω+(n)(h · k) D(x, h) dωh

.

(5)

(k · n)

R

T

The shadowing term is smooth [Ashikmin et al. 2000; Ngan et al.
2005], a fact we exploit in partial NDF recovery to constrain the
shadowing term (Section 5.1).

The full SVBRDF model is therefore

ρ(x, o, i) =

+ ks(x)

kd(x)

π

D(x, h) S(x, i) S(x, o) F(x, o, i)

4 (i · n) (o · n)

(6)

and is represented by four quantities: an NDF D, a scalar Fresnel
refraction index η, and scalar specular and diffuse coefﬁcients, kd
and ks. Each is a function of surface location x.

Given the SVBRDF, outgoing radiance L(x, o) at each point x

can be computed by the rendering equation as

L(x, o) =

ρ(x, i, o) (i · n) L(x, i) dωi

(7)

ZΩ+

where L(x, i) is the incoming radiance from direction i.

Our

implementation parameterizes direction space with a
hemicube, typically subdivided into 32 × 32 cells on the top face
and 32 × 16 cells on each side. For more specular materials such
as aluminum, we subdivide the hemicube more ﬁnely. Here “direc-
tion space” refers to half-angle directions h for the NDF, and light
directions i for the 2D BRDF slice for a single view direction, o.

4 Reﬂectance Data Acquisition
Data is acquired by illuminating the surface from different direc-
tions and capturing its reﬂectance from one view. We adapt the de-
vice introduced in [Gardner et al. 2003]. As shown in Figure 3, the
setup includes a camera and a linear light source mounted above a
ﬂat sample and controlled by a stepping motor. Typical dimensions
of a surface sample are 10cm×10cm. We replace the linear light

Motor

LED Array

L E D Array

i

Scan Direction

Y

o

Camera

Material 
Sample

p0

h

p

Sample Plane

(a)

x
Material 
Sample

X

S a m ple Plane

p1

(b)

Figure 3: Our data acquisition device: (a) photograph, (b) diagram.

source used in [Gardner et al. 2003] with a linear array of 40 LEDs.
The distance between neighboring LEDs in the array is 0.6cm. A
Canon 30D camera with EF-100 2.8 lens is placed about 1.0m away
and 0.6m above the center of the surface sample, making an angle
of roughly θ=60◦ from vertical. Image resolution is 3504×2336.

Before capturing, we calibrate the camera’s position and orien-
tation with the method in [Zhang 2000]. A colored checker pattern
is used to calibrate the color and intensity of each LED. After geo-
metric and photometric calibration, we put the ﬂat material sample
onto the XY plane, centered at the origin. Based on the size and
thickness of the material sample, we can adjust the height h of the
LED array above the sample plane, but the typical value is 4cm.
The LED array is then placed at the starting position p0, as far as
possible away from the sample, and translated over it. The step
length is equal to the LED separation size. For each LED position,
images of different exposures are taken to reconstruct an HDR im-
age as in [Debevec and Malik 1997]. The scan is ﬁnished when the
LED array reaches p1, where it starts to occlude the sample from
the camera’s view. The result is a sequence of images Iq(x) where
the subscript q ∈ {1, 2, . . . , n} indicates a different point light source
(i.e. different LED with different Y translation). We manually mea-
sure p0 and p1 so that the light source position can be recovered.

After capturing, the HDR images are reconstructed and rectiﬁed.
A BRDF sample at each surface point x can then be computed from
the image sequence Iq, as

ρ

x, iq(x), o(x)

=

(cid:0)

(cid:1)

Iq(x)

(n · iq(x)) Lq ||Pq − x||2

(8)

where Pq is the position of the light source in image q and Lq is
its intensity. The lighting direction i is computed as iq(x) = (Pq −
x)/||Pq − x||. Since the camera is relatively far from the sample, we
use the viewing direction at the sample center for all surface points,
o = V /||V ||, where V is the calibrated camera position.

We then separate the diffuse from specular components using

q

(cid:8)

ρd(x) = min

ρ(x, iq(x), o) | Iq(x) > 0.05 Iavg

(9)

(cid:9)

where ρ(x, iq(x), o) = Iq(x)/(Iq(x)·n). Intensity measurements be-
low ﬁve percent of average Iavg tend to be noisy and unreliable and
so are removed. This method is naive compared with existing ap-
proaches [Debevec et al. 2000; Gardner et al. 2003], but it pro-
duces reasonable results nonetheless. After separation we obtain
the scaled specular measurement ˜ρs(x, iq(x), o) = ρ
−
ρd(x) = ks(x)ρs
at densely-sampled lighting direc-
tions. Finally, these scattered measurements are interpolated with
the push-pull method [Gortler et al. 1996], as in [Lawrence et al.
2006]. This yields a 2D slice of the specular component ˜ρs(x, i, o)
that is uniformly sampled over the hemicube of incident lighting
directions i. The next phase uses ˜ρs to ﬁt the NDF and the BRDF
model’s other parameters.

x, iq(x), o

x, iq(x), o

(cid:1)

(cid:0)

(cid:0)

(cid:1)

It is possible that a single view can fail to provide enough exem-
plars for NDF synthesis, if there is insufﬁcient spatial redundancy
or local frame variation over the material sample. An example is
brushed metal whose brush direction is constant over the entire
sample. Such cases can easily be addressed by capturing image
sequences for different rotations of the sample. BRDF slices from

Modeling Anisotropic Surface Reflectance with Example-Based Microfacet Synthesis       •       41:3ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.h Ω
h

o
o

n
n
Ω+(i)
Ω+(i)

i
i

i

Ω+

n
n

x

(a)

o

Ω+

x
x

(b)

Figure 4: Domains for the partial NDF and its shadowing term. (a) The
partial NDF’s domain Ω for a given view direction, o, is shaded in blue. (b)
Computing the shadow term S for a given light direction i needs D over the
domain shaded in yellow. Only part of it is covered in (a).

these different rotations can then be put together as if they were
captured from a larger sample in a single pass. None of our results
have required additional rotations.

5 Example-Based Microfacet Synthesis
With the captured 2D BRDF data at each surface point, the surface’s
SVBRDF is modeled in three steps. We ﬁrst construct the partial
NDF of the microfacets at each point. The NDF is partial because
the single view direction generates half-angle reﬂected directions
covering only a portion of the hemisphere. Microfacet synthesis
then completes the partial NDF by “stitching” partial NDFs of sim-
ilar regions together. The shadowing and Fresnel terms are derived
from the completed NDF in the ﬁnal step. Each step is detailed in
the following subsections.

5.1 Partial NDF Fitting
Given a 2D slice of specular BRDF data at each surface point, we
ﬁt its NDF in this step. Each surface point’s NDF is computed
independently. To avoid effects from the Fresnel term that will be
derived later, we exclude reﬂectance data near the grazing angle
and assume F(x, i, o) = 1. As shown in Figure 4a, with a ﬁxed view
direction o and light directions i over the whole hemisphere, the
sampled half-angle reﬂectance directions cover only a sub-region
Ω of the hemisphere:

i + o

||i + o||

Ω =

(cid:26)

i ∈ Ω+

=

h

reﬂ (o, h) · n > 0

(10)

(cid:12)
(cid:12)
(cid:12)

(cid:27)

n

(cid:12)
(cid:12)
(cid:12)

o

where reﬂ(o, h) = 2(h · o)h − o reﬂects the unit vector o about h.
So the captured data speciﬁes the NDF only partially, over Ω.

A straightforward solution for ﬁtting this partial normal distri-
bution function D(x, h)1 adapts the method in [Ngan et al. 2005].
Starting from constant shadow term S(x, k)=1, the partial NDF is
computed as:

4π ˜ρs (x, o, i (h)) (i (h) · n) (o · n)

D(x, h) =

S (x, i (h)) S(x, o)




0,

, h ∈ Ω

h 6∈ Ω

(11)



where i(h) = reﬂ(o, h). The shadowing term is then derived from
the NDF using (5). This leads to a scheme that iteratively updates
ﬁrst D and then S until convergence. Although this method ﬁts the
captured data well, it is biased as illustrated in Figure 5b, and does
not accurately predict specular response at other views.

The problem arises because single-view data determines a par-
tial NDF over Ω (Figure 4a), while the shadowing term requires
the full NDF over Ω+ (Figure 4b). If we assume that D = 0 out-
side Ω and use it to estimate the shadowing term in (5), we end up
overestimating S. After iterating, the NDF becomes biased.

To solve this problem, we constrain S to its minimum value over
all azimuthal angles via S(x, i) = min i′ {S(x, i′) | i′ · n = i · n}. With

1Though the NDF D and its domain Ω are inferred in terms of half-angle
space, h, they determine a probability distribution over the hemisphere of
microfacet normal directions. Nevertheless, we will continue to denote the
function’s argument as h.

Figure 5: Recovering the partial NDF from a single-view BRDF slice: (a)
ground truth, (b) reconstruction using [Ngan et al. 2005] (domain Ω is inside
the dashed blue curve), (c) reconstruction computed by our method, (d) con-
ﬁdence function W . The top row (a-c) shows the NDF D while the bottom
row (a-c) shows its shadowing term S (log of value). Both are visualized
using an orthographic projection.

1
2

+

(cid:3)

this isotropically constrained S, we iteratively update the NDF (11)
and its shadowing term (5) until convergence, as in the straightfor-
ward method. Figure 5c shows that the resulting partial NDF is
closer to the ground truth in Figure 5a. We have experimented with
other schemes to extend the domain of D outside Ω in order to de-
ﬁne S, including projection to low-order spherical harmonics and
push/pull. None has worked as well as this simple min-azimuthal
method. Note that the constrained shadowing term is only used to
ﬁt the partial NDF; the ﬁnal S is derived from the completed NDF
in the last step.

To represent the partial NDF’s domain Ω, we deﬁne a conﬁdence

function via

W (x, h) =

(reﬂ(o, h) · n)

(12)

(cid:2)

where [ · ]+ denotes max{ · , 0}. W is positive for h within Ω, grad-
ually decreases to 0 at its boundary, and remains 0 outside it. Low
conﬁdence is assigned near the boundary of Ω where BRDF values
tend to be extrapolated and dominated by the Fresnel term. The
partial NDF D(x, h) and its conﬁdence function W (x, h) are repre-
sented as a hemicube over h.

Note that it is possible to explicitly represent spatial variation in
the set of light directions iq(x) and view direction o(x), by using
a spatially varying NDF domain Ω(x). This accounts for the ﬁnite
lighting span and camera distance. Unfortunately, it also compli-
cates our synthesis algorithm and we leave the idea for future work.

5.2 NDF Completion using Synthesis

After recovering the partial NDF D(x, h) at each surface point, we
complete it using partial NDFs at other points. The key observation
is that on a sample surface, we can always ﬁnd surface points having
similar NDFs but different local frames; i.e., different azimuthal
rotations around the normal. So the captured data actually reveals
different parts of the common NDF at such points. As shown in
Figure 6, we exploit this idea by ﬁnding rotated partial NDFs at
other surface points that are similar within their shared half-space
domain and merging them.

Figure 6: Merging partial NDFs from different points. (a) Partial NDF of
point x is similar to points a and b. (b) Da and Db are aligned to Dx by
azimuthal rotation. Aligned NDFs D′
b are merged to complete Dx.

a and D′

41:4       •       J. Wang et al.ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.Given the partial NDF tuple Ψ(x) = hD(x, h),W (x, h)i deﬁned
on each surface point, the exemplar set Ψ∗ is generated by rotating
Ψ(x) around the normal n by all possible azimuthal angles ϕ:

Ψ∗ = {Ψ(x,ϕ)} = {hDϕ(x, h),W ϕ(x, h)i}

=

hD (x, R(ϕ) h) ,W (x, R(ϕ) h)i

ϕ ∈ [0, 2π]

(13)

n

where R(ϕ) is an azimuthal rotation of ϕ.

(cid:12)
(cid:12)
(cid:12)

o

NDFSynthesis(Ψ(x),Ψ∗)

For each surface point x

Ψ0(x) = Ψ(x)
While (Ωi(x) < Ω+)

Ψ(x′,ϕ′) = BestMatch(Ψi(x),Ψ∗)
Ψi+1(x) = Merge(Ψi(x),Ψ(x′,ϕ′))

We complete each point’s partial NDF with iterative synthesis
using the pseudo-code shown above. For each surface point x, start-
ing from the initial NDF tuple Ψ0(x) = Ψ(x) = hD(x, h),W (x, h)i,
we update the NDF and its conﬁdence function iteratively, yield-
ing Ψi(x) = hDi(x, h),Wi(x, h)i at each iteration i. Each iteration
extends the NDF domain incrementally in counter-clockwise order
around the azimuth, as we will further explain in the next section.
The update searches the exemplar set Ψ∗ to ﬁnd a match of the

current NDF tuple Ψi(x), Ψ(x′,ϕ′), via

(x′,ϕ′) = argmin
˜x, ˜ϕ

{dist (Ψi(x), Ψ(˜x, ˜ϕ))} .

(14)

Distance between two partial NDF tuples Ψ1 = hD1,W1i and

Ψ2 = hD2,W2i is deﬁned using the integral

dist(Ψ1, Ψ2) = ZΩ

Tp

over their overlapping region

W1(h)W2(h)

D1(h)

−

s1

(cid:13)
(cid:13)
(cid:13)
(cid:13)

W1(h)W2(h) dωh

2

dωh

D2(h)
s2 (cid:13)
(cid:13)
(cid:13)
(cid:13)

(15)

ZΩ

Tp

Ω

= {Ω1

Ω2} = {h |W1(h)W2(h) > 0}.

T

\

The scalars s1 and s2 normalize the partial NDFs over the over-
lapped region and are deﬁned as sk =

Dk(h) dωh for k=1,2.

Ω

To maintain synthesis quality, we exclude candidates from the
search set Ψ∗ whose partial domains overlap insufﬁciently with
Ψi(x). We also exclude candidates that insufﬁciently extend Ψi(x).
We adopt the simple rule that candidates must have 50 − 85% over-
lap with Ψi(x).

R

T

After determining the best match, the new NDF tuple Ψi+1(x) is

updated by merging in the optimal extension Ψ(x′,ϕ′) via

Di+1(x, h) =

Wi(x, h) Di(x, h) + s1
s2

W ϕ′

(x′, h) Dϕ′

Wi(x, h) +W ϕ′ (x′, h)

(x′, h)
,

Wi+1(x, h) = max

Wi(x, h), W ϕ′
n

(x′, h)

.

o

Continuing with the new partial NDF tuples Ψi+1(x) at each sur-
face point, we repeat the above steps until each point’s NDF cov-
ers the hemisphere. The NDF coverage Ωi(x) after each iteration
can be reconstructed from Wi(x, h) via Ωi(x) = {h | Wi(x, h) > 0}.
There may be small uncovered regions left in some NDFs after syn-
thesis, which can be interpolated with the push-pull method. We
ﬁnd that NDFs are suitably completed after ﬁve to seven iterations.

(16)

(17)

φ

jn

f

1j

(a)

(b)

(c)

(d)

Figure 7: Overlap region approximation in search pruning.
(a) Current
Ψi(x), formed by an earlier merge of two partial NDFs. (b) Overlap region
(enclosed by red line) of Ψi(x) and a candidate (orange). (c) The overlap
Ω
region can be approximated by the intersection of Ω with a rotated version
of itself. (d) A range of rotations, ϕi, are uniformly sampled to get a discrete
set of overlap regions used for search pruning.

T

5.3 Synthesis Acceleration

A naive synthesis implementation is prohibitively slow due to the
expensive distance calculation in the candidate search and the large
number of surface points. Two ideas speed up synthesis.

Search Pruning We accelerate the search by pruning the set of
candidates. At ﬁrst sight, the region Ψi(x) is extended differently
at each point and each iteration, depending on which candidate is
selected for the merge. The overlap region therefore cannot be pre-
determined. However as shown in Figure 7b, as we extend the NDF
domain azimuthally, the overlap region is mostly determined by the
candidate we merged last and the current candidate. Therefore, the
overlap region can be represented as the intersection of Ω with a
rotated version of itself, Ω(ϕ) = Ω

R(ϕ)Ω as in Figure 7c.

T

Since the candidates have a 50-85% overlap with Ψi(x), ϕ need
only be chosen in a limited range which we uniformly sample using
nφ=20 angles. The result is a set of regions {Ω(ϕi)|i = 1, 2, . . . , nφ}
as shown in Figure 7d. Within each Ω(ϕi), we compute the his-
togram of D(x, h) at each surface point x using m = 32 buckets over
D’s range [0,1]. We then use the resulting 32D vector as a search
key to ﬁnd merge candidates that are similar within the region of
overlap. To accelerate this search, we precompute an ANN tree of
the histogram vectors before synthesis [Mount and Arya 1997]. A
separate tree is built for each ϕi.

During synthesis, for each ϕi, we compute the histogram of the
current region Ψi(x) over Ω(ϕi). We use the corresponding ANN
tree to quickly ﬁnd the ﬁve best matches in terms of L2 distance in
histogram space. For each match, gradient descent obtains the opti-
mal ϕ′ by minimizing (14) using the full-blown distance computa-
tion in (15). The minimal error match over all ϕ is then selected to
merge. In the ﬁnal iteration, we must consider overlaps between the
ﬁrst as well as the last merged domain because azimuthal rotation
is periodic. We simply do the ANN search over both these domains
to form a larger candidate set before applying the ϕ optimization.

NDF Clustering The second acceleration idea reduces both the
number of NDFs that must be synthesized as well as searched.
Since many surface points have similar reﬂectance and can be
approximated well by a linear combination of a few representa-
tives [Matusik et al. 2003; Lawrence et al. 2006], we can perform
expensive NDF completion on a smaller set of representatives, and
obtain a high-resolution result by interpolating their completions.

To ﬁnd the set of representatives, we apply k-means clustering
to the partial NDFs of all surface points. A representative in each
cluster is selected that is closest to the cluster center where distance
is computed according to (15). All examples in the paper set the
number of representatives to be 1% of the number of surface points.
A large number of clusters ensures each contains only samples that
are similar.

We then ﬁnd interpolation weights on the partial data. Each
(non-representative) partial NDF, D(xi, h), is approximated by lin-

Modeling Anisotropic Surface Reflectance with Example-Based Microfacet Synthesis       •       41:5ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.ear interpolation on a set of neighbor representatives, D(x∗

j , h), via

D(xi, h) = ∑
j∈Ni

wi j D(x∗

j , h),

(18)

where j ∈ Ni indexes one of the neighbor representatives of xi, and
wi j are the interpolation coefﬁcients. To determine the neighbor set
Ni for xi, we ﬁrst collect its k=16 nearest representatives, exclud-
ing those whose distance is larger than 5λ where λ is the smallest
distance between two representative NDFs. We then solve for the
weights wi j in the linear equation system represented by (18), aug-
mented by the single equation ∑ j∈Ni wi j = 1. We set k=16 based on
the observation that the intrinsic dimension of the BRDF space is
roughly 16 [Matusik et al. 2003].

5.4 Estimating the Remaining Parameters
We compute the specular coefﬁcient given the completed NDF D
via ks(x) =
(n · h) D(x, h) dωh. We then normalize the NDF by
D(x, h)/ks(x) and use it to compute the shadowing term from (5).
Finally, the relative refraction index η(x) at each surface point is

Ω+

R

estimated by minimizing

E(η(x)) =

||Fc(i, o,η(x)) − Fm(x, i, o)||2 dω

(19)

ZΩ+

where Fc(i, o,η(x)) is computed according to (3), and Fm(x, i, o) is
computed from the measured ρs(x, o, i) as

Fm(x, i, o) =

4πρs(x, o, i) (i · n) (o · n)
S(x, i) S(x, o) ks(x) D(x, h)

.

(20)

We solve for η(x) with the Levenberg-Marquardt algorithm [Press
et al. 1992].

6 Experimental Results
We tested our method on publicly available, full 6D SVBRDF data
as well as 4D, ﬁxed-view data slices captured with our simple de-
vice. Table 1 summarizes statistics for the latter, including spatial
resolution of acquired images, light resolution (product of the num-
ber of LEDs used in capture and the number of translation steps),
resolution of the top hemicube face of the resulting NDFs, and the
camera viewing angles. Viewing direction is measured in terms of
its elevation angle (angle with vertical axis Z) θ and azimuthal an-
gle (angle in XY plane) ϕ.

We implemented our microfacet synthesis algorithm on a PC
with Intel CoreTM2 Quad 2.13GHz CPU and 4GB memory. Cap-
turing takes about 1 hour using single-exposure acquisition (for
less specular materials like velvet) and 5-10 hours using multiple-
exposure acquisition (for highly specular materials like aluminum).
The angular sampling density for lighting is manually chosen: for
relatively diffuse materials, we can disable half the LEDs to speed
up the capturing process. Image data processing (including calibra-
tion, HDR reconstruction, diffuse separation, and resampling) takes
about 2-4 hours, and is dominated by disk I/O. Partial NDF recon-
struction takes about an hour, synthesis 2-3 hours, and estimation
of the remaining BRDF parameters 3-4 hours. Rendering results
shown in the paper use ray tracing. Only direct lighting effects are
included; inter-reﬂection between surfaces is ignored.

6.1 Validation with Dense-View Data
We applied our synthesis algorithm on two SVBRDF datasets from
[Lawrence et al. 2006] and shared by the Princeton Graphics Group.
This data was captured by a spherical gantry whose movable cam-
era/lamp samples hundreds of lighting and tens of viewing direc-
tions. We applied our algorithm to a single view slice of the data,
reserving the remaining views as a validation reference. The com-
parison is shown in Figure 8. On the wallpaper example (a,b,c,d),

Sample

red satin
yellow satin
wallpaper
velvet
rose wood
oak wood
aluminium
copper

Image Res. Light Res. NDF Res. View (θ,ϕ)
(57.6◦, 0.6◦)
(58.3◦, −0.2◦)
(63.6◦, −0.8◦)
(61.2◦, 2.1◦)
(53.3◦, 4.6◦)
(48.6◦, −0.3◦)
(40.8◦, 4.9◦)
(51.0◦, 1.9◦)

32 × 32
32 × 32
32 × 32
32 × 32
32 × 32
32 × 32
128 × 128
32 × 32

850×850
750×750
800×800
600×500
600×600
800×800
250×400
800×800

20×24
20×24
20×20
20×20
40×65
40×65
40×65
40×50

Table 1: Acquisition parameters for various samples.

the anisotropic reﬂectance and the local frame variation over fan-
like regions is reproduced well by our technique. The greeting
card result (e,f,g,h) preserves the reﬂectance properties (in this case,
isotropic) and their spatial variation.

6.2 Results with Single-View Data

We also experimented with data from our simple acquisition device.
The following results were all obtained from data captured on this
device and synthesized using our technique.

Figure 9 compares real images to rendered results from our
method, on three material samples. The reconstruction uses a differ-
ent view than the one captured. Although a good match is achieved,
subtle differences could be due to errors in photometric calibration
and white balance correction in the camera. A slight reduction in
sharpness on the aluminum highlights in (b) probably means that
our NDF hemicube resolution could be usefully increased. Results
for other material samples can be found in the accompanying video.
Figure 10 compares our synthesized microfacet model with a
ﬁtted Ward model. Given data from our device, the Ward model
parameters are ﬁt at each surface point using the Levenberg-
Marquardt algorithm [Press et al. 1992], as in [Goldman et al.
2005]. This process took about 6 hours for the anisotropic version
of the model and so is comparable to the processing cost of our syn-
thesis algorithm. Though the anisotropic Ward model matches bet-
ter than the isotropic one, neither captures the visual characteristics
of this red satin example as well as our technique. A comparison
of 6D SVBRDFs is difﬁcult to convey in a single image; please see
the accompanying video for more extensive comparisons.

Figure 1 shows pillows decorated with four different materials
and rendered under an HDR lighting environment. Satin (a,b) ex-
hibits strong anisotropy due to the consistent ﬁber orientation. Fine
details in the needlework (b) are reproduced by our model. The
wallpaper example (c) shows local frame rotation of the plastic
coating microstructure. A result for velvet in shown in (d).

Figure 11ab shows dishes mapped with weathered copper and
brushed aluminum. Our model captures spatial variation to pro-

Figure 8: Validation comparison. The ﬁrst row shows original measure-
ments from the database; the second shows our synthesis results. The left-
most two columns are from wallpaper data [a,c = view#1/light#125; b,d =
view#2/light#124]. The rightmost two columns are from greeting card data
[e,g = view#0/light#188; f,h = view#2/light#12]. View #3 (wallpaper) and
#0 (greeting card) were used as the input slice for our synthesis.

41:6       •       J. Wang et al.ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.samples. We have demonstrated successful results for a variety of
materials from data captured from a single view. Our method avoids
image registration and greatly simpliﬁes data acquisition and pro-
cessing. We hope this leads to a proliferation of measured SVBRDF
data for many materials and applications.

Our approach is also subject to a number of limitations. Since
the NDF at each point is synthesized from partial NDFs at other
points rather than from 4D BRDF data, the resulting BRDF is not
captured exactly. Our micro-facet model assumes only direct re-
ﬂection, and so does not capture unusual phenomena dominated by
multiple light bounces, such as retro-reﬂection. The intent of our
method is to visually convey anisotropic reﬂectance of common
materials from a small amount of easily captured data. Acquisi-
tion from a single view assumes enough sample points with shared
but rotated reﬂectance. As we state in Section 4, more reﬂectance
data can be obtained simply by rotating the sample.

In future work, we are interested in further optimizing the perfor-
mance of the data capture, synthesis, and parameter estimation al-
gorithms. Acquisition and processing might be sped up by exploit-
ing sparsity still further, by capturing smaller domains over light
direction and completing them by synthesis. We would also like
to handle samples that are not ﬂat. Both these ideas would require
extending our synthesis algorithm to account for spatial variation in
the NDF domain Ω(x). Backtracking during the NDF merging and
capturing multiple views with (perhaps limited) surface correspon-
dence information might improve synthesis accuracy. Generalizing
the microfacet model to capture translucent objects and multiple-
bounce effects is another extension. Finally, we want to explore
ways to accelerate rendering of our SVBRDF model.

Acknowledgements
The LED array was designed and produced by Le Ma. Qiang Dai
helped us to capture the raw data. The authors thank Steve Lin
for discussions on BRDF modeling and for proofreading this paper,
and Dong Xu for discussions on NDF clustering. We also thank the
anonymous reviewers for their helpful suggestions and comments.

References
ASHIKHMIN, M., AND SHIRLEY, P. 2000. An anisotropic phong

BRDF model. Journal of Graphics Tools 5, 2, 25–32.

ASHIKMIN, M., PREMO ˇZE, S., AND SHIRLEY, P.

2000. A
microfacet-based BRDF generator. In Proceedings of ACM SIG-
GRAPH 2000, Computer Graphics Proceeding, Annual Confer-
ence Series, ACM Press/Addison-Wesley Publishing Co., New
York, NY, USA, 65–74.

BECKMANN, P. 1965. Shadowing of random rough surfaces. IEEE

Transactions on Antennas and Propagation, 13, 384–388.

COOK, R. L., AND TORRANCE, K. E. 1981. A reﬂectance model
for computer graphics. In Computer Graphics (Proceedings of
SIGGRAPH 81), 307–316.

DANA, K. J., NAYAR, S. K., VAN GINNEKEN, B., AND KOEN-
DERINK, J. J. 1999. Reﬂectance and texture of real-world sur-
faces. ACM Transactions on Graphics 18, 1, 1–34.

DANA, K. J. 2001. BRDF/BTF measurement device.

In Pro-
ceedings of Eighth IEEE International Conference on Computer
Vision, vol. 2, 460–466.

DEBEVEC, P. E., AND MALIK, J. 1997. Recovering high dy-
namic range radiance maps from photographs. In Proceedings
of ACM SIGGRAPH 1997, Computer Graphics Proceeding, An-
nual Conference Series, ACM Press/Addison-Wesley Publishing
Co., New York, NY, USA, 369–378.

Figure 9: Comparison using single-view data from our simple device: (a)
yellow satin, (b) brushed aluminum, (c) oak. We compare two different
lighting directions (consecutive pairs of rows, direction is speciﬁed below
the row pair), at a view (θ=50.9◦, ϕ=-15.3◦) different from the one captured.
Rows (1) and (3) are images of the original sample; (2) and (4) are rendered
from our synthesized model.

vide a realistic weathered appearance in (a), which includes both
isotropic and anisotropic reﬂectance. The brushed aluminum in (b)
is mapped onto the dish model using texture coordinates which sim-
ulate a circular brushing. Convincing, fan-shaped anisotropic high-
lights are generated.

Figure 11cd shows two kinds of wood mapped on a simple board
model. Our method visually captures the anisotropic reﬂectance
of wood and preserves subtle differences in appearance between
the coarser oak strands vs.
the much ﬁner rosewood ﬁbers. Our
method models both surface and (thin layer) subsurface reﬂections
[Marschner et al. 2005], without requiring their explicit separation.
The accompanying video shows more light/view conﬁgurations.

7 Conclusion
Our microfacet synthesis technique generates anisotropic, spatially
varying surface reﬂectance consistent with the appearance of real

Figure 10: Comparison with parametric models: (a) real measured appear-
ance, (b) our result, (c) isotropic Ward, (d) anisotropic Ward. The viewing
direction reconstructed here is (θ=50.9◦,ϕ=-15.3◦).

Modeling Anisotropic Surface Reflectance with Example-Based Microfacet Synthesis       •       41:7ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.Figure 11: More results: (a) weathered copper, (b) brushed aluminum, (c) oak wood, (d) rose wood.

DEBEVEC, P., HAWKINS, T., TCHOU, C., DUIKER, H.-P.,
2000. Acquiring the re-
SAROKIN, W., AND SAGAR, M.
In Proceedings of ACM SIG-
ﬂectance ﬁeld of a human face.
GRAPH 2000, Computer Graphics Proceeding, Annual Confer-
ence Series, ACM Press/Addison-Wesley Publishing Co., New
York, NY, USA, 145–156.

EFROS, A. A., AND FREEMAN, W. T. 2001.

Image quilting
for texture synthesis and transfer. In Proceedings of ACM SIG-
GRAPH 2001, Computer Graphics Proceeding, Annual Confer-
ence Series, ACM, New York, NY, USA, 341–346.

GARDNER, A., TCHOU, C., HAWKINS, T., AND DEBEVEC, P.
2003. Linear light source reﬂectometry. ACM Transactions on
Graphics 22, 3, 749–758.

GARG, G., TALVALA, E.-V., LEVOY, M., AND LENSCH, H. P. A.
2006. Symmetric photography: exploiting data-sparseness in re-
ﬂectance ﬁelds. In Eurographics Workshop/ Symposium on Ren-
dering, Eurographics Association, Nicosia, Cyprus, 251–262.

GOLDMAN, D. B., CURLESS, B., HERTZMANN, A., AND SEITZ,
S. M. 2005. Shape and spatially-varying BRDFs from photo-
metric stereo. In International Conference on Computer Vision,
I: 341–348.

GORTLER, S. J., GRZESZCZUK, R., SZELISKI, R., AND COHEN,
M. F. 1996. The lumigraph. In Proceedings of ACM SIGGRAPH
1996, Computer Graphics Proceeding, Annual Conference Se-
ries, ACM, New York, NY, USA, 43–54.

GU, J., TU, C.-I., RAMAMOORTHI, R., BELHUMEUR, P., MA-
TUSIK, W., AND NAYAR, S. 2006. Time-varying surface ap-
pearance: acquisition, modeling and rendering. ACM Transac-
tions on Graphics 25, 3, 762–771.

HAN, J. Y., AND PERLIN, K. 2003. Measuring bidirectional
texture reﬂectance with a kaleidoscope. ACM Transactions on
Graphics 22, 3, 741–748.

IRAWAN, P., AND MARSCHNER, S. R. 2006. A simple, accurate
texture model for woven cotton cloth. Technical report PCG-06-
01, Program of Computer Graphics, Cornell University, June.

KAJIYA, J. T. 1985. Anisotropic reﬂection models.

In Com-
puter Graphics (Proceedings of ACM SIGGRAPH 85), ACM,
New York, NY, USA, 15–21.

KWATRA, V., SCH ¨ODL, A., ESSA, I., TURK, G., AND BOBICK,
A. 2003. Graphcut textures: Image and video synthesis using
graph cuts. ACM Transactions on Graphics 22, 3 (July), 277–
286.

LAFORTUNE, E. P. F., FOO, S.-C., TORRANCE, K. E., AND
GREENBERG, D. P.
1997. Non-linear approximation of
In Proceedings of ACM SIGGRAPH
reﬂectance functions.
1997, Computer Graphics Proceeding, Annual Conference Se-
ries, ACM Press/Addison-Wesley Publishing Co., New York,
NY, USA, 117–126.

LAWRENCE, J., BEN-ARTZI, A., DECORO, C., MATUSIK, W.,
PFISTER, H., RAMAMOORTHI, R., AND RUSINKIEWICZ, S.
2006. Inverse shade trees for non-parametric material represen-
tation and editing. ACM Transactions on Graphics 25, 3, 735–
745.

LENSCH, H. P. A., KAUTZ, J., GOESELE, M., HEIDRICH, W.,
AND SEIDEL, H.-P. 2003. Image-based reconstruction of spatial
appearance and geometric detail. ACM Transaction on Graphics
22, 2 (Apr.), 234–257.

LENSCH, H. P. A., LANG, J., S ´A, A. M., AND SEIDEL, H.-P.
2003. Planned sampling of spatially varying BRDFs. Computer
Graphics Forum 22, 3, 473–482.

MARSCHNER, S. R., JENSEN, H. W., CAMMARANO, M., WOR-
LEY, S., AND HANRAHAN, P. 2003. Light scattering from
In Proceedings of ACM SIGGRAPH 2003,
human hair ﬁbers.
J. Hodgins and J. C. Hart, Eds., vol. 22(3) of ACM Transactions
on Graphics, 780–791.

41:8       •       J. Wang et al.ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.ZICKLER, T., ENRIQUE, S., RAMAMOORTHI, R., AND BEL-
HUMEUR, P. 2005. Reﬂectance sharing: image-based rendering
from a sparse set of images. In Eurographics Symposium on Ren-
dering, Eurographics Association, Konstanz, Germany, K. Bala
and P. Dutr´e, Eds., 253–264.

MARSCHNER, S. R., WESTIN, S. H., ARBREE, A., AND MOON,
J. T. 2005. Measuring and modeling the appearance of ﬁnished
wood. ACM Transactions on Graphics 24, 3 (July), 727–734.

MATUSIK, W., PFISTER, H., BRAND, M., AND MCMILLAN, L.
2003. A data-driven reﬂectance model. ACM Transactions on
Graphics 22, 3, 759–769.

MCALLISTER, D. K., LASTRA, A. A., AND HEIDRICH, W.
2002. Efﬁcient rendering of spatial bi-directional reﬂectance
In Proceedings of the 17th Eurograph-
distribution functions.
ics/SIGGRAPH workshop on graphics hardware (EGGH-02),
ACM Press, New York, S. N. Spencer, Ed., 79–88.

MOUNT, D., AND ARYA, S. 1997. ANN: A library for approxi-
mate nearest neighbor searching. In CGC 2nd Annual Fall Work-
shop on Computational Geometry.

MULLER, G., MESETH, J., SATTLER, M., SARLETTE, R., AND
KLEIN, R. 2005. Acquisition, synthesis, and rendering of bidi-
rectional texture functions. Computer Graphics Forum 24, 1,
83–109.

NGAN, A., DURAND, F., AND MATUSIK, W. 2005. Experimental
analysis of BRDF models. In Rendering Techniques 2005: 16th
Eurographics Workshop on Rendering, 117–126.

NICODEMUS, F. E., RICHMOND, J. C., HSIA, J. J., GINSBERG,
I. W., AND LIMPERIS, T. 1977. Geometric considerations and
nomenclature for reﬂectance. Monograph 161,National Bureau
of Standards (US).

POULIN, P., AND FOURNIER, A. 1990. A model for anisotropic
In Computer Graphics (Proceedings of ACM SIG-

reﬂection.
GRAPH 90), F. Baskett, Ed., vol. 24, 273–282.

PRESS, W. H., ET AL. 1992. Numerical recipes in C (second

edition). Cambridge University Press.

RUSINKIEWICZ, S. M. 1998. A new change of variables for efﬁ-
cient BRDF representation. In Rendering Techniques (Proceed-
ing of Eurographics Workshop on Rendering), 11–22.

SMITH, B. G. 1967. Geometrical shadowing of a random rough
surface. IEEE Transactions on Antennas and Propagation, 15,
668 – 671.

WARD, G. J. 1992. Measuring and modeling anisotropic reﬂection.
In Computer Graphics (Proceedings of ACM SIGGRAPH 92),
ACM Press, New York, NY, USA, 265–272.

WESTIN, S. H., ARVO, J. R., AND TORRANCE, K. E. 1992. Pre-
In Com-
dicting reﬂectance functions from complex surfaces.
puter Graphics (Proceedings of ACM SIGGRAPH 92), ACM
Press, New York, NY, USA, 255–264.

WEYRICH, T., LAWRENCE,

J., LENSCH, H. P. A.,
RUSINKIEWICZ, S., AND ZICKLER, T.
Principles
of appearance acquisition and representation. In Short Course
ICCV 2007.

2007.

YASUDA, T., YOKOI, S., ICHIRO TORIWAKI, J., AND INAGAKI,
K. 1992. A shading model for cloth objects. IEEE Computer
Graphics and Applications 12, 6 (Nov.), 15–24.

ZHANG, Z. 2000. A ﬂexible new technique for camera calibration.
In IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, vol. 22, 1330– 1334.

Modeling Anisotropic Surface Reflectance with Example-Based Microfacet Synthesis       •       41:9ACM Transactions on Graphics, Vol. 27, No. 3, Article 41, Publication date: August 2008.