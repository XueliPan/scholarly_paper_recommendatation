Yanyun Chen

Xin Tong

Jiaping Wang(cid:3)

Stephen Lin

Baining Guo

Heung-Yeung Shum

Shell Texture Functions

Microsoft Research Asia

Abstract

We propose a texture function for realistic modeling and ef(cid:2)cient
rendering of materials that exhibit surface mesostructures, translu-
cency and volumetric texture variations. The appearance of such
complex materials for dynamic lighting and viewing directions is
expensive to calculate and requires an impractical amount of stor-
age to precompute. To handle this problem, our method models an
object as a shell layer, formed by texture synthesis of a volumetric
material sample, and a homogeneous inner core. To facilitate com-
putation of surface radiance from the shell layer, we introduce the
shell texture function (STF) which describes voxel irradiance (cid:2)elds
based on precomputed (cid:2)ne-level light interactions such as shadow-
ing by surface mesostructures and scattering of photons inside the
object. Together with a diffusion approximation of homogeneous
inner core radiance, the STF leads to fast and detailed raytraced
renderings of complex materials.

Keywords:
mesostructure, subsurface scattering, texture synthesis, BTF

Texture mapping, re(cid:3)ectance and shading models,

1 Introduction

The appearance of an object arises from a multitude of light in-
teractions on and within the object volume. These various forms
of re(cid:3)ection and scattering produce visual effects such as shad-
owing, masking, interre(cid:3)ection, translucency and (cid:2)ne-scale silhou-
ettes which elevate the realism of rendered images when they are
accounted for. These interactions are physically governed by shape
and material attributes that typically vary over an object.

Texture functions have long been used to map spatially-variant ma-
terial attributes such as color, surface normal perturbations [Blinn
1978], height (cid:2)eld displacements [Cook 1984] and volumetric ge-
ometry [Neyret 1998] onto surfaces. While these methods can ad-
equately model (cid:2)ne-scale surface geometry, known as mesostruc-
ture, and its interaction with illumination, appearance effects that
arise from light transport within the material are not considered.
Since many materials in the physical world are translucent to some
degree, subsurface scattering is a vital element in realistic appear-
ance [Hanrahan and Krueger 1993]. Subsurface scattering and
other visual phenomena of a material can be captured in an image-
based representation such as a bidirectional texture function (BTF)
[Dana et al. 1999], which records the appearance of a surface patch
under various lighting and viewing directions. The BTF, however,
is an incomplete representation for mapping and synthesis, because

(cid:3)This work was done while Jiaping Wang was visiting Microsoft Re-
search Asia from the Institute of Computing Technology, Chinese Academy
of Sciences.
Permission  to  make  digital  or  hard  copies  of  part  or  all  of  this  work  for  personal  or
classroom use is granted without fee provided that copies are not made or distributed for
profit or direct commercial advantage and that copies show this notice on the first page or
initial  screen  of  a  display  along  with  the  full  citation.  Copyrights  for  components  of  this
work owned by others than ACM must be honored. Abstracting with credit is permitted. To
copy  otherwise,  to  republish,  to  post  on  servers,  to  redistribute  to  lists,  or  to  use  any
component  of  this  work  in  other  works  requires  prior  specific  permission  and/or  a  fee.
Permissions may be requested from Publications Dept., ACM, Inc., 1515 Broadway, New
York, NY 10036 USA, fax +1 (212) 869-0481, or permissions@acm.org.
© 2004 ACM 0730-0301/04/0800-0343 $5.00

Figure 1: Shell texture function renderings of a non-homogeneous
bird with surface mesostructures, from different viewing angles.
Evident are detailed appearance features such as mesostructure sil-
houettes, translucency with material variations, and transmission of
backlighting.

it does not provide explicit shape information needed for rendering
mesostructure silhouettes. Moreover, the effects of subsurface scat-
tering are inadequately captured, e.g., backlighting through translu-
cent objects is not captured in BTF acquisition.

In this paper, we present a method that models and renders not
only mesostructure shadowing, masking, interre(cid:3)ection and silhou-
ettes on a surface, but also subsurface scattering within a non-
homogeneous volume. For modeling, we propose an object repre-
sentation consisting of a volumetric shell layer and an inner core, as
illustrated in Fig. 2. The shell is created by texture synthesis using
a volumetric material sample that can contain mesostructures and
material non-homogeneities. Since material non-homogeneities
from deep within the volume have a relatively subtle effect on ap-
pearance, the inner core is modelled as a homogeneous material.

Rendering this model with a full participating media simulation
[Jensen and Christensen 1998] could capture all the aforementioned
appearance details but also would incur a large computational ex-
pense. To ef(cid:2)ciently render the detailed shell-core model, we pro-
pose the shell texture function (STF), which represents the irra-
diance distribution of a shell voxel with respect to incident illu-
mination direction. The STF is precomputed by photon mapping
that accounts for the (cid:2)ne-level lighting interactions among surface
mesostructures and the scattering and absorption of photons within
the possibly non-homogeneous material volume. With STF irra-
diance values for each shell voxel and a rapid simulation of sub-
surface scattering in the homogeneous inner core using the dipole
diffusion approximation of [Jensen and Buhler 2002], objects with
complex mesostructure and volume non-homogeneity can be ef(cid:2)-
ciently rendered by simple radiance calculations and ray tracing.

Using the STF in the shell-core framework allows us to ef(cid:2)ciently
generate realistic images of complex materials such as shown in
Fig. 1. We note that detailed silhouettes of the orange mesostruc-
ture protrusions cannot be rendered by mapping BTF images onto
the mesh, and the transmissions of backlighting shown in the right-

343

(cid:8)(cid:9)(cid:3)(cid:10)(cid:10)

 

(cid:8)(cid:11)(cid:12)(cid:13)(cid:11)(cid:4)(cid:14)(cid:15)(cid:16)(cid:3)(cid:5)(cid:17)(cid:15)(cid:18)(cid:3)(cid:4)

 

(cid:1)(cid:2)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:4)(cid:3)

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:4)(cid:3)

Figure 2: Shell-core object model. (a) An object is composed of
a volumetric shell and an inner core. (b) The shell is formed by
texture synthesis of a material sample. The sample is represented
by a rectangular volume with mesostructure, such that it contains
voxels of both the subsurface layer and the surrounding free space.

most image cannot be reasonably modelled in an image-based tex-
ture, since backlighting appearance captured from a given geome-
try is not (cid:2)t for use on arbitrary shapes. As a texture function in a
shell-core model, the STF of a volumetric material sample has the
(cid:3)exibility to be used with any mesh.

2 Related Work

Mesostructures and subsurface scattering are signi(cid:2)cant factors that
determine the appearance of real-world surfaces. In previous work
on subsurface scattering, detailed renderings of translucent objects
have been computed by simulations of radiative transfer through
a participating medium [Dorsey et al. 1999; Pharr and Hanrahan
2000]. Although these simulations can handle materials of arbitrary
composition, they are computationally expensive, and other meth-
ods achieve greater ef(cid:2)ciency by speci(cid:2)cally addressing translucent
materials that are homogeneous. Hanrahan and Krueger [Hanrahan
and Krueger 1993] presented an analytic expression for single scat-
tering in a homogeneous, uniformly lit slab. To this single scatter-
ing solution, Jensen et al. used diffusion approximations for multi-
ple scattering to rapidly compute subsurface scattering in homoge-
neous media [Jensen et al. 2001; Jensen and Buhler 2002] (see also
[Koenderink and van Doorn 2001]). Recently, several researchers
have proposed methods for interactive rendering of homogeneous
scattering materials [Mertens et al. 2003; Hao et al. 2003]. A large
number of translucent objects, however, are not homogeneous, such
as veined marble and human skin, and an ef(cid:2)cient rendering tech-
nique that accommodates some degree of non-homogeneity is de-
sirable. Moreover, previous subsurface methods do not account for
surface mesostructures, which affect the distribution of light enter-
ing a volume.

Koenderink and van Doorn pointed out
the importance of
mesostructures to surface appearance, and noted the shortcomings
of traditional texture mapping and bump mapping for mesostruc-
ture rendering [Koenderink and Doorn 1996]. Dana et al.
intro-
duced the BTF as an image-based description of mesostructures,
and measured the BTFs of many real-world surfaces to form the
CUReT database [Dana et al. 1999]. Leung and Malik introduced
3D textons for analyzing surface mesostructures [Leung and Malik
2001], and building on this work, Tong et al. derived an algorithm
for synthesizing a BTF on arbitrary surfaces [Tong et al. 2002].

Besides BTFs, other image-based representations of appearance
have been proposed, such as surface light (cid:2)elds [Wood et al. 2000;
Chen et al. 2002] and polynomial texture maps [Malzbender et al.
2001]. These image-based descriptors are intended for restricted
lighting and viewing conditions. Surface light (cid:2)elds and view-
dependent texture maps record surface appearance from varying
viewing directions under a (cid:2)xed lighting condition, while polyno-

mial texture maps represent appearance for (cid:2)xed viewing geome-
try and variable illumination. Additionally, image-based techniques
[Wood et al. 2000; Chen et al. 2002; Debevec et al. 2000; Matusik
et al. 2002] model the appearance of a given object. In all of these
image-based methods, translucency features such as transmission
of backlighting are represented speci(cid:2)cally for the geometry of the
captured object and are generally unsuitable for mapping onto ar-
bitrary shapes. Our work addresses ef(cid:2)cient rendering of complex
materials on arbitrary meshes under dynamic lighting and viewing
conditions, which requires texture functions with more modeling
(cid:3)exibility and generality than that practically provided by image-
based structures.

Objects with intricate surface geometry can be rendered by vol-
ume texturing techniques [Neyret 1998; Lengyel et al. 2001], which
map a replicated volumetric pattern onto a surface. Volume texture
variations can also be formed by procedural modeling [Ebert et al.
1994], which is effective for certain classes of materials (wood,
marble, etc.). These methods concentrate on ef(cid:2)cient handling of
(cid:2)ne geometric or material detail and do not address the complicated
re(cid:3)ectance that results. In [Dorsey et al. 1999], a method for mod-
eling the detailed appearance of weathered stone is presented, using
an inhomogeneous volume layer around an opaque core. This work
presents a technique speci(cid:2)c to comprehensive modeling of stone
weathering, for which rendering is done with an expensive full par-
ticipating media simulation. Our work develops a general-purpose
texture function for complex materials, and addresses ef(cid:2)cient ren-
dering that accounts for detailed light interactions on and within
such materials.

3 Overview

Our proposed method models objects as two components: a hetero-
geneous shell layer with mesostructures and a homogeneous inner
core. The basic idea behind the inner core is that light from deep
within a volume undergoes signi(cid:2)cant scattering such that its ra-
diance exhibits an averaging effect of its material properties. To
take advantage of this characteristic, the inner core is modelled as
a homogeneous material, for which radiance can be rapidly com-
puted [Jensen and Buhler 2002]. In contrast, shell voxels lie near
the object surface, so their variations in material properties have a
relatively large effect on appearance.

Since the combination of volume non-homogeneities with surface
mesostructures results in complicated scattering of light within the
shell, it is desirable to precompute this scattering as much as pos-
sible to facilitate run-time rendering. The quantities we precom-
pute are the STF voxel irradiances in the volumetric material sam-
ple with respect to illumination direction, as described in Section 4.
The STF allows rapid determination of radiance for each voxel in
the sample volume by simple calculations. Since the shell is synthe-
sized from the volumetric material sample onto a closed mesh, the
radiance of the shell voxels and at the shell surface can be quickly
computed from the STF as well.

Based on the STF, our modeling and rendering technique performs
the following steps:

(cid:15) Acquisition of material parameters for voxels in the volumet-

ric material sample, described in Section 5.1.

(cid:15) STF construction by photon mapping in the material sample,

presented in Section 5.2.

(cid:15) Object shell formation by texture synthesis of the material
sample onto a given mesh, outlined in Section 6. With shell

344

synthesis, STF values are effectively assigned to each shell
voxel.

(cid:15) Rendering with the STF and the dipole approximation of the

inner core, explained in Section 7.

Some results of our algorithm and a discussion of our method are
presented in Section 8, followed by conclusions and future work in
Section 9.

4 The STF Representation

The STF represents irradiance distributions of points in a material
sample for all incident illumination directions. The material sam-
ple is modelled as a volume Vb called the STF base volume. Vb
contains an nx (cid:2) ny (cid:2) nz array of voxels on a regular 3D grid, where
nx (cid:2)ny determines the size of the texture parameter space and nz de-
(cid:2)nes the thickness of the STF. Since mesostructure is represented
in the base volume, the voxels of Vb may lie in either the subsur-
face layer or the surrounding free space, as illustrated in Fig. 2(b).
For each subsurface voxel x, we store the following material prop-
erties: extinction coef(cid:2)cient k(x), albedo a(x), and phase function
f (x;w0;w), where w and w0 are the incoming and outgoing light
directions, respectively. The scattering coef(cid:2)cient ss of a material
is related to extinction and albedo as ss = ak, and the absorption
coef(cid:2)cient is de(cid:2)ned as sa = k (cid:0) ss. The extinction coef(cid:2)cient
k(x) and albedo a(x) describe the radiative transfer properties of a
participating medium [Siegel and Howell 1992], which determine
the translucency and chromatic properties of a voxel. A (cid:3)ag for
indicating surface voxels is also included, and when it is on, the
surface normal and relative index of refraction are stored as well.

Now we de(cid:2)ne the 5D STF by specifying its single- and multiple-
scattering components Is(x;wl) and Im(x;wl), where x is the posi-
tion in Vb and wl is the light direction. We also describe how these
STF values allow rapid computation of the radiance L(x;w) at any
point x of Vb and in any direction w. According to the light trans-
port equation in a participating medium [Siegel and Howell 1992],
the radiance L(x;w) is expressed as

(w (cid:1) (cid:209))L(x;w) = sa(x)Le(x;w) +ss(x)Li(x;w) (cid:0)k(x)L(x;w):

(1)
Le(x;w) is the emitted radiance, and Li(x;w) is the in-scattered ra-
diance. An ef(cid:2)cient way to evaluate the radiance L(x;w) is using
the ray marching algorithm [Ebert et al. 1994]. By far, the most
computationally expensive part of the ray march is the calculation
of in-scattered radiance, which can be computed using volume pho-
ton mapping [Jensen and Christensen 1998] as

Li(x;w) =

f (x;wp;w)

1

ss(x)

n
(cid:229)
p=1

DFp(x;wp)

;

DV

where the radiance is summed over the n photons inside a differ-
ential volume DV , and DFp(x;wp) is the (cid:3)ux carried by a photon
from incoming direction wp.

The (cid:3)ux is divided into single-scattering and multiple-scattering
terms. This classi(cid:2)cation was used in [Jensen and Buhler 2002]
because single scattering can be ef(cid:2)ciently rendered by ray tracing,
while multiple scattering through a homogeneous medium can be
rapidly simulated using a dipole diffusion approximation. In our
scenario, the dipole approximation cannot be employed since the
material sample is non-homogeneous, but we take advantage of the
property that multiple scattering can be considered approximately
isotropic [Stam 1995]. For isotropic multiple scattering, we can

re-write the expression of Li(x;w) as

f (x;wl;w)

(cid:229)s DFp(x;wl)

(cid:229)m DFp(x;wp)

+

1
4p

ss(x)DV

;

ss(x)DV

where (cid:229)s and (cid:229)m are sums over single- and multiple-scattering pho-
tons respectively (we include a photon in (cid:229)m only if it is actually
scattered). For single-scattering photons, their incoming directions
must be the light direction wl. Although multiple scattering is as-
sumed to be isotropic, it is still a function of light direction wl
because of surface mesostructures, which affect the direct illumi-
nation arriving at each surface point. The in-scattered radiance is
(cid:2)nally formulated as

Li(x;w) = f (x;wl;w)Is(x;wl) +

Im(x;wl)

1
4p

where

Is(x;wl) =

(cid:229)s DFp(x;wl)

ss(x)DV

; Im(x;wl) =

(cid:229)m DFp(x;wp)

ss(x)DV

(2)

The quantities Is(x;wl) and Im(x;wl) represent the voxel irradi-
ance at x when the incident lighting comes from direction wl.
These single- and multiple-scattering irradiances are precomputed
as the STF, a 5D function that can be easily stored. With the STF,
Li(x;w) can be quickly calculated and Eq. (1) can be easily inte-
grated through the material sample to compute radiance L(x;w).

In theory, one could precompute or capture the re(cid:3)ectance (cid:2)eld
[Debevec et al. 2000] of a material sample to minimize run-time
computation. The re(cid:3)ectance (cid:2)eld, however, is an 8D function of a
4D (cid:2)eld of incident illumination and a 4D (cid:2)eld of radiance, hence
too large to store. By considering only directional lighting, illu-
mination becomes 2D and the re(cid:3)ectance (cid:2)eld reduces to 6D, but
mesostructure geometry still needs to be known to accurately ren-
der silhouettes. For practical reasons, we instead precompute and
store the STF, an expensive 5D sub-function in the radiance calcu-
lation, and then perform the remaining relatively inexpensive com-
putation at run time. Although precomputing a re(cid:3)ectance (cid:2)eld
for use with recorded mesostructure geometry can reduce run-time
computation, the amount of additional data for the extra viewing
dimensions, which should be sampled densely, can be quite sub-
stantial1. Furthermore, the STF combines naturally with volumetric
mesostructures, while it is not clear how to combine a re(cid:3)ectance
(cid:2)eld with such (non-height-(cid:2)eld) mesostructures. Because of these
practical bene(cid:2)ts of having a lower-dimensional texture function
and since radiance from surface voxels can be calculated rather sim-
ply from irradiance data, we use precomputed voxel irradiances in
our STF representation.

5 Construction of the STF Sample

To precompute the irradiance functions that compose the 5D STF,
the surface mesostructures and scattering characteristics within the
volumetric material sample Vb must (cid:2)rst be determined. Although
this could be done procedurally [Ebert et al. 1994], greater realism
could be obtained by scanning material properties from real vol-
umes [Hanrahan and Krueger 1993] and measuring mesostructures
from real-world surfaces [Dana et al. 1999; Tong et al. 2002]. From
the base volume, the STF is constructed by calculating and stor-
ing the single-scattering and multiple-scattering irradiance of each
voxel under sampled light directions.

1For the strawberry example exhibited in Fig. 16, which has a non height
(cid:2)eld mesostructure, its re(cid:3)ectance (cid:2)eld data would require 1.3 GB of mem-
ory, while the STF occupies a more manageable 159 MB of space, which is
also more feasible for future hardware implementation.

345

5.1 Acquisition of the Base Volume

We generate the base volume Vb using volume modeling and pro-
cessing techniques that are well-studied for volume visualization
[Kaufman 1991]. There are two ways to obtain Vb. One is to mea-
sure real materials using volume imaging technologies such as com-
puted tomography (CT), and the other is to scan convert existing 3D
geometry models [Kaufman 1991].

For measured volume data, we create Vb using voxel classi(cid:2)cation
followed by table lookups. Voxel classi(cid:2)cation is a standard pro-
cess for determining material(s) contained in each voxel of mea-
sured volume data [Kaufman 1991]. The classi(cid:2)cation technique
proposed in [Levoy 1988] can be used to determine voxel materials
in certain classes of volumes, and for each material its extinction co-
ef(cid:2)cient k and albedo a can be obtained in published measurement
tables such as the one in [Jensen et al. 2001]. Extinction coef(cid:2)cients
and albedos of multiple materials in the same voxel are averaged
according to their relative composition in the voxel. Voxels that lie
on the mesostructure surface are identi(cid:2)ed as those that lie along
the outermost isosurface [Kaufman 1991]. In the STF base volume,
a binary function is used to indicate voxels on the mesostructure
surface.

In scan conversion, 3D geometry models are converted into volume
data [Kaufman 1991]. A 3D geometry model usually consists of
several components, each associated with a given material. When
a geometric model is scan converted, the conversion algorithm de-
termines the material(s) in each voxel, and as in the case of mea-
sured volume data, the voxel extinction coef(cid:2)cient and albedo can
be determined from tables. As in previous work [Jensen et al. 2001;
Jensen and Buhler 2002] we use the Henyey-Greenstein phase func-
tion [Henyey and Greenstein 1941] for both measured and scan con-
verted volume data.

For some materials such as veined marble, a spatially-varying
albedo map a(x) is needed, but published measurement tables gen-
erally provide only a single albedo value [Jensen et al. 2001]. To
obtain an albedo map we (cid:2)rst generate voxel colors for the object
interior using solid texture synthesis, which can be either procedu-
ral [Ebert et al. 1994], sample-based [Wei 2001], or sample-view-
based [Dischler et al. 1998; Wei 2001]. The procedural approach
works for limited types of textures. The sample-based approach
works for any solid texture in principle, but it requires as input a
solid texture sample, which may not be easy to obtain. The sample-
view-based approach requires only a few (typically 2 (cid:24) 3) 2D im-
ages of the target solid texture and is thus easier to use. The voxel
colors can then be converted to albedos a(x) using Jensen’s tech-
nique [Jensen and Buhler 2002] by treating voxel colors as diffuse
re(cid:3)ectance coef(cid:2)cients.

The scattering properties of the homogeneous inner core are deter-
mined from properties of the core surface, according to the dipole
diffusion approximation (with surface texture extension) [Jensen
et al. 2001]. In our shell-core model, the core surface properties
are those of the bottom layer of voxels in the shell.

5.2 STF Irradiance Sampling

Using the material properties of Vb, the STF irradiance values for
each voxel x of Vb are computed for sampled illumination direc-
tions, as illustrated in Fig. 3(a). For a given light direction wl, we
compute Is(x;wl) and Im(x;wl) using a variant of the algorithm pro-
posed in [Jensen and Christensen 1998] for photon tracing in a par-
ticipating medium. We emit photons along a light direction wl and
evaluate their contributions to the STF as photons re(cid:3)ect off of the

(cid:1)(cid:19)(cid:15)(cid:4)(cid:15)(cid:8)(cid:14)(cid:10)(cid:18)(cid:3)(cid:15)(cid:20)(cid:10)
(cid:21)(cid:5)(cid:9)(cid:19)(cid:4)(cid:10)(cid:14)(cid:15)(cid:16)(cid:3)(cid:6)(cid:12)

(cid:17)(cid:5)(cid:8)(cid:9)(cid:21)(cid:12)(cid:10)(cid:17)(cid:6)(cid:2)(cid:4)(cid:4)(cid:12)(cid:3)(cid:5)(cid:8)(cid:9)(cid:10)(cid:1)(cid:19)(cid:15)(cid:4)(cid:15)(cid:8)(cid:14)

(cid:11)(cid:16)(cid:21)(cid:4)(cid:5)(cid:7)(cid:21)(cid:12)(cid:10)(cid:17)(cid:6)(cid:2)(cid:4)(cid:4)(cid:12)(cid:3)(cid:5)(cid:8)(cid:9)(cid:10)(cid:1)(cid:19)(cid:15)(cid:4)(cid:15)(cid:8)(cid:14)

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:4)(cid:3)

(cid:11)(cid:12)(cid:14)(cid:15)(cid:14)(cid:4)(cid:3)(cid:16)(cid:6)(cid:4)(cid:16)(cid:3)(cid:12)(cid:10)

(cid:17)(cid:16)(cid:3)(cid:18)(cid:2)(cid:6)(cid:12)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:5)(cid:7)(cid:2)(cid:4)(cid:5)(cid:8)(cid:9)(cid:10)(cid:10)

(cid:11)(cid:12)(cid:13)(cid:5)(cid:2)(cid:10)

Figure 3: STF irradiance sampling. (a) To sample irradiance within
an STF base volume, we surround it by eight other STF base vol-
umes and calculate irradiance data for sampled lighting directions
(marked by orange arrows).
(b) Photon tracing in the STF base
volume.

mesostructure surface and scatter within the object interior. From
the mapped photons, we evaluate the STF components of a voxel at
x according to Eq. (2). In our implementation, DV is chosen to be a
sphere with a radius of one voxel.

To avoid boundary effects in STF sampling, we surround the base
volume by eight other identical volumes as shown in Fig. 3(a). Here
we assume that the base volume is tilable and has texture dimen-
sions nx; ny greater than twice the diffuse mean free path of Vb
[Jensen and Buhler 2002]. Since Vb can be non-homogeneous, its
diffuse mean free path is computed as a weighted average among
the materials that compose Vb. This constraint on Vb dimensions
ensures that the eight identical volumes around Vb provide a suf(cid:2)-
ciently large volume neighborhood for computing the STF of each
voxel in Vb. The thickness nz of Vb is set to be greater than the
maximum mesostructure depth plus three times the average mean
free path of Vb. This choice of nz ensures that we can ignore the
single-scattering contribution from the homogeneous inner core. A
non-tilable base volume of insuf(cid:2)cient size can be converted to a
larger tilable volume using constrained solid texture synthesis [Wei
2001].

The photon tracing process is illustrated in Fig. 3(b). A photon
p (cid:2)rst interacts with the mesostructure surface where it is either
re(cid:3)ected at the surface or refracted into the object interior, accord-
ing to Fresnel’s formulae for unpolarized light. Photons that re(cid:3)ect
off a surface point are not recorded, because these interactions are
handled by raytracing during the rendering stage. A photon that
propagates through the object interior can either pass through the
medium unaffected or interact with it. Each time the photon p in-
teracts with the medium at a voxel x, its contribution is added to
Is(x;wl) if it is p’s (cid:2)rst interaction or to Im(x;wl) otherwise, where
surface re(cid:3)ection is considered an interaction. The probability that
the photon p interacts with the medium at position x is determined
by the following cumulative probability density function

p(x) = 1 (cid:0) e(cid:0)

x
x0
R

k(x)dx

where x0 is the mesostructure surface point where p refracted into
the object interior. The integral in the equation is evaluated by the
ray marching method described in [Dorsey et al. 1999]. If a pho-

346

(cid:8)

(cid:8)(cid:9)

(cid:8)(cid:6)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid:7)

(cid:7)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid:7)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid:7)

(cid:7)

(cid:8)(cid:6)

(cid:8)(cid:2)

(cid:6)

(cid:8)(cid:2)

(cid:6)

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid:7)

(cid:1)(cid:4)(cid:3)

(cid:1)(cid:5)(cid:3)

Figure 4: Object shell synthesis. (a) The STF base volume is re-
garded as a 2D texture T (x; y), in which each T (x; y) is a stack of
voxels. (b) For each mesh vertex v, the synthesis algorithm assign
it a texture coordinate (xv; yv). (c) The stack of voxels at (xv; yv) in
the texture domain is placed in the object shell right below vertex v
along the surface normal at v.

ton interacts with the medium, Russian roulette decides whether
the photon is scattered or absorbed according to a scattering prob-
ability based on the albedo a(x). The direction of the scattered
photon is calculated by importance sampling of the phase function
f (x;w0;w).

We perform photon tracing for a set of discretized light directions
which sample the upper and lower hemispheres. For each light di-
rection wl, a large number of photons are traced and their contri-
butions to the STF are added to Is(x;wl) and Im(x;wl). In our im-
plementation, 1000 photons are traced for each RGB channel. The
upper hemisphere is sampled by 72 = 6 (cid:2) 12 light directions. The
lower hemisphere is sampled identically, but this incident light is
considered to be isotropic multiple scattering, because backlight-
ing arrives from the homogeneous inner core. Based on this prop-
erty, the multiple-scattering STF values of all directions in the lower
hemisphere are averaged and recorded as Im(x;wb) where wb rep-
resents all backlight directions.

A moderate amount of storage is needed for the STF. For example,
the material sample for the strawberry shown in Fig. 16, which has a
96 (cid:2) 96 (cid:2) 10 base volume and is sampled under 73 light directions,
occupies 205 MB of storage space before compression. For com-
pression, we employ a scheme similar to [Beers et al. 1996] using
vector quantization (VQ) followed by entropy coding, where each
VQ codeword is a 6D vector of the single- and multiple-scattering
irradiance colors for a given voxel and lighting direction. For STFs,
this scheme can yield a compression ratio of 48:1.

6 Shell Synthesis

To form the shell model, we synthesize the material base volume Vb
onto the target mesh, such that each point in the shell is assigned a
texture coordinate in the base volume Vb. Each shell voxel is then
assigned the STF values of the base volume voxel with which it is
associated.

Object Shell Synthesis: Fig. 4 illustrates the synthesis of the ma-
terial shell from the nx(cid:2) ny (cid:2) nz STF base volume of the material
sample. For this synthesis we regard Vb as a 2D texture T (x; y) of

347

nx (cid:2) ny texels. Each texel T (xi; y j) consists of a stack of nz vox-
els f(xi; y j; z1), ..., (xi; y j; znz )g with their material properties. We
synthesize the texture T (x; y) onto the target surface mesh using the
algorithm proposed by Tong et al. [Tong et al. 2002].

The basic approach of [Tong et al. 2002] is similar to several
techniques for synthesizing color textures on surfaces [Turk 2001;
Wei 2001; Ying et al. 2001] except that it can handle high-
dimensional texture functions, i.e., 2D textures in which texels
are high-dimensional vectors. This method is based on the ob-
servation that at a local scale a given high-dimensional texture
sample contains only a small number of perceptually distinguish-
able mesostructures and re(cid:3)ectance variations, known as textons.
The textons of a high-dimensional texture function are determined
through a texton analysis or a K-means clustering step [Leung and
Malik 2001], and then are encoded in a 2D texton map that captures
the essence of the texture in a compact representation. Synthesis of
this 2D texton map onto the target mesh effectively determines a
mapping of the high-dimensional texture. The computational cost
is similar to that of color texture synthesis (e.g. [Turk 2001; Wei
2001]) and can be accelerated using the k-coherence search tech-
nique [Tong et al. 2002].

For our material sample, synthesis is based on the following voxel
properties: extinction coef(cid:2)cient k, albedo a, and phase function
f (x;w0;w). Phase functions present a technical dif(cid:2)culty for our
synthesis algorithm. Since they are a function of w0 and w, the sim-
ilarity between two phase functions cannot ef(cid:2)ciently be measured.
To reduce this problem, we follow the convention (e.g., [Jensen
et al. 2001]) in which it is assumed that f (x;w0;w) = f (x;w0 (cid:1)w),
i.e., f depends only on x and the phase angle w0 (cid:1) w. Under this
assumption, we can measure the similarity of two phase functions
f (x;w0 (cid:1)w) and f (x0;w0 (cid:1)w) by densely sampling the phase angles
at points x and x0. For further simpli(cid:2)cation we employ the mo-
ments similarity relation [Wyman et al. 1989] which allows us to
alter the scattering properties of the medium without signi(cid:2)cantly
affecting the light distribution. With this, the scattering coef(cid:2)cient
ss(x) is reduced to

s0

s(x) = ss(x)(1 (cid:0)

f (x;w (cid:1)w0)(w (cid:1)w0)dw0):

Z4p

as done in [Jensen and Buhler 2002]. This moments similarity rela-
tion is an effective approximation when light scattering is strongly-
peaked forward scattering [Wyman et al. 1989], which is the case
for most translucent materials of interest in computer graphics
[Jensen and Buhler 2002]. With the above simpli(cid:2)cations, synthe-
sis of the material shell is performed using the reduced extinction
coef(cid:2)cient k0(x) = s0
s(x)=k0(x).
We note that the scattering coef(cid:2)cient is reduced only for texture
synthesis purposes, and the original scattering coef(cid:2)cient is used to
compute the STF.

s(x) +sa(x) and albedo a0(x) = s0

The synthesis process assigns a 2D texture coordinate (xv; yv) to
each vertex v on the target mesh. The material shell is then obtained
as shown in Fig. 4 by placing nz voxels f(xv; yv; z1), ..., (xv; yv; znz )g
along the surface normal at every vertex v. The material shell rep-
resented this way is a dense set of points on an irregular grid. To
facilitate the subsequent rendering operations, these points are re-
sampled onto a regular grid.

Shell Resampling: We generate a distance (cid:2)eld of the target sur-
face mesh on a regular grid, with the grid interval d0 equal to the
voxel size of the base volume [Payne and Toga 1992]. As shown in
Fig. 5(a), for each sampling point x on the regular grid, we know
the nearest point v f on the mesh and the distance d between v f and
x. The texture coordinate of x is then (tu;tv; d=d0), where (tu;tv) is
the texture coordinate of the mesh vertex v nearest to v f . Using the

(cid:3)(cid:4)

(cid:3)

(cid:2)

(cid:1)

(cid:15)(cid:16)(cid:3)(cid:12)(cid:12)(cid:5)(cid:10)(cid:17)(cid:18)(cid:3)(cid:4)

(cid:1)(cid:2)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:4)(cid:3)

(cid:15)(cid:17)(cid:19)(cid:9)(cid:12)(cid:20)(cid:2)(cid:21)(cid:5)(cid:22)(cid:7)(cid:20)(cid:2)(cid:23)

(cid:24)(cid:10)(cid:3)(cid:17)(cid:25)(cid:5)(cid:13)(cid:7)(cid:14)(cid:3)(cid:26)

(cid:8)(cid:7)(cid:9)(cid:5)(cid:10)(cid:3)(cid:11)(cid:3)(cid:12)(cid:5)

(cid:13)(cid:7)(cid:14)(cid:3)

(cid:1)(cid:4)(cid:3)

(cid:1)(cid:2)(cid:3)

Figure 5: Shell resampling (2D case). (a) Computing the texture
coordinates of point x. (b) Two-level storage structure for the shell
voxels.

texture coordinate of the nearest vertex avoids interpolation calcu-
lations and provides a close approximation, because for synthesis
the mesh is densely re-tiled such that each voxel corresponds to a
vertex on the surface.

Since the material shell occupies only the space near the target sur-
face mesh, many sampling points of the regular grid have no mean-
ingful data to store. This allows us to achieve space ef(cid:2)ciency by
using hierarchical spatial data structures such as octrees and k-d
trees. In our implementation, we use a simple two-level data struc-
ture shown in Fig. 5(b). The (bottom-level) leaf nodes correspond
to the sampling points of the regular grid and store data for the sub-
surface layer. A top-level node contains 8 (cid:2) 8 (cid:2) 8 leaf nodes. Space
ef(cid:2)ciency is achieved by setting top-level nodes to null in areas not
occupied by the material shell.

Assigning STF Values: For a sampling point x in the material
shell with texture coordinate (tu;tv; d=d0), its material properties
are those of the corresponding point x0 = (tu;tv; d=d0) in the base
volume. We further use the single- and multiple-scattering STF val-
ues at x0 as those at x. This assignment of STF values is legitimate
because in synthesis of the material shell, each point x has a vol-
ume neighborhood Nx whose material properties are similar to that
of the volume neighborhood Nx0 around point x0 in the base volume
Vb. For an optically thick medium and a given light direction, the
multiple-scattering irradiance contribution to a point is primarily
determined by the material properties of a suf(cid:2)ciently large volume
neighborhood around the point; contributions from areas outside
this neighborhood are negligible by comparison. For single scatter-
ing, photons from outside the neighborhood can bring irradiance to
a voxel, but such photons are so few that their irradiance contribu-
tion can be safely ignored.

The validity of STF values assigned to shell voxels is contingent on
the neighborhoods Nx; Nx0 being large enough to contain the vox-
els that affect the irradiance of x; x0. The range over which voxels
affect each other is dependent on the material properties. As de-
scribed in Section 4.2, we express this range as twice the diffuse
mean free path of the material. This neighborhood size is included
as a parameter in the texture synthesis algorithm to ensure that an
appropriate range of neighborhood similarity is used.

The similarity of neighborhoods Nx; Nx0 can also be affected by cur-
vature in the shell, which warps the con(cid:2)guration of Nx. In this
work, we assume the size of Nx to be relatively small in relation
to variations in mesh shape, such that Nx is approximately (cid:3)at. To
roughly handle instances where this assumption does not hold, the
STF could potentially be extended to include a single curvature pa-
rameter without requiring an impractical amount of storage.

(cid:1)(cid:2)(cid:3)(cid:4)(cid:3)(cid:5)(cid:6)(cid:7)(cid:8)(cid:5)(cid:7)(cid:6)(cid:2)(cid:9)

(cid:10)(cid:7)(cid:6)(cid:11)(cid:12)(cid:8)(cid:2)(cid:9)

lx¢

(cid:10)(cid:13)(cid:2)(cid:14)(cid:14)(cid:9)(cid:10)(cid:7)(cid:6)(cid:11)(cid:12)(cid:8)(cid:2)

lw

 

rw

w

(cid:1)

tw

dx¢

x¢

0x

(cid:10)(cid:7)(cid:18)(cid:3)(cid:7)(cid:6)(cid:11)(cid:12)(cid:8)(cid:2)(cid:9)(cid:19)(cid:12)(cid:20)(cid:2)(cid:6)

(cid:15)(cid:16)(cid:16)(cid:2)(cid:6)(cid:9)(cid:17)(cid:4)(cid:6)(cid:2)

Figure 6: Ray tracing geometry.

7 STF Rendering

Represented by a STF-based shell and a homogeneous inner core,
an object can be rendered ef(cid:2)ciently by ray tracing. The radiance
calculation involves three steps. First, the illumination that enters
the homogeneous core is obtained as the irradiances at the bottom
layer of shell voxels, calculated by multiplying the light intensity
with the bottom layer STF values. Second, from the light enter-
ing the core, the dipole approximation is employed to compute the
light exiting the homogeneous core. Third, the light incident upon
the object and the light exiting the inner core are used to determine
the irradiances of the shell voxels using the STF. From these irra-
diance values, the exiting radiance at the mesostructure surface is
calculated by ray marching [Ebert et al. 1994] into the object inte-
rior.

Fig. 6 illustrates the geometry of radiance evaluation for a point or
directional light source with local light direction wl. The radiance
L(x;w) of a surface voxel x towards viewing direction w is com-
posed of radiance re(cid:3)ected off the object surface, LR, and radiance
exiting the object volume, LT :

L(x;w) = (1 (cid:0) Ft )LR(x;wr) + Ft LT (x;wt )

(3)

where Ft is the Fresnel transmittance, wr is the mirror direction of w
across the mesostructure surface normal at x, and wt is the refracted
ray direction with respect to w. The value of LR(x;wr) is evaluated
by conventional ray tracing, recursively spawning rays. Because
of the recursive spawning, interre(cid:3)ections over the mesostructure
surface are included in LR(x;wr).

To evaluate the refracted ray radiance LT (x;wt ), we integrate along
the refraction ray into the object interior according to the equation:

x

Z

x0

ss(x0)e(cid:0)

x0 k(x)dxIb(x0;wt )dx0;
R

x

where Ib(x0;wt ) is the irradiance of voxel x0 that contributes to radi-
ance in direction wt . The irradiance distribution Ib(x0;wt ) is com-
puted from the local light source intensity I0(x0
l;wl) on the shell
surface, the homogeneous core radiance Ld(x;wl), and the single-
and multiple-scattering STF values as follows:

1
4p

I0(x0

l;wl)Im(x0;wl) +

1
4p
f (x0;wl;wt )I0(x0
l;wl)Is(x0;wl):

Ld(x0

d;wl)Im(x0;wb)+

(4)

The (cid:2)rst term of this expression is the multiple-scattering STF value
scaled by the illumination I0 arriving at the top of the object shell.
The second term accounts for the contribution of inner core radi-
ance Ld(x0
d, the projection of x0 in the shell nor-
mal direction onto the inner core. The value of Ld(x0
d;wl) is ob-
tained from the dipole calculation, and its contributions to shell

d;wl) from point x0

348

(cid:8)(cid:6)(cid:9)(cid:3)(cid:9)(cid:10)(cid:7)(cid:11)(cid:4)(cid:10)(cid:11)(cid:7)(cid:6)(cid:12)

(cid:13)(cid:11)(cid:7)(cid:14)(cid:15)(cid:4)(cid:6)(cid:12)

lx

lx¢

(cid:13)(cid:16)(cid:6)(cid:2)(cid:2)(cid:12)(cid:13)(cid:11)(cid:7)(cid:14)(cid:15)(cid:4)(cid:6)

lw

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)

x¢

(cid:13)(cid:11)(cid:20)(cid:9)(cid:11)(cid:7)(cid:14)(cid:15)(cid:4)(cid:6)(cid:12)(cid:21)(cid:15)(cid:22)(cid:6)(cid:7)

(cid:17)(cid:18)(cid:18)(cid:6)(cid:7)(cid:12)(cid:19)(cid:3)(cid:7)(cid:6)

Figure 7: To handle instances where illumination onto the shell
is not locally uniform, the irradiance correction kernel propagates
shadow/light into the subsurface layer to account for the lighting
differences.

voxel irradiances are scaled by the multiple-scattering STF val-
ues Im(x0;wb) for backlight direction wb. The (cid:2)rst two terms of
Ib(x0;wt ) together account for the isotropic multiple scattering con-
tribution from voxels within the object shell. Finally, the third term
of Ib(x0;wt ) is the single scattering contribution from within the
shell that is re(cid:3)ected in direction wt . We do not include the single
scattering contribution of the homogeneous inner core because of
the negligible likelihood of a photon traversing the subsurface layer
without being scattered or absorbed.

For each sample point x, we obtain Is(x;wl) and Im(x;wl) by tri-
linearly interpolating the corresponding single and multiple STF
values of the eight surrounding voxels. Material properties needed
for evaluating LT (x;wt ) are also obtained by trilinear interpolation.
Irradiance Correction: Since the STF values Im(x0;wl) and
Is(x0;wl) in Eq. (4) are precomputed with uniform directional illu-
mination over the material sample, the calculation of Ib(x0;wt ) for
a shell voxel is valid only when the illumination is uniform over the
surface neighborhood around x0
l, the projection of x0 onto the shell
surface along the shell normal direction. While this lighting uni-
formity approximately holds for most points on the shell surface,
abrupt illumination changes occur near boundaries of shadows cast
by external geometry, as illustrated in Fig. 7. Unlike mesostructure
shadows, these external geometry shadows are not modelled in the
STF. For shell voxels near the shadow boundaries cast by external
geometry, we employ an irradiance correction technique to improve
the accuracy of irradiance calculation.
Let us (cid:2)rst consider instances where x0 is in shadow near a shadow
boundary. In this case, Ib(x0;wt ) is calculated based on the assump-
tion that all shell surface voxels near x0
l have the same illumination
I0(x0
l but not in
shadow, the difference between assumed and actual illumination at
xl, DI0(xl;wl) = I0(xl;wl) (cid:0) I0(x0
l;wl), will be signi(cid:2)cant because
of the abrupt change of illumination across a shadow boundary,
and the calculation of irradiance Ib(x0;wt ) must be corrected ac-
cordingly. This extra illumination DI0(xl;wl) should diffuse across
shadow boundaries as observed in previous work [Pharr and Han-
rahan 2000; Jensen et al. 2001].
To compute the correction term of Ib(x0;wt ), we emit a large num-
ber of photons into the object shell from xl in all directions, and then
calculate the multiple-scattering irradiance contribution of these
photons to the voxel at x0 as

l;wl). For a shell surface voxel xl that is near x0

(cid:136)Im(x0; xl) =

1
4p

(cid:229)m DFp(x0;wp)

;

ss(x0)DV

which is evaluated the same way as the multiple-scattering STF
value Im(x0;wl). The correction to Ib(x0;wt ) due to xl
is thus

(cid:136)Im(x0; xl)DI0(xl;wl). The total correction to Ib(x0;wt ) includes the
individual correction term of each xl that is in the neighborhood of
x0
l but not in shadow. The neighborhood dimension is set to twice
the diffuse mean free path [Jensen et al. 2001]. For the case where
x0 is near a shadow boundary but not in shadow, the correction term
is computed identically, because the correction is negative when
DI0(xl;wl) is negative.
For a given shell surface voxel xl, we call (cid:136)Im(x; xl) the irradiance
correction kernel (ICK) and represent it as a function de(cid:2)ned on a
3D array of voxels, called the domain of the ICK. Because the ob-
ject shell is synthesized from the STF base volume Vb, the ICK can
be precomputed with Vb and then applied to the object shell during
rendering. Since Vb is non-homogeneous, we should in principle
precompute an ICK for each shell surface voxel of Vb. To reduce
the number of different ICKs, we cluster the shell surface voxels us-
ing the K-means algorithm according to material properties in their
ICK domains. A single ICK is then computed and stored for each
cluster. The similarity measure for ICK domains is the same as the
neighborhood similarity used in shell synthesis.

While higher precision in irradiance correction could be obtained
with a larger number of ICKs, for the examples in this paper we
simply used one ICK computed by tracing 1000 photons in a ho-
mogeneous array. This simpli(cid:2)ed model typically gives a reason-
able irradiance correction, as shown in Fig. 12. The left image is
rendered without irradiance correction along the shadow boundary,
while the right one is rendered with irradiance correction.

8 Results and Discussion

Our implemented STF modeling and rendering system consists of
four components: one for modelling the STF base volume Vb, one
for generating a STF sample from Vb using photon tracing, one for
synthesizing the STF sample onto a surface, and one for rendering
the (cid:2)nal STF-based model. The system is fairly easy to use. The
main user intervention required is for modelling a small piece of
the material sample. Once the STF sample is obtained, the syn-
thesis and rendering steps follow the conventional surface textur-
ing pipeline. In the following we report results for STFs generated
from both scan-converted geometry models and CT-scan data and
demonstrate various visual effects of non-homogeneous materials
with surface mesostructures and volumetric texture variations.

In Fig. 14, we display STF modeling and rendering results for the
Stanford bunny under different viewing and lighting conditions.
When the light source is behind the bunny, backlighting caused by
multiple scattering can be observed. The extinction coef(cid:2)cient k
of the marble is a constant taken from published measurement data
[Jensen et al. 2001]. For the albedo map a(x), we generated voxel
colors with the sample-view-based synthesis approach [Wei 2001]
and converted the color map to the albedo map using the technique
proposed in [Jensen and Buhler 2002]. The two input views of the
marble sample used for solid texture synthesis are included on the
right side of Fig. 14. One view is a texture image of real marble,
while the other view is synthesized from the (cid:2)rst view using 2D
texture synthesis [Wei 2001].

Fig. 15 exhibits a wax torus rendered under different viewing and
lighting conditions with an STF obtained from a CT scan of a real
volume. Both the mesostructure on the wax surface and the volu-
metric texture variations within the wax are well captured and ren-
dered. Fig. 10 (a) illustrates a volume rendering result of the origi-
nal CT data, which is classi(cid:2)ed into three materials (wax, ball and
air). For STF construction, we assign constant extinction coef(cid:2)-
cients to each material and manually determine the albedo for each

349

Figure 8: Radiance contributions from different STF components
for a bumpy bunny: object shell irradiated by only the inner core
contribution (left), the object shell irradiated by only external light-
ing without the inner core (middle), and the (cid:2)nal result (right).

object

jade torus

bunny

strawberry

object size

304 (cid:2) 304 (cid:2) 112
336 (cid:2) 336 (cid:2) 272
240 (cid:2) 240 (cid:2) 272

Vb size

96 (cid:2) 96 (cid:2) 10
96 (cid:2) 96 (cid:2) 6
96 (cid:2) 96 (cid:2) 10

rendering
84 (38)
102 (52)
94 (54)

Table 1: Rendering timings based on our unoptimized implementa-
tion. The (cid:147)rendering(cid:148) column gives the timings for 720 (cid:2) 486 im-
ages in seconds. The numbers in parentheses are timings for com-
puting irradiance distributions, including the dipole approximation.

ball. The mesostructure surface is extracted from the CT data as an
isosurface [Kaufman 1991]. Finally, we simply mirrored the origi-
nal sample to form a 2 (cid:2) 2 pattern which is used as the STF sample.
Note that the balls are completely immersed in the wax and the
light we see from the color balls in Fig. 15 completely comes from
within the object interior. This is an effect that cannot be generated
by a dipole diffusion approximation with surface texture extension
[Jensen et al. 2001].

Another set of results is given in Fig. 16, which shows a straw-
berry rendered under different viewing and lighting conditions. In
this example, surface mesostructures include the small dents on the
strawberry and the seeds in the dents. Both subsurface scattering
and mesostructures are important for the appearance of the straw-
berry. Subsurface scattering gives the strawberry its distinctive or-
ganic look, whereas mesostructures provide the realistic surface de-
tails. Its surface mesh shown in Fig. 10 (c) was modeled by an artist.
Voxel densities of the STF base volume were scan converted from
the meso-geometry model shown in Fig. 10 (d). We hand-tuned
a constant k separately for strawberry seeds and body because we
did not (cid:2)nd published measurement data for strawberries. As for
the albedo map a(x), we generated voxel colors with a procedural
approach [Ebert et al. 1994] and then converted the color map to
an albedo map using the technique proposed in [Jensen and Buhler
2002].

Fig. 8 exhibits the radiance contributions from the inner core
through the object shell, from the object shell as illuminated by
only external lighting, and the (cid:2)nal rendering result as the sum of
the two components.

Two additional STFs are rendered in Fig. 9. Our technique cap-
tures both mesostructures and subsurface scattering within non-
homogeneous materials of the two samples modelled by an artist.
In particular, the mesostructure silhouettes are rendered properly,
even for the non height (cid:2)eld mesostructure of the bunny.

These examples demonstrate that the STF is an effective technique
for modelling a broad range of non-homogeneous materials that
have both surface mesostructures and volumetric texture variations.
With the STF-based approach, the visual effects that arise from
these material and object properties are automatically generated for

Figure 9: Models rendered with different STFs. Top row:
torus. Bottom row: bunny with non-height-(cid:2)eld bumps.

jade

(cid:1)(cid:6)(cid:3)

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:5)(cid:3)

(cid:1)(cid:4)(cid:3)

Figure 10: STF modeling. Wax torus of Fig. 15: (a) Direct volume
rendering of the original CT data; (b) The outermost isosurface of
the wax extracted from the CT data. Strawberry of Fig. 16: (c)
Stawberry surface mesh; (d) Meso-geometry model for the base
volume of the material sample. The dents are generated as a dis-
placement map, and the seeds (shown in yellow) are manually
placed into the dents. The modeling is done using 3D Studio Max.

an object from only a material sample and a given mesh.

Rendering times on a 2.4 GHZ Xeon workstation are listed in Ta-
ble 1 for the bunny, torus and strawberry. The timings indicate that
the STF provides an ef(cid:2)cient way to capture the visual effects of
non-homogeneous materials under dynamic lighting and viewing
conditions. Currently, achieving these visual effects would require
a full participating media simulation, which is about two orders of
magnitude more expensive than the run-time costs of STF rendering
(see Fig. 11).

These timings are only preliminary and could be improved signif-
icantly. For example, the long irradiance calculation time is due
to the very high resolution dipole model we employ, and our dif-
fuse dipole approximation is not accelerated as in [Jensen and Buh-
ler 2002]. The ef(cid:2)ciency of STF rendering can be attributed to
simple calculations of surface radiance from the precomputed STF
data and the fast dipole approximation. The only object areas that
require additional computation are those near shadow boundaries,
which generally constitute just a small portion of the object. To pre-
compute the STF values by photon mapping, it takes about 30 (cid:24) 50

350

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:4)(cid:3)

Figure 11: Side-by-side comparison of bunny rendered (a) with
photon mapping in 3190 seconds and (b) with the STF in 77 sec-
onds. The results appear similar.

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:4)(cid:3)

Figure 12: Comparison of the bunny rendered (a) without irradiance
correction. (b) with irradiance correction.

minutes for each light direction, which corresponds to 10-20 hours
for the examples used in this paper. This procedure, however, can
be easily parallelized. On the above-mentioned CPU, synthesis of
an STF onto a mesh model takes about half an hour.

Discussion: For an STF-based model, STF rendering generates
similar results as photon mapping [Jensen and Christensen 1998]
but at much lower costs. For the example presented in Fig. 11,
photon mapping requires 3190 seconds and STF rendering takes 77
seconds on a 2.4 GHZ Xeon workstation. The speed increase of
STF rendering can be attributed to the fast irradiance computation
of STF rendering, which consists of the dipole computation for the
inner core and a simple look-up procedure for the material shell.

The homogeneous core approximation is an effective way to han-
dle the inner core of a non-homogeneous object. Fig. 13 exhibits
the comparisons of a full photon tracing simulation, the STF-based
rendering of varying shell thickness, and a diffuse dipole approx-
imation of the same cube which contains volumetric texture vari-
ations. For the dipole approximation shown in (f), material varia-
tions within the volume are not modelled and do not appear in the
rendering. With an increasing shell thickness, the result of STF ren-
dering becomes closer to that of the full photon mapping solution
displayed in (a). A 12-layer STF, shown in (b), well approximates
the full photon tracing result for this volume.

Since our technique is intended for optically thick materials in
which multiple scattering is predominant, the STF is not suitable
for very thin or very translucent objects where the extinction coef-
(cid:2)cient is small. Also, as described in Section 5.2, the STF should
be suf(cid:2)ciently thick according to the scattering properties so that
subsurface details are adequately conveyed.

It is important to note that the STF approach addresses both model-
ing (i.e., authoring) and rendering of objects of non-homogeneous
materials. The STF rendering ef(cid:2)ciency only applies to STF-based

351

(cid:1)(cid:2)(cid:3)

(cid:1)(cid:4)(cid:3)

(cid:1)(cid:5)(cid:3)

(cid:1)(cid:6)(cid:3)

(cid:1)(cid:7)(cid:3)

(cid:1)(cid:8)(cid:3)

Figure 13: Comparison of different rendering results for a mate-
rial sample with colored blocks at different depths. (a) full photon
mapping, (b) (e) STF with 12, 8, 4, and 2 layers respectively, and
(f) dipole approximation. Note that the dipole approximation can
only model the color blocks touching the object surface, and not the
color blocks that do not touch the top surface. STF rendering ap-
pears more and more similar to full photon mapping for increasing
STF thicknesses.

models; the STF is not intended to be a rendering technique for arbi-
trary existing objects of non-homogeneous materials. For rendering
such objects, a full participating media simulation is still necessary
at present.

9 Conclusion

We have presented a texture function for realistic modeling and ef(cid:2)-
cient rendering of objects of non-homogeneous materials with sur-
face mesostructures and volumetric texture variations. Our results
demonstrate that this texture function provides an effective and ef-
(cid:2)cient way to capture the rich visual effects associated with such
materials under dynamic lighting and viewing conditions. A num-
ber of improvements to our system are possible, such as acceler-
ating the dipole diffusion approximation, more precise processing
of non-uniform local illumination, and hardware accelerated ren-
dering. Some other directions for future work include modeling
surface curvature in the STF, modulating the material and STF over
the mesh to allow for greater modeling (cid:3)exibility, and improving
shadow computation in the spirit of [Dachsbacher and Stamminger
2003].

Acknowledgements

We are grateful to the anonymous SIGGRAPH reviewers, whose
comments were very valuable in re(cid:2)ning our paper. Many thanks
also to the following people for their assistance in this work: Ming-
dong Xie of D5 Studio for creating the strawberry model, Zhunping
Zhang for his help in the early stages of this project and for writ-
ing the photon mapping code for STF sampling, Ying Song for her
help in processing CT-scanned data, and Prof. Julie Dorsey and
Prof. Leonard McMillan for useful discussions.

References

KOENDERINK, J., AND VAN DOORN, A. 2001. Shading in the
case of translucent objects. Proceedings of SPIE 4299, 312(cid:150)320.

BEERS, A. C., AGRAWALA, M., AND CHADDHA, N. 1996. Ren-
dering from compressed textures. In Proceedings of SIGGRAPH
1996, 373(cid:150)378.

LENGYEL, J. E., PRAUN, E., FINKELSTEIN, A., AND HOPPE, H.
2001. Real-time fur over arbitrary surfaces. In Symposium on
Interactive 3D Graphics, 227(cid:150)232.

BLINN, J. F. 1978. Simulation of wrinkled surfaces. Computer

Graphics (SIGGRAPH ’78 Proceedings) 12, 3, 286(cid:150)292.

CHEN, W.-C., BOUGUET,
2002.

J.-Y., CHU, M. H., AND
GRZESZCZUK, R.
Light (cid:2)eld mapping: Ef(cid:2)cient
representation and hardware rendering of surface light (cid:2)elds.
ACM Transactions on Graphics 21, 3 (July), 447(cid:150)456.

COOK, R. L. 1984. Shade trees. Computer Graphics (SIGGRAPH

’84 Proceedings) 18, 3, 223(cid:150)231.

DACHSBACHER, C., AND STAMMINGER, M. 2003. Translucent
shadow maps. In Proceedings of the 14th Eurographics Work-
shop on Rendering, 197(cid:150)201.

DANA, K. J., VAN GINNEKEN, B., NAYAR, S. K., AND KOEN-
DERINK, J. J. 1999. Re(cid:3)ectance and texture of real-world sur-
faces. ACM Transactions on Graphics 18, 1 (January), 1(cid:150)34.

DEBEVEC, P., HAWKINS, T., TCHOU, C., DUIKER, H.-P.,
SAROKIN, W., AND SAGAR, M.
2000. Acquiring the re-
(cid:3)ectance (cid:2)eld of a human face. In Proceedings of SIGGRAPH
2000, 145(cid:150)156.

DISCHLER, J. M., GHAZANFARPOUR, D., AND FREYDIER, R.
1998. Anisotropic solid texture synthesis using orthogonal 2D
views. Computer Graphics Forum 17, 3, 87(cid:150)96.

DORSEY, J., EDELMAN, A., LEGAKIS, J., JENSEN, H. W., AND
PEDERSEN, H. K. 1999. Modeling and rendering of weathered
stone. In Proceedings of SIGGRAPH 1999, 225(cid:150)234.

EBERT, D., MUSGRAVE, K., PEACHEY, D., PERLIN, K., AND
WORLEY, S. 1994. Texturing and Modeling: A Procedural
Approach. AP Professional.

HANRAHAN, P., AND KRUEGER, W. 1993. Re(cid:3)ection from lay-
In Proceedings of

ered surfaces due to subsurface scattering.
SIGGRAPH 1993, 165(cid:150)174.

HAO, X., BABY, T., AND VARSHNEY, A. 2003. Interactive sub-
surface scattering for translucent meshes. In ACM Symposium
on Interactive 3D Graphics, 75(cid:150)82.

JENSEN, H. W., AND BUHLER, J. 2002. A rapid hierarchical
rendering technique for translucent materials. In Proceedings of
SIGGRAPH 2002, 576(cid:150)581.

JENSEN, H. W., AND CHRISTENSEN, P. 1998. Ef(cid:2)cient simulation
of light transport in scenes with participating media using photon
maps. In Proceedings of SIGGRAPH 1998, 311(cid:150)320.

JENSEN, H. W., MARSCHNER, S. R., LEVOY, M., AND HANRA-
HAN, P. 2001. A practical model for subsurface light transport.
In Proceedings of SIGGRAPH 2001, 511(cid:150)518.

KAUFMAN, A. 1991. Volume Visualization. IEEE Computer Soci-

ety Press.

KOENDERINK, J. J., AND DOORN, A. J. V. 1996. Illuminance
texture due to surface mesostructure. Journal of the Optical So-
ciety of America 13, 3, 452(cid:150)463.

352

LEUNG, T., AND MALIK, J. 2001. Representing and recognizing
Interna-

the visual appearance of materials using 3D textons.
tional Journal of Computer Vision 43, 1 (June), 29(cid:150)44.

LEVOY, M. 1988. Display of surfaces from volume data. IEEE

Computer Graphics & Applications 8, 3 (May), 29(cid:150)37.

MALZBENDER, T., GELB, D., AND WOLTERS, H. 2001. Polyno-
mial texture maps. Proceedings of SIGGRAPH 2001, 519(cid:150)528.

MATUSIK, W., PFISTER, H., NGAN, A., BEARDSLEY, P.,
ZIEGLER, R., AND MCMILLAN, L. 2002.
Image-based 3D
photography using opacity hulls. ACM Transactions on Graph-
ics 21, 3 (July), 427(cid:150)437.

MERTENS, T., KAUTZ, J., BEKAERT, P., SEIDEL, H.-P., AND
REETH, F. V. 2003.
Interactive rendering of translucent de-
formable objects. In Proceedings of the 14th Eurographics Work-
shop on Rendering, 130(cid:150)140.

NEYRET, F. 1998. Modeling, animating, and rendering complex
scenes using volumetric textures. IEEE Trans. on Visualization
and Computer Graphics 4, 1, 55(cid:150)70.

PAYNE, B. A., AND TOGA, A. W. 1992. Distance (cid:2)eld manipu-
lation of surface models. IEEE Computer Graphics & Applica-
tions 12, 1, 65(cid:150)71.

PHARR, M., AND HANRAHAN, P. M. 2000. Monte Carlo evalua-
tion of non-linear scattering equations for subsurface re(cid:3)ection.
In Proceedings of SIGGRAPH 2000, 275(cid:150)286.

SIEGEL, R., AND HOWELL, J. 1992. Thermal Radiation Heat

Transfer. Hemisphere Publishing Corp.

STAM, J. 1995. Multiple scattering as a diffusion process.

In

Eurographics Rendering Workshop, 41(cid:150)50.

TONG, X., ZHANG, J., LIU, L., WANG, X., GUO, B., AND
SHUM, H.-Y. 2002. Synthesis of bidirectional texture func-
tions on arbitrary surfaces. ACM Transactions on Graphics 21,
3 (July), 665(cid:150)672.

TURK, G. 2001. Texture synthesis on surfaces. Proceedings of

SIGGRAPH 2001, 347(cid:150)354.

WOOD, D., AZUMA, D., ALDINGER, W., CURLESS, B.,
DUCHAMP, T., SALESIN, D., AND STUETZLE, W. 2000. Sur-
face light (cid:2)elds for 3D photography. Proceedings of SIGGRAPH
2000, 287(cid:150)296.

WYMAN, D. R., PATTERSON, M. S., AND WILSON, B. C. 1989.
Similarity relations for anisotropic scattering in Monte Carlo
simulations of deeply penetrating neutral particles. J. Compu-
tational Physics 81, 137(cid:150)150.

YING, L., HERTZMANN, A., BIERMANN, H., AND ZORIN, D.
2001. Texture and shape synthesis on surfaces. Proceedings of
12th Eurographics Workshop on Rendering (June), 301(cid:150)312.

HENYEY, L., AND GREENSTEIN, J. 1941. Diffuse radiation in the

galaxy. Astrophysics Journal 93, 70(cid:150)83.

WEI, L.-Y.

2001. Texture Synthesis by Fixed Neighborhood

Searching. Ph.D. Dissertation, Stanford University.

Figure 14: Stanford bunny with marble. The STF used in this example is synthesized from two sample images on the right

Figure 15: Torus modelled with a wax STF. The STF is obtained from the CT scan of a real volume.

Figure 16: Strawberry rendered by a STF generated from a scan-converted geometry model. Note that both the dents and seeds are part of
the surface mesostructure.

353

